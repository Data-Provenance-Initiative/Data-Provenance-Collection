{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8095d4af-c903-456e-8780-dc39917c963d",
   "metadata": {},
   "source": [
    "Add this to the preamble to get symbols used in the tables:\n",
    "```\n",
    "\\newcommand{\\emojiblank}{\\phantom{\\emoji{smile}}}\n",
    "\\newcommand{\\NCDataCircle}{\\tikz[baseline=-0.85ex]{\\definecolor{mycolor}{HTML}{e04c71} \\fill[mycolor] (0,0) circle (0.85ex);}}\n",
    "\\newcommand{\\UnspecifiedDataCircle}{\\tikz[baseline=-0.85ex]{\\definecolor{mycolor}{HTML}{e0cd92} \\fill[mycolor] (0,0) circle (0.85ex);}}\n",
    "\\newcommand{\\CommercialDataCircle}{\\tikz[baseline=-0.85ex]{\\definecolor{mycolor}{HTML}{82b5cf} \\fill[mycolor] (0,0) circle (0.85ex);}}\n",
    "\\newcommand{\\TransparentCircle}{\\tikz[baseline=-0.85ex]{\\fill[fill opacity=0] (0,0) circle (0.85ex);}}\n",
    "```\n",
    "\n",
    "Formatting tweaks still needed after pasting these tables into the LaTeX doc:\n",
    "* Move the caption and label down to the bottom. Pandas doesn't have an option to specify caption position.\n",
    "* Put the \"Collection\" column header on the same line as the others.\n",
    "* Put `\\resizebox{\\textwidth}{!}{` and `}` around the tabular environment.\n",
    "\n",
    "If you want [horizontal spacing](https://tex.stackexchange.com/questions/509393/table-cellcolor-any-way-to-paint-only-part-of-cell) between the color blocks, add \\addlinespace[.25em] after every row's `\\\\`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1937b851-b7a2-4b52-adae-a4f32552376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mp\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af21738b-828d-4f9c-94fd-712f092dc766",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser('~/github/Data-Provenance-Collection'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c05ed-0cfd-42d8-82f4-79461080f91c",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad0bd77-6c2a-4d12-9441-a91ad50b8129",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68460a4-c2e1-4b83-b7a6-f6dd423e7f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_with_none(s):\n",
    "    all_vals = []\n",
    "    for lst in s:\n",
    "        if lst is None:\n",
    "            pass\n",
    "        else:\n",
    "            all_vals += lst\n",
    "    \n",
    "    return len(set(all_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0784d801-73b6-4b53-8188-1e9fd496574f",
   "metadata": {},
   "source": [
    "## Datasets and some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0aa587-e76a-4b65-ae75-b1f8bb0196a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame([\n",
    "    ('Anthropic HH', 'Anthropic HH-RLHF', 'bai2022training, gangulired'),\n",
    "    ('Dolly 15k', 'Dolly 15k', 'dolly15k_2023'),\n",
    "    ('OpenAssistant', 'Open Assistant', 'kopf2023openassistant'),\n",
    "    ('Flan Collection', 'Flan Collection (Chain-of-Thought)|Flan Collection (Dialog)|Flan Collection (Flan 2021)|Flan Collection (P3)|Flan Collection (Super-NaturalInstructions)', 'longpre2023flan'),\n",
    "    ('xP3x', 'xP3x', 'muennighoff2022crosslingual'),\n",
    "    ('Tasksource Ins.', 'Tasksource Instruct', 'sileo2023tasksource'),\n",
    "    ('LAION OIG', 'OIG', 'oig2023'),\n",
    "    ('SHP', 'Stanford Human Preferences', 'SHP'),\n",
    "    ('ShareGPT', 'ShareGPT Vicuna', r'sharegpt'),\n",
    "    ('Self-Instruct', 'Self-Instruct', 'selfinstruct2022'),\n",
    "    ('WebGPT', 'OpenAI (WebGPT)', 'nakano2021webgpt'),\n",
    "    ('OpenAI Summ.', 'OpenAI (Summarize from Feedback)', 'stienon2020learning'),\n",
    "    ('Airoboros', 'Airoboros', 'Durbin2023Airoboros'),\n",
    "    ('Alpaca', 'Alpaca', 'alpaca'),\n",
    "    ('BaizeChat', 'Baize Chat Data', 'xu2023baize'),\n",
    "    ('BookSum', 'Book Summaries', 'kryscinski2022booksum'),\n",
    "    ('CamelAI Sci.', 'Camel-AI Science', 'li2023camel'),\n",
    "    ('CoT Coll.', 'CoT Collection', 'kim2023cot'),\n",
    "    ('Code Alpaca', 'Code Alpaca', ''),\n",
    "    ('GPT-4-Alpaca', 'GPT-4-Alpaca', 'peng2023instruction'),\n",
    "    ('GPTeacher', 'GPTeacher', ''),\n",
    "    ('Gorilla', 'Gorilla', 'patil2023gorilla'),\n",
    "    ('HC3', 'HC3 (Chinese)|HC3 (English)', 'guo2023close'),\n",
    "    ('Joke Expl.', 'Joke Explanation',''),\n",
    "    ('LIMA', 'LIMA', 'zhou2023lima'),\n",
    "    ('Longform', 'Longform', 'koksal2023longform'),\n",
    "    ('GPT4AllJ', 'NomicAI GPT4AllJ', 'gpt4all'),\n",
    "    ('OpenOrca', 'Open Orca', 'mukherjee2023orca'),\n",
    "    ('Tool-Llama', 'Tool-Llama', 'qin2023toolllm'),\n",
    "    ('UltraChat', 'UltraChat', 'ding2023enhancing'),\n",
    "    ('Unnatural Instr.', 'Unnatural Instructions', 'honovich2022unnatural'),\n",
    "    ('Evol-Instr.', 'WizardLM Evol-Instruct|WizardLM Evol-Instruct V2', 'xu2023wizardlm'),\n",
    "    ('StarCoder', 'StarCoder Self-Instruct', 'li2023starcoder'),\n",
    "    ('TinyStories', 'Tiny Stories', 'eldan2023tinystories'),\n",
    "    ('StackExchange', 'Stack Exchange Instruction', ''),\n",
    "    ('Tasksource ST', 'Tasksource Symbol-Tuning', 'weston2015aicomplete'),\n",
    "    ('CommitPackFT', 'CommitPackFT', 'muennighoff2023octopack'),\n",
    "    ('OpAsst OctoPack', 'Open Assistant OctoPack', 'muennighoff2023octopack'),\n",
    "], columns=['Collection', 'summary_keys', 'Cite']).set_index('Collection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7508391f-367d-4a26-ae00-fbe06fd5f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = [y for x in dat['summary_keys'].str.split('|').tolist() for y in x]\n",
    "\n",
    "files = [\n",
    "    os.path.splitext(f)[0]\n",
    "    for f in os.listdir('data_summaries')\n",
    "    if not f.startswith('_template')\n",
    "]\n",
    "\n",
    "assert len(set(sk)) == len(sk)\n",
    "assert set(sk) == set(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9f63d4-8588-43c1-90af-dbe5bc65f2e8",
   "metadata": {},
   "source": [
    "## Other supporting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f51bd-d10f-405b-9178-8fc59908d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_downloads_new = pd.read_csv('scripts/hf_downloads.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949fe910-4d04-47ff-b215-a5a7f32d76ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "short_names = pd.DataFrame(dat['summary_keys'].str.split('|')).to_records().tolist()\n",
    "for short, keys in short_names:\n",
    "    for key in keys:\n",
    "        tmp += [(short, key)]\n",
    "short_names = pd.DataFrame(tmp, columns=['short_name', 'summary_key']).set_index('summary_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddabc229-c3cf-4e19-8257-9c7642c6f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = {}\n",
    "for file in os.listdir('data_summaries'):\n",
    "    if file.startswith('_template'):\n",
    "        continue\n",
    "    \n",
    "    with open(os.path.join('data_summaries', file), 'rt') as f:\n",
    "        summaries[file.split('.')[0]] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb01af1d-e511-4056-a451-73b900988468",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('constants/domain_groups.json', 'rt') as f:\n",
    "    domain_groups = json.load(f)\n",
    "    domain_groups = {\n",
    "        v: k\n",
    "        for k, vs in domain_groups.items()\n",
    "        for v in vs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef36a96-8993-4b89-9342-efedc7aaca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('constants/task_groups.json', 'rt') as f:\n",
    "    task_groups = json.load(f)\n",
    "    task_groups = {\n",
    "        v: k\n",
    "        for k, vs in task_groups.items()\n",
    "        for v in vs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87523fb2-3c74-4f78-ab1e-972b0332c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('constants/license_classes.json', 'rt') as f:\n",
    "    license_classes = json.load(f)\n",
    "    license_classes = {k : v[-1] for k, v in license_classes.items()}\n",
    "    license_classes['Custom'] = 'Unspecified'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26662c7-5d8a-450c-81d7-72e1b7b4784e",
   "metadata": {},
   "source": [
    "## Licenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34659407-729b-4c53-87d3-efdce68c6e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "licenses = {}\n",
    "for k in summaries.keys():\n",
    "    for ds in summaries[k].keys():\n",
    "        for lic in summaries[k][ds]['Licenses']:\n",
    "            licenses[k] = licenses.get(k, []) + [lic['License']]\n",
    "licenses = pd.Series({k : list(set(v)) for k, v in licenses.items()})\n",
    "\n",
    "tmp = short_names.copy()\n",
    "tmp['licenses'] = licenses\n",
    "dat['License'] = tmp.groupby('short_name')['licenses'].apply(lambda s: list(set([y for x in s for y in x])))\n",
    "\n",
    "dat['OAI'] = dat['License'].apply(lambda s: 'OpenAI' in s or 'OANC' in s)\n",
    "dat['OAI'] = dat['OAI'].replace({True: r'\\greencheck', False: '\\emojiblank'})\n",
    "dat['License'] = dat['License'].apply(lambda s: [v for v in s if v != 'OpenAI' and v != 'OANC'])\n",
    "\n",
    "license_table = dat[['License', 'Cite']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1141ce-cfc0-4452-8879-8c8833ca54a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['Use'] = dat['License'].apply(lambda s: list(set([license_classes[v] for v in s])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a7601-7b39-4981-a7c5-25ab21d86969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def color_license_classes(s):\n",
    "    ret = []\n",
    "\n",
    "    if 'All' in s:\n",
    "        ret += [r'\\CommercialDataCircle']\n",
    "    else:\n",
    "        ret += [r'\\TransparentCircle']\n",
    "    \n",
    "    if 'Unspecified' in s or len(s) == 0:\n",
    "        ret += [r'\\UnspecifiedDataCircle']\n",
    "    else:\n",
    "        ret += [r'\\TransparentCircle']\n",
    "    \n",
    "    if 'Acad' in s or 'NC' in s:\n",
    "        ret += [r'\\NCDataCircle']\n",
    "    else:\n",
    "        ret += [r'\\TransparentCircle']\n",
    "    \n",
    "    return ' '.join(ret)\n",
    "\n",
    "dat['Use'] = dat['License'].apply(lambda s: list(set([license_classes[v] for v in s])))\n",
    "dat['Use'] = dat['Use'].apply(color_license_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3409805-d5df-4e1a-becd-1d8dc75ee360",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.drop(['License', 'Cite'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc195158-48fe-4775-825b-275a4649f958",
   "metadata": {},
   "source": [
    "## Property counts and text lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0be802-6b39-4368-8ada-dd4aa237c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = []\n",
    "for collection in dat.index:\n",
    "    for file in dat.loc[collection, 'summary_keys'].split('|'):\n",
    "        for k in summaries[file].keys():\n",
    "            if 'Languages' in summaries[file][k].keys():\n",
    "                langs = summaries[file][k]['Languages']\n",
    "            else:\n",
    "                langs = None\n",
    "            \n",
    "            metrics = summaries[file][k].get('Text Metrics', None)\n",
    "            if metrics is None or metrics == '' or metrics == {}:\n",
    "                num_dialogs = np.nan\n",
    "                mean_inputs_length = np.nan\n",
    "                mean_targets_length = np.nan\n",
    "            else:\n",
    "                num_dialogs = metrics['Num Dialogs']\n",
    "                mean_inputs_length = metrics['Mean Inputs Length']\n",
    "                mean_targets_length = metrics['Mean Targets Length']\n",
    "                \n",
    "            if 'Text Sources' not in summaries[file][k].keys():\n",
    "                domains = None\n",
    "            elif not isinstance(summaries[file][k]['Text Sources'], (list, tuple)):\n",
    "                domains = None\n",
    "            else:\n",
    "                domains = summaries[file][k]['Text Sources']\n",
    "                domains = [domain_groups[d] for d in domains]\n",
    "\n",
    "            if 'Task Categories' not in summaries[file][k].keys():\n",
    "                tasks = None\n",
    "            elif not isinstance(summaries[file][k]['Task Categories'], (list, tuple)):\n",
    "                tasks = None\n",
    "            else:\n",
    "                tasks = summaries[file][k]['Task Categories']\n",
    "                tasks = [task_groups[d] for d in tasks]\n",
    "\n",
    "            inf_metadata = summaries[file][k].get('Inferred Metadata', None)\n",
    "            if inf_metadata is None or inf_metadata == '' or inf_metadata == {}:\n",
    "                topics = None\n",
    "            else:\n",
    "                if 'Text Topics' not in inf_metadata.keys():\n",
    "                    topics = None\n",
    "                elif not isinstance(inf_metadata['Text Topics'], (list, tuple)):\n",
    "                    topics = None\n",
    "                else:\n",
    "                    topics = inf_metadata['Text Topics']\n",
    "\n",
    "            raw += [{\n",
    "                'collection': collection,\n",
    "                'summary_key': file,\n",
    "                'sub': k,\n",
    "\n",
    "                'num_dialogs': num_dialogs,\n",
    "                'mean_inputs_length': mean_inputs_length,\n",
    "                'mean_targets_length': mean_targets_length,\n",
    "\n",
    "                'langs': langs,\n",
    "                'topics': topics,\n",
    "                'domains': domains,\n",
    "                'tasks': tasks,\n",
    "                'datasets': 1,\n",
    "            }]\n",
    "raw = pd.DataFrame(raw)\n",
    "\n",
    "total_input_length = raw['num_dialogs'] * raw['mean_inputs_length']\n",
    "total_targets_length = raw['num_dialogs'] * raw['mean_targets_length']\n",
    "\n",
    "num_dialogs = raw.groupby('collection')['num_dialogs'].sum()\n",
    "mean_inputs_length = total_input_length.groupby(raw['collection']).sum() / num_dialogs\n",
    "mean_targets_length = total_targets_length.groupby(raw['collection']).sum() / num_dialogs\n",
    "\n",
    "num_langs = raw.groupby('collection')['langs'].apply(count_unique_with_none)\n",
    "num_topics = raw.groupby('collection')['topics'].apply(count_unique_with_none)\n",
    "num_domains = raw.groupby('collection')['domains'].apply(count_unique_with_none)\n",
    "num_tasks = raw.groupby('collection')['tasks'].apply(count_unique_with_none)\n",
    "num_datasets = raw.groupby('collection')['datasets'].sum()\n",
    "\n",
    "dat['Num Langs'] = num_langs.fillna(0).astype(int)\n",
    "dat['Num Dialogs'] = num_dialogs.fillna(0).astype(int)\n",
    "dat['Mean Inputs Length'] = mean_inputs_length.fillna(0).astype(int)\n",
    "dat['Mean Targets Length'] = mean_targets_length.fillna(0).astype(int)\n",
    "dat['Num Topics'] = num_topics.fillna(0).astype(int)\n",
    "dat['Num Datasets'] = num_datasets.fillna(0).astype(int)\n",
    "dat['Num Tasks'] = num_tasks.fillna(0).astype(int)\n",
    "dat['Num Domains'] = num_domains.fillna(0).astype(int).apply(lambda s: max(s, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7946fe5-01c7-4c84-9cce-5db82cd2ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_downs = []\n",
    "for collection in dat.index:\n",
    "    for file in dat.loc[collection, 'summary_keys'].split('|'):\n",
    "        if file in hf_downloads_new['Collection'].tolist():\n",
    "            downs = hf_downloads_new.loc[hf_downloads_new['Collection'] == file, 'sum HF Downloads (October 2023)'].item()\n",
    "        else:\n",
    "            downs = np.nan\n",
    "\n",
    "        num_downs += [(file, downs)]\n",
    "\n",
    "downs = short_names.copy().rename({'short_name': 'collection'}, axis=1)\n",
    "downs['downs'] = pd.Series(dict(num_downs))\n",
    "num_downs = downs.groupby('collection').sum()\n",
    "dat['Num Downs'] = num_downs.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3735c5f2-c5f7-4837-aedd-ead6cc21453d",
   "metadata": {},
   "source": [
    "## Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb479332-8bd6-412f-b841-87e10c790663",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen = {}\n",
    "for k in summaries.keys():\n",
    "    for ds in summaries[k].keys():\n",
    "        models = summaries[k][ds]['Model Generated']\n",
    "        models = [m for m in models if m != '']\n",
    "        mgen[k] = mgen.get(k, []) + [len(models) > 0]\n",
    "mgen = pd.Series({k : list(set(v)) for k, v in mgen.items()})\n",
    "tmp = short_names.copy()\n",
    "tmp['mgen'] = mgen\n",
    "dat['Source'] = tmp.groupby('short_name')['mgen'] \\\n",
    "    .agg(lambda x: [item for sublist in x for item in sublist]) \\\n",
    "    .apply(lambda s: 1 - sum(s) / len(s))\n",
    "\n",
    "dat.loc[(dat['Source'] > 0) & (dat['Source'] < 1), 'Source'] = r'\\emoji{globe-with-meridians}\\emoji{robot}'\n",
    "dat.loc[dat['Source'] == 1, 'Source'] = r'\\emoji{globe-with-meridians}\\emojiblank'\n",
    "dat.loc[dat['Source'] == 0, 'Source'] = r'\\emojiblank\\emoji{robot}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5838c91-b252-4be9-be85-3db3412cf581",
   "metadata": {},
   "source": [
    "## Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb184790-c5c2-4611-b049-3a67529c346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "formats_map = {\n",
    "    'Chain-of-Thought': 'CT',\n",
    "    'Few-shot': 'FS',\n",
    "    'Multi-turn Dialog': 'MD',\n",
    "    'Response Ranking': 'RR',\n",
    "    'Zero-shot': 'ZS',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6111a88-2c0c-462a-bdcc-21a296c22ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_formats = [\n",
    "    summaries[file][k]['Format']\n",
    "    for file in summaries.keys()\n",
    "    for k in summaries[file].keys()\n",
    "]\n",
    "found_formats = set([y for x in found_formats for y in x])\n",
    "assert found_formats <= set(formats_map.keys())\n",
    "\n",
    "fmts = []\n",
    "for collection in dat.index:\n",
    "    for file in dat.loc[collection, 'summary_keys'].split('|'):\n",
    "        for k in summaries[file].keys():\n",
    "            tmp_fmts = summaries[file][k].get('Format', [])\n",
    "            tmp_fmts = [formats_map[f] for f in tmp_fmts]\n",
    "            \n",
    "            fmts += [{\n",
    "                'collection': collection,\n",
    "                'summary_key': file,\n",
    "                'sub': k,\n",
    "                \n",
    "                'formats': tmp_fmts,\n",
    "            }]\n",
    "fmts = pd.DataFrame(fmts)\n",
    "fmts = fmts.groupby('collection')['formats'] \\\n",
    "           .apply(lambda s: list(set([y for x in s for y in x]))) \\\n",
    "           .rename('formats')\n",
    "\n",
    "for fmt in formats_map.values():\n",
    "    dat[fmt] = fmts.apply(lambda s: fmt in s) \\\n",
    "        .replace(True, r'\\greencheck') \\\n",
    "        .replace(False, r'\\emojiblank')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acde63d-c13f-4346-bd7f-1047182717ff",
   "metadata": {},
   "source": [
    "## Format for LaTeX output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a62b6-ce23-4d37-9598-21f9c3ea1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat[[\n",
    "    'Num Datasets',\n",
    "    'Num Dialogs',\n",
    "    'Num Tasks',\n",
    "    'Num Langs',\n",
    "    'Num Topics',\n",
    "    'Num Domains',\n",
    "    'Num Downs',\n",
    "    \n",
    "    'Mean Inputs Length',\n",
    "    'Mean Targets Length',\n",
    "    \n",
    "    'Source',\n",
    "    \n",
    "    'ZS',\n",
    "    'FS',\n",
    "    'CT',\n",
    "    'RR',\n",
    "    'MD',\n",
    "    \n",
    "    'Use',\n",
    "    'OAI',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e435e1d-0fc5-47b2-b5c9-42d0f7d8784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'Num Datasets': ('Property Counts', 'Datasets'),\n",
    "    'Num Dialogs': ('Property Counts', 'Dialogs'),\n",
    "    'Num Tasks': ('Property Counts', 'Tasks'),\n",
    "    'Num Langs': ('Property Counts', 'Langs'),\n",
    "    'Num Topics': ('Property Counts', 'Topics'),\n",
    "    'Num Cites': ('Property Counts', 'Cites'),\n",
    "    'Num Downs': ('Property Counts', 'Downs'),\n",
    "    'Num Domains': ('Property Counts', 'Domains'),\n",
    "    'Mean Inputs Length': ('Text Lens', 'Inpt'),\n",
    "    'Mean Targets Length': ('Text Lens', 'Tgt'),\n",
    "    'Source': ('Dataset Types', 'Source'),\n",
    "\n",
    "    'CT': ('Dataset Types', 'C'),\n",
    "    'ZS': ('Dataset Types', 'Z'),\n",
    "    'RR': ('Dataset Types', 'R'),\n",
    "    'MD': ('Dataset Types', 'M'),\n",
    "    'FS': ('Dataset Types', 'F'),\n",
    "    \n",
    "    'Use': ('Dataset Types', 'Use'),\n",
    "    'OAI': ('Dataset Types', 'O'),\n",
    "}\n",
    "\n",
    "dat.columns = pd.MultiIndex.from_arrays([\n",
    "    [column_mapping[col][0] for col in dat.columns],\n",
    "    [column_mapping[col][1] for col in dat.columns]\n",
    "])\n",
    "\n",
    "dat.columns = pd.MultiIndex.from_tuples([\n",
    "    (r'\\textsc{' + c[0] + r'}', r'\\textsc{\\thead{' + c[1] + r'}}')\n",
    "    for c in dat.columns\n",
    "])\n",
    "\n",
    "dat.index.name = r'\\textsc{' + dat.index.name + r'}'\n",
    "\n",
    "def color_map(value, cmap='BrBG', vmin=None, vmax=None):\n",
    "    norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    colormap = mp.colormaps[cmap]\n",
    "    color = [int(255*x) for x in colormap(norm(value))[:3]]\n",
    "    return ','.join(map(str, color))  # Convert the color to a CSV string\n",
    "\n",
    "color_def = ''\n",
    "formatters = {}\n",
    "tmp_val_color = {}\n",
    "num_cols = [\n",
    "    c\n",
    "    for c in dat.columns\n",
    "    if (\n",
    "        'Property Counts' in c[0] or\n",
    "        'Text Lens' in c[0]\n",
    "    )\n",
    "]\n",
    "\n",
    "for col in num_cols:\n",
    "    tmp_val_color[col] = {}\n",
    "    \n",
    "    vmin = np.log(dat[col].min() + 1e-6)\n",
    "    vmax = np.log(dat[col].max() + 1e-6)\n",
    "    midpt = (vmax + vmin) / 2\n",
    "    vmin, vmax = vmin - midpt, vmax - midpt\n",
    "    \n",
    "    for row in dat.index:\n",
    "        value = np.log(dat.loc[row, col] + 1e-6)\n",
    "        value -= midpt\n",
    "        \n",
    "        if pd.notnull(value):\n",
    "            row_color_name = row.replace(' ', '') \\\n",
    "                .replace(r'\\textsc{', '').replace('}', '')\n",
    "            col_color_name = '_'.join(col).replace(' ', '') \\\n",
    "                .replace(r'\\textsc{\\thead{', '').replace('}}', '') \\\n",
    "                .replace(r'\\textsc{', '').replace('}', '')\n",
    "            \n",
    "            color_name = f\"color{row_color_name}{col_color_name}\"\n",
    "            \n",
    "            color_def += f\"\\\\definecolor{{{color_name}}}{{RGB}}{{{color_map(value / 4, vmin=vmin, vmax=vmax)}}}\\n\"\n",
    "            \n",
    "            tmp_val_color[col][dat.loc[row, col]] = color_name\n",
    "\n",
    "    if 'Dialogs' in col[1] or 'Downs' in col[1]:\n",
    "        def func(v, col=col):\n",
    "            color_name = tmp_val_color[col][v]\n",
    "    \n",
    "            if col in num_cols and v >= 1000:\n",
    "                v /= 1000\n",
    "                return f'\\\\cellcolor{{{color_name}}}{{{v:,.0f}k}}' if pd.notnull(v) else '-'\n",
    "            elif col in num_cols and v == 0:\n",
    "                return '-'\n",
    "            else:\n",
    "                return f'\\\\cellcolor{{{color_name}}}{{<1k}}' if pd.notnull(v) else '-'\n",
    "    else:\n",
    "        def func(v, col=col):\n",
    "            color_name = tmp_val_color[col][v]\n",
    "    \n",
    "            if col in num_cols and v >= 1000:\n",
    "                v /= 1000\n",
    "                return f'\\\\cellcolor{{{color_name}}}{{{v:,.0f}k}}' if pd.notnull(v) else '-'\n",
    "            elif col in num_cols and v == 0:\n",
    "                return '-'\n",
    "            else:\n",
    "                return f'\\\\cellcolor{{{color_name}}}{{{v:,.0f}}}' if pd.notnull(v) else '-'\n",
    "    \n",
    "    formatters[col] = func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6431fe91-5470-41fb-8207-f8aa2e740160",
   "metadata": {},
   "source": [
    "# Main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526d036-6a7c-482e-97d3-b4dfc5edd48e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'environment': 'table*',\n",
    "    'label': 'tab:collections',\n",
    "    'position_float': 'centering',\n",
    "    'column_format': 'l|ccccccc|rr|cp{0.3cm}p{0.3cm}p{0.3cm}p{0.3cm}p{0.3cm}cp{0.3cm}',\n",
    "    'multicol_align': 'c',\n",
    "    \n",
    "    'caption': r'''\n",
    "    \\textbf{Alignment tuning collections and their characteristics}. Collection properties include numbers of datasets, dialogs, tasks, languages, topics, Huggingface downloads (\"Downs\"), text domains, and average length of input and target text. The \\textsc{Source} column indicates whether a collection contains human-generated web text (\\emoji{globe-with-meridians}), language model outputs (\\emoji{robot}) or both (\\emoji{globe-with-meridians}\\emoji{robot}). Several columns indicate the type of dialogs, with some collections having more than one: zero-shot (Z), few-shot (F), response ranking (R), chain-of-thought (C), and multi-turn dialog (M). Finally, the \\textsc{Use} column indicates whether a collection includes data freely usable even for commercial purposes (\\protect\\CommercialDataCircle), data usable only for noncommercial purposes or academic research (\\protect\\NCDataCircle) and data whose license status is not specified precisely enough to allow us to determine commercial use permissions (\\protect\\UnspecifiedDataCircle). Note that each collection may have different datasets with one, two, or all three of these statuses. The O column indicates collections which include OpenAI model generations.\n",
    "    '''.strip(),\n",
    "    \n",
    "    'hrules': True,\n",
    "    'convert_css': True,\n",
    "}\n",
    "\n",
    "latex = dat \\\n",
    "    .sort_index() \\\n",
    "    .style \\\n",
    "    .format(formatter=formatters) \\\n",
    "    .to_latex(**kwargs)\n",
    "\n",
    "print('\\n'.join([\n",
    "    r'\\setlength{\\tabcolsep}{1.9pt}',\n",
    "    color_def,\n",
    "    latex,\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1335a6b5-9fb1-4c83-9954-80320d9257b7",
   "metadata": {},
   "source": [
    "# Appendix license/cite table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ec891-8345-4649-9d1a-b375c818a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "license_table['OpenAI NC'] = license_table['License'] \\\n",
    "    .apply(lambda s: 'OpenAI' in s) \\\n",
    "    .replace(True, r'\\redcross') \\\n",
    "    .replace(False, r'\\emojiblank')\n",
    "\n",
    "license_table['License'] = license_table['License'].apply(lambda s: [v for v in s if v != 'OpenAI'])\n",
    "license_table['License'] = license_table['License'].apply(lambda s: [v if v != 'Academic Research Purposes Only' else 'Academic Only' for v in s])\n",
    "license_table['License'] = license_table['License'].apply(lambda s: s if 'Various' not in s else ['Various'])\n",
    "license_table['License'] = license_table['License'].apply(lambda s: s if len(s) > 0 else ['Unspecified'])\n",
    "license_table['License'] = license_table['License'].apply(lambda s: s if len(s) <= 3 else ['Various'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd044b-a57c-445d-a3c5-83ca52edb804",
   "metadata": {},
   "outputs": [],
   "source": [
    "license_table = license_table[[\n",
    "#    'OpenAI NC',\n",
    "    'Cite',\n",
    "    'License'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f58c9d-c813-4e2e-a301-57c89a4e0fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "license_table['Cite'] = license_table['Cite'].apply(lambda s: r'\\citet{' + s + '}')\n",
    "license_table.loc[license_table['Cite'] == r'\\citet{}', 'Cite'] = '--'\n",
    "\n",
    "license_table['License'] = license_table['License'].str.join(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a5568e-ffb2-45e3-81a1-55a3680b149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "license_table.rename({'License': 'Licenses'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abd2b9d-b83f-4c68-a24b-3787f13caec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'environment': 'table*',\n",
    "    'label': 'tab:licenses',\n",
    "    'position_float': 'centering',\n",
    "    'column_format': 'l|lp{5.5cm}',\n",
    "    \n",
    "    'caption': r'''\n",
    "    \\textbf{Licenses and citations} for the dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having ''Various`` licenses, and we refer readers to our raw data for the full details.\n",
    "    '''.strip(),\n",
    "    \n",
    "    'hrules': True,\n",
    "    'convert_css': True,\n",
    "}\n",
    "\n",
    "latex = license_table \\\n",
    "    .sort_index() \\\n",
    "    .style \\\n",
    "    .to_latex(**kwargs)\n",
    "\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa945fa4-75d7-4b50-aeb5-52e126e219e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
