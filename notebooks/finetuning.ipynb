{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8095d4af-c903-456e-8780-dc39917c963d",
   "metadata": {},
   "source": [
    "Add this to the preamble to get symbols used in the tables:\n",
    "```\n",
    "\\newcommand{\\emojiblank}{\\phantom{\\emoji{smile}}}\n",
    "\\newcommand{\\NCDataCircle}{\\tikz[baseline=-0.85ex]{\\definecolor{mycolor}{HTML}{e04c71} \\fill[mycolor] (0,0) circle (0.85ex);}}\n",
    "\\newcommand{\\UnspecifiedDataCircle}{\\tikz[baseline=-0.85ex]{\\definecolor{mycolor}{HTML}{e0cd92} \\fill[mycolor] (0,0) circle (0.85ex);}}\n",
    "\\newcommand{\\CommercialDataCircle}{\\tikz[baseline=-0.85ex]{\\definecolor{mycolor}{HTML}{82b5cf} \\fill[mycolor] (0,0) circle (0.85ex);}}\n",
    "\\newcommand{\\TransparentCircle}{\\tikz[baseline=-0.85ex]{\\fill[fill opacity=0] (0,0) circle (0.85ex);}}\n",
    "```\n",
    "\n",
    "Formatting tweaks still needed after pasting these tables into the LaTeX doc:\n",
    "* Move the caption and label down to the bottom. Pandas doesn't have an option to specify caption position.\n",
    "* Put the \"Collection\" column header on the same line as the others.\n",
    "* Put `\\resizebox{\\textwidth}{!}{` and `}` around the tabular environment.\n",
    "\n",
    "If you want [horizontal spacing](https://tex.stackexchange.com/questions/509393/table-cellcolor-any-way-to-paint-only-part-of-cell) between the color blocks, add \\addlinespace[.25em] after every row's `\\\\`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1937b851-b7a2-4b52-adae-a4f32552376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mp\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af21738b-828d-4f9c-94fd-712f092dc766",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser('~/github/Data-Provenance-Collection'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c05ed-0cfd-42d8-82f4-79461080f91c",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0784d801-73b6-4b53-8188-1e9fd496574f",
   "metadata": {},
   "source": [
    "## List of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0aa587-e76a-4b65-ae75-b1f8bb0196a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame([\n",
    "    ('Aya', 'Aya Dataset', 'singhAyaDatasetOpenAccess2024'),\n",
    "    ('ChatbotArena', 'ChatbotArena', 'zhengJudgingLLMasaJudgeMTBench2023'),\n",
    "    ('Open Assistant v2', 'Open Assistant v2', 'kopfOpenAssistantConversationsDemocratizing2023'),\n",
    "    ('UltraChat_200k', 'UltraChat_200k', 'dingEnhancingChatLanguage2023'),\n",
    "    ('AgentInstruct', 'AgentInstruct', 'shridharALFWorldAligningText2021|yaoWebShopScalableRealWorld2023|liuAgentBenchEvaluatingLLMs2023|zengAgentTuningEnablingGeneralized2023|dengMind2WebGeneralistAgent2023'),\n",
    "    ('Bactrian-X', 'Bactrian-X', 'liBactrianXMultilingualReplicable2023'),\n",
    "    ('COIG', 'COIG|COIG-CQIA', 'zhangChineseOpenInstruction2023|baiCOIGCQIAQualityAll2024'),\n",
    "    ('ChatDoctor', 'ChatDoctor', 'liChatDoctorMedicalChat2023'),\n",
    "    ('Cidar', 'Cidar', 'alyafeaiCIDARCulturallyRelevant2024'),\n",
    "    ('Cobra Frames', 'Cobra Frames', 'zhouCOBRAFramesContextual2023'),\n",
    "    ('Conifer', 'Conifer', 'sunConiferImprovingComplex2024'),\n",
    "    ('Deita 10K', 'Deita 10K', 'liuWhatMakesGood2024'),\n",
    "    ('ExpertQA', 'ExpertQA', 'malaviyaExpertQAExpertCuratedQuestions2024'),\n",
    "    ('Feedback Collection', 'Feedback Collection', 'kimPrometheusInducingFinegrained2024'),\n",
    "    ('HelpSteer', 'HelpSteer', 'wangHelpSteerMultiattributeHelpfulness2023'),\n",
    "    ('Indic-Instruct', 'Indic-Instruct', 'galaAiravataIntroducingHindi2024'),\n",
    "    ('KIWI', 'KIWI', 'xuKIWIDatasetKnowledgeIntensive2024'),\n",
    "    ('Llama2-MedTuned-Instructions', 'Llama2-MedTuned-Instructions', 'rohanianExploringEffectivenessInstruction2023'),\n",
    "    ('LongAlign-10k', 'LongAlign-10k', 'baiLongAlignRecipeLong2024'),\n",
    "    ('MathDial', 'MathDial', 'macinaMathDialDialogueTutoring2023'),\n",
    "    ('MathInstruct', 'MathInstruct', 'yueMAmmoTHBuildingMath2023'),\n",
    "    ('MedInstruct', 'MedInstruct', 'zhangAlpaCareInstructiontunedLarge2024'),\n",
    "    ('Medical Meadow', 'Medical Meadow', 'hanMedAlpacaOpenSourceCollection2023|wangCORD19COVID19Open2020|jinWhatDiseaseDoes2020|saveryQuestionDrivenSummarizationAnswers2020'),\n",
    "    ('MegaWika', 'MegaWika', 'barhamMegaWikaMillionsReports2023'),\n",
    "    ('MetaMathQA', 'MetaMathQA', 'yuMetaMathBootstrapYour2023'),\n",
    "    ('OpenMathInstruct-1', 'OpenMathInstruct-1', 'toshniwalOpenMathInstruct1MillionMath2024'),\n",
    "    ('Orca-Math', 'Orca-Math', 'mitraOrcaMathUnlockingPotential2024'),\n",
    "    ('PMC-LLaMA Instructions', 'PMC-LLaMA Instructions', 'wuPMCLLaMABuildingOpensource2023|jinPubMedQADatasetBiomedical2019'),\n",
    "    ('PygmalionAI-PIPPA', 'PygmalionAI-PIPPA', 'goslingPIPPAPartiallySynthetic2023'),\n",
    "    ('RiddleSense', 'RiddleSense', 'linRiddleSenseReasoningRiddle2021'),\n",
    "    ('SeaBench', 'SeaBench', 'nguyenSeaLLMsLargeLanguage2023'),\n",
    "    ('SelFee', 'SelFee', 'yeSelFeeIterativeSelfRevising2023'),\n",
    "    ('WildChat', 'WildChat', 'zhaoWildChat1MChatGPT2023'),\n",
    "    ('lmsys_chat_1m', 'lmsys_chat_1m', 'zhengLMSYSChat1MLargeScaleRealWorld2024'),\n",
    "    ('Open-Platypus', 'Open-Platypus', 'sawadaARBAdvancedReasoning2023|dettmersQLoRAEfficientFinetuning2023|lightmanLetVerifyStep2023a|yuReClorReadingComprehension2020|wangSciBenchEvaluatingCollegeLevel2024|luLearnExplainMultimodal2022|chenTheoremQATheoremdrivenQuestion2023'),\n",
    "    ('DialogStudio', 'DialogStudio', 'chenActionBasedConversationsDataset2021|weiAirDialogueEnvironmentGoalOriented2018|linBiToDBilingualMultiDomain2021|chawlaCaSiNoCorpusCampsite2021|heDecouplingStrategyGeneration2018|mrksicNeuralBeliefTracker2017|qianDatabaseSearchResults2022|liuDuRecDialBilingualParallel2021|elasriFramesCorpusAdding2017|quanGECOREndtoEndGenerative2019|chenSemanticallyConditionedDialog2019a|chenKETODKnowledgeEnrichedTaskOriented2022|ericKeyValueRetrievalNetworks2017|zangMultiWOZDialogueDataset2020|shalyminovFewShotDialogueGeneration2019|martinMuDoCoCorpusMultidomain2020|peskovMultiDomainGoalOrientedDialogues2019|ericMultiWOZConsolidatedMultiDomain2019|moonOpenDialKGExplainableConversational2019|rastogiScalableMultidomainConversational2020|mosigSTARSchemaGuidedDialog2020|chiuSalesBotTransitioningChitChat2022|shahBuildingConversationalAgent2018|byrneTaskmaster1RealisticDiverse2019|mrksicFullyStatisticalNeural2018|shangUnsupervisedAbstractiveMeeting2018|rameshkumarStorytellingDialogueCritical2020|fabbriConvoSummConversationSummarization2021|chenDialogSumRealLifeScenario2021|mukherjeeECTSumNewBenchmark2022|shangUnsupervisedAbstractiveMeeting2018|zhuMediaSumLargescaleMedia2021|zhongQMSumNewBenchmark2021|gliwaSAMSumCorpusHumanannotated2019|chenSummScreenDatasetAbstractive2022|feigenblatTWEETSUMMDialogSummarization2021|liEndtoEndTrainableNonCollaborative2019|dinanSecondConversationalIntelligence2019|rashkinEmpatheticOpendomainConversation2019|baiTrainingHelpfulHarmless2022|chenPLACESPromptingLanguage2023|kimProsocialDialogProsocialBackbone2022|myersConversationalScaffoldingAnalogybased2020|reddyCoQAConversationalQuestion2019|yuCoSQLConversationalTexttoSQL2019|talmorWebKnowledgeBaseAnswering2018|nanDARTOpenDomainStructured2021|nanFeTaQAFreeformTable2022|guThreeLevelsGeneralization2021|chenHybridQADatasetMultiHop2020|guptaMMQAMultidomainMultilingual2018|liMTOPComprehensiveMultilingual2021|talmorMultiModalQAComplexQuestion2021|yuSParCCrossDomainSemantic2019|iyyerSearchbasedNeuralStructured2017|yuSpiderLargeScaleHumanLabeled2019|parikhToTToControlledTableToText2020|yihValueSemanticParse2016|zhongSeq2SQLGeneratingStructured2017|pasupatCompositionalSemanticParsing2015|komeiliInternetAugmentedDialogueGeneration2022|dinanWizardWikipediaKnowledgePowered2019|hemphillATISSpokenLanguage1990|casanuevaEfficientIntentDetection2020|zhangArePretrainedTransformers2022|larsonEvaluationDatasetIntent2019|rastogiScalableMultidomainConversational2020|liuBenchmarkingNaturalLanguage2019|liuAsgardPortableArchitecture2013|coopeSpanConveRTFewshotSpan2020|couckeSnipsVoicePlatform2018|guptaSemanticParsingTask2018'),\n",
    "    \n",
    "    # no paper\n",
    "    ('10k Prompt Ranked', '10k Prompt Ranked', ''),\n",
    "    ('Capybara', 'Capybara', ''),\n",
    "    ('CollectiveCognition', 'CollectiveCognition', ''),\n",
    "    ('EverythingLM', 'EverythingLM', ''),\n",
    "    ('Glaive Code Assistant', 'Glaive Code Assistant', ''),\n",
    "    ('Gretel Text-to-SQL', 'Gretel Text-to-SQL', ''),\n",
    "    ('Nectar', 'Nectar', ''),\n",
    "    ('No Robots', 'No Robots', ''),\n",
    "    ('OpenGPT Healthcare', 'OpenGPT Healthcare', ''),\n",
    "    ('PII-masking-200k', 'PII-masking-200k', ''),\n",
    "    ('Pure-Dove', 'Pure-Dove', ''),\n",
    "    ('Thai Gen AI', 'Thai Gen AI (Alpaca)|Thai Gen AI (Dolly)|Thai Gen AI (GPTeacher)', ''),\n",
    "    ('UltraFeedback Argilla', 'UltraFeedback Argilla', ''),    \n",
    "], columns=['Collection', 'summary_keys']).set_index('Collection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7508391f-367d-4a26-ae00-fbe06fd5f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = [y for x in dat['summary_keys'].str.split('|').tolist() for y in x]\n",
    "\n",
    "files = [\n",
    "    os.path.splitext(f)[0]\n",
    "    for f in os.listdir('data_summaries')\n",
    "    if not f.startswith('_template')\n",
    "]\n",
    "\n",
    "assert set(sk) <= set(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949fe910-4d04-47ff-b215-a5a7f32d76ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "short_names = pd.DataFrame(dat['summary_keys'].str.split('|')).to_records().tolist()\n",
    "for short, keys in short_names:\n",
    "    for key in keys:\n",
    "        tmp += [(short, key)]\n",
    "short_names = pd.DataFrame(tmp, columns=['short_name', 'summary_key']).set_index('summary_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9f63d4-8588-43c1-90af-dbe5bc65f2e8",
   "metadata": {},
   "source": [
    "## Dimension data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb01af1d-e511-4056-a451-73b900988468",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('constants/domain_groups.json', 'rt') as f:\n",
    "    domain_groups = json.load(f)\n",
    "    domain_groups = {\n",
    "        v: k\n",
    "        for k, vs in domain_groups.items()\n",
    "        for v in vs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef36a96-8993-4b89-9342-efedc7aaca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('constants/task_groups.json', 'rt') as f:\n",
    "    task_groups = json.load(f)\n",
    "    task_groups = {\n",
    "        v: k\n",
    "        for k, vs in task_groups.items()\n",
    "        for v in vs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87523fb2-3c74-4f78-ab1e-972b0332c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('constants/license_classes.json', 'rt') as f:\n",
    "    license_classes = json.load(f)\n",
    "    license_classes = {k : v[-1] for k, v in license_classes.items()}\n",
    "    license_classes['Custom'] = 'Unspecified'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70abbe3-3456-4815-b66b-8e1420a211b6",
   "metadata": {},
   "source": [
    "## Load summary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddabc229-c3cf-4e19-8257-9c7642c6f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = {}\n",
    "for file in os.listdir('data_summaries'):\n",
    "    if file.startswith('_template'):\n",
    "        continue\n",
    "    \n",
    "    with open(os.path.join('data_summaries', file), 'rt') as f:\n",
    "        summaries[file.split('.')[0]] = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26662c7-5d8a-450c-81d7-72e1b7b4784e",
   "metadata": {},
   "source": [
    "## Licenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34659407-729b-4c53-87d3-efdce68c6e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "licenses = {}\n",
    "for k in summaries.keys():\n",
    "    for ds in summaries[k].keys():\n",
    "        for lic in summaries[k][ds]['Licenses']:\n",
    "            licenses[k] = licenses.get(k, []) + [lic['License']]\n",
    "licenses = pd.Series({k : list(set(v)) for k, v in licenses.items()})\n",
    "\n",
    "tmp = short_names.copy()\n",
    "tmp['licenses'] = licenses\n",
    "dat['License'] = tmp.groupby('short_name')['licenses'].apply(lambda s: list(set([y for x in s for y in x])))\n",
    "\n",
    "dat['OAI'] = dat['License'].apply(lambda s: 'OpenAI' in s or 'OANC' in s)\n",
    "dat['OAI'] = dat['OAI'].replace({True: r'\\greencheck', False: '\\emojiblank'})\n",
    "dat['License'] = dat['License'].apply(lambda s: [v for v in s if v != 'OpenAI' and v != 'OANC'])\n",
    "\n",
    "license_table = dat[['License', 'Cite']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1141ce-cfc0-4452-8879-8c8833ca54a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['Use'] = dat['License'].apply(lambda s: list(set([license_classes[v] for v in s])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a7601-7b39-4981-a7c5-25ab21d86969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def color_license_classes(s):\n",
    "    ret = []\n",
    "\n",
    "    if 'All' in s:\n",
    "        ret += [r'\\CommercialDataCircle']\n",
    "    else:\n",
    "        ret += [r'\\TransparentCircle']\n",
    "    \n",
    "    if 'Unspecified' in s or len(s) == 0:\n",
    "        ret += [r'\\UnspecifiedDataCircle']\n",
    "    else:\n",
    "        ret += [r'\\TransparentCircle']\n",
    "    \n",
    "    if 'Acad' in s or 'NC' in s:\n",
    "        ret += [r'\\NCDataCircle']\n",
    "    else:\n",
    "        ret += [r'\\TransparentCircle']\n",
    "    \n",
    "    return ' '.join(ret)\n",
    "\n",
    "dat['Use'] = dat['License'].apply(lambda s: list(set([license_classes[v] for v in s])))\n",
    "dat['Use'] = dat['Use'].apply(color_license_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3409805-d5df-4e1a-becd-1d8dc75ee360",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.drop(['License', 'Cite'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc195158-48fe-4775-825b-275a4649f958",
   "metadata": {},
   "source": [
    "## Property counts and text lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0be802-6b39-4368-8ada-dd4aa237c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = []\n",
    "for collection in dat.index:\n",
    "    for file in dat.loc[collection, 'summary_keys'].split('|'):\n",
    "        for k in summaries[file].keys():\n",
    "            if 'Languages' in summaries[file][k].keys():\n",
    "                langs = summaries[file][k]['Languages']\n",
    "            else:\n",
    "                langs = None\n",
    "            \n",
    "            metrics = summaries[file][k].get('Text Metrics', None)\n",
    "            if metrics is None or metrics == '' or metrics == {}:\n",
    "                num_dialogs = np.nan\n",
    "                mean_inputs_length = np.nan\n",
    "                mean_targets_length = np.nan\n",
    "            else:\n",
    "                num_dialogs = metrics['Num Dialogs']\n",
    "                mean_inputs_length = metrics['Mean Inputs Length']\n",
    "                mean_targets_length = metrics['Mean Targets Length']\n",
    "                \n",
    "            if 'Text Sources' not in summaries[file][k].keys():\n",
    "                domains = None\n",
    "            elif not isinstance(summaries[file][k]['Text Sources'], (list, tuple)):\n",
    "                domains = None\n",
    "            else:\n",
    "                domains = summaries[file][k]['Text Sources']\n",
    "                domains = [domain_groups[d] for d in domains]\n",
    "\n",
    "            if 'Task Categories' not in summaries[file][k].keys():\n",
    "                tasks = None\n",
    "            elif not isinstance(summaries[file][k]['Task Categories'], (list, tuple)):\n",
    "                tasks = None\n",
    "            else:\n",
    "                tasks = summaries[file][k]['Task Categories']\n",
    "                tasks = [task_groups[d] for d in tasks]\n",
    "\n",
    "            inf_metadata = summaries[file][k].get('Inferred Metadata', None)\n",
    "            if inf_metadata is None or inf_metadata == '' or inf_metadata == {}:\n",
    "                topics = None\n",
    "            else:\n",
    "                if 'Text Topics' not in inf_metadata.keys():\n",
    "                    topics = None\n",
    "                elif not isinstance(inf_metadata['Text Topics'], (list, tuple)):\n",
    "                    topics = None\n",
    "                else:\n",
    "                    topics = inf_metadata['Text Topics']\n",
    "\n",
    "            raw += [{\n",
    "                'collection': collection,\n",
    "                'summary_key': file,\n",
    "                'sub': k,\n",
    "\n",
    "                'num_dialogs': num_dialogs,\n",
    "                'mean_inputs_length': mean_inputs_length,\n",
    "                'mean_targets_length': mean_targets_length,\n",
    "\n",
    "                'langs': langs,\n",
    "                'topics': topics,\n",
    "                'domains': domains,\n",
    "                'tasks': tasks,\n",
    "                'datasets': 1,\n",
    "            }]\n",
    "raw = pd.DataFrame(raw)\n",
    "\n",
    "total_input_length = raw['num_dialogs'] * raw['mean_inputs_length']\n",
    "total_targets_length = raw['num_dialogs'] * raw['mean_targets_length']\n",
    "\n",
    "num_dialogs = raw.groupby('collection')['num_dialogs'].sum()\n",
    "mean_inputs_length = total_input_length.groupby(raw['collection']).sum() / num_dialogs\n",
    "mean_targets_length = total_targets_length.groupby(raw['collection']).sum() / num_dialogs\n",
    "\n",
    "num_langs = raw.groupby('collection')['langs'].apply(ut.count_unique_with_none)\n",
    "num_topics = raw.groupby('collection')['topics'].apply(ut.count_unique_with_none)\n",
    "num_domains = raw.groupby('collection')['domains'].apply(ut.count_unique_with_none)\n",
    "num_tasks = raw.groupby('collection')['tasks'].apply(ut.count_unique_with_none)\n",
    "num_datasets = raw.groupby('collection')['datasets'].sum()\n",
    "\n",
    "dat['Num Langs'] = num_langs.fillna(0).astype(int)\n",
    "dat['Num Dialogs'] = num_dialogs.fillna(0).astype(int)\n",
    "dat['Mean Inputs Length'] = mean_inputs_length.fillna(0).astype(int)\n",
    "dat['Mean Targets Length'] = mean_targets_length.fillna(0).astype(int)\n",
    "dat['Num Topics'] = num_topics.fillna(0).astype(int)\n",
    "dat['Num Datasets'] = num_datasets.fillna(0).astype(int)\n",
    "dat['Num Tasks'] = num_tasks.fillna(0).astype(int)\n",
    "dat['Num Domains'] = num_domains.fillna(0).astype(int).apply(lambda s: max(s, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3735c5f2-c5f7-4837-aedd-ead6cc21453d",
   "metadata": {},
   "source": [
    "## Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb479332-8bd6-412f-b841-87e10c790663",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen = {}\n",
    "for k in summaries.keys():\n",
    "    for ds in summaries[k].keys():\n",
    "        models = summaries[k][ds]['Model Generated']\n",
    "        models = [m for m in models if m != '']\n",
    "        mgen[k] = mgen.get(k, []) + [len(models) > 0]\n",
    "mgen = pd.Series({k : list(set(v)) for k, v in mgen.items()})\n",
    "tmp = short_names.copy()\n",
    "tmp['mgen'] = mgen\n",
    "dat['Source'] = tmp.groupby('short_name')['mgen'] \\\n",
    "    .agg(lambda x: [item for sublist in x for item in sublist]) \\\n",
    "    .apply(lambda s: 1 - sum(s) / len(s))\n",
    "\n",
    "dat.loc[(dat['Source'] > 0) & (dat['Source'] < 1), 'Source'] = r'\\emoji{globe-with-meridians}\\emoji{robot}'\n",
    "dat.loc[dat['Source'] == 1, 'Source'] = r'\\emoji{globe-with-meridians}\\emojiblank'\n",
    "dat.loc[dat['Source'] == 0, 'Source'] = r'\\emojiblank\\emoji{robot}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5838c91-b252-4be9-be85-3db3412cf581",
   "metadata": {},
   "source": [
    "## Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb184790-c5c2-4611-b049-3a67529c346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "formats_map = {\n",
    "    'Chain-of-Thought': 'CT',\n",
    "    'Few-shot': 'FS',\n",
    "    'Multi-turn Dialog': 'MD',\n",
    "    'Response Ranking': 'RR',\n",
    "    'Zero-shot': 'ZS',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6111a88-2c0c-462a-bdcc-21a296c22ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_formats = [\n",
    "    summaries[file][k]['Format']\n",
    "    for file in summaries.keys()\n",
    "    for k in summaries[file].keys()\n",
    "]\n",
    "found_formats = set([y for x in found_formats for y in x])\n",
    "assert found_formats <= set(formats_map.keys())\n",
    "\n",
    "fmts = []\n",
    "for collection in dat.index:\n",
    "    for file in dat.loc[collection, 'summary_keys'].split('|'):\n",
    "        for k in summaries[file].keys():\n",
    "            tmp_fmts = summaries[file][k].get('Format', [])\n",
    "            tmp_fmts = [formats_map[f] for f in tmp_fmts]\n",
    "            \n",
    "            fmts += [{\n",
    "                'collection': collection,\n",
    "                'summary_key': file,\n",
    "                'sub': k,\n",
    "                \n",
    "                'formats': tmp_fmts,\n",
    "            }]\n",
    "fmts = pd.DataFrame(fmts)\n",
    "fmts = fmts.groupby('collection')['formats'] \\\n",
    "           .apply(lambda s: list(set([y for x in s for y in x]))) \\\n",
    "           .rename('formats')\n",
    "\n",
    "for fmt in formats_map.values():\n",
    "    dat[fmt] = fmts.apply(lambda s: fmt in s) \\\n",
    "        .replace(True, r'\\greencheck') \\\n",
    "        .replace(False, r'\\emojiblank')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acde63d-c13f-4346-bd7f-1047182717ff",
   "metadata": {},
   "source": [
    "## Format for LaTeX output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a62b6-ce23-4d37-9598-21f9c3ea1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat[[\n",
    "    'Num Datasets',\n",
    "    'Num Dialogs',\n",
    "    'Num Tasks',\n",
    "    'Num Langs',\n",
    "    'Num Topics',\n",
    "    'Num Domains',\n",
    "    \n",
    "    'Mean Inputs Length',\n",
    "    'Mean Targets Length',\n",
    "    \n",
    "    'Source',\n",
    "    \n",
    "    'ZS',\n",
    "    'FS',\n",
    "    'CT',\n",
    "    'RR',\n",
    "    'MD',\n",
    "    \n",
    "    'Use',\n",
    "    'OAI',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e435e1d-0fc5-47b2-b5c9-42d0f7d8784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'Num Datasets': ('Property Counts', 'Datasets'),\n",
    "    'Num Dialogs': ('Property Counts', 'Dialogs'),\n",
    "    'Num Tasks': ('Property Counts', 'Tasks'),\n",
    "    'Num Langs': ('Property Counts', 'Langs'),\n",
    "    'Num Topics': ('Property Counts', 'Topics'),\n",
    "    'Num Cites': ('Property Counts', 'Cites'),\n",
    "    'Num Domains': ('Property Counts', 'Domains'),\n",
    "    'Mean Inputs Length': ('Text Lens', 'Inpt'),\n",
    "    'Mean Targets Length': ('Text Lens', 'Tgt'),\n",
    "    'Source': ('Dataset Types', 'Source'),\n",
    "\n",
    "    'CT': ('Dataset Types', 'C'),\n",
    "    'ZS': ('Dataset Types', 'Z'),\n",
    "    'RR': ('Dataset Types', 'R'),\n",
    "    'MD': ('Dataset Types', 'M'),\n",
    "    'FS': ('Dataset Types', 'F'),\n",
    "    \n",
    "    'Use': ('Dataset Types', 'Use'),\n",
    "    'OAI': ('Dataset Types', 'O'),\n",
    "}\n",
    "\n",
    "dat.columns = pd.MultiIndex.from_arrays([\n",
    "    [column_mapping[col][0] for col in dat.columns],\n",
    "    [column_mapping[col][1] for col in dat.columns]\n",
    "])\n",
    "\n",
    "dat.columns = pd.MultiIndex.from_tuples([\n",
    "    (r'\\textsc{' + c[0] + r'}', r'\\textsc{\\thead{' + c[1] + r'}}')\n",
    "    for c in dat.columns\n",
    "])\n",
    "\n",
    "dat.index.name = r'\\textsc{' + dat.index.name + r'}'\n",
    "\n",
    "def color_map(value, cmap='BrBG', vmin=None, vmax=None):\n",
    "    norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    colormap = mp.colormaps[cmap]\n",
    "    color = [int(255*x) for x in colormap(norm(value))[:3]]\n",
    "    return ','.join(map(str, color))  # Convert the color to a CSV string\n",
    "\n",
    "color_def = ''\n",
    "formatters = {}\n",
    "tmp_val_color = {}\n",
    "num_cols = [\n",
    "    c\n",
    "    for c in dat.columns\n",
    "    if (\n",
    "        'Property Counts' in c[0] or\n",
    "        'Text Lens' in c[0]\n",
    "    )\n",
    "]\n",
    "\n",
    "for col in num_cols:\n",
    "    tmp_val_color[col] = {}\n",
    "    \n",
    "    vmin = np.log(dat[col].min() + 1e-6)\n",
    "    vmax = np.log(dat[col].max() + 1e-6)\n",
    "    midpt = (vmax + vmin) / 2\n",
    "    vmin, vmax = vmin - midpt, vmax - midpt\n",
    "    \n",
    "    for row in dat.index:\n",
    "        value = np.log(dat.loc[row, col] + 1e-6)\n",
    "        value -= midpt\n",
    "        \n",
    "        if pd.notnull(value):\n",
    "            row_color_name = row.replace(' ', '') \\\n",
    "                .replace(r'\\textsc{', '').replace('}', '')\n",
    "            col_color_name = '_'.join(col).replace(' ', '') \\\n",
    "                .replace(r'\\textsc{\\thead{', '').replace('}}', '') \\\n",
    "                .replace(r'\\textsc{', '').replace('}', '')\n",
    "            \n",
    "            color_name = f\"color{row_color_name}{col_color_name}\"\n",
    "            \n",
    "            color_def += f\"\\\\definecolor{{{color_name}}}{{RGB}}{{{color_map(value / 4, vmin=vmin, vmax=vmax)}}}\\n\"\n",
    "            \n",
    "            tmp_val_color[col][dat.loc[row, col]] = color_name\n",
    "\n",
    "    if 'Dialogs' in col[1]:  # or 'Downs' in col[1]:\n",
    "        def func(v, col=col):\n",
    "            color_name = tmp_val_color[col][v]\n",
    "    \n",
    "            if col in num_cols and v >= 1000:\n",
    "                v /= 1000\n",
    "                return f'\\\\cellcolor{{{color_name}}}{{{v:,.0f}k}}' if pd.notnull(v) else '-'\n",
    "            elif col in num_cols and v == 0:\n",
    "                return '-'\n",
    "            else:\n",
    "                return f'\\\\cellcolor{{{color_name}}}{{<1k}}' if pd.notnull(v) else '-'\n",
    "    else:\n",
    "        def func(v, col=col):\n",
    "            color_name = tmp_val_color[col][v]\n",
    "    \n",
    "            if col in num_cols and v >= 1000:\n",
    "                v /= 1000\n",
    "                return f'\\\\cellcolor{{{color_name}}}{{{v:,.0f}k}}' if pd.notnull(v) else '-'\n",
    "            elif col in num_cols and v == 0:\n",
    "                return '-'\n",
    "            else:\n",
    "                return f'\\\\cellcolor{{{color_name}}}{{{v:,.0f}}}' if pd.notnull(v) else '-'\n",
    "    \n",
    "    formatters[col] = func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6431fe91-5470-41fb-8207-f8aa2e740160",
   "metadata": {},
   "source": [
    "# Main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526d036-6a7c-482e-97d3-b4dfc5edd48e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'environment': 'table*',\n",
    "    'label': 'tab:collections',\n",
    "    'position_float': 'centering',\n",
    "    'column_format': 'l|ccccccc|rr|cp{0.3cm}p{0.3cm}p{0.3cm}p{0.3cm}p{0.3cm}cp{0.3cm}',\n",
    "    'multicol_align': 'c',\n",
    "    \n",
    "    'caption': r'''\n",
    "    \\textbf{Alignment tuning collections and their characteristics}. Collection properties include numbers of datasets, dialogs, tasks, languages, topics, Huggingface downloads (\"Downs\"), text domains, and average length of input and target text. The \\textsc{Source} column indicates whether a collection contains human-generated web text (\\emoji{globe-with-meridians}), language model outputs (\\emoji{robot}) or both (\\emoji{globe-with-meridians}\\emoji{robot}). Several columns indicate the type of dialogs, with some collections having more than one: zero-shot (Z), few-shot (F), response ranking (R), chain-of-thought (C), and multi-turn dialog (M). Finally, the \\textsc{Use} column indicates whether a collection includes data freely usable even for commercial purposes (\\protect\\CommercialDataCircle), data usable only for noncommercial purposes or academic research (\\protect\\NCDataCircle) and data whose license status is not specified precisely enough to allow us to determine commercial use permissions (\\protect\\UnspecifiedDataCircle). Note that each collection may have different datasets with one, two, or all three of these statuses. The O column indicates collections which include OpenAI model generations.\n",
    "    '''.strip(),\n",
    "    \n",
    "    'hrules': True,\n",
    "    'convert_css': True,\n",
    "}\n",
    "\n",
    "latex = dat \\\n",
    "    .sort_index() \\\n",
    "    .style \\\n",
    "    .format(formatter=formatters) \\\n",
    "    .to_latex(**kwargs)\n",
    "\n",
    "print('\\n'.join([\n",
    "    r'\\setlength{\\tabcolsep}{1.9pt}',\n",
    "    color_def,\n",
    "    latex,\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1335a6b5-9fb1-4c83-9954-80320d9257b7",
   "metadata": {},
   "source": [
    "# Appendix license/cite table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ec891-8345-4649-9d1a-b375c818a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "license_table['OpenAI NC'] = license_table['License'] \\\n",
    "    .apply(lambda s: 'OpenAI' in s) \\\n",
    "    .replace(True, r'\\redcross') \\\n",
    "    .replace(False, r'\\emojiblank')\n",
    "\n",
    "license_table['License'] = license_table['License'].apply(lambda s: [v for v in s if v != 'OpenAI'])\n",
    "license_table['License'] = license_table['License'].apply(lambda s: [v if v != 'Academic Research Purposes Only' else 'Academic Only' for v in s])\n",
    "license_table['License'] = license_table['License'].apply(lambda s: s if 'Various' not in s else ['Various'])\n",
    "license_table['License'] = license_table['License'].apply(lambda s: s if len(s) > 0 else ['Unspecified'])\n",
    "license_table['License'] = license_table['License'].apply(lambda s: s if len(s) <= 3 else ['Various'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd044b-a57c-445d-a3c5-83ca52edb804",
   "metadata": {},
   "outputs": [],
   "source": [
    "license_table = license_table[[\n",
    "#    'OpenAI NC',\n",
    "    'Cite',\n",
    "    'License'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f58c9d-c813-4e2e-a301-57c89a4e0fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "license_table['Cite'] = license_table['Cite'].apply(lambda s: r'\\citet{' + s + '}')\n",
    "license_table.loc[license_table['Cite'] == r'\\citet{}', 'Cite'] = '--'\n",
    "\n",
    "license_table['License'] = license_table['License'].str.join(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a5568e-ffb2-45e3-81a1-55a3680b149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "license_table.rename({'License': 'Licenses'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abd2b9d-b83f-4c68-a24b-3787f13caec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'environment': 'table*',\n",
    "    'label': 'tab:licenses',\n",
    "    'position_float': 'centering',\n",
    "    'column_format': 'l|lp{5.5cm}',\n",
    "    \n",
    "    'caption': r'''\n",
    "    \\textbf{Licenses and citations} for the dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having ''Various`` licenses, and we refer readers to our raw data for the full details.\n",
    "    '''.strip(),\n",
    "    \n",
    "    'hrules': True,\n",
    "    'convert_css': True,\n",
    "}\n",
    "\n",
    "latex = license_table \\\n",
    "    .sort_index() \\\n",
    "    .style \\\n",
    "    .to_latex(**kwargs)\n",
    "\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa945fa4-75d7-4b50-aeb5-52e126e219e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LMHTE",
   "language": "python",
   "name": "lmhte"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
