{
    "OLKAVS": {
        "Dataset Name": "olkavs",
        "Unique Dataset Identifier": "olkavs",
        "Collection": "OLKAVS",
        "Hours": 1150.0,
        "Languages (Count)": 1,
        "Languages": [
            "Korean"
        ],
        "Languages (ISO)": [
            "ko"
        ],
        "Language Groups": [
            "Korean"
        ],
        "Language Families": [
            "Koreanic"
        ],
        "Speakers": 1107,
        "Tasks": [
            "Speech Recognition",
            "Speaker Recognition"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://aihub.or.kr/intrcn/guid/usagepolicy.do"
            }
        ],
        "License Notes": "",
        "Topics": [
            "Health/Diet",
            "Daily",
            "Job/Work",
            "Financial",
            "Human Relations",
            "Pet",
            "Sports/Leisure",
            "Food",
            "Education/School",
            "Vacation",
            "Art/Culture",
            "Transportation",
            "Social Issue",
            "Ceremonial Occasions"
        ],
        "Source Category": [
            "Human Participants"
        ],
        "Source": [
            "Human Participants"
        ],
        "Process Description": "Audios Recorded First, Text Transcribed Later",
        "GitHub URL": "https://github.com/IIP-Sogang/olkavs-avspeech",
        "Hugging Face URL": "",
        "Website URL": [
            "https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=538"
        ],
        "Papers with Code URL": "https://paperswithcode.com/dataset/olkavs",
        "Paper URL": "https://arxiv.org/pdf/2301.06375",
        "Semantic Scholar Corpus ID": 255942323,
        "Creators": [
            "Sogang University",
            "Mindslab Inc."
        ],
        "Creator Categories": [
            "Academia",
            "Industry"
        ],
        "Year Released": 2022,
        "Location": [
            "South Korea"
        ],
        "Notes": "",
        "Inferred Metadata": {
            "GitHub License": "",
            "GitHub Stars (June 2024)": 26,
            "GitHub Topics": [
                "dataset",
                "deep-learning",
                "pytorch"
            ],
            "Github Date": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Dataset": "",
            "HF Date": "",
            "HF Downloads (June 2024)": "",
            "HF Likes (June 2024)": "",
            "HF Yaml License": "",
            "PwC Date": "2023-01-16",
            "PwC Description": "The dataset contains 1,150 hours of transcribed audio from 1,107 Korean speakers in a studio setup with nine different viewpoints and various noise situations. We also provide the pre-trained baseline models for two tasks, audio-visual speech recognition and lip reading.",
            "PwC License Name": "Unspecified",
            "PwC License URL": null,
            "S2 Citation Count (June 2024)": "",
            "S2 Date": ""
        }
    }
}