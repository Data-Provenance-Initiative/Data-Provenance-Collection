{
    "cotcollection-en": {
        "Unique Dataset Identifier": "cotcollection-en",
        "Dataset Name": "cotcollection_en",
        "Collection": "CoT Collection",
        "Collection URL": "https://github.com/kaistAI/CoT-Collection",
        "Dataset URL": "https://github.com/kaistAI/CoT-Collection",
        "GitHub URL": "https://github.com/kaistAI/CoT-Collection",
        "Hugging Face URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection",
        "Paper Title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2305.14045",
        "Semantic Scholar Corpus ID": 258841149,
        "Languages": [
            "English",
            "Code"
        ],
        "Task Categories": [
            "Chain-of-Thought",
            "Natural Language Inference",
            "Question Answering",
            "Commonsense Classification",
            "Commonsense Reasoning",
            "Explanation",
            "Dialog Generation",
            "Code",
            "Natural Language Generation (NLG)",
            "Summarization",
            "Cause Effect Classification",
            "Toxicity Detection",
            "Logical Reasoning",
            "Ethics Classification"
        ],
        "Format": [
            "Chain-of-Thought"
        ],
        "Text Metrics": {
            "Num Dialogs": 1837928,
            "Mean Inputs Length": 793.0108,
            "Mean Targets Length": 283.4774,
            "Max Inputs Length": 34648,
            "Max Targets Length": 6802,
            "Min Inputs Length": 3,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flan-t5"
        ],
        "Model Generated": [
            "flan-t5",
            "OpenAI Codex"
        ],
        "Creators": [
            "KAIST",
            "Yonsei University",
            "NAVER AI Lab"
        ],
        "Licenses": [
            {
                "License": "Non Commercial",
                "License URL": "https://github.com/kaistAI/CoT-Collection#license"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2305.14045"
            }
        ],
        "License Notes": "Uses OpenAI Codex model to generate rationales and ChatGPT to translate to other languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "en"
        ],
        "Inferred Metadata": {
            "HF Dataset": "kaist-ai/CoT-Collection",
            "HF Config": "en",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-05-23",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "History",
                "Linguistics",
                "Science",
                "International relations",
                "Mathematics",
                "Sports",
                "Logic",
                "Climate change",
                "Travel",
                "Ethics"
            ],
            "Github Date": "",
            "HF Date": "2023-06-05",
            "HF Downloads (September 2023)": 680,
            "HF Likes (September 2023)": 12,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "cotcollection-fr": {
        "Unique Dataset Identifier": "cotcollection-fr",
        "Dataset Name": "cotcollection_fr",
        "Collection": "CoT Collection",
        "Collection URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Dataset URL": "https://github.com/kaistAI/CoT-Collection",
        "GitHub URL": "https://github.com/kaistAI/CoT-Collection",
        "Hugging Face URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Paper Title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2305.14045",
        "Semantic Scholar Corpus ID": 258841149,
        "Languages": [
            "French",
            "Code"
        ],
        "Task Categories": [
            "Chain-of-Thought",
            "Natural Language Inference",
            "Question Answering",
            "Commonsense Classification",
            "Commonsense Reasoning",
            "Explanation",
            "Dialog Generation",
            "Code",
            "Natural Language Generation (NLG)",
            "Summarization",
            "Cause Effect Classification",
            "Toxicity Detection",
            "Logical Reasoning",
            "Ethics Classification"
        ],
        "Format": [
            "Chain-of-Thought"
        ],
        "Text Metrics": {
            "Num Dialogs": 70400,
            "Mean Inputs Length": 668.903,
            "Mean Targets Length": 282.4849,
            "Max Inputs Length": 3749,
            "Max Targets Length": 3652,
            "Min Inputs Length": 6,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flan-t5"
        ],
        "Model Generated": [
            "flan-t5",
            "OpenAI Codex",
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "KAIST",
            "Yonsei University",
            "NAVER AI Lab"
        ],
        "Licenses": [
            {
                "License": "Non Commercial",
                "License URL": "https://github.com/kaistAI/CoT-Collection#license"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2305.14045"
            }
        ],
        "License Notes": "Uses OpenAI Codex model to generate rationales and ChatGPT to translate to other languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "fr"
        ],
        "Inferred Metadata": {
            "HF Dataset": "kaist-ai/CoT-Collection",
            "HF Config": "en",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-05-23",
            "GitHub License": "",
            "Text Topics": [
                "History",
                "Language learning",
                "Linguistics",
                "Language understanding",
                "Translation",
                "Geography",
                "Emotions",
                "Logic",
                "Politics",
                "Grammar"
            ],
            "Github Date": "",
            "HF Date": "2023-06-05",
            "HF Downloads (September 2023)": 103,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "cotcollection-ja": {
        "Unique Dataset Identifier": "cotcollection-ja",
        "Dataset Name": "cotcollection_ja",
        "Collection": "CoT Collection",
        "Collection URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Dataset URL": "https://github.com/kaistAI/CoT-Collection",
        "GitHub URL": "https://github.com/kaistAI/CoT-Collection",
        "Hugging Face URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Paper Title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2305.14045",
        "Semantic Scholar Corpus ID": 258841149,
        "Languages": [
            "Japanese",
            "Code"
        ],
        "Task Categories": [
            "Chain-of-Thought",
            "Natural Language Inference",
            "Question Answering",
            "Commonsense Classification",
            "Commonsense Reasoning",
            "Explanation",
            "Dialog Generation",
            "Code",
            "Natural Language Generation (NLG)",
            "Summarization",
            "Cause Effect Classification",
            "Toxicity Detection",
            "Logical Reasoning",
            "Ethics Classification"
        ],
        "Format": [
            "Chain-of-Thought"
        ],
        "Text Metrics": {
            "Num Dialogs": 65072,
            "Mean Inputs Length": 277.4443,
            "Mean Targets Length": 117.1297,
            "Max Inputs Length": 3254,
            "Max Targets Length": 1991,
            "Min Inputs Length": 2,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flan-t5"
        ],
        "Model Generated": [
            "flan-t5",
            "OpenAI Codex",
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "KAIST",
            "Yonsei University",
            "NAVER AI Lab"
        ],
        "Licenses": [
            {
                "License": "Non Commercial",
                "License URL": "https://github.com/kaistAI/CoT-Collection#license"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2305.14045"
            }
        ],
        "License Notes": "Uses OpenAI Codex model to generate rationales and ChatGPT to translate to other languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "ja"
        ],
        "Inferred Metadata": {
            "HF Dataset": "kaist-ai/CoT-Collection",
            "HF Config": "en",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-05-23",
            "GitHub License": "",
            "Text Topics": [
                "Travel",
                "Algorithms",
                "String manipulation",
                "History",
                "Science",
                "Translation",
                "Math",
                "Sports",
                "Linguistics",
                "Data analysis"
            ],
            "Github Date": "",
            "HF Date": "2023-06-05",
            "HF Downloads (September 2023)": 103,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "cotcollection-ko": {
        "Unique Dataset Identifier": "cotcollection-ko",
        "Dataset Name": "cotcollection_ko",
        "Collection": "CoT Collection",
        "Collection URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Dataset URL": "https://github.com/kaistAI/CoT-Collection",
        "GitHub URL": "https://github.com/kaistAI/CoT-Collection",
        "Hugging Face URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Paper Title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2305.14045",
        "Semantic Scholar Corpus ID": 258841149,
        "Languages": [
            "Korean",
            "Code"
        ],
        "Task Categories": [
            "Chain-of-Thought",
            "Natural Language Inference",
            "Question Answering",
            "Commonsense Classification",
            "Commonsense Reasoning",
            "Explanation",
            "Dialog Generation",
            "Code",
            "Natural Language Generation (NLG)",
            "Summarization",
            "Cause Effect Classification",
            "Toxicity Detection",
            "Logical Reasoning",
            "Ethics Classification"
        ],
        "Format": [
            "Chain-of-Thought"
        ],
        "Text Metrics": {
            "Num Dialogs": 77200,
            "Mean Inputs Length": 292.2117,
            "Mean Targets Length": 132.6346,
            "Max Inputs Length": 3196,
            "Max Targets Length": 1657,
            "Min Inputs Length": 2,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flan-t5"
        ],
        "Model Generated": [
            "flan-t5",
            "OpenAI Codex",
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "KAIST",
            "Yonsei University",
            "NAVER AI Lab"
        ],
        "Licenses": [
            {
                "License": "Non Commercial",
                "License URL": "https://github.com/kaistAI/CoT-Collection#license"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2305.14045"
            }
        ],
        "License Notes": "Uses OpenAI Codex model to generate rationales and ChatGPT to translate to other languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "ko"
        ],
        "Inferred Metadata": {
            "HF Dataset": "kaist-ai/CoT-Collection",
            "HF Config": "en",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-05-23",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "Travel",
                "History",
                "Sports",
                "Biology",
                "Transportation",
                "Science",
                "Translation",
                "Chemistry",
                "Physics"
            ],
            "Github Date": "",
            "HF Date": "2023-06-05",
            "HF Downloads (September 2023)": 103,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "cotcollection-ru": {
        "Unique Dataset Identifier": "cotcollection-ru",
        "Dataset Name": "cotcollection_ru",
        "Collection": "CoT Collection",
        "Collection URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Dataset URL": "https://github.com/kaistAI/CoT-Collection",
        "GitHub URL": "https://github.com/kaistAI/CoT-Collection",
        "Hugging Face URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Paper Title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2305.14045",
        "Semantic Scholar Corpus ID": 258841149,
        "Languages": [
            "Russian",
            "Code"
        ],
        "Task Categories": [
            "Chain-of-Thought",
            "Natural Language Inference",
            "Question Answering",
            "Commonsense Classification",
            "Commonsense Reasoning",
            "Explanation",
            "Dialog Generation",
            "Code",
            "Natural Language Generation (NLG)",
            "Summarization",
            "Cause Effect Classification",
            "Toxicity Detection",
            "Logical Reasoning",
            "Ethics Classification"
        ],
        "Format": [
            "Chain-of-Thought"
        ],
        "Text Metrics": {
            "Num Dialogs": 60570,
            "Mean Inputs Length": 517.5606,
            "Mean Targets Length": 253.6704,
            "Max Inputs Length": 4078,
            "Max Targets Length": 4173,
            "Min Inputs Length": 7,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flan-t5"
        ],
        "Model Generated": [
            "flan-t5",
            "OpenAI Codex",
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "KAIST",
            "Yonsei University",
            "NAVER AI Lab"
        ],
        "Licenses": [
            {
                "License": "Non Commercial",
                "License URL": "https://github.com/kaistAI/CoT-Collection#license"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2305.14045"
            }
        ],
        "License Notes": "Uses OpenAI Codex model to generate rationales and ChatGPT to translate to other languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "ru"
        ],
        "Inferred Metadata": {
            "HF Dataset": "kaist-ai/CoT-Collection",
            "HF Config": "en",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-05-23",
            "GitHub License": "",
            "Text Topics": [
                "Translation",
                "Mathematics",
                "Geography",
                "Problem-solving",
                "Linguistics",
                "Language understanding",
                "Storytelling",
                "Language learning",
                "Math",
                "Arithmetic"
            ],
            "Github Date": "",
            "HF Date": "2023-06-05",
            "HF Downloads (September 2023)": 103,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "cotcollection-zh": {
        "Unique Dataset Identifier": "cotcollection-zh",
        "Dataset Name": "cotcollection_zh",
        "Collection": "CoT Collection",
        "Collection URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Dataset URL": "https://github.com/kaistAI/CoT-Collection",
        "GitHub URL": "https://github.com/kaistAI/CoT-Collection",
        "Hugging Face URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Paper Title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2305.14045",
        "Semantic Scholar Corpus ID": 258841149,
        "Languages": [
            "Chinese",
            "Code"
        ],
        "Task Categories": [
            "Chain-of-Thought",
            "Natural Language Inference",
            "Question Answering",
            "Commonsense Classification",
            "Commonsense Reasoning",
            "Explanation",
            "Dialog Generation",
            "Code",
            "Natural Language Generation (NLG)",
            "Summarization",
            "Cause Effect Classification",
            "Toxicity Detection",
            "Logical Reasoning",
            "Ethics Classification"
        ],
        "Format": [
            "Chain-of-Thought"
        ],
        "Text Metrics": {
            "Num Dialogs": 71638,
            "Mean Inputs Length": 204.6967,
            "Mean Targets Length": 84.34,
            "Max Inputs Length": 2148,
            "Max Targets Length": 1570,
            "Min Inputs Length": 3,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flan-t5"
        ],
        "Model Generated": [
            "flan-t5",
            "OpenAI Codex",
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "KAIST",
            "Yonsei University",
            "NAVER AI Lab"
        ],
        "Licenses": [
            {
                "License": "Non Commercial",
                "License URL": "https://github.com/kaistAI/CoT-Collection#license"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2305.14045"
            }
        ],
        "License Notes": "Uses OpenAI Codex model to generate rationales and ChatGPT to translate to other languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "zh"
        ],
        "Inferred Metadata": {
            "HF Dataset": "kaist-ai/CoT-Collection",
            "HF Config": "en",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-05-23",
            "GitHub License": "",
            "Text Topics": [
                "Math",
                "Geography",
                "Linguistics",
                "Sports",
                "Travel",
                "Logic",
                "Daily routine",
                "History",
                "Biology",
                "Translation"
            ],
            "Github Date": "",
            "HF Date": "2023-06-05",
            "HF Downloads (September 2023)": 103,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    }
}