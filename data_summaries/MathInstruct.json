{
    "mathinstruct": {
        "Unique Dataset Identifier": "mathinstruct",
        "Dataset Name": "mathinstruct",
        "Paper Title": "MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning",
        "Dataset URL": "https://huggingface.co/datasets/TIGER-Lab/MathInstruct",
        "GitHub URL": "https://github.com/TIGER-AI-Lab/MAmmoTH",
        "Hugging Face URL": "https://huggingface.co/datasets/TIGER-Lab/MathInstruct",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mathinstruct",
        "ArXiv URL": "https://arxiv.org/abs/2309.05653",
        "Semantic Scholar Corpus ID": 261696697,
        "Collection": "MathInstruct",
        "Collection URL": "https://github.com/TIGER-AI-Lab/MAmmoTH",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Chain-of-Thought",
            "Instruction Following",
            "Logical Reasoning",
            "Logical Reasoning Question Answering",
            "Probabilistic Reasoning",
            "Probabilistic Reasoning Question Answering",
            "Algebraic Expression Evaluation"
        ],
        "Text Sources": [],
        "Model Generated": [
            "OpenAI GPT-4"
        ],
        "Format": [
            "Zero-shot",
            "Chain-of-Thought",
            "Program-of-Thought"
        ],
        "Human Annotation": "No",
        "Derived from Datasets": [
            "GSM8K",
            "GSM8K-RFT",
            "AQuA-RAT",
            "MATH",
            "TheoremQA",
            "Camel-Math",
            "NumGLUE",
            "MathQA"
        ],
        "Creators": [
            "University of Waterloo",
            "The Ohio State University"
        ],
        "Licenses": [
            {
                "License": "MIT License",
                "License URL": "https://github.com/TIGER-AI-Lab/MAmmoTH#license"
            },
            {
                "License": "OpenAI",
                "License URL": ""
            }
        ],
        "License Notes": "The authors provided a table for licenses of the original datasets. Although one dataset has a cc-by-nc license, the authors chose an MIT license for their curated dataset",
        "License Verified By": "Mohammed Hamdy",
        "Dataset Filter IDs": [
            "cot_MATH_train",
            "cot_TheoremQA",
            "cot_aqua_rat",
            "cot_college_math",
            "cot_gsm_rft",
            "cot_gsm_train",
            "cot_math50k_camel",
            "cot_number_comparison",
            "pot_MATH_train",
            "pot_TheoremQA",
            "pot_aqua_rat_filtered",
            "pot_gsm_gpt4",
            "pot_mathqa",
            "pot_numglue"
        ],
        "Bibtex": "@Article{Yue2023MAmmoTHBM,\n author = {Xiang Yue and Xingwei Qu and Ge Zhang and Yao Fu and Wenhao Huang and Huan Sun and Yu Su and Wenhu Chen},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning},\n volume = {abs/2309.05653},\n year = {2023}\n}\n",
        "Inferred Metadata": {
            "GitHub License": "",
            "GitHub Stars (May 2024)": 276,
            "GitHub Topics": [],
            "Github Date": "",
            "HF Config": "default",
            "HF Config License": "",
            "HF Dataset": "TIGER-Lab/MathInstruct",
            "HF Date": "2023-09-11",
            "HF Downloads (May 2024)": 9841,
            "HF Likes (May 2024)": 175,
            "HF Yaml License": [
                "mit"
            ],
            "PwC Date": "2023-09-11",
            "PwC Description": "MathInstruct is a meticulously curated instruction tuning dataset that combines data from 13 mathematical rationale datasets. It uniquely focuses on the hybrid use of chain-of-thought (CoT) and program-of-thought (PoT) rationales, ensuring extensive coverage of diverse mathematical fields¬π¬≤¬≥.\n\nHere are some key points about the MathInstruct dataset:\n\n\nCompilation: MathInstruct is compiled from 13 math rationale datasets, six of which are newly curated by this work.\nInstruction Types: It emphasizes both CoT (chain-of-thought) and PoT (program-of-thought) rationales, providing a rich foundation of intermediate reasoning.\nCoverage: The dataset spans various mathematical topics, making it valuable for training and evaluating models in mathematical reasoning.\n\nFor more details, you can explore the MathInstruct dataset on Hugging Face or visit the project page¬π‚Å¥. üìöüßÆ\n\n(1) TIGER-Lab/MathInstruct ¬∑ Datasets at Hugging Face. https://huggingface.co/datasets/TIGER-Lab/MathInstruct.\n(2) Mathematical Reasoning: Open-Source LLMs with Hybrid Instructional .... https://news.superagi.com/2023/09/12/mathematical-reasoning-mammoth-models-elevate-open-source-llms-with-hybrid-instructional-techniques/.\n(3) OpenDataLab ÂºïÈ¢ÜAIÂ§ßÊ®°ÂûãÊó∂‰ª£ÁöÑÂºÄÊîæÊï∞ÊçÆÂπ≥Âè∞. https://opendatalab.com/OpenDataLab/MathInstruct.\n(4) MathInstruct. https://www.modelscope.cn/datasets/AI-ModelScope/MathInstruct/summary.\n(5) undefined. https://tiger-ai-lab.github.io/MAmmoTH/.",
            "PwC License Name": [
                null
            ],
            "PwC License URL": [
                null
            ],
            "S2 Citation Count (May 2024)": 111,
            "S2 Date": "2023-09-11"
        },
        "Text Metrics": {
            "Num Dialogs": 262039,
            "Mean Inputs Length": 247.275,
            "Mean Targets Length": 435.078,
            "Max Inputs Length": 5072,
            "Max Targets Length": 6333,
            "Min Inputs Length": 16,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        }
    }
}