{
    "open-orca-niv": {
        "Unique Dataset Identifier": "open-orca-niv",
        "Dataset Name": "Open Orca niv",
        "Collection": "Open Orca",
        "Collection URL": "https://huggingface.co/datasets/Open-Orca/OpenOrca",
        "Dataset URL": "https://atlas.nomic.ai/map/c1b88b47-2d9b-47e0-9002-b80766792582/2560fd25-52fe-42f1-a58f-ff5eccc890d2",
        "GitHub URL": "https://github.com/Agora-X/Orca",
        "Hugging Face URL": "https://huggingface.co/datasets/Open-Orca/OpenOrca",
        "Paper Title": "Orca: Progressive Learning from Complex Explanation Traces of GPT-4",
        "Papers with Code URL": "https://paperswithcode.com/dataset/big-bench",
        "ArXiv URL": "https://arxiv.org/abs/2306.02707",
        "Semantic Scholar Corpus ID": "256415991",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Information Extraction",
            "Question Understanding",
            "Bias Detection",
            "Toxicity Detection",
            "Natural Language Inference",
            "Sequence Tagging",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 293396,
            "Mean Inputs Length": 893.9349,
            "Mean Targets Length": 513.4336,
            "Max Inputs Length": 38832,
            "Max Targets Length": 16718,
            "Min Inputs Length": 47,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "project gutenberg",
            "jigsaw civil comments",
            "stormfront.org",
            "huffpost.com",
            "ohchr.org",
            "acn.cat",
            "reddit",
            "translated movie subtitiles",
            "web exams",
            "verbnet",
            "european central bank",
            "politifact.com",
            "yelp",
            "worldtree",
            "propara",
            "conversations",
            "sat exams",
            "opus movie subtitles",
            "rottentomatoes.com",
            "moniteur belge/belgisch staatsblad",
            "github.com/miras-tech/mirastext",
            "amara.org",
            "sadilar",
            "github.com/christos-c/bible-corpus",
            "daily nayadiganta",
            "harvard caselaw project",
            "dailymail.co.uk",
            "theonion.com",
            "wikihow.com",
            "de morgen newspaper",
            "fiction books",
            "craigslist.org",
            "movies.stackexchange.com",
            "cooking.stackexchange.com",
            "wikisource",
            "the chronicles of newgate",
            "marion harland's cookery for beginners",
            "semantic scholar articles",
            "last.fm",
            "pri",
            "ted.com",
            "non-fiction books",
            "anandabazar patrika",
            "udacity.com",
            "amazon.com",
            "thai government documents",
            "factcheck",
            "loria",
            "us congressional bills",
            "dihana",
            "khanacademy.org",
            "jeopardy",
            "javabkoo.com",
            "debatepedia.org",
            "gv news",
            "healthtap.com",
            "travel.stackexchange.com",
            "freebase",
            "globalvoices.org",
            "quizdb.org",
            "gmat",
            "bbc",
            "moniteur belge newspaper",
            "cnn.com",
            "sports web articles",
            "frankfurter rundshau newspaper",
            "taskmaster-1 dataset",
            "von news",
            "masc dataset",
            "movies",
            "opus dogc corpus",
            "cawac corpus",
            "winograd schema challenge dataset",
            "eu legistlative texts",
            "youtube",
            "huggingface.co/datasets/facebook/babi_qa",
            "drupal.org/project/civilcomments",
            "ag news",
            "amazon.com",
            "dbpedia",
            "sogou news",
            "yahoo! answers",
            "yahoo review",
            "national commission on terrorist attacks reports",
            "crowdsourced (amt)",
            "callhome spanish",
            "the science - history of the universe",
            "bing search queries",
            "iranian university exams",
            "creative commons license textbooks",
            "stories",
            "patents.google.com",
            "books",
            "nytmes",
            "reuters.com",
            "templates",
            "eur-lex portal",
            "california state bills",
            "webdunia.com",
            "paracrawl",
            "yelp",
            "imdb.com",
            "google search",
            "tripadvisor",
            "the national university of singapore (nus) sms corpus",
            "sports portal",
            "wordnet",
            "wikipedia.org",
            "sec.gov/edgar/about",
            "ap news",
            "maptask",
            "idebate.org",
            "out of his mind (book)",
            "cooking websites",
            "wikinews",
            "blogs",
            "createdebate.com",
            "4forums.com",
            "convinceme.net",
            "hyatt.com",
            "academic paper reviews",
            "hosted by scholastic corporation.",
            "zee news",
            "trivia websites",
            "debate.org",
            "crowdsourced (daemo)",
            "wenshu.court.gov.cn",
            "sogou news",
            "9/11 reports",
            "microsoft research paraphrase identification corpus",
            "online novels",
            "government speeches",
            "gab.com",
            "friends tv show",
            "sentences written by english language learners for the toefl exam",
            "pib.gov.in/indexd.aspx",
            "mozilla common voice dataset",
            "poems written by children in grades 1 to 12",
            "etv bangla",
            "protobowl.com",
            "spanish efe news agency",
            "human",
            "online newspaper articles",
            "arts and crafts essays",
            "bapra.bg",
            "daily jugontor",
            "digikala.com",
            "spontaneanation podcast",
            "newswire",
            "catalan open subtitles",
            "slate magazine",
            "vol. 5: biology",
            "gre exams",
            "bond fm radio",
            "ukwac",
            "quora",
            "flickr",
            "facebook",
            "grammar-based",
            "fullfact",
            "dime",
            "conceptnet",
            "textbooks",
            "dbpedia",
            "yahoo! answers",
            "original",
            "twitter",
            "family feud",
            "google syntactic n-grams",
            "quran",
            "debatewise.org",
            "youtube",
            "github.com/commonsense/omcs",
            "the president's commission report on the JFK assassination",
            "tehran english-persian parallel corpus",
            "catalan government crawling",
            "diplomacy (online game)",
            "icwsm.org/data",
            "ntv",
            "fiction e-books",
            "ag news",
            "truthorfiction",
            "custom model/code generated",
            "linkedin",
            "commoncrawl.org",
            "wiktionary.org",
            "anc.org",
            "movie scripts",
            "academic papers",
            "nps.gov",
            "letters",
            "opus software projects",
            "search-engine(google) auto-complete",
            "stackexchange.com",
            "yahoo",
            "coursera.org",
            "yoruba proverbs",
            "press releases",
            "mctest",
            "pmindia.gov.in/en/mann-ki-baat",
            "wikidata",
            "crowdsourced",
            "openreview.net",
            "arc corpus",
            "ilisten",
            "encyclopedic articles",
            "abc",
            "deutsche welle",
            "allegro.pl",
            "opensubtitles.org",
            "web search queries",
            "wsj",
            "wikipedia.org",
            "voa",
            "answers.com",
            "verbmobil",
            "jeopardy",
            "pubmed articles",
            "casetext company",
            "whitehouse.gov",
            "procon.org",
            "eurovoc thesaurus",
            "the fireside chats of franklin delano roosevelt",
            "travel guides",
            "sanidad.gob.es",
            "snopes.com",
            "lexisnexis database",
            "telephone conversations",
            "select thai websites",
            "newsela",
            "european union",
            "pubmed",
            "spinn3r blogs",
            "ck12.org",
            "opus",
            "the seven wonders of the ancient world",
            "editorials",
            "ict localisation data",
            "goodreads.com",
            "creative commons license texts",
            "allocine.fr",
            "chat with agent",
            "launchpad.net",
            "health news reviews (hnr)",
            "wikianswers",
            "anc corpus",
            "virtual reality collection",
            "tiwall.com",
            "google play store",
            "open movie database",
            "jw news",
            "daily prothom alo",
            "dainik jugasankha",
            "discussion forums",
            "jon.dehdari.org/corpora",
            "biomed articles",
            "undisclosed web"
        ],
        "Model Generated": [
            "OpenAI GPT-3",
            "OpenAI GPT-4"
        ],
        "Creators": [
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "Various",
                "License URL": "https://github.com/google-research/FLAN/tree/main/flan/v2"
            },
            {
                "License": "MIT License",
                "License URL": "https://huggingface.co/datasets/Open-Orca/OpenOrca"
            },
            {
                "License": "OpenAI",
                "License URL": "https://github.com/Agora-X/Orca"
            }
        ],
        "License Notes": "A data instance in this dataset represents entries from the FLAN collection which have been augmented by submitting the listed question to either GPT-4 or GPT-3.5. The response is then entered into the response field.",
        "License Verified By": "Alexis Wu",
        "Dataset Filter IDs": [
            "niv"
        ],
        "Inferred Metadata": {
            "GitHub License": "GNU General Public License v3.0",
            "Github Date": "",
            "HF Date": "2023-06-15",
            "HF Downloads (September 2023)": 29829,
            "HF Likes (September 2023)": 628,
            "PwC Date": "2022-06-09",
            "PwC Description": "The Beyond the Imitation Game Benchmark (BIG-bench) is a collaborative benchmark intended to probe large language models and extrapolate their future capabilities. Big-bench include more than 200 tasks.",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "https://github.com/google/BIG-bench/blob/main/LICENSE",
            "S2 Citation Count (September 2023)": "",
            "S2 Date": "",
            "GitHub Stars": 25,
            "GitHub Topics": [],
            "Text Topics": [
                "Translation",
                "Language learning",
                "Multilingualism",
                "Linguistics",
                "Language processing",
                "Critical thinking",
                "General knowledge",
                "Natural Language Processing",
                "Language proficiency",
                "Logic"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [
            "Flan Collection"
        ]
    },
    "open-orca-t0": {
        "Unique Dataset Identifier": "open-orca-t0",
        "Dataset Name": "Open Orca t0",
        "Collection": "Open Orca",
        "Collection URL": "https://huggingface.co/datasets/Open-Orca/OpenOrca",
        "Dataset URL": "https://atlas.nomic.ai/map/c1b88b47-2d9b-47e0-9002-b80766792582/2560fd25-52fe-42f1-a58f-ff5eccc890d2",
        "GitHub URL": "https://github.com/Agora-X/Orca",
        "Hugging Face URL": "https://huggingface.co/datasets/Open-Orca/OpenOrca",
        "Paper Title": "Orca: Progressive Learning from Complex Explanation Traces of GPT-4",
        "Papers with Code URL": "https://paperswithcode.com/dataset/big-bench",
        "ArXiv URL": "https://arxiv.org/abs/2306.02707",
        "Semantic Scholar Corpus ID": "256415991",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Information Extraction",
            "Question Understanding",
            "Sentiment Analysis",
            "Summarization",
            "Commonsense Reasoning"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2149573,
            "Mean Inputs Length": 1521.1713,
            "Mean Targets Length": 420.2,
            "Max Inputs Length": 36325,
            "Max Targets Length": 7954,
            "Min Inputs Length": 24,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "books",
            "dbpedia",
            "crowdsourced (amt)",
            "yahoo! answers",
            "imdb.com",
            "wikipedia.org",
            "yelp",
            "ag news",
            "web exams",
            "creative commons license textbooks",
            "bing search queries",
            "amazon.com",
            "sogou news",
            "propara",
            "crowdsourced",
            "ck12.org",
            "conceptnet",
            "undisclosed web"
        ],
        "Model Generated": [
            "OpenAI GPT-3",
            "OpenAI GPT-4"
        ],
        "Creators": [
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "Various",
                "License URL": "https://github.com/google-research/FLAN/tree/main/flan/v2"
            },
            {
                "License": "MIT License",
                "License URL": "https://huggingface.co/datasets/Open-Orca/OpenOrca"
            },
            {
                "License": "OpenAI",
                "License URL": "https://github.com/Agora-X/Orca"
            }
        ],
        "License Notes": "A data instance in this dataset represents entries from the FLAN collection which have been augmented by submitting the listed question to either GPT-4 or GPT-3.5. The response is then entered into the response field.",
        "License Verified By": "Alexis Wu",
        "Dataset Filter IDs": [
            "t0"
        ],
        "Inferred Metadata": {
            "GitHub License": "GNU General Public License v3.0",
            "Github Date": "",
            "HF Date": "2023-06-15",
            "HF Downloads (September 2023)": 29829,
            "HF Likes (September 2023)": 628,
            "PwC Date": "2022-06-09",
            "PwC Description": "The Beyond the Imitation Game Benchmark (BIG-bench) is a collaborative benchmark intended to probe large language models and extrapolate their future capabilities. Big-bench include more than 200 tasks.",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "https://github.com/google/BIG-bench/blob/main/LICENSE",
            "S2 Citation Count (September 2023)": "",
            "S2 Date": "",
            "GitHub Stars": 25,
            "GitHub Topics": [],
            "Text Topics": [
                "Geology",
                "History",
                "Sports",
                "Geography",
                "Biology",
                "Earth Science",
                "Reading comprehension",
                "Biography",
                "Product reviews",
                "Music"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [
            "Flan Collection"
        ]
    },
    "open-orca-cot": {
        "Unique Dataset Identifier": "open-orca-cot",
        "Dataset Name": "Open Orca cot",
        "Collection": "Open Orca",
        "Collection URL": "https://huggingface.co/datasets/Open-Orca/OpenOrca",
        "Dataset URL": "https://atlas.nomic.ai/map/c1b88b47-2d9b-47e0-9002-b80766792582/2560fd25-52fe-42f1-a58f-ff5eccc890d2",
        "GitHub URL": "https://github.com/Agora-X/Orca",
        "Hugging Face URL": "https://huggingface.co/datasets/Open-Orca/OpenOrca",
        "Paper Title": "Orca: Progressive Learning from Complex Explanation Traces of GPT-4",
        "Papers with Code URL": "https://paperswithcode.com/dataset/big-bench",
        "ArXiv URL": "https://arxiv.org/abs/2306.02707",
        "Semantic Scholar Corpus ID": "256415991",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Information Extraction",
            "Question Understanding",
            "Chain-of-Thought",
            "Explanation",
            "Logical Reasoning Question Answering",
            "Commonsense Reasoning"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 141695,
            "Mean Inputs Length": 382.8741,
            "Mean Targets Length": 650.5565,
            "Max Inputs Length": 34752,
            "Max Targets Length": 13788,
            "Min Inputs Length": 103,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "sbic",
            "crowdsourced (amt)",
            "comve",
            "gre exams",
            "wikipedia.org",
            "gmat",
            "ecqa",
            "e-snli",
            "crowdsourced",
            "ck12.org",
            "conceptnet"
        ],
        "Model Generated": [
            "OpenAI GPT-3",
            "OpenAI GPT-4"
        ],
        "Creators": [
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "Various",
                "License URL": "https://github.com/google-research/FLAN/tree/main/flan/v2"
            },
            {
                "License": "MIT License",
                "License URL": "https://huggingface.co/datasets/Open-Orca/OpenOrca"
            },
            {
                "License": "OpenAI",
                "License URL": "https://github.com/Agora-X/Orca"
            }
        ],
        "License Notes": "A data instance in this dataset represents entries from the FLAN collection which have been augmented by submitting the listed question to either GPT-4 or GPT-3.5. The response is then entered into the response field.",
        "License Verified By": "Alexis Wu",
        "Dataset Filter IDs": [
            "cot"
        ],
        "Inferred Metadata": {
            "GitHub License": "GNU General Public License v3.0",
            "Github Date": "",
            "HF Date": "2023-06-15",
            "HF Downloads (September 2023)": 29829,
            "HF Likes (September 2023)": 628,
            "PwC Date": "2022-06-09",
            "PwC Description": "The Beyond the Imitation Game Benchmark (BIG-bench) is a collaborative benchmark intended to probe large language models and extrapolate their future capabilities. Big-bench include more than 200 tasks.",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "https://github.com/google/BIG-bench/blob/main/LICENSE",
            "S2 Citation Count (September 2023)": "",
            "S2 Date": "",
            "GitHub Stars": 25,
            "GitHub Topics": [],
            "Text Topics": [
                "Logic",
                "Sports",
                "Language comprehension",
                "Mathematics",
                "General knowledge",
                "Problem-solving",
                "Logic and reasoning",
                "Visual perception",
                "Language and grammar",
                "Reasoning"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [
            "Flan Collection"
        ]
    },
    "open-orca-flan": {
        "Unique Dataset Identifier": "open-orca-flan",
        "Dataset Name": "Open Orca flan",
        "Collection": "Open Orca",
        "Collection URL": "https://huggingface.co/datasets/Open-Orca/OpenOrca",
        "Dataset URL": "https://atlas.nomic.ai/map/c1b88b47-2d9b-47e0-9002-b80766792582/2560fd25-52fe-42f1-a58f-ff5eccc890d2",
        "GitHub URL": "https://github.com/Agora-X/Orca",
        "Hugging Face URL": "https://huggingface.co/datasets/Open-Orca/OpenOrca",
        "Paper Title": "Orca: Progressive Learning from Complex Explanation Traces of GPT-4",
        "Papers with Code URL": "https://paperswithcode.com/dataset/big-bench",
        "ArXiv URL": "https://arxiv.org/abs/2306.02707",
        "Semantic Scholar Corpus ID": "256415991",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Information Extraction",
            "Question Understanding",
            "Sentiment Analysis",
            "Summarization",
            "Translation",
            "Commonsense Reasoning"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1649259,
            "Mean Inputs Length": 852.659,
            "Mean Targets Length": 569.649,
            "Max Inputs Length": 40653,
            "Max Targets Length": 12279,
            "Min Inputs Length": 113,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "project gutenberg",
            "united nations",
            "ai2 science questions",
            "image descriptions",
            "student answers",
            "news commentary",
            "sogou news",
            "reddit",
            "czeng v1.6pre",
            "web exams",
            "mctest",
            "forum posts",
            "verbnet",
            "activitynet",
            "crowdsourced",
            "yelp",
            "nytmes",
            "race exams",
            "rottentomatoes.com",
            "opus news-commentary",
            "opensubtitles.org",
            "quora",
            "wikipedia.org",
            "wsj",
            "articles on society",
            "flickr",
            "grammar-based",
            "enron corporation",
            "bloomberg news",
            "imdb.com",
            "model generated negative candidates using adversarial filtering",
            "google search",
            "dailymail.co.uk",
            "wiktionary.org",
            "cmu movie plots",
            "wikihow.com",
            "european parliament proceedings",
            "wordnet",
            "dbpedia",
            "u.s. government reports",
            "yandex",
            "bbc",
            "original",
            "yahoo! answers",
            "glosses",
            "twitter",
            "syntax textbooks",
            "ap news",
            "articles on history and anthropology",
            "amazon.com",
            "ck12.org",
            "icwsm.org/data",
            "washington post",
            "law and justice",
            "instructables.com",
            "ag news",
            "cnn.com",
            "central news agency of taiwan",
            "videos",
            "9/11 reports",
            "commoncrawl.org",
            "anc.org",
            "xinhua news agency",
            "crowdsourced (daemo)",
            "los angeles times",
            "agence france-presse",
            "wikipedia headlines",
            "undisclosed web"
        ],
        "Model Generated": [
            "OpenAI GPT-3",
            "OpenAI GPT-4"
        ],
        "Creators": [
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "Various",
                "License URL": "https://github.com/google-research/FLAN/tree/main/flan/v2"
            },
            {
                "License": "MIT License",
                "License URL": "https://huggingface.co/datasets/Open-Orca/OpenOrca"
            },
            {
                "License": "OpenAI",
                "License URL": "https://github.com/Agora-X/Orca"
            }
        ],
        "License Notes": "A data instance in this dataset represents entries from the FLAN collection which have been augmented by submitting the listed question to either GPT-4 or GPT-3.5. The response is then entered into the response field.",
        "License Verified By": "Alexis Wu",
        "Dataset Filter IDs": [
            "flan"
        ],
        "Inferred Metadata": {
            "GitHub License": "GNU General Public License v3.0",
            "Github Date": "",
            "HF Date": "2023-06-15",
            "HF Downloads (September 2023)": 29829,
            "HF Likes (September 2023)": 628,
            "PwC Date": "2022-06-09",
            "PwC Description": "The Beyond the Imitation Game Benchmark (BIG-bench) is a collaborative benchmark intended to probe large language models and extrapolate their future capabilities. Big-bench include more than 200 tasks.",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "https://github.com/google/BIG-bench/blob/main/LICENSE",
            "S2 Citation Count (September 2023)": "",
            "S2 Date": "",
            "GitHub Stars": 25,
            "GitHub Topics": [],
            "Text Topics": [
                "Translation",
                "Geography",
                "Sports",
                "Grammar",
                "Technology",
                "General knowledge",
                "Health",
                "Language and grammar",
                "Logic",
                "Critical thinking"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [
            "Flan Collection"
        ]
    }
}