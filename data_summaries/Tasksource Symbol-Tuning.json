{
    "tsy-babi_nli-two_arg_relations": {
        "Unique Dataset Identifier": "tsy-babi_nli-two_arg_relations",
        "Dataset Name": "babi_nli-two_arg_relations",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 1109.2793,
            "Mean Targets Length": 6.6937,
            "Max Inputs Length": 1156,
            "Max Targets Length": 13,
            "Min Inputs Length": 1058,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/two-arg-relations"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Logic",
                "Translation",
                "Language understanding",
                "Spatial relationships",
                "Geography",
                "Language",
                "Directions",
                "Language comprehension"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-three_supporting_facts": {
        "Unique Dataset Identifier": "tsy-babi_nli-three_supporting_facts",
        "Dataset Name": "babi_nli-three_supporting_facts",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 13320.9009,
            "Mean Targets Length": 6.5405,
            "Max Inputs Length": 23363,
            "Max Targets Length": 14,
            "Min Inputs Length": 6957,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/three-supporting-facts"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Travel",
                "Sports",
                "Object possession",
                "Daily routine",
                "Geography",
                "Object manipulation",
                "General knowledge",
                "Location",
                "Actions",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-indefinite_knowledge": {
        "Unique Dataset Identifier": "tsy-babi_nli-indefinite_knowledge",
        "Dataset Name": "babi_nli-indefinite_knowledge",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 102,
            "Mean Inputs Length": 2054.1569,
            "Mean Targets Length": 6.8824,
            "Max Inputs Length": 2560,
            "Max Targets Length": 15,
            "Min Inputs Length": 1374,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/indefinite-knowledge"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Inference",
                "Language understanding",
                "Travel",
                "Inference and reasoning",
                "General knowledge",
                "Deductive reasoning",
                "Logic",
                "Location",
                "Reasoning"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-time_reasoning": {
        "Unique Dataset Identifier": "tsy-babi_nli-time_reasoning",
        "Dataset Name": "babi_nli-time_reasoning",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 3419.1171,
            "Mean Targets Length": 6.4505,
            "Max Inputs Length": 4544,
            "Max Targets Length": 18,
            "Min Inputs Length": 2517,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/time-reasoning"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Location",
                "Travel",
                "General knowledge",
                "Identity",
                "Logic",
                "Inference",
                "Daily routine",
                "Language"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-two_supporting_facts": {
        "Unique Dataset Identifier": "tsy-babi_nli-two_supporting_facts",
        "Dataset Name": "babi_nli-two_supporting_facts",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 4568.5135,
            "Mean Targets Length": 6.4324,
            "Max Inputs Length": 6383,
            "Max Targets Length": 12,
            "Min Inputs Length": 2893,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/two-supporting-facts"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Language and grammar",
                "Object manipulation",
                "Language understanding",
                "Sports",
                "General knowledge",
                "Location",
                "Daily routine",
                "Inference"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-path_finding": {
        "Unique Dataset Identifier": "tsy-babi_nli-path_finding",
        "Dataset Name": "babi_nli-path_finding",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 2289.1982,
            "Mean Targets Length": 6.6757,
            "Max Inputs Length": 2330,
            "Max Targets Length": 14,
            "Min Inputs Length": 2240,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/path-finding"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Daily routine",
                "Directions and navigation",
                "Logic and reasoning",
                "Directions",
                "Interior design",
                "Spatial reasoning"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-yes_no_questions": {
        "Unique Dataset Identifier": "tsy-babi_nli-yes_no_questions",
        "Dataset Name": "babi_nli-yes_no_questions",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 109,
            "Mean Inputs Length": 2084.4312,
            "Mean Targets Length": 6.8807,
            "Max Inputs Length": 3354,
            "Max Targets Length": 14,
            "Min Inputs Length": 1402,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/yes-no-questions"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Daily routine",
                "Travel",
                "Language understanding",
                "Location",
                "Reasoning",
                "Inference",
                "Geography",
                "Textual entailment",
                "Sports"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-basic_coreference": {
        "Unique Dataset Identifier": "tsy-babi_nli-basic_coreference",
        "Dataset Name": "babi_nli-basic_coreference",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 2229.5676,
            "Mean Targets Length": 6.4144,
            "Max Inputs Length": 2955,
            "Max Targets Length": 12,
            "Min Inputs Length": 1414,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/basic-coreference"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Daily routine",
                "Geography",
                "Reasoning",
                "Location",
                "Inference",
                "Sequence of events",
                "Language understanding",
                "General knowledge",
                "Travel",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-counting": {
        "Unique Dataset Identifier": "tsy-babi_nli-counting",
        "Dataset Name": "babi_nli-counting",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 2937.3604,
            "Mean Targets Length": 6.6216,
            "Max Inputs Length": 4499,
            "Max Targets Length": 13,
            "Min Inputs Length": 1864,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/counting"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Travel",
                "Object identification",
                "Location",
                "Logic",
                "Inference",
                "Sports",
                "Language understanding",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-compound_coreference": {
        "Unique Dataset Identifier": "tsy-babi_nli-compound_coreference",
        "Dataset Name": "babi_nli-compound_coreference",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 2548.1802,
            "Mean Targets Length": 6.5405,
            "Max Inputs Length": 3480,
            "Max Targets Length": 12,
            "Min Inputs Length": 1610,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/compound-coreference"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Social interactions",
                "General knowledge",
                "Travel",
                "Inference",
                "Location",
                "Logic",
                "Daily routine",
                "Language understanding",
                "Geography"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-three_arg_relations": {
        "Unique Dataset Identifier": "tsy-babi_nli-three_arg_relations",
        "Dataset Name": "babi_nli-three_arg_relations",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 5392.5676,
            "Mean Targets Length": 6.8378,
            "Max Inputs Length": 9193,
            "Max Targets Length": 13,
            "Min Inputs Length": 3307,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/three-arg-relations"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Object possession",
                "Daily routine",
                "Communication",
                "Object manipulation",
                "Sports",
                "Location",
                "Inference",
                "Language understanding",
                "Travel"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-single_supporting_fact": {
        "Unique Dataset Identifier": "tsy-babi_nli-single_supporting_fact",
        "Dataset Name": "babi_nli-single_supporting_fact",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 2019.7297,
            "Mean Targets Length": 6.7748,
            "Max Inputs Length": 2668,
            "Max Targets Length": 14,
            "Min Inputs Length": 1276,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/single-supporting-fact"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Daily routine",
                "Travel",
                "Inference",
                "Language understanding",
                "General knowledge",
                "Logic",
                "Location tracking",
                "Reasoning",
                "Logical reasoning",
                "Location"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-simple_negation": {
        "Unique Dataset Identifier": "tsy-babi_nli-simple_negation",
        "Dataset Name": "babi_nli-simple_negation",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 91,
            "Mean Inputs Length": 1956.7582,
            "Mean Targets Length": 7.0659,
            "Max Inputs Length": 2422,
            "Max Targets Length": 15,
            "Min Inputs Length": 1561,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/simple-negation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Logic",
                "Language understanding",
                "Location",
                "Reasoning",
                "Spatial reasoning",
                "Inference"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-lists_sets": {
        "Unique Dataset Identifier": "tsy-babi_nli-lists_sets",
        "Dataset Name": "babi_nli-lists_sets",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 2715.2613,
            "Mean Targets Length": 6.4324,
            "Max Inputs Length": 3746,
            "Max Targets Length": 15,
            "Min Inputs Length": 1929,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/lists-sets"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Inference",
                "Travel",
                "Location",
                "Reasoning",
                "Logic",
                "Daily routine",
                "Textual entailment"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-basic_induction": {
        "Unique Dataset Identifier": "tsy-babi_nli-basic_induction",
        "Dataset Name": "babi_nli-basic_induction",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 1703.1892,
            "Mean Targets Length": 6.9009,
            "Max Inputs Length": 1752,
            "Max Targets Length": 14,
            "Min Inputs Length": 1659,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/basic-induction"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Animal colors",
                "General knowledge",
                "Categorization",
                "Logic",
                "Animal classification",
                "Language understanding",
                "Color perception",
                "Animal characteristics",
                "Inference",
                "Reasoning"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-size_reasoning": {
        "Unique Dataset Identifier": "tsy-babi_nli-size_reasoning",
        "Dataset Name": "babi_nli-size_reasoning",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 110,
            "Mean Inputs Length": 2830.2909,
            "Mean Targets Length": 6.5818,
            "Max Inputs Length": 4405,
            "Max Targets Length": 15,
            "Min Inputs Length": 2237,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/size-reasoning"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Inference",
                "Language understanding",
                "Puzzle-solving",
                "General knowledge",
                "Size comparison",
                "Spatial reasoning",
                "Logic",
                "Size and comparison"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-conjunction": {
        "Unique Dataset Identifier": "tsy-babi_nli-conjunction",
        "Dataset Name": "babi_nli-conjunction",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 2563.3604,
            "Mean Targets Length": 6.7477,
            "Max Inputs Length": 3425,
            "Max Targets Length": 15,
            "Min Inputs Length": 1609,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/conjunction"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Social interactions",
                "Reasoning",
                "Language understanding",
                "Inference",
                "Relationships",
                "Daily routine",
                "Textual entailment",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-basic_deduction": {
        "Unique Dataset Identifier": "tsy-babi_nli-basic_deduction",
        "Dataset Name": "babi_nli-basic_deduction",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 2035.2613,
            "Mean Targets Length": 6.4595,
            "Max Inputs Length": 2080,
            "Max Targets Length": 12,
            "Min Inputs Length": 1998,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/basic-deduction"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Animal classification",
                "Animal hierarchy",
                "Predatory instincts",
                "Logic and reasoning",
                "Logic",
                "Categorization of animals",
                "Fear and phobias"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-babi_nli-positional_reasoning": {
        "Unique Dataset Identifier": "tsy-babi_nli-positional_reasoning",
        "Dataset Name": "babi_nli-positional_reasoning",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 1428.6667,
            "Mean Targets Length": 6.5225,
            "Max Inputs Length": 1566,
            "Max Targets Length": 13,
            "Min Inputs Length": 1277,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/positional-reasoning"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Reasoning",
                "Visual perception",
                "Spatial reasoning",
                "Geometry",
                "Spatial relationships"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1029,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsy-wanli": {
        "Unique Dataset Identifier": "tsy-wanli",
        "Dataset Name": "wanli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/alisawuffles/wanli",
        "GitHub URL": "https://github.com/alisawuffles/wanli",
        "Hugging Face URL": "https://huggingface.co/datasets/alisawuffles/WANLI",
        "Paper Title": "WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2201.05955",
        "Semantic Scholar Corpus ID": 246016339,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 1510.5645,
            "Mean Targets Length": 6.6254,
            "Max Inputs Length": 2579,
            "Max Targets Length": 22,
            "Min Inputs Length": 875,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "OpenAI GPT-3"
        ],
        "Creators": [
            "University of Washington",
            "AI2",
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Uses the MultiNLI corpus as a starting point for sentence collection and then uses GPT-3 to write sentences that are similar in structure and topic. The corpus says it is crowdsourced but states to check the paper to be sure. Paper on MultiNLI: https://cims.nyu.edu/~sbowman/multinli/",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "WANLI"
        ],
        "Inferred Metadata": {
            "HF Dataset": "alisawuffles/WANLI",
            "HF Config": "alisawuffles--WANLI",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-01-16",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "General knowledge",
                "Travel",
                "Communication",
                "Interpersonal relationships",
                "Decision-making",
                "History",
                "Language and communication",
                "Politics"
            ],
            "Github Date": "",
            "HF Date": "2022-04-21",
            "HF Downloads (September 2023)": 152,
            "HF Likes (September 2023)": 6,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 104,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "MNLI"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Liu2022WANLIWA,\n author = {Alisa Liu and Swabha Swayamdipta and Noah A. Smith and Yejin Choi},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {6826-6847},\n title = {WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation},\n year = {2022}\n}\n"
    },
    "tsy-recast-recast_verbnet": {
        "Unique Dataset Identifier": "tsy-recast-recast_verbnet",
        "Dataset Name": "recast-recast_verbnet",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://decomp.io/",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/recast",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 141,
            "Mean Inputs Length": 823.9078,
            "Mean Targets Length": 6.4539,
            "Max Inputs Length": 1278,
            "Max Targets Length": 13,
            "Min Inputs Length": 591,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/decompositional-semantics-initiative/decomp#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast/recast_verbnet"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Interpersonal relationships",
                "Textual entailment",
                "Linguistics",
                "Logic",
                "Language",
                "Communication",
                "Information transfer",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 545,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-recast-recast_verbcorner": {
        "Unique Dataset Identifier": "tsy-recast-recast_verbcorner",
        "Dataset Name": "recast-recast_verbcorner",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/recast",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/recast",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 851.3042,
            "Mean Targets Length": 6.6061,
            "Max Inputs Length": 1071,
            "Max Targets Length": 18,
            "Min Inputs Length": 680,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/decompositional-semantics-initiative/decomp#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast/recast_verbcorner"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Inference",
                "Natural language processing",
                "Logic",
                "Logic and reasoning",
                "Communication",
                "Language understanding"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 545,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-recast-recast_ner": {
        "Unique Dataset Identifier": "tsy-recast-recast_ner",
        "Dataset Name": "recast-recast_ner",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/recast",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/recast",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5554,
            "Mean Inputs Length": 1734.0221,
            "Mean Targets Length": 6.6089,
            "Max Inputs Length": 2229,
            "Max Targets Length": 15,
            "Min Inputs Length": 1253,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/decompositional-semantics-initiative/decomp#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast/recast_ner"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Diplomacy",
                "History",
                "Politics",
                "Geography",
                "Current events",
                "General knowledge",
                "Middle East conflict",
                "International relations"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 545,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-recast-recast_sentiment": {
        "Unique Dataset Identifier": "tsy-recast-recast_sentiment",
        "Dataset Name": "recast-recast_sentiment",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/recast",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/recast",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 533,
            "Mean Inputs Length": 1488.3565,
            "Mean Targets Length": 6.6717,
            "Max Inputs Length": 2314,
            "Max Targets Length": 15,
            "Min Inputs Length": 1056,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/decompositional-semantics-initiative/decomp#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast/recast_sentiment"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Product reviews",
                "Restaurant reviews",
                "Customer satisfaction",
                "Personal opinions",
                "Consumer preferences",
                "Communication",
                "Movie reviews",
                "Communication skills",
                "Personal opinions and preferences",
                "Communication and language"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 545,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-recast-recast_puns": {
        "Unique Dataset Identifier": "tsy-recast-recast_puns",
        "Dataset Name": "recast-recast_puns",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/recast",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/recast",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1559,
            "Mean Inputs Length": 1104.7588,
            "Mean Targets Length": 6.5164,
            "Max Inputs Length": 2132,
            "Max Targets Length": 18,
            "Min Inputs Length": 781,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/decompositional-semantics-initiative/decomp#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast/recast_puns"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Humor and puns",
                "Puns and wordplay",
                "Information processing",
                "Language and communication",
                "Communication",
                "Language understanding",
                "General knowledge",
                "Interpretation and understanding",
                "Understanding and interpretation"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 545,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-recast-recast_factuality": {
        "Unique Dataset Identifier": "tsy-recast-recast_factuality",
        "Dataset Name": "recast-recast_factuality",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/recast",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/recast",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4227,
            "Mean Inputs Length": 1568.37,
            "Mean Targets Length": 6.5775,
            "Max Inputs Length": 3163,
            "Max Targets Length": 22,
            "Min Inputs Length": 793,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/decompositional-semantics-initiative/decomp#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast/recast_factuality"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Customer service",
                "Time management",
                "Communication and understanding",
                "Language understanding",
                "National security",
                "Language and communication",
                "Politics",
                "Terrorism"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 545,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-recast-recast_megaveridicality": {
        "Unique Dataset Identifier": "tsy-recast-recast_megaveridicality",
        "Dataset Name": "recast-recast_megaveridicality",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/recast",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/recast",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 787,
            "Mean Inputs Length": 1052.0826,
            "Mean Targets Length": 6.6023,
            "Max Inputs Length": 1187,
            "Max Targets Length": 18,
            "Min Inputs Length": 905,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/decompositional-semantics-initiative/decomp#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast/recast_megaveridicality"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Epistemology",
                "Communication",
                "Inference",
                "General knowledge",
                "Logic",
                "Philosophy",
                "Reasoning",
                "Language understanding"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 545,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-probability_words_nli-reasoning_1hop": {
        "Unique Dataset Identifier": "tsy-probability_words_nli-reasoning_1hop",
        "Dataset Name": "probability_words_nli-reasoning_1hop",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/nlp-verbal-probabilities",
        "GitHub URL": "https://github.com/sileod/nlp-verbal-probabilities",
        "Hugging Face URL": "https://huggingface.co/datasets/sileod/probability_words_nli",
        "Paper Title": "Probing neural language models for understanding of words of estimative probability",
        "Papers with Code URL": "https://paperswithcode.com/dataset/probability-words-nli-1",
        "ArXiv URL": "https://arxiv.org/abs/2211.03358v1",
        "Semantic Scholar Corpus ID": 253383825,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Natural Language Inference",
            "Probabilistic Reasoning Question Answering",
            "Binary Classification Question Answering",
            "Multiple Choice Question Answering",
            "Negation Detection",
            "Logical Reasoning Question Answering",
            "Boolean Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 444,
            "Mean Inputs Length": 2114.5203,
            "Mean Targets Length": 6.4234,
            "Max Inputs Length": 2329,
            "Max Targets Length": 16,
            "Min Inputs Length": 1895,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "babi",
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Lille",
            "KU Leuven"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": null
            },
            {
                "License": "Apache License 2.0",
                "License URL": null
            }
        ],
        "License Notes": "Derived originally from SNLI (CC BY-SA 4.0) and the authors themselves (Apache 2)",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "probability_words_nli/reasoning_1hop"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sileod/probability_words_nli",
            "HF Config": "reasoning_1hop",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "",
            "PwC Date": "2022-11-07",
            "S2 Date": "2022-11-07",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Language and semantics",
                "Linguistics",
                "Animal classification",
                "Reasoning and inference",
                "Logic",
                "Inference",
                "Reasoning"
            ],
            "Github Date": "",
            "HF Date": "2022-11-03",
            "HF Downloads (September 2023)": 154,
            "HF Likes (September 2023)": 3,
            "PwC Description": "This dataset tests the capabilities of language models to correctly capture the meaning of words denoting probabilities (WEP, also called verbal probabilities), e.g. words like \"probably\", \"maybe\", \"surely\", \"impossible\".",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 1,
            "GitHub Topics": [
                "benchmark",
                "classification",
                "dataset",
                "english",
                "entailment",
                "language-model",
                "llm",
                "natural-language",
                "natural-language-inference",
                "nli",
                "nlp",
                "probabilities",
                "probably",
                "probing",
                "verbal",
                "verbal-probabilities",
                "wep"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sileo2022ProbingNL,\n author = {Damien Sileo and M. Moens},\n booktitle = {STARSEM},\n pages = {469-476},\n title = {Probing neural language models for understanding of words of estimative probability},\n year = {2022}\n}\n"
    },
    "tsy-probability_words_nli-usnli": {
        "Unique Dataset Identifier": "tsy-probability_words_nli-usnli",
        "Dataset Name": "probability_words_nli-usnli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://sileod.s3.eu-west-3.amazonaws.com/probability_words/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sileod/probability_words_nli",
        "Paper Title": "Probing neural language models for understanding of words of estimative probability",
        "Papers with Code URL": "https://paperswithcode.com/dataset/probability-words-nli-1",
        "ArXiv URL": "https://arxiv.org/abs/2211.03358v1",
        "Semantic Scholar Corpus ID": 253383825,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Open-Domain Question Answering",
            "Natural Language Inference",
            "Multiple Choice Question Answering",
            "Natural Language Classification",
            "Binary Classification",
            "Open-Domain Relation Extraction"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5553,
            "Mean Inputs Length": 1560.3782,
            "Mean Targets Length": 6.6285,
            "Max Inputs Length": 2099,
            "Max Targets Length": 22,
            "Min Inputs Length": 1130,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "babi",
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Lille",
            "KU Leuven"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": null
            },
            {
                "License": "Apache License 2.0",
                "License URL": null
            }
        ],
        "License Notes": "Derived originally from SNLI (CC BY-SA 4.0) and the authors themselves (Apache 2)",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "probability_words_nli/usnli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sileod/probability_words_nli",
            "HF Config": "reasoning_1hop",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "",
            "PwC Date": "2022-11-07",
            "S2 Date": "2022-11-07",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Logic",
                "Daily routine",
                "Outdoor activities",
                "Observation and perception",
                "Language understanding",
                "Sports",
                "Inference",
                "Visual perception"
            ],
            "Github Date": "",
            "HF Date": "2022-11-03",
            "HF Downloads (September 2023)": 154,
            "HF Likes (September 2023)": 3,
            "PwC Description": "This dataset tests the capabilities of language models to correctly capture the meaning of words denoting probabilities (WEP, also called verbal probabilities), e.g. words like \"probably\", \"maybe\", \"surely\", \"impossible\".",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sileo2022ProbingNL,\n author = {Damien Sileo and M. Moens},\n booktitle = {STARSEM},\n pages = {469-476},\n title = {Probing neural language models for understanding of words of estimative probability},\n year = {2022}\n}\n"
    },
    "tsy-probability_words_nli-reasoning_2hop": {
        "Unique Dataset Identifier": "tsy-probability_words_nli-reasoning_2hop",
        "Dataset Name": "probability_words_nli-reasoning_2hop",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://sileod.s3.eu-west-3.amazonaws.com/probability_words/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sileod/probability_words_nli",
        "Paper Title": "Probing neural language models for understanding of words of estimative probability",
        "Papers with Code URL": "https://paperswithcode.com/dataset/probability-words-nli-1",
        "ArXiv URL": "https://arxiv.org/abs/2211.03358v1",
        "Semantic Scholar Corpus ID": 253383825,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Conditional Probability Inference",
            "Boolean Expression Evaluation",
            "Probabilistic Reasoning",
            "Natural Language Inference",
            "Multiple Choice Question Answering",
            "Probabilistic Reasoning Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 443,
            "Mean Inputs Length": 4992.0045,
            "Mean Targets Length": 6.7065,
            "Max Inputs Length": 5268,
            "Max Targets Length": 16,
            "Min Inputs Length": 4747,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "babi",
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Lille",
            "KU Leuven"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": null
            },
            {
                "License": "Apache License 2.0",
                "License URL": null
            }
        ],
        "License Notes": "Derived originally from SNLI (CC BY-SA 4.0) and the authors themselves (Apache 2)",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "probability_words_nli/reasoning_2hop"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sileod/probability_words_nli",
            "HF Config": "reasoning_1hop",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "",
            "PwC Date": "2022-11-07",
            "S2 Date": "2022-11-07",
            "GitHub License": "",
            "Text Topics": [
                "Deductive reasoning",
                "Probability",
                "Philosophy",
                "Language and communication",
                "Animal classification",
                "Linguistics",
                "Language understanding",
                "Reasoning",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2022-11-03",
            "HF Downloads (September 2023)": 154,
            "HF Likes (September 2023)": 3,
            "PwC Description": "This dataset tests the capabilities of language models to correctly capture the meaning of words denoting probabilities (WEP, also called verbal probabilities), e.g. words like \"probably\", \"maybe\", \"surely\", \"impossible\".",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sileo2022ProbingNL,\n author = {Damien Sileo and M. Moens},\n booktitle = {STARSEM},\n pages = {469-476},\n title = {Probing neural language models for understanding of words of estimative probability},\n year = {2022}\n}\n"
    },
    "tsy-nan_nli-joey234__nan_nli": {
        "Unique Dataset Identifier": "tsy-nan_nli-joey234__nan_nli",
        "Dataset Name": "nan_nli-joey234__nan_nli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/joey234/nan-nli",
        "GitHub URL": "https://github.com/joey234/nan-nli",
        "Hugging Face URL": "https://huggingface.co/datasets/joey234/nan-nli",
        "Paper Title": "Not another Negation Benchmark: The NaN-NLI Test Suite for Sub-clausal Negation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2210.03256",
        "Semantic Scholar Corpus ID": 252762383,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 25,
            "Mean Inputs Length": 966.6,
            "Mean Targets Length": 6.56,
            "Max Inputs Length": 1231,
            "Max Targets Length": 11,
            "Min Inputs Length": 826,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "human",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Melbourne",
            "RMIT University",
            "MBZUAI"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "nan-nli/joey234--nan-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "joey234/nan-nli",
            "HF Config": "joey234--nan-nli",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-10-06",
            "GitHub License": "",
            "Text Topics": [
                "Language understanding",
                "Communication and understanding",
                "Language and communication",
                "Interpersonal relationships",
                "Linguistics",
                "Communication",
                "Daily routine",
                "Logic",
                "Language use",
                "Language"
            ],
            "Github Date": "",
            "HF Date": "2022-10-13",
            "HF Downloads (September 2023)": 78,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 7,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "Pullum and Huddleston 2002"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Truong2022NotAN,\n author = {Thinh Hung Truong and Yulia Otmakhova and Tim Baldwin and Trevor Cohn and Karin M. Verspoor and Jey Han Lau},\n booktitle = {AACL},\n pages = {883-894},\n title = {Not another Negation Benchmark: The NaN-NLI Test Suite for Sub-clausal Negation},\n year = {2022}\n}\n"
    },
    "tsy-nli_fever": {
        "Unique Dataset Identifier": "tsy-nli_fever",
        "Dataset Name": "nli_fever",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/easonnie/combine-FEVER-NSMN/blob/master/other_resources/nli_fever.md",
        "GitHub URL": "https://github.com/easonnie/combine-FEVER-NSMN/blob/master/other_resources/nli_fever.md",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/nli_fever",
        "Paper Title": "Adversarial NLI: A New Benchmark for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1910.14599",
        "Semantic Scholar Corpus ID": 207756753,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5043,
            "Mean Inputs Length": 3450.4194,
            "Mean Targets Length": 6.6094,
            "Max Inputs Length": 7955,
            "Max Targets Length": 22,
            "Min Inputs Length": 1671,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "commoncrawl.org",
            "wikihow.com",
            "crowdsourced",
            "project gutenberg"
        ],
        "Model Generated": [],
        "Creators": [
            "UNC Chapel Hill",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Subset of another dataset: https://arxiv.org/pdf/1803.05355",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "nli_fever"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/nli_fever",
            "HF Config": "pietrolesci--nli_fever",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-10-31",
            "GitHub License": "",
            "Text Topics": [
                "Music",
                "Biography",
                "Sports",
                "Politics",
                "Film industry",
                "Geography",
                "General knowledge",
                "Entertainment industry"
            ],
            "Github Date": "",
            "HF Date": "2022-03-25",
            "HF Downloads (September 2023)": 477,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 601,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "StoryCloze",
            "The Childrens Book Test dataset",
            "RTE5",
            "Manually Annotated Sub-Corpus (MASC) of the Open American National Corpus"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Nie2019AdversarialNA,\n author = {Yixin Nie and Adina Williams and Emily Dinan and Mohit Bansal and J. Weston and Douwe Kiela},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Adversarial NLI: A New Benchmark for Natural Language Understanding},\n volume = {abs/1910.14599},\n year = {2019}\n}\n"
    },
    "tsy-breaking_nli": {
        "Unique Dataset Identifier": "tsy-breaking_nli",
        "Dataset Name": "breaking_nli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/BIU-NLP/Breaking_NLI",
        "GitHub URL": "https://github.com/BIU-NLP/Breaking_NLI",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/breaking_nli",
        "Paper Title": "Breaking NLI Systems with Sentences that Require Simple Lexical Inferences",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1805.02266",
        "Semantic Scholar Corpus ID": 19204066,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 225,
            "Mean Inputs Length": 1281.1867,
            "Mean Targets Length": 6.8444,
            "Max Inputs Length": 1979,
            "Max Targets Length": 15,
            "Min Inputs Length": 868,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "TU Darmstadt",
            "Bar-Ilan University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/BIU-NLP/Breaking_NLI#data-source"
            }
        ],
        "License Notes": "Sentences taken from SNLI Corpus which has CC BY-SA 4.0 license as well. Link: https://nlp.stanford.edu/projects/snli/",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "breaking_nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/breaking_nli",
            "HF Config": "pietrolesci--breaking_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-05-06",
            "GitHub License": "",
            "Text Topics": [
                "Language understanding",
                "Language and semantics",
                "Language and communication",
                "Culture",
                "Visual perception",
                "Geography",
                "Travel"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 33,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 324,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Glockner2018BreakingNS,\n author = {Max Glockner and Vered Shwartz and Yoav Goldberg},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Breaking NLI Systems with Sentences that Require Simple Lexical Inferences},\n volume = {abs/1805.02266},\n year = {2018}\n}\n"
    },
    "tsy-conj_nli": {
        "Unique Dataset Identifier": "tsy-conj_nli",
        "Dataset Name": "conj_nli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/swarnaHub/ConjNLI",
        "GitHub URL": "https://github.com/swarnaHub/ConjNLI",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/conj_nli",
        "Paper Title": "ConjNLI: Natural Language Inference over Conjunctive Sentences",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.10418",
        "Semantic Scholar Corpus ID": 224803276,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1666,
            "Mean Inputs Length": 2082.7503,
            "Mean Targets Length": 6.5588,
            "Max Inputs Length": 2864,
            "Max Targets Length": 18,
            "Min Inputs Length": 1526,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "UNC Chapel Hill"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "conj_nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/conj_nli",
            "HF Config": "pietrolesci--conj_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-20",
            "GitHub License": "MIT License",
            "Text Topics": [
                "History",
                "Music",
                "Tennis",
                "Entertainment industry",
                "Basketball",
                "Education",
                "Linguistics"
            ],
            "Github Date": "",
            "HF Date": "2022-03-25",
            "HF Downloads (September 2023)": 50,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 24,
            "GitHub Stars": 9,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Saha2020ConjNLINL,\n author = {Swarnadeep Saha and Yixin Nie and Mohit Bansal},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {8240-8252},\n title = {ConjNLI: Natural Language Inference over Conjunctive Sentences},\n year = {2020}\n}\n"
    },
    "tsy-fracas": {
        "Unique Dataset Identifier": "tsy-fracas",
        "Dataset Name": "fracas",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/felipessalvatore/NLI_datasets",
        "GitHub URL": "https://github.com/felipessalvatore/NLI_datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/fracas",
        "Paper Title": "Using the framework method for the analysis of qualitative data in multi-disciplinary health research",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 92904,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 23,
            "Mean Inputs Length": 1103.1739,
            "Mean Targets Length": 7.087,
            "Max Inputs Length": 1402,
            "Max Targets Length": 12,
            "Min Inputs Length": 876,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "A 1996 Stanford dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "fracas"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/fracas",
            "HF Config": "pietrolesci--fracas",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2013-09-18",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Daily routine",
                "Time management",
                "Geography",
                "General knowledge",
                "Logic",
                "Language understanding",
                "Reasoning"
            ],
            "Github Date": "",
            "HF Date": "2022-04-22",
            "HF Downloads (September 2023)": 37,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 6030,
            "GitHub Stars": 5,
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Gale2013UsingTF,\n author = {N. Gale and G. Heath and E. Cameron and S. Rashid and S. Redwood},\n booktitle = {BMC Medical Research Methodology},\n journal = {BMC Medical Research Methodology},\n pages = {117 - 117},\n title = {Using the framework method for the analysis of qualitative data in multi-disciplinary health research},\n volume = {13},\n year = {2013}\n}\n"
    },
    "tsy-dialogue_nli": {
        "Unique Dataset Identifier": "tsy-dialogue_nli",
        "Dataset Name": "dialogue_nli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://wellecks.github.io/dialogue_nli/",
        "GitHub URL": "https://wellecks.github.io/dialogue_nli/",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/dialogue_nli",
        "Paper Title": "Dialogue Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1811.00671",
        "Semantic Scholar Corpus ID": 53298765,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 889.2976,
            "Mean Targets Length": 6.6157,
            "Max Inputs Length": 1233,
            "Max Targets Length": 22,
            "Min Inputs Length": 641,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "dialogue_nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/dialogue_nli",
            "HF Config": "pietrolesci--dialogue_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-11-01",
            "GitHub License": "",
            "Text Topics": [
                "Education",
                "Personal interests and hobbies",
                "Daily routine",
                "Personal interests",
                "Personal preferences",
                "Personal experiences",
                "Travel"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 43,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 183,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "Persona-Chat dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Welleck2018DialogueNL,\n author = {S. Welleck and J. Weston and Arthur Szlam and Kyunghyun Cho},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {3731-3741},\n title = {Dialogue Natural Language Inference},\n year = {2018}\n}\n"
    },
    "tsy-mpe": {
        "Unique Dataset Identifier": "tsy-mpe",
        "Dataset Name": "mpe",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/aylai/MultiPremiseEntailment",
        "GitHub URL": "https://github.com/aylai/MultiPremiseEntailment",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/mpe",
        "Paper Title": "Natural Language Inference from Multiple Premises",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1710.02925",
        "Semantic Scholar Corpus ID": 29033327,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 888,
            "Mean Inputs Length": 2684.5225,
            "Mean Targets Length": 6.6284,
            "Max Inputs Length": 3316,
            "Max Targets Length": 16,
            "Min Inputs Length": 2126,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flickr",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Illinois Urbana-Champaign",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mpe"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/mpe",
            "HF Config": "pietrolesci--mpe",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2017-10-09",
            "GitHub License": "",
            "Text Topics": [
                "Photography",
                "Cultural diversity",
                "Fashion",
                "Music",
                "Animals",
                "Daily routine",
                "Visual perception"
            ],
            "Github Date": "",
            "HF Date": "2022-04-22",
            "HF Downloads (September 2023)": 44,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 46,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lai2017NaturalLI,\n author = {Alice Lai and Yonatan Bisk and J. Hockenmaier},\n booktitle = {International Joint Conference on Natural Language Processing},\n journal = {ArXiv},\n title = {Natural Language Inference from Multiple Premises},\n volume = {abs/1710.02925},\n year = {2017}\n}\n"
    },
    "tsy-dnc": {
        "Unique Dataset Identifier": "tsy-dnc",
        "Dataset Name": "dnc",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/decompositional-semantics-initiative/DNC",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/dnc",
        "Paper Title": "Collecting Diverse Natural Language Inference Problems for Sentence Representation Evaluation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1804.08207",
        "Semantic Scholar Corpus ID": 52123220,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 1047.1109,
            "Mean Targets Length": 6.5442,
            "Max Inputs Length": 1948,
            "Max Targets Length": 18,
            "Min Inputs Length": 723,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Johns Hopkins University",
            "BITS Pilani",
            "Goa Campus",
            "Brown University",
            "University of Rochester"
        ],
        "Licenses": [
            {
                "License": "Various",
                "License URL": null
            }
        ],
        "License Notes": "A collection of multiple data sets. Link: https://github.com/decompositional-semantics-initiative/DNC/blob/master/additional_references.md. This lists all sub data sets within this dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "dnc"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/dnc",
            "HF Config": "pietrolesci--dnc",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-04-23",
            "GitHub License": "",
            "Text Topics": [
                "Communication and understanding",
                "Linguistics",
                "Language and communication",
                "Logic",
                "Semantics",
                "Natural language processing",
                "Logic and reasoning",
                "Inference",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 41,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 134,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Poliak2018CollectingDN,\n author = {Adam Poliak and Aparajita Haldar and Rachel Rudinger and J. E. Hu and Ellie Pavlick and Aaron Steven White and Benjamin Van Durme},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {67-81},\n title = {Collecting Diverse Natural Language Inference Problems for Sentence Representation Evaluation},\n year = {2018}\n}\n"
    },
    "tsy-recast_white-fnplus": {
        "Unique Dataset Identifier": "tsy-recast_white-fnplus",
        "Dataset Name": "recast_white-fnplus",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/decompositional-semantics-initiative/DNC/",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/recast_white",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5439,
            "Mean Inputs Length": 3224.3593,
            "Mean Targets Length": 6.5883,
            "Max Inputs Length": 6046,
            "Max Targets Length": 22,
            "Min Inputs Length": 1815,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast_white/fnplus"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Religion",
                "International relations",
                "Politics",
                "History",
                "Language and communication",
                "Linguistics",
                "Nuclear proliferation"
            ],
            "Github Date": "",
            "HF Date": "2022-04-22",
            "HF Downloads (September 2023)": 91,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-recast_white-sprl": {
        "Unique Dataset Identifier": "tsy-recast_white-sprl",
        "Dataset Name": "recast_white-sprl",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/decompositional-semantics-initiative/DNC/",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/recast_white",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4320,
            "Mean Inputs Length": 1832.2278,
            "Mean Targets Length": 6.5519,
            "Max Inputs Length": 2672,
            "Max Targets Length": 22,
            "Min Inputs Length": 1147,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast_white/sprl"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Language and communication",
                "Economics",
                "Finance",
                "International relations",
                "Logic",
                "Language understanding",
                "Language and semantics",
                "Politics",
                "Finance and investment"
            ],
            "Github Date": "",
            "HF Date": "2022-04-22",
            "HF Downloads (September 2023)": 91,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-recast_white-dpr": {
        "Unique Dataset Identifier": "tsy-recast_white-dpr",
        "Dataset Name": "recast_white-dpr",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/decompositional-semantics-initiative/DNC/",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/recast_white",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 366,
            "Mean Inputs Length": 1744.8634,
            "Mean Targets Length": 6.6995,
            "Max Inputs Length": 2286,
            "Max Targets Length": 16,
            "Min Inputs Length": 1204,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast_white/dpr"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Language understanding",
                "Inference",
                "Logic",
                "Language comprehension",
                "Linguistics",
                "Reasoning",
                "Entertainment",
                "Language and communication",
                "Animal behavior"
            ],
            "Github Date": "",
            "HF Date": "2022-04-22",
            "HF Downloads (September 2023)": 91,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-robust_nli-is_cs": {
        "Unique Dataset Identifier": "tsy-robust_nli-is_cs",
        "Dataset Name": "robust_nli-is_cs",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 64,
            "Mean Inputs Length": 2201.6719,
            "Mean Targets Length": 6.9219,
            "Max Inputs Length": 2848,
            "Max Targets Length": 14,
            "Min Inputs Length": 1638,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/easonnie/analyze-compositionality-sensitivity-NLI"
            },
            {
                "License": "MIT License",
                "License URL": "https://github.com/easonnie/analyze-compositionality-sensitivity-NLI"
            },
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/easonnie/analyze-compositionality-sensitivity-NLI"
            }
        ],
        "License Notes": "This subset is originally taken from https://github.com/easonnie/analyze-compositionality-sensitivity-NLI, which is MIT, but is derivative from SNLI (CC BY-SA 4.0) and MNLI (OANC)",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/IS_CS"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Education",
                "Daily routine",
                "International relations",
                "History",
                "Retail industry",
                "Cultural differences",
                "Fundraising"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsy-robust_nli-li_li": {
        "Unique Dataset Identifier": "tsy-robust_nli-li_li",
        "Dataset Name": "robust_nli-li_li",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 232,
            "Mean Inputs Length": 1413.7845,
            "Mean Targets Length": 6.6207,
            "Max Inputs Length": 2345,
            "Max Targets Length": 14,
            "Min Inputs Length": 937,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/AbhilashaRavichander/NLI_StressTest"
            }
        ],
        "License Notes": "This subset is originally taken from https://github.com/AbhilashaRavichander/NLI_StressTest, derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/LI_LI"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Language understanding",
                "Language and communication",
                "Communication",
                "Cultural differences",
                "Culture",
                "Geography",
                "Daily routine",
                "Cultural diversity",
                "Language and semantics"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsy-robust_nli-st_wo": {
        "Unique Dataset Identifier": "tsy-robust_nli-st_wo",
        "Dataset Name": "robust_nli-st_wo",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 983,
            "Mean Inputs Length": 1973.6358,
            "Mean Targets Length": 6.6511,
            "Max Inputs Length": 3090,
            "Max Targets Length": 15,
            "Min Inputs Length": 1151,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/AbhilashaRavichander/NLI_StressTest"
            }
        ],
        "License Notes": "This subset is originally taken from https://github.com/AbhilashaRavichander/NLI_StressTest, derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/ST_WO"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Education",
                "Aviation",
                "Personal preferences",
                "Military operations",
                "Language and linguistics",
                "Terrorism",
                "Language and communication",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsy-robust_nli-pi_sp": {
        "Unique Dataset Identifier": "tsy-robust_nli-pi_sp",
        "Dataset Name": "robust_nli-pi_sp",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 36,
            "Mean Inputs Length": 1997.4167,
            "Mean Targets Length": 6.7222,
            "Max Inputs Length": 2765,
            "Max Targets Length": 11,
            "Min Inputs Length": 1436,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://aclanthology.org/2020.lrec-1.846/"
            },
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://aclanthology.org/2020.lrec-1.846/"
            }
        ],
        "License Notes": "This subset is originally derived from SNLI and MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/PI_SP"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "International relations",
                "Time management",
                "Politics",
                "Storytelling",
                "Language and linguistics",
                "Religion",
                "Aviation",
                "Decision-making"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsy-robust_nli-pi_cd": {
        "Unique Dataset Identifier": "tsy-robust_nli-pi_cd",
        "Dataset Name": "robust_nli-pi_cd",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 325,
            "Mean Inputs Length": 1197.7385,
            "Mean Targets Length": 6.8985,
            "Max Inputs Length": 1544,
            "Max Targets Length": 14,
            "Min Inputs Length": 952,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://aclanthology.org/N18-2017/"
            },
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://aclanthology.org/N18-2017/"
            }
        ],
        "License Notes": "This subset is originally derived from SNLI and MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/PI_CD"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Daily routine",
                "Daily life",
                "Communication",
                "Music",
                "Animals",
                "Fashion",
                "Sports"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsy-robust_nli-st_se": {
        "Unique Dataset Identifier": "tsy-robust_nli-st_se",
        "Dataset Name": "robust_nli-st_se",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3120,
            "Mean Inputs Length": 1791.517,
            "Mean Targets Length": 6.617,
            "Max Inputs Length": 3524,
            "Max Targets Length": 15,
            "Min Inputs Length": 921,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/AbhilashaRavichander/NLI_StressTest"
            }
        ],
        "License Notes": "This subset is originally taken from https://github.com/AbhilashaRavichander/NLI_StressTest, derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/ST_SE"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Education",
                "History",
                "Daily routine",
                "Politics",
                "Language understanding",
                "Time management",
                "Health",
                "Economics"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsy-robust_nli-st_ne": {
        "Unique Dataset Identifier": "tsy-robust_nli-st_ne",
        "Dataset Name": "robust_nli-st_ne",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 983,
            "Mean Inputs Length": 2018.0417,
            "Mean Targets Length": 6.531,
            "Max Inputs Length": 3127,
            "Max Targets Length": 15,
            "Min Inputs Length": 1204,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/AbhilashaRavichander/NLI_StressTest"
            }
        ],
        "License Notes": "This subset is originally taken from https://github.com/AbhilashaRavichander/NLI_StressTest, derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/ST_NE"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Terrorism",
                "Aviation",
                "Logical reasoning",
                "Communication",
                "Child development",
                "Language and linguistics",
                "Education",
                "Language understanding",
                "Logic",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsy-robust_nli-st_lm": {
        "Unique Dataset Identifier": "tsy-robust_nli-st_lm",
        "Dataset Name": "robust_nli-st_lm",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 983,
            "Mean Inputs Length": 2537.1699,
            "Mean Targets Length": 6.7396,
            "Max Inputs Length": 3523,
            "Max Targets Length": 15,
            "Min Inputs Length": 1763,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/AbhilashaRavichander/NLI_StressTest"
            }
        ],
        "License Notes": "This subset is originally taken from https://github.com/AbhilashaRavichander/NLI_StressTest, derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/ST_LM"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Education",
                "Philosophy",
                "Logic",
                "Cognitive processes and reasoning",
                "General knowledge",
                "Communication",
                "Language understanding",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsy-robust_nli_is_sd": {
        "Unique Dataset Identifier": "tsy-robust_nli_is_sd",
        "Dataset Name": "robust_nli_is_sd",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/pietrolesci/robust_nli_is_sd",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli_is_sd",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2999,
            "Mean Inputs Length": 946.2347,
            "Mean Targets Length": 6.4878,
            "Max Inputs Length": 1147,
            "Max Targets Length": 16,
            "Min Inputs Length": 768,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://aclanthology.org/P19-1334/"
            }
        ],
        "License Notes": "Derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli_is_sd"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_is_sd",
            "HF Config": "pietrolesci--robust_nli_is_sd",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Textual entailment",
                "Logic and reasoning",
                "Natural language processing",
                "Sentence structure",
                "Logic",
                "Semantics",
                "Language understanding"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 33,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsy-robust_nli_li_ts": {
        "Unique Dataset Identifier": "tsy-robust_nli_li_ts",
        "Dataset Name": "robust_nli_li_ts",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/pietrolesci/robust_nli_is_sd",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli_li_ts",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Paraphrase Detection",
            "Document Classification",
            "Information Retrieval",
            "Multiple Choice Question Answering",
            "Open-Domain Question Answering",
            "Factual Statement Verification",
            "Sentiment Analysis",
            "Natural Language Inference",
            "Temporal Anomaly Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 730,
            "Mean Inputs Length": 1840.1712,
            "Mean Targets Length": 6.7041,
            "Max Inputs Length": 3071,
            "Max Targets Length": 15,
            "Min Inputs Length": 1100,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://huggingface.co/datasets/pietrolesci/robust_nli_is_sd"
            }
        ],
        "License Notes": "Derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli_li_ts"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Literature",
                "Aviation",
                "Logic",
                "Language and communication",
                "Personal preferences",
                "Education",
                "Linguistics",
                "History"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 33,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsy-gen_debiased_nli-snli_seq_z": {
        "Unique Dataset Identifier": "tsy-gen_debiased_nli-snli_seq_z",
        "Dataset Name": "gen_debiased_nli-snli_seq_z",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "GitHub URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/gen_debiased_nli",
        "Paper Title": "Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets",
        "Papers with Code URL": "https://paperswithcode.com/dataset/gd-nli",
        "ArXiv URL": "https://arxiv.org/abs/2203.12942",
        "Semantic Scholar Corpus ID": 247628095,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 1082.9732,
            "Mean Targets Length": 6.5813,
            "Max Inputs Length": 1565,
            "Max Targets Length": 18,
            "Min Inputs Length": 801,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "University College London",
            "Microsoft Semantic Machines",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/jimmycode/gen-debiased-nli"
            }
        ],
        "License Notes": "Derived from SNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "gen_debiased_nli/snli_seq_z"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/gen_debiased_nli",
            "HF Config": "pietrolesci--gen_debiased_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-03-24",
            "S2 Date": "2022-03-24",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Visual perception",
                "Geography",
                "Outdoor activities",
                "General knowledge",
                "Transportation",
                "Entertainment",
                "Sports",
                "Culture"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 177,
            "HF Likes (September 2023)": 0,
            "PwC Description": "This is a set of debiased Natural Language Inference (NLI) datasets produced by the paper  Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets. The datasets are constructed by augmenting SNLI or MNLI with data samples that are generated to mitigate the spurious correlations in the original datasets. Please visit this repository for more details.\n\nCitation:\n@inproceedings{gen-debiased-nli-2022,\n    title = \"Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets\",\n    author = \"Wu, Yuxiang  and\n      Gardner, Matt  and\n      Stenetorp, Pontus  and\n      Dasigi, Pradeep\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\",\n    month = may,\n    year = \"2022\",\n    publisher = \"Association for Computational Linguistics\",\n}",
            "S2 Citation Count (September 2023)": 31,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "MNLI"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wu2022GeneratingDT,\n author = {Yuxiang Wu and Matt Gardner and Pontus Stenetorp and Pradeep Dasigi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets},\n volume = {abs/2203.12942},\n year = {2022}\n}\n"
    },
    "tsy-gen_debiased_nli-snli_z_aug": {
        "Unique Dataset Identifier": "tsy-gen_debiased_nli-snli_z_aug",
        "Dataset Name": "gen_debiased_nli-snli_z_aug",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "GitHub URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/gen_debiased_nli",
        "Paper Title": "Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets",
        "Papers with Code URL": "https://paperswithcode.com/dataset/gd-nli",
        "ArXiv URL": "https://arxiv.org/abs/2203.12942",
        "Semantic Scholar Corpus ID": 247628095,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 1099.9941,
            "Mean Targets Length": 6.6045,
            "Max Inputs Length": 1655,
            "Max Targets Length": 22,
            "Min Inputs Length": 823,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "University College London",
            "Microsoft Semantic Machines",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/jimmycode/gen-debiased-nli"
            }
        ],
        "License Notes": "Derived from SNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "gen_debiased_nli/snli_z_aug"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/gen_debiased_nli",
            "HF Config": "pietrolesci--gen_debiased_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-03-24",
            "S2 Date": "2022-03-24",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "Sports",
                "Fashion and clothing",
                "General knowledge",
                "Language and communication",
                "Culture",
                "Visual perception",
                "Performing arts"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 177,
            "HF Likes (September 2023)": 0,
            "PwC Description": "This is a set of debiased Natural Language Inference (NLI) datasets produced by the paper  Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets. The datasets are constructed by augmenting SNLI or MNLI with data samples that are generated to mitigate the spurious correlations in the original datasets. Please visit this repository for more details.\n\nCitation:\n@inproceedings{gen-debiased-nli-2022,\n    title = \"Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets\",\n    author = \"Wu, Yuxiang  and\n      Gardner, Matt  and\n      Stenetorp, Pontus  and\n      Dasigi, Pradeep\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\",\n    month = may,\n    year = \"2022\",\n    publisher = \"Association for Computational Linguistics\",\n}",
            "S2 Citation Count (September 2023)": 31,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "MNLI"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wu2022GeneratingDT,\n author = {Yuxiang Wu and Matt Gardner and Pontus Stenetorp and Pradeep Dasigi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets},\n volume = {abs/2203.12942},\n year = {2022}\n}\n"
    },
    "tsy-gen_debiased_nli-snli_par_z": {
        "Unique Dataset Identifier": "tsy-gen_debiased_nli-snli_par_z",
        "Dataset Name": "gen_debiased_nli-snli_par_z",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "GitHub URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/gen_debiased_nli",
        "Paper Title": "Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets",
        "Papers with Code URL": "https://paperswithcode.com/dataset/gd-nli",
        "ArXiv URL": "https://arxiv.org/abs/2203.12942",
        "Semantic Scholar Corpus ID": 247628095,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 1081.9339,
            "Mean Targets Length": 6.5856,
            "Max Inputs Length": 1543,
            "Max Targets Length": 15,
            "Min Inputs Length": 798,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "University College London",
            "Microsoft Semantic Machines",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/jimmycode/gen-debiased-nli"
            }
        ],
        "License Notes": "Derived from SNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "gen_debiased_nli/snli_par_z"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/gen_debiased_nli",
            "HF Config": "pietrolesci--gen_debiased_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-03-24",
            "S2 Date": "2022-03-24",
            "GitHub License": "",
            "Text Topics": [
                "Social interactions",
                "Daily routine",
                "General knowledge",
                "Sports",
                "Politics",
                "Entertainment",
                "Visual perception",
                "Culture",
                "Communication",
                "Photography"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 177,
            "HF Likes (September 2023)": 0,
            "PwC Description": "This is a set of debiased Natural Language Inference (NLI) datasets produced by the paper  Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets. The datasets are constructed by augmenting SNLI or MNLI with data samples that are generated to mitigate the spurious correlations in the original datasets. Please visit this repository for more details.\n\nCitation:\n@inproceedings{gen-debiased-nli-2022,\n    title = \"Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets\",\n    author = \"Wu, Yuxiang  and\n      Gardner, Matt  and\n      Stenetorp, Pontus  and\n      Dasigi, Pradeep\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\",\n    month = may,\n    year = \"2022\",\n    publisher = \"Association for Computational Linguistics\",\n}",
            "S2 Citation Count (September 2023)": 31,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "MNLI"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wu2022GeneratingDT,\n author = {Yuxiang Wu and Matt Gardner and Pontus Stenetorp and Pradeep Dasigi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets},\n volume = {abs/2203.12942},\n year = {2022}\n}\n"
    },
    "tsy-gen_debiased_nli-mnli_par_z": {
        "Unique Dataset Identifier": "tsy-gen_debiased_nli-mnli_par_z",
        "Dataset Name": "gen_debiased_nli-mnli_par_z",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/jimmycode/gen-debiased-nli",
        "GitHub URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/gen_debiased_nli",
        "Paper Title": "Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets",
        "Papers with Code URL": "https://paperswithcode.com/dataset/gd-nli",
        "ArXiv URL": "https://arxiv.org/abs/2203.12942",
        "Semantic Scholar Corpus ID": 247628095,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5554,
            "Mean Inputs Length": 1722.6302,
            "Mean Targets Length": 6.6221,
            "Max Inputs Length": 2889,
            "Max Targets Length": 22,
            "Min Inputs Length": 897,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "University College London",
            "Microsoft Semantic Machines",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/jimmycode/gen-debiased-nli"
            }
        ],
        "License Notes": "Derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "gen_debiased_nli/mnli_par_z"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/gen_debiased_nli",
            "HF Config": "pietrolesci--gen_debiased_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-03-24",
            "S2 Date": "2022-03-24",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "International relations",
                "Journalism",
                "Travel",
                "Architecture",
                "History",
                "Geography",
                "Language and communication",
                "Politics",
                "Tourism"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 177,
            "HF Likes (September 2023)": 0,
            "PwC Description": "This is a set of debiased Natural Language Inference (NLI) datasets produced by the paper  Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets. The datasets are constructed by augmenting SNLI or MNLI with data samples that are generated to mitigate the spurious correlations in the original datasets. Please visit this repository for more details.\n\nCitation:\n@inproceedings{gen-debiased-nli-2022,\n    title = \"Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets\",\n    author = \"Wu, Yuxiang  and\n      Gardner, Matt  and\n      Stenetorp, Pontus  and\n      Dasigi, Pradeep\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\",\n    month = may,\n    year = \"2022\",\n    publisher = \"Association for Computational Linguistics\",\n}",
            "S2 Citation Count (September 2023)": 31,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "MNLI"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wu2022GeneratingDT,\n author = {Yuxiang Wu and Matt Gardner and Pontus Stenetorp and Pradeep Dasigi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets},\n volume = {abs/2203.12942},\n year = {2022}\n}\n"
    },
    "tsy-gen_debiased_nli-mnli_z_aug": {
        "Unique Dataset Identifier": "tsy-gen_debiased_nli-mnli_z_aug",
        "Dataset Name": "gen_debiased_nli-mnli_z_aug",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/jimmycode/gen-debiased-nli",
        "GitHub URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/gen_debiased_nli",
        "Paper Title": "Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets",
        "Papers with Code URL": "https://paperswithcode.com/dataset/gd-nli",
        "ArXiv URL": "https://arxiv.org/abs/2203.12942",
        "Semantic Scholar Corpus ID": 247628095,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 1728.4241,
            "Mean Targets Length": 6.5645,
            "Max Inputs Length": 2872,
            "Max Targets Length": 22,
            "Min Inputs Length": 961,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "University College London",
            "Microsoft Semantic Machines",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/jimmycode/gen-debiased-nli"
            }
        ],
        "License Notes": "Derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "gen_debiased_nli/mnli_z_aug"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/gen_debiased_nli",
            "HF Config": "pietrolesci--gen_debiased_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-03-24",
            "S2 Date": "2022-03-24",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "Politics",
                "General knowledge",
                "Journalism",
                "Travel",
                "Language and communication",
                "Communication",
                "Linguistics"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 177,
            "HF Likes (September 2023)": 0,
            "PwC Description": "This is a set of debiased Natural Language Inference (NLI) datasets produced by the paper  Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets. The datasets are constructed by augmenting SNLI or MNLI with data samples that are generated to mitigate the spurious correlations in the original datasets. Please visit this repository for more details.\n\nCitation:\n@inproceedings{gen-debiased-nli-2022,\n    title = \"Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets\",\n    author = \"Wu, Yuxiang  and\n      Gardner, Matt  and\n      Stenetorp, Pontus  and\n      Dasigi, Pradeep\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\",\n    month = may,\n    year = \"2022\",\n    publisher = \"Association for Computational Linguistics\",\n}",
            "S2 Citation Count (September 2023)": 31,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "MNLI"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wu2022GeneratingDT,\n author = {Yuxiang Wu and Matt Gardner and Pontus Stenetorp and Pradeep Dasigi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets},\n volume = {abs/2203.12942},\n year = {2022}\n}\n"
    },
    "tsy-gen_debiased_nli-mnli_seq_z": {
        "Unique Dataset Identifier": "tsy-gen_debiased_nli-mnli_seq_z",
        "Dataset Name": "gen_debiased_nli-mnli_seq_z",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/jimmycode/gen-debiased-nli",
        "GitHub URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/gen_debiased_nli",
        "Paper Title": "Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets",
        "Papers with Code URL": "https://paperswithcode.com/dataset/gd-nli",
        "ArXiv URL": "https://arxiv.org/abs/2203.12942",
        "Semantic Scholar Corpus ID": 247628095,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5554,
            "Mean Inputs Length": 1729.7144,
            "Mean Targets Length": 6.5722,
            "Max Inputs Length": 2894,
            "Max Targets Length": 16,
            "Min Inputs Length": 965,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "University College London",
            "Microsoft Semantic Machines",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/jimmycode/gen-debiased-nli"
            }
        ],
        "License Notes": "Derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "gen_debiased_nli/mnli_seq_z"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/gen_debiased_nli",
            "HF Config": "pietrolesci--gen_debiased_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-03-24",
            "S2 Date": "2022-03-24",
            "GitHub License": "",
            "Text Topics": [
                "Travel",
                "History",
                "Language and communication",
                "Language understanding",
                "Communication",
                "Technology",
                "Religion",
                "Linguistics",
                "Politics"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 177,
            "HF Likes (September 2023)": 0,
            "PwC Description": "This is a set of debiased Natural Language Inference (NLI) datasets produced by the paper  Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets. The datasets are constructed by augmenting SNLI or MNLI with data samples that are generated to mitigate the spurious correlations in the original datasets. Please visit this repository for more details.\n\nCitation:\n@inproceedings{gen-debiased-nli-2022,\n    title = \"Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets\",\n    author = \"Wu, Yuxiang  and\n      Gardner, Matt  and\n      Stenetorp, Pontus  and\n      Dasigi, Pradeep\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\",\n    month = may,\n    year = \"2022\",\n    publisher = \"Association for Computational Linguistics\",\n}",
            "S2 Citation Count (September 2023)": 31,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "MNLI"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wu2022GeneratingDT,\n author = {Yuxiang Wu and Matt Gardner and Pontus Stenetorp and Pradeep Dasigi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets},\n volume = {abs/2203.12942},\n year = {2022}\n}\n"
    },
    "tsy-add_one_rte": {
        "Unique Dataset Identifier": "tsy-add_one_rte",
        "Dataset Name": "add_one_rte",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/rabeehk/robust-nli/blob/c32ff958d4df68ac2fad9bf990f70d30eab9f297/data/scripts/add_one_rte.py",
        "GitHub URL": "https://github.com/rabeehk/robust-nli/blob/c32ff958d4df68ac2fad9bf990f70d30eab9f297/data/scripts/add_one_rte.py#L51-L52",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/add_one_rte",
        "Paper Title": "End-to-End Bias Mitigation by Modelling Biases in Corpora",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1909.06321",
        "Semantic Scholar Corpus ID": 215191351,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 258,
            "Mean Inputs Length": 1334.3643,
            "Mean Targets Length": 6.4806,
            "Max Inputs Length": 2458,
            "Max Targets Length": 15,
            "Min Inputs Length": 978,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "rte"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "EPFL",
            "Harvard University",
            "Massachusetts Institute of Technology",
            "Idiap Research Institute"
        ],
        "Licenses": [
            {
                "License": "Non Commercial",
                "License URL": "https://tac.nist.gov/data/forms/index.html"
            }
        ],
        "License Notes": "Non-commercial, research only",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "add_one_rte"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/add_one_rte",
            "HF Config": "pietrolesci--add_one_rte",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-09-13",
            "GitHub License": "",
            "Text Topics": [
                "Language and communication",
                "Language and semantics",
                "Sports",
                "Communication",
                "Logic",
                "Politics",
                "Language and linguistics",
                "Inference",
                "Linguistics"
            ],
            "Github Date": "",
            "HF Date": "2022-04-22",
            "HF Downloads (September 2023)": 44,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 117,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Mahabadi2019EndtoEndBM,\n author = {Rabeeh Karimi Mahabadi and Yonatan Belinkov and J. Henderson},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8706-8716},\n title = {End-to-End Bias Mitigation by Modelling Biases in Corpora},\n year = {2019}\n}\n"
    },
    "tsy-imppres-presupposition_all_n_presupposition-presupposition": {
        "Unique Dataset Identifier": "tsy-imppres-presupposition_all_n_presupposition-presupposition",
        "Dataset Name": "imppres-presupposition_all_n_presupposition-presupposition",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 190,
            "Mean Inputs Length": 1349.9053,
            "Mean Targets Length": 6.3737,
            "Max Inputs Length": 1667,
            "Max Targets Length": 13,
            "Min Inputs Length": 1125,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_all_n_presupposition/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Logic and reasoning",
                "Language understanding",
                "Logic",
                "Communication",
                "Mathematics",
                "Reasoning",
                "Linguistics",
                "Language and communication",
                "Education"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-presupposition_both_presupposition-presupposition": {
        "Unique Dataset Identifier": "tsy-imppres-presupposition_both_presupposition-presupposition",
        "Dataset Name": "imppres-presupposition_both_presupposition-presupposition",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 190,
            "Mean Inputs Length": 1243.6526,
            "Mean Targets Length": 6.7684,
            "Max Inputs Length": 1532,
            "Max Targets Length": 14,
            "Min Inputs Length": 1088,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_both_presupposition/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Education",
                "Communication",
                "Mathematics",
                "Reasoning",
                "Language and communication",
                "General knowledge",
                "Language understanding",
                "Logic and reasoning"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-presupposition_change_of_state-presupposition": {
        "Unique Dataset Identifier": "tsy-imppres-presupposition_change_of_state-presupposition",
        "Dataset Name": "imppres-presupposition_change_of_state-presupposition",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 190,
            "Mean Inputs Length": 686.1579,
            "Mean Targets Length": 6.2947,
            "Max Inputs Length": 795,
            "Max Targets Length": 13,
            "Min Inputs Length": 587,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_change_of_state/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Relationships",
                "Logic",
                "Linguistics",
                "Health",
                "Communication",
                "Employment",
                "Language understanding",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-presupposition_cleft_existence-presupposition": {
        "Unique Dataset Identifier": "tsy-imppres-presupposition_cleft_existence-presupposition",
        "Dataset Name": "imppres-presupposition_cleft_existence-presupposition",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 190,
            "Mean Inputs Length": 947.3526,
            "Mean Targets Length": 6.7263,
            "Max Inputs Length": 1133,
            "Max Targets Length": 14,
            "Min Inputs Length": 759,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_cleft_existence/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Communication",
                "Linguistics",
                "Daily routine",
                "Logic and reasoning",
                "Logic",
                "Interpersonal relationships",
                "Language understanding",
                "Relationships"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-presupposition_only_presupposition-presupposition": {
        "Unique Dataset Identifier": "tsy-imppres-presupposition_only_presupposition-presupposition",
        "Dataset Name": "imppres-presupposition_only_presupposition-presupposition",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 190,
            "Mean Inputs Length": 844.8474,
            "Mean Targets Length": 6.2632,
            "Max Inputs Length": 1080,
            "Max Targets Length": 14,
            "Min Inputs Length": 688,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_only_presupposition/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Language and communication",
                "Language understanding",
                "Linguistics",
                "Logic and reasoning",
                "Daily routine",
                "Interpersonal relationships",
                "Health",
                "Logic",
                "Relationships",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-presupposition_possessed_definites_existence-presupposition": {
        "Unique Dataset Identifier": "tsy-imppres-presupposition_possessed_definites_existence-presupposition",
        "Dataset Name": "imppres-presupposition_possessed_definites_existence-presupposition",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 190,
            "Mean Inputs Length": 817.4053,
            "Mean Targets Length": 6.7158,
            "Max Inputs Length": 954,
            "Max Targets Length": 15,
            "Min Inputs Length": 701,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_possessed_definites_existence/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Language understanding",
                "Language and communication",
                "Logic and reasoning",
                "Communication",
                "Logic",
                "General knowledge",
                "Relationships",
                "Personal preferences",
                "Social interactions"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-presupposition_possessed_definites_uniqueness-presupposition": {
        "Unique Dataset Identifier": "tsy-imppres-presupposition_possessed_definites_uniqueness-presupposition",
        "Dataset Name": "imppres-presupposition_possessed_definites_uniqueness-presupposition",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 190,
            "Mean Inputs Length": 1267.8211,
            "Mean Targets Length": 6.6737,
            "Max Inputs Length": 1439,
            "Max Targets Length": 13,
            "Min Inputs Length": 1096,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_possessed_definites_uniqueness/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Photography",
                "Logic",
                "Interpersonal relationships",
                "Linguistics",
                "Language and communication",
                "Communication",
                "Logic and reasoning",
                "Language understanding"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-presupposition_question_presupposition-presupposition": {
        "Unique Dataset Identifier": "tsy-imppres-presupposition_question_presupposition-presupposition",
        "Dataset Name": "imppres-presupposition_question_presupposition-presupposition",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 190,
            "Mean Inputs Length": 1036.2684,
            "Mean Targets Length": 6.4526,
            "Max Inputs Length": 1290,
            "Max Targets Length": 13,
            "Min Inputs Length": 829,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_question_presupposition/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Problem-solving",
                "Communication and understanding",
                "Language and communication",
                "Memory and forgetfulness",
                "Interpersonal relationships",
                "Language understanding",
                "Logic",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-presupposition_cleft_uniqueness-presupposition": {
        "Unique Dataset Identifier": "tsy-imppres-presupposition_cleft_uniqueness-presupposition",
        "Dataset Name": "imppres-presupposition_cleft_uniqueness-presupposition",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 190,
            "Mean Inputs Length": 1061.3474,
            "Mean Targets Length": 6.5,
            "Max Inputs Length": 1256,
            "Max Targets Length": 14,
            "Min Inputs Length": 869,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_cleft_uniqueness/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Social interactions",
                "Language understanding",
                "Language and communication",
                "Logic and reasoning",
                "Logic",
                "Communication",
                "Reasoning"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-implicature_connectives-prag": {
        "Unique Dataset Identifier": "tsy-imppres-implicature_connectives-prag",
        "Dataset Name": "imppres-implicature_connectives-prag",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 43,
            "Mean Inputs Length": 1141.2326,
            "Mean Targets Length": 6.186,
            "Max Inputs Length": 1380,
            "Max Targets Length": 13,
            "Min Inputs Length": 1017,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_connectives/prag"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Logic and reasoning",
                "Logic",
                "Communication",
                "Language and communication",
                "Social interactions",
                "Education",
                "Pragmatics",
                "Linguistics",
                "Language understanding",
                "Language and semantics"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-implicature_gradable_adjective-prag": {
        "Unique Dataset Identifier": "tsy-imppres-implicature_gradable_adjective-prag",
        "Dataset Name": "imppres-implicature_gradable_adjective-prag",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 43,
            "Mean Inputs Length": 584.2558,
            "Mean Targets Length": 6.1628,
            "Max Inputs Length": 629,
            "Max Targets Length": 11,
            "Min Inputs Length": 529,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_gradable_adjective/prag"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Intelligence and abilities",
                "Language and semantics",
                "Body size and appearance",
                "Evaluating individuals",
                "Intelligence",
                "Food",
                "Language and communication",
                "Descriptive language",
                "Personal characteristics and traits",
                "Comparative adjectives"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-implicature_numerals_2_3-prag": {
        "Unique Dataset Identifier": "tsy-imppres-implicature_numerals_2_3-prag",
        "Dataset Name": "imppres-implicature_numerals_2_3-prag",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 87,
            "Mean Inputs Length": 832.2644,
            "Mean Targets Length": 6.4253,
            "Max Inputs Length": 958,
            "Max Targets Length": 14,
            "Min Inputs Length": 733,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_numerals_2_3/prag"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Interpersonal relationships",
                "Education",
                "Daily routine",
                "Language and communication",
                "Logic",
                "General knowledge",
                "Language understanding",
                "Communication",
                "Pragmatics"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-implicature_gradable_verb-prag": {
        "Unique Dataset Identifier": "tsy-imppres-implicature_gradable_verb-prag",
        "Dataset Name": "imppres-implicature_gradable_verb-prag",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 43,
            "Mean Inputs Length": 806.5349,
            "Mean Targets Length": 6.1395,
            "Max Inputs Length": 903,
            "Max Targets Length": 13,
            "Min Inputs Length": 711,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_gradable_verb/prag"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Language understanding",
                "Daily routine",
                "Pragmatics",
                "Social interactions",
                "Geography",
                "Language and communication",
                "Linguistics"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-implicature_numerals_10_100-prag": {
        "Unique Dataset Identifier": "tsy-imppres-implicature_numerals_10_100-prag",
        "Dataset Name": "imppres-implicature_numerals_10_100-prag",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 87,
            "Mean Inputs Length": 871.8966,
            "Mean Targets Length": 6.3448,
            "Max Inputs Length": 964,
            "Max Targets Length": 14,
            "Min Inputs Length": 758,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_numerals_10_100/prag"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Social interactions",
                "Pragmatics",
                "Linguistics",
                "Communication",
                "Logic",
                "Education"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-implicature_modals-prag": {
        "Unique Dataset Identifier": "tsy-imppres-implicature_modals-prag",
        "Dataset Name": "imppres-implicature_modals-prag",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 43,
            "Mean Inputs Length": 835.0465,
            "Mean Targets Length": 6.1628,
            "Max Inputs Length": 1004,
            "Max Targets Length": 12,
            "Min Inputs Length": 660,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_modals/prag"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Language and communication",
                "Communication and understanding",
                "Ethics",
                "Problem-solving",
                "Education",
                "Pragmatics"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-implicature_quantifiers-prag": {
        "Unique Dataset Identifier": "tsy-imppres-implicature_quantifiers-prag",
        "Dataset Name": "imppres-implicature_quantifiers-prag",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 43,
            "Mean Inputs Length": 783.6977,
            "Mean Targets Length": 6.2326,
            "Max Inputs Length": 903,
            "Max Targets Length": 11,
            "Min Inputs Length": 676,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_quantifiers/prag"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Logic and reasoning",
                "Customer behavior",
                "Pragmatics",
                "Language and communication",
                "Communication",
                "Language understanding",
                "Logic",
                "Linguistics",
                "General knowledge",
                "Education"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-implicature_connectives-log": {
        "Unique Dataset Identifier": "tsy-imppres-implicature_connectives-log",
        "Dataset Name": "imppres-implicature_connectives-log",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 118,
            "Mean Inputs Length": 1135.8644,
            "Mean Targets Length": 6.3644,
            "Max Inputs Length": 1307,
            "Max Targets Length": 12,
            "Min Inputs Length": 956,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_connectives/log"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Clothing and fashion",
                "Language and communication",
                "Language",
                "Logic",
                "Grammar",
                "Communication",
                "Relationships",
                "Reasoning"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-implicature_gradable_adjective-log": {
        "Unique Dataset Identifier": "tsy-imppres-implicature_gradable_adjective-log",
        "Dataset Name": "imppres-implicature_gradable_adjective-log",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 118,
            "Mean Inputs Length": 581.2288,
            "Mean Targets Length": 6.1441,
            "Max Inputs Length": 654,
            "Max Targets Length": 13,
            "Min Inputs Length": 525,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_gradable_adjective/log"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Language understanding",
                "Language and semantics",
                "Semantics",
                "General knowledge",
                "Communication",
                "Logic",
                "Intelligence",
                "Food"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-implicature_gradable_verb-log": {
        "Unique Dataset Identifier": "tsy-imppres-implicature_gradable_verb-log",
        "Dataset Name": "imppres-implicature_gradable_verb-log",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 118,
            "Mean Inputs Length": 797.322,
            "Mean Targets Length": 6.4746,
            "Max Inputs Length": 906,
            "Max Targets Length": 13,
            "Min Inputs Length": 645,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_gradable_verb/log"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Geography",
                "Daily routine",
                "Education",
                "Reasoning",
                "Linguistics",
                "Communication",
                "Language understanding",
                "Language and communication",
                "Language"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-implicature_quantifiers-log": {
        "Unique Dataset Identifier": "tsy-imppres-implicature_quantifiers-log",
        "Dataset Name": "imppres-implicature_quantifiers-log",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 118,
            "Mean Inputs Length": 774.1102,
            "Mean Targets Length": 5.9746,
            "Max Inputs Length": 900,
            "Max Targets Length": 12,
            "Min Inputs Length": 637,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_quantifiers/log"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Reasoning",
                "Communication",
                "Language",
                "Language understanding",
                "Language and communication",
                "Clothing and fashion",
                "Social interactions",
                "Philosophy"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-implicature_numerals_2_3-log": {
        "Unique Dataset Identifier": "tsy-imppres-implicature_numerals_2_3-log",
        "Dataset Name": "imppres-implicature_numerals_2_3-log",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 118,
            "Mean Inputs Length": 830.4322,
            "Mean Targets Length": 6.678,
            "Max Inputs Length": 968,
            "Max Targets Length": 14,
            "Min Inputs Length": 678,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_numerals_2_3/log"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Language and communication",
                "Mathematics",
                "Reasoning",
                "Logic",
                "Interpersonal relationships",
                "Daily routine",
                "Language understanding"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-implicature_modals-log": {
        "Unique Dataset Identifier": "tsy-imppres-implicature_modals-log",
        "Dataset Name": "imppres-implicature_modals-log",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 118,
            "Mean Inputs Length": 812.2627,
            "Mean Targets Length": 6.7542,
            "Max Inputs Length": 1003,
            "Max Targets Length": 16,
            "Min Inputs Length": 633,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_modals/log"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Communication",
                "Clothing",
                "Ethics",
                "Education",
                "Linguistics",
                "Language",
                "Language understanding"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-imppres-implicature_numerals_10_100-log": {
        "Unique Dataset Identifier": "tsy-imppres-implicature_numerals_10_100-log",
        "Dataset Name": "imppres-implicature_numerals_10_100-log",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 118,
            "Mean Inputs Length": 871.9831,
            "Mean Targets Length": 6.7881,
            "Max Inputs Length": 972,
            "Max Targets Length": 14,
            "Min Inputs Length": 778,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_numerals_10_100/log"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Daily routine",
                "Language understanding",
                "Medical profession",
                "Communication",
                "Mathematics",
                "Reasoning",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsy-glue_diagnostics-diagnostics": {
        "Unique Dataset Identifier": "tsy-glue_diagnostics-diagnostics",
        "Dataset Name": "glue_diagnostics-diagnostics",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://gluebenchmark.com/diagnostics",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/glue_diagnostics",
        "Paper Title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
        "Papers with Code URL": "https://paperswithcode.com/dataset/glue",
        "ArXiv URL": "https://arxiv.org/abs/1804.07461",
        "Semantic Scholar Corpus ID": 5034059,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 110,
            "Mean Inputs Length": 1930.2364,
            "Mean Targets Length": 6.7,
            "Max Inputs Length": 2737,
            "Max Targets Length": 14,
            "Min Inputs Length": 1201,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "videos",
            "glosses",
            "forum posts",
            "twitter",
            "student answers",
            "wikipedia.org",
            "image descriptions"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University",
            "Paul G. Allen School of Computer Science & Engineering",
            "DeepMind"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "glue_diagnostics/diagnostics"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/glue_diagnostics",
            "HF Config": "pietrolesci--glue_diagnostics",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Various",
            "PwC License URL": "https://gluebenchmark.com/faq",
            "PwC Date": "2019-01-01",
            "S2 Date": "2018-04-20",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Communication",
                "Current events",
                "Technology",
                "Natural language processing",
                "Biology",
                "Language and communication",
                "History"
            ],
            "Github Date": "",
            "HF Date": "2022-04-21",
            "HF Downloads (September 2023)": 52,
            "HF Likes (September 2023)": 0,
            "PwC Description": "General Language Understanding Evaluation (GLUE) benchmark is a collection of nine natural language understanding tasks, including single-sentence tasks CoLA and SST-2, similarity and paraphrasing tasks MRPC, STS-B and QQP, and natural language inference tasks MNLI, QNLI, RTE and WNLI.",
            "S2 Citation Count (September 2023)": 4366,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Wang2018GLUEAM,\n author = {Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},\n booktitle = {BlackboxNLP@EMNLP},\n pages = {353-355},\n title = {GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n year = {2018}\n}\n"
    },
    "tsy-hlgd": {
        "Unique Dataset Identifier": "tsy-hlgd",
        "Dataset Name": "hlgd",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tingofurro/headline_grouping",
        "GitHub URL": "https://github.com/tingofurro/headline_grouping",
        "Hugging Face URL": "https://huggingface.co/datasets/hlgd",
        "Paper Title": "News Headline Grouping as a Challenging NLU Task",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hlgd",
        "ArXiv URL": "https://arxiv.org/abs/2105.05391",
        "Semantic Scholar Corpus ID": 232371994,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Paraphrase Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 543,
            "Mean Inputs Length": 1315.8471,
            "Mean Targets Length": 6.4346,
            "Max Inputs Length": 1569,
            "Max Targets Length": 15,
            "Min Inputs Length": 1122,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "cnn.com",
            "nytmes",
            "france24"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "UC Berkeley"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/tingofurro/headline_grouping/blob/main/LEGAL.md"
            }
        ],
        "License Notes": "Dataset is made of news headlines which fall under fair use according to this article: https://www.americanbar.org/groups/gpsolo/publications/gp_solo/2011/september/fair_use_news_reviews/",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "hlgd"
        ],
        "Inferred Metadata": {
            "HF Dataset": "hlgd",
            "HF Config": "default",
            "HF Config License": "Apache License 2.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "https://github.com/tingofurro/headline_grouping/blob/main/LICENSE",
            "PwC Date": "2021-05-12",
            "S2 Date": "2021-05-12",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Government actions",
                "News reporting",
                "International relations",
                "Environmental issues",
                "Social issues",
                "Current events",
                "Natural disasters"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 999,
            "HF Likes (September 2023)": 2,
            "PwC Description": "The Headline Grouping dataset is a binary classification dataset on pairs of news headline.\nFor each pair of headline, the binary label indicates whether the two headlines are part of the same group (and describe the same underlying event), or whether they are in distinct groups.\nThe dataset contains a total of 20k annotated headline pairs, further split in a train, validation and test portions.",
            "S2 Citation Count (September 2023)": 12,
            "GitHub Stars": 11,
            "GitHub Topics": [
                "headline",
                "headline-generation",
                "headline-grouping",
                "headlines",
                "naacl2021",
                "news"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Laban2021NewsHG,\n author = {Philippe Laban and Lucas Bandarkar and Marti A. Hearst},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {News Headline Grouping as a Challenging NLU Task},\n volume = {abs/2105.05391},\n year = {2021}\n}\n"
    },
    "tsy-medical_questions_pairs": {
        "Unique Dataset Identifier": "tsy-medical_questions_pairs",
        "Dataset Name": "medical_questions_pairs",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/curai/medical-question-pair-dataset",
        "GitHub URL": "https://github.com/curai/medical-question-pair-dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/medical_questions_pairs",
        "Paper Title": "Effective Transfer Learning for Identifying Similar Questions: Matching User Questions to COVID-19 FAQs",
        "Papers with Code URL": "https://paperswithcode.com/dataset/medical-question-pairs",
        "ArXiv URL": "https://arxiv.org/abs/2008.13546",
        "Semantic Scholar Corpus ID": 221191709,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Open-Domain Question Answering",
            "Multiple Choice Question Answering",
            "Clinical Diagnosis Question Answering",
            "Natural Language Understanding",
            "Fact Checking",
            "Medical Diagnosis Question Answering",
            "Symptom Prediction Question Answering",
            "Binary Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 304,
            "Mean Inputs Length": 2079.1316,
            "Mean Targets Length": 6.4836,
            "Max Inputs Length": 3351,
            "Max Targets Length": 14,
            "Min Inputs Length": 1316,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "healthtap.com"
        ],
        "Model Generated": [],
        "Creators": [
            "EightSleep",
            "Curai",
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Hand written and labelled by Doctors at Curai: https://github.com/curai/medical-question-pair-dataset#medical-question-pairs-mqp-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "medical_questions_pairs"
        ],
        "Inferred Metadata": {
            "HF Dataset": "medical_questions_pairs",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-08-04",
            "S2 Date": "2020-07-06",
            "GitHub License": "",
            "Text Topics": [
                "Injury",
                "Medical symptoms",
                "Pain management",
                "Health",
                "Dermatology",
                "Medical procedures",
                "Sexual health",
                "Medical advice",
                "Medical conditions"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 35210,
            "HF Likes (September 2023)": 27,
            "PwC Description": "Medical Question Pairs (MQP) Dataset\nThis repository contains a dataset of 3048 similar and dissimilar medical question pairs hand-generated and labeled by Curai's doctors. The dataset is described in detail in our paper.\n\nMethodology\nWe present our doctors with a list of 1524 patient-asked questions randomly sampled from the publicly available crawl of HealthTap. Each question results in one similar and one different pair through the following instructions provided to the labelers:\n\n\nRewrite the original question in a different way while maintaining the same intent. Restructure the syntax as much as possible and change medical details that would not impact your response.\n e.g. \"I'm a 22-y-o female\" could become \"My 26 year old daughter\"\nCome up with a related but dissimilar question for which the answer to the original question would be WRONG OR IRRELEVANT. Use similar key words.\n\nThe first instruction generates a positive question pair (similar) and the second generates a negative question pair (different). With the above instructions, we intentionally frame the task such that positive question pairs can look very different by superficial metrics, and negative question pairs can conversely look very similar. This ensures that the task is not trivial.\n\nDataset format\nThe dataset is formatted as dr_id, question_1, question_2, label. We used 11 different doctors for this task so dr_id ranges from 1 to 11. The label is 1 if the question pair is similar and 0 otherwise.\n\nDataset statistics\nThe final dataset contains 4567 unique questions. The minimum, maximum, median and average number of tokens in these questions are 4, 81, 20 and 22.675 respectively showing there is reasonable variance in the length of the questions. The shortest question is Are fibroadenomas malignant?\n\nAn off-the-shelf medical entity recognizer finds around 1000 unique medical entities in the questions. Some of the top entity mentions were: physician, pregnancy, pain, lasting weeks, menstruation, emotional state, cancer, visual function, headache, bleeding, fever, sexual intercourse",
            "S2 Citation Count (September 2023)": 41,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{McCreery2020EffectiveTL,\n author = {Clara H. McCreery and Namit Katariya and A. Kannan and Manish Chablani and X. Amatriain},\n booktitle = {Knowledge Discovery and Data Mining},\n journal = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining},\n title = {Effective Transfer Learning for Identifying Similar Questions: Matching User Questions to COVID-19 FAQs},\n year = {2020}\n}\n"
    },
    "tsy-insincere_questions": {
        "Unique Dataset Identifier": "tsy-insincere_questions",
        "Dataset Name": "insincere_questions",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://www.kaggle.com/c/quora-insincere-questions-classification",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/SetFit/insincere-questions",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Open-Ended Question Answering",
            "Factoid Question Answering",
            "Open-Domain Question Answering",
            "Natural Language Understanding",
            "Binary Classification Question Answering",
            "Medical Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 788,
            "Mean Inputs Length": 879.0825,
            "Mean Targets Length": 6.6713,
            "Max Inputs Length": 1375,
            "Max Targets Length": 16,
            "Min Inputs Length": 553,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "quora"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "insincere-questions"
        ],
        "Inferred Metadata": {
            "HF Dataset": "SetFit/insincere-questions",
            "HF Config": "SetFit--insincere-questions",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Relationships",
                "General knowledge",
                "Philosophy",
                "Technology",
                "Travel",
                "Sports",
                "Education",
                "History"
            ],
            "Github Date": "",
            "HF Date": "2022-01-19",
            "HF Downloads (September 2023)": 474,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-turingbench": {
        "Unique Dataset Identifier": "tsy-turingbench",
        "Dataset Name": "turingbench",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/TuringBench/TuringBench",
        "GitHub URL": "https://github.com/TuringBench/TuringBench",
        "Hugging Face URL": "https://huggingface.co/datasets/turingbench/TuringBench",
        "Paper Title": "TURINGBENCH: A Benchmark Environment for Turing Test in the Age of Neural Text Generation ",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2109.13296",
        "Semantic Scholar Corpus ID": 237589233,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5543,
            "Mean Inputs Length": 11387.2311,
            "Mean Targets Length": 6.5566,
            "Max Inputs Length": 21362,
            "Max Targets Length": 16,
            "Min Inputs Length": 3923,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "human"
        ],
        "Model Generated": [
            "pplm_distil",
            "OpenAI GPT-3",
            "OpenAI GPT-1",
            "transformer_xl",
            "xlm",
            "Grover",
            "CTRL",
            "OpenAI GPT-2",
            "XLNet",
            "wmt"
        ],
        "Creators": [
            "The Pennsylvania State University",
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/TuringBench/TuringBench/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "TuringBench"
        ],
        "Inferred Metadata": {
            "HF Dataset": "turingbench/TuringBench",
            "HF Config": "AA",
            "HF Config License": "Apache License 2.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-09-27",
            "GitHub License": "",
            "Text Topics": [
                "Current events",
                "Mutual Funds",
                "Finance",
                "News and current events",
                "Corruption",
                "Politics",
                "Mutual funds"
            ],
            "Github Date": "",
            "HF Date": "2021-05-04",
            "HF Downloads (September 2023)": 521,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 29,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Uchendu2021TURINGBENCHAB,\n author = {Adaku Uchendu and Zeyu Ma and Thai Le and Rui Zhang and Dongwon Lee},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {2001-2016},\n title = {TURINGBENCH: A Benchmark Environment for Turing Test in the Age of Neural Text Generation},\n year = {2021}\n}\n"
    },
    "tsy-vitaminc-tals__vitaminc": {
        "Unique Dataset Identifier": "tsy-vitaminc-tals__vitaminc",
        "Dataset Name": "vitaminc-tals__vitaminc",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/TalSchuster/VitaminC",
        "GitHub URL": "https://github.com/TalSchuster/VitaminC",
        "Hugging Face URL": "https://huggingface.co/datasets/tals/vitaminc",
        "Paper Title": "Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence",
        "Papers with Code URL": "https://paperswithcode.com/dataset/vitaminc",
        "ArXiv URL": "https://arxiv.org/abs/2103.08541",
        "Semantic Scholar Corpus ID": 232233599,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Fact Verification",
            "Span Selection Question Answering",
            "Multiple Choice Question Answering",
            "Natural Language Inference",
            "Regression-based Prediction of Box Office Gross",
            "Sentiment Analysis",
            "Sentence Classification",
            "Factual Statement Verification",
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 2187.5185,
            "Mean Targets Length": 6.5802,
            "Max Inputs Length": 4899,
            "Max Targets Length": 18,
            "Min Inputs Length": 1374,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Massachusetts Institute of Technology"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Github states the dataset is deribed from wikipedia pages: https://github.com/TalSchuster/VitaminC#vitaminc",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "vitaminc/tals--vitaminc"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tals/vitaminc",
            "HF Config": "tals--vitaminc",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "https://github.com/TalSchuster/VitaminC/edit/main/DATA_LICENSE",
            "PwC Date": "2021-03-15",
            "S2 Date": "2021-03-15",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Health",
                "Entertainment",
                "Entertainment industry",
                "Geography",
                "Film industry",
                "Music",
                "Historical events",
                "Sports",
                "COVID-19 statistics",
                "Biography"
            ],
            "Github Date": "",
            "HF Date": "2022-06-21",
            "HF Downloads (September 2023)": 284,
            "HF Likes (September 2023)": 2,
            "PwC Description": "The VitaminC dataset contains more than 450,000 claim-evidence pairs for fact verification and factual consistent generation. Based on over 100,000 revisions to popular Wikipedia pages, and additional \"synthetic\" revisions.",
            "S2 Citation Count (September 2023)": 95,
            "GitHub Stars": 58,
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "FEVER"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Schuster2021GetYV,\n author = {Tal Schuster and Adam Fisch and R. Barzilay},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {624-643},\n title = {Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence},\n year = {2021}\n}\n"
    },
    "tsy-rumoureval_2019-rumoureval2019": {
        "Unique Dataset Identifier": "tsy-rumoureval_2019-rumoureval2019",
        "Dataset Name": "rumoureval_2019-rumoureval2019",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/leondz",
        "GitHub URL": "https://github.com/leondz",
        "Hugging Face URL": "https://huggingface.co/datasets/strombergnlp/rumoureval_2019",
        "Paper Title": "SemEval-2019 Task 7: RumourEval, Determining Rumour Veracity and Support for Rumours",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1809.06683",
        "Semantic Scholar Corpus ID": 52298363,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 344,
            "Mean Inputs Length": 2159.5785,
            "Mean Targets Length": 6.6715,
            "Max Inputs Length": 5536,
            "Max Targets Length": 13,
            "Min Inputs Length": 1495,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter",
            "reddit",
            "snopes.com"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Sheffield",
            "IT University of Copenhagen",
            "University of Warwick"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://competitions.codalab.org/competitions/19938#learn_the_details-terms_and_conditions"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "rumoureval_2019/RumourEval2019"
        ],
        "Inferred Metadata": {
            "HF Dataset": "strombergnlp/rumoureval_2019",
            "HF Config": "RumourEval2019",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-09-18",
            "GitHub License": "",
            "Text Topics": [
                "News and current events",
                "Current events/news",
                "Social media and online communication",
                "Law enforcement",
                "Politics",
                "Social justice and police brutality",
                "Social justice",
                "Current events",
                "Terrorism",
                "Social media"
            ],
            "Github Date": "",
            "HF Date": "2022-05-12",
            "HF Downloads (September 2023)": 112,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 130,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Gorrell2018SemEval2019T7,\n author = {G. Gorrell and Kalina Bontcheva and Leon Derczynski and E. Kochkina and Maria Liakata and A. Zubiaga},\n booktitle = {International Workshop on Semantic Evaluation},\n journal = {ArXiv},\n title = {SemEval-2019 Task 7: RumourEval, Determining Rumour Veracity and Support for Rumours},\n volume = {abs/1809.06683},\n year = {2018}\n}\n"
    },
    "tsy-tweet_eval-irony": {
        "Unique Dataset Identifier": "tsy-tweet_eval-irony",
        "Dataset Name": "tweet_eval-irony",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Irony Detection",
            "Open-Ended Question Answering",
            "Hashtag Classification",
            "Sentiment Analysis",
            "Binary Classification",
            "Multiple Choice Question Answering",
            "Information Retrieval"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 317,
            "Mean Inputs Length": 841.4038,
            "Mean Targets Length": 6.5426,
            "Max Inputs Length": 1822,
            "Max Targets Length": 13,
            "Min Inputs Length": 551,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/irony"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Social media and online communication",
                "Emotions",
                "Humor and irony",
                "Social media",
                "Humor",
                "Health",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsy-tweet_eval-stance_abortion": {
        "Unique Dataset Identifier": "tsy-tweet_eval-stance_abortion",
        "Dataset Name": "tweet_eval-stance_abortion",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Binary Classification",
            "Multiple Choice Question Answering",
            "Sentiment Analysis",
            "Natural Language Understanding",
            "Binary Classification Question Answering",
            "Dialogue Understanding",
            "Open-Ended Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 64,
            "Mean Inputs Length": 1083.5312,
            "Mean Targets Length": 6.5781,
            "Max Inputs Length": 1257,
            "Max Targets Length": 12,
            "Min Inputs Length": 872,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/stance_abortion"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Human rights",
                "Religion",
                "Pro-life movement",
                "Ethics and morality",
                "Social issues",
                "Reproductive rights",
                "Political discourse",
                "Ethics"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsy-tweet_eval-hate": {
        "Unique Dataset Identifier": "tsy-tweet_eval-hate",
        "Dataset Name": "tweet_eval-hate",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Binary Classification",
            "Natural Language Understanding",
            "Hashtag Classification",
            "Multiple Choice Question Answering",
            "Binary Classification of Hate Speech",
            "Offensive Language Detection",
            "Document Classification",
            "Binary Classification Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 944,
            "Mean Inputs Length": 1248.4958,
            "Mean Targets Length": 6.643,
            "Max Inputs Length": 1972,
            "Max Targets Length": 14,
            "Min Inputs Length": 691,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/hate"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Social media",
                "Communication",
                "Social media etiquette",
                "International relations",
                "Politics",
                "Current events",
                "Gender equality",
                "Immigration policy",
                "Social justice"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsy-tweet_eval-stance_atheism": {
        "Unique Dataset Identifier": "tsy-tweet_eval-stance_atheism",
        "Dataset Name": "tweet_eval-stance_atheism",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Binary Classification Question Answering",
            "Bible Verse Interpretation",
            "Open-Ended Question Answering",
            "Binary Classification",
            "Multiple Choice Question Answering",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 47,
            "Mean Inputs Length": 1097.1064,
            "Mean Targets Length": 6.6383,
            "Max Inputs Length": 1229,
            "Max Targets Length": 12,
            "Min Inputs Length": 909,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/stance_atheism"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Religion",
                "Belief",
                "Spirituality",
                "Social issues",
                "Philosophy",
                "Communication",
                "Prayer",
                "Identity",
                "Social media"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsy-tweet_eval-stance_climate": {
        "Unique Dataset Identifier": "tsy-tweet_eval-stance_climate",
        "Dataset Name": "tweet_eval-stance_climate",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Open-Domain Question Answering",
            "Multiple Choice Question Answering",
            "Binary Classification",
            "Natural Language Inference",
            "Open-Ended Question Answering",
            "Sentence Classification",
            "Binary Classification Question Answering",
            "Hashtag Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 38,
            "Mean Inputs Length": 1053.3158,
            "Mean Targets Length": 6.8158,
            "Max Inputs Length": 1191,
            "Max Targets Length": 14,
            "Min Inputs Length": 888,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/stance_climate"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Weather",
                "Environmental activism",
                "Environmental conservation",
                "Climate change",
                "Religion",
                "Social media",
                "Politics",
                "Environmental issues",
                "Environmental impact",
                "Current events"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsy-tweet_eval-emoji": {
        "Unique Dataset Identifier": "tsy-tweet_eval-emoji",
        "Dataset Name": "tweet_eval-emoji",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4992,
            "Mean Inputs Length": 779.8301,
            "Mean Targets Length": 6.5681,
            "Max Inputs Length": 1013,
            "Max Targets Length": 18,
            "Min Inputs Length": 485,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/emoji"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Social media",
                "Travel",
                "Entertainment",
                "Location",
                "Social media and online communication",
                "Food and dining experiences",
                "Geography",
                "Photography",
                "Social media and hashtags"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsy-tweet_eval-offensive": {
        "Unique Dataset Identifier": "tsy-tweet_eval-offensive",
        "Dataset Name": "tweet_eval-offensive",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Natural Language Inference",
            "Multiple Choice Question Answering",
            "Binary Classification",
            "Narrative Generation",
            "Open-Domain Question Answering",
            "Offensive Language Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 985,
            "Mean Inputs Length": 1269.8112,
            "Mean Targets Length": 6.4711,
            "Max Inputs Length": 2153,
            "Max Targets Length": 16,
            "Min Inputs Length": 559,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/offensive"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Gun control",
                "Political discourse",
                "Social media",
                "Online communication",
                "Public opinion",
                "Politics",
                "Social media etiquette",
                "Social issues",
                "Language and communication",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsy-tweet_eval-sentiment": {
        "Unique Dataset Identifier": "tsy-tweet_eval-sentiment",
        "Dataset Name": "tweet_eval-sentiment",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5065,
            "Mean Inputs Length": 1103.5418,
            "Mean Targets Length": 6.6464,
            "Max Inputs Length": 1360,
            "Max Targets Length": 15,
            "Min Inputs Length": 770,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/sentiment"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Sports",
                "Entertainment",
                "Pop culture",
                "Religion",
                "Travel",
                "Social media",
                "Current events"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsy-tweet_eval-emotion": {
        "Unique Dataset Identifier": "tsy-tweet_eval-emotion",
        "Dataset Name": "tweet_eval-emotion",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 355,
            "Mean Inputs Length": 962.3183,
            "Mean Targets Length": 6.6394,
            "Max Inputs Length": 1226,
            "Max Targets Length": 13,
            "Min Inputs Length": 670,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/emotion"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Entertainment",
                "Relationships",
                "Communication",
                "Social issues",
                "Personal experiences",
                "Emotions",
                "Customer service"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsy-tweet_eval-stance_feminist": {
        "Unique Dataset Identifier": "tsy-tweet_eval-stance_feminist",
        "Dataset Name": "tweet_eval-stance_feminist",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Binary Classification",
            "Multiple Choice Question Answering",
            "Sentiment Analysis",
            "Binary Classification Question Answering",
            "Natural Language Inference",
            "Algebraic Expression Evaluation",
            "Natural Language Understanding"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 65,
            "Mean Inputs Length": 1094.9538,
            "Mean Targets Length": 6.4308,
            "Max Inputs Length": 1224,
            "Max Targets Length": 13,
            "Min Inputs Length": 922,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/stance_feminist"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Gender equality",
                "Feminism",
                "Online harassment",
                "Social activism",
                "Online activism",
                "Social media discourse",
                "Social media",
                "Social issues",
                "Social justice"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsy-tweet_eval-stance_hillary": {
        "Unique Dataset Identifier": "tsy-tweet_eval-stance_hillary",
        "Dataset Name": "tweet_eval-stance_hillary",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Binary Classification",
            "Open-Domain Question Answering",
            "Open-Ended Question Answering",
            "Multiple Choice Question Answering",
            "None-of-the-Above Question Answering",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 65,
            "Mean Inputs Length": 1034.3231,
            "Mean Targets Length": 6.4308,
            "Max Inputs Length": 1253,
            "Max Targets Length": 13,
            "Min Inputs Length": 787,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/stance_hillary"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Language and communication",
                "Current events",
                "Social media activism",
                "Politics",
                "Political discourse",
                "Social media etiquette",
                "Social issues",
                "Online communication",
                "Social media",
                "Gender equality"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsy-discovery-discovery": {
        "Unique Dataset Identifier": "tsy-discovery-discovery",
        "Dataset Name": "discovery-discovery",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/Discovery",
        "GitHub URL": "https://github.com/sileod/Discovery",
        "Hugging Face URL": "https://huggingface.co/datasets/discovery",
        "Paper Title": "Mining Discourse Markers for Unsupervised Sentence Representation Learning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/discovery",
        "ArXiv URL": "https://arxiv.org/abs/1903.11850",
        "Semantic Scholar Corpus ID": 85543290,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5443,
            "Mean Inputs Length": 1928.8732,
            "Mean Targets Length": 6.6191,
            "Max Inputs Length": 2778,
            "Max Targets Length": 18,
            "Min Inputs Length": 1189,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "inf.uni-hamburg.de/en/inst/ab/lt/resources/data/depcc.html"
        ],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Comes from: https://www.inf.uni-hamburg.de/en/inst/ab/lt/resources/data/depcc.html",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "discovery/discovery"
        ],
        "Inferred Metadata": {
            "HF Dataset": "discovery",
            "HF Config": "discovery",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "",
            "PwC Date": "2019-03-28",
            "S2 Date": "2019-03-28",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Technology",
                "Computer hardware",
                "Engineering",
                "Ethics and morality",
                "Communication",
                "Decision-making",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1559,
            "HF Likes (September 2023)": 5,
            "PwC Description": "The Discovery datasets consists of adjacent sentence pairs (s1,s2) with a discourse marker (y) that occurred at the beginning of s2. They were extracted from the depcc web corpus.\n\nMarkers prediction can be used in order to train a sentence encoders. Discourse markers can be considered as noisy labels for various semantic tasks, such as entailment (y=therefore), subjectivity analysis (y=personally) or sentiment analysis (y=sadly), similarity (y=similarly), typicality, (y=curiously) ...\n\nThe specificity of this dataset is the diversity of the markers, since previously used data used only ~10 imbalanced classes. The author of the dataset provide:\n\n\na list of the 174 discourse markers\na Base version of the dataset with 1.74 million pairs (10k examples per marker)\na Big version with 3.4 million pairs\na Hard version with 1.74 million pairs where the connective couldn't be predicted with a fastText linear model",
            "S2 Citation Count (September 2023)": 52,
            "GitHub Stars": 59,
            "GitHub Topics": [
                "dataset",
                "deep-learning",
                "discourse-analysis",
                "discourse-connectives",
                "discourse-markers",
                "discourse-parsing",
                "infersent",
                "large-dataset",
                "natural-language-inference",
                "natural-language-processing",
                "natural-language-understanding",
                "pdtb",
                "pretrained-model",
                "sentence-embeddings",
                "unsupervised-learning"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Sileo2019MiningDM,\n author = {Damien Sileo and T. V. D. Cruys and Camille Pradel and Philippe Muller},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {3477-3486},\n title = {Mining Discourse Markers for Unsupervised Sentence Representation Learning},\n year = {2019}\n}\n"
    },
    "tsy-pragmeval-verifiability": {
        "Unique Dataset Identifier": "tsy-pragmeval-verifiability",
        "Dataset Name": "pragmeval-verifiability",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Unverifiable Claim Classification",
            "Customer Service Dialogue Generation",
            "Open-Domain Question Answering",
            "Experiential Question Answering",
            "Classification",
            "Experiential Classification",
            "Natural Language Understanding"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 430,
            "Mean Inputs Length": 912.8256,
            "Mean Targets Length": 6.386,
            "Max Inputs Length": 1507,
            "Max Targets Length": 14,
            "Min Inputs Length": 499,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/verifiability"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Decision-making",
                "Health",
                "Finance",
                "Communication",
                "Epistemology",
                "Economics",
                "Customer service",
                "Personal finance",
                "Allergies"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsy-pragmeval-mrda": {
        "Unique Dataset Identifier": "tsy-pragmeval-mrda",
        "Dataset Name": "pragmeval-mrda",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 174,
            "Mean Inputs Length": 605.6149,
            "Mean Targets Length": 6.477,
            "Max Inputs Length": 1053,
            "Max Targets Length": 13,
            "Min Inputs Length": 292,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/mrda"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Data analysis",
                "Language",
                "Linguistics",
                "Decision-making",
                "Problem-solving",
                "Technology",
                "Communication skills",
                "Language understanding",
                "Communication",
                "Conversation analysis"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsy-pragmeval-switchboard": {
        "Unique Dataset Identifier": "tsy-pragmeval-switchboard",
        "Dataset Name": "pragmeval-switchboard",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1124,
            "Mean Inputs Length": 480.863,
            "Mean Targets Length": 6.6735,
            "Max Inputs Length": 862,
            "Max Targets Length": 22,
            "Min Inputs Length": 242,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/switchboard"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Personal finance",
                "Linguistics",
                "Conversation analysis",
                "Social interactions",
                "Language",
                "General knowledge",
                "Communication",
                "Language understanding"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsy-pragmeval-emergent": {
        "Unique Dataset Identifier": "tsy-pragmeval-emergent",
        "Dataset Name": "pragmeval-emergent",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Natural Language Inference",
            "Sentiment Analysis",
            "Span Selection Question Answering",
            "Document Classification",
            "Sentence Classification",
            "Named Entity Recognition",
            "Document Retrieval",
            "Date Prediction",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 229,
            "Mean Inputs Length": 1363.786,
            "Mean Targets Length": 6.5939,
            "Max Inputs Length": 1840,
            "Max Targets Length": 14,
            "Min Inputs Length": 1075,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/emergent"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Media coverage",
                "Terrorism",
                "News reporting",
                "Entertainment industry",
                "Current events",
                "Technology",
                "News and current events"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsy-pragmeval-gum": {
        "Unique Dataset Identifier": "tsy-pragmeval-gum",
        "Dataset Name": "pragmeval-gum",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 142,
            "Mean Inputs Length": 1533.7535,
            "Mean Targets Length": 6.5915,
            "Max Inputs Length": 3012,
            "Max Targets Length": 13,
            "Min Inputs Length": 729,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/gum"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Gardening",
                "Cultural differences",
                "Communication",
                "Cooking",
                "Travel",
                "Education",
                "Geography",
                "Personal development",
                "Culinary arts",
                "History"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsy-pragmeval-sarcasm": {
        "Unique Dataset Identifier": "tsy-pragmeval-sarcasm",
        "Dataset Name": "pragmeval-sarcasm",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Irony Detection",
            "Multiple Choice Question Answering",
            "Argument Resolution",
            "Argumentative Discourse Analysis",
            "Dialogue Act Recognition",
            "Argumentative Reasoning",
            "Argumentative Question Answering",
            "Open-Domain Question Answering",
            "Sarcasm Detection",
            "Argumentative Dialogue Generation"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 416,
            "Mean Inputs Length": 5225.4375,
            "Mean Targets Length": 6.6875,
            "Max Inputs Length": 13372,
            "Max Targets Length": 14,
            "Min Inputs Length": 2730,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/sarcasm"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Science",
                "Philosophy",
                "Ethics and morality",
                "Biology",
                "Language and communication",
                "Evolution",
                "Logic",
                "Gun control"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsy-pragmeval-stac": {
        "Unique Dataset Identifier": "tsy-pragmeval-stac",
        "Dataset Name": "pragmeval-stac",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1207,
            "Mean Inputs Length": 522.4068,
            "Mean Targets Length": 6.3977,
            "Max Inputs Length": 751,
            "Max Targets Length": 15,
            "Min Inputs Length": 335,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/stac"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Bartering",
                "Social interaction",
                "Agriculture",
                "Daily routine",
                "Technology",
                "Food",
                "General conversation"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsy-pragmeval-pdtb": {
        "Unique Dataset Identifier": "tsy-pragmeval-pdtb",
        "Dataset Name": "pragmeval-pdtb",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 15,
            "Mean Inputs Length": 1999.8667,
            "Mean Targets Length": 6.5333,
            "Max Inputs Length": 2178,
            "Max Targets Length": 12,
            "Min Inputs Length": 1707,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/pdtb"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Business operations",
                "Earnings",
                "Business",
                "Economics",
                "Finance",
                "Business and finance",
                "Communication",
                "Technology",
                "Financial markets"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsy-silicone-dyda_e": {
        "Unique Dataset Identifier": "tsy-silicone-dyda_e",
        "Dataset Name": "silicone-dyda_e",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://yanran.li/dailydialog.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2150,
            "Mean Inputs Length": 665.246,
            "Mean Targets Length": 6.546,
            "Max Inputs Length": 1415,
            "Max Targets Length": 22,
            "Min Inputs Length": 336,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "http://yanran.li/dailydialog.html, https://huggingface.co/datasets/silicone#licensing-information"
            },
            {
                "License": "CC BY-SA 4.0",
                "License URL": "http://yanran.li/dailydialog.html, https://huggingface.co/datasets/silicone#licensing-information"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "silicone/dyda_e"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "Communication skills",
                "Personal preferences",
                "Relationships",
                "Travel",
                "Communication",
                "Education",
                "Health",
                "Daily routine",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsy-silicone-oasis": {
        "Unique Dataset Identifier": "tsy-silicone-oasis",
        "Dataset Name": "silicone-oasis",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/silicone",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 539,
            "Mean Inputs Length": 481.0798,
            "Mean Targets Length": 6.5176,
            "Max Inputs Length": 2033,
            "Max Targets Length": 15,
            "Min Inputs Length": 175,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/silicone#licensing-information"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "silicone/oasis"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "Telecommunications",
                "Customer service",
                "Technology",
                "Social interactions",
                "General knowledge",
                "Daily routine",
                "Communication skills",
                "Linguistics"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsy-silicone-meld_s": {
        "Unique Dataset Identifier": "tsy-silicone-meld_s",
        "Dataset Name": "silicone-meld_s",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://affective-meld.github.io/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1106,
            "Mean Inputs Length": 532.2134,
            "Mean Targets Length": 6.5371,
            "Max Inputs Length": 943,
            "Max Targets Length": 15,
            "Min Inputs Length": 248,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/silicone#licensing-information"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "silicone/meld_s"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "Emotions",
                "Language understanding",
                "Communication",
                "Social interactions",
                "Relationships",
                "Daily routine",
                "Social interaction",
                "Linguistics",
                "Interpersonal relationships"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsy-silicone-meld_e": {
        "Unique Dataset Identifier": "tsy-silicone-meld_e",
        "Dataset Name": "silicone-meld_e",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://affective-meld.github.io/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1109,
            "Mean Inputs Length": 533.2146,
            "Mean Targets Length": 6.6141,
            "Max Inputs Length": 1097,
            "Max Targets Length": 18,
            "Min Inputs Length": 229,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/silicone#licensing-information"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "silicone/meld_e"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "Social interactions",
                "Travel",
                "Emotions",
                "Relationships",
                "Entertainment",
                "Daily routine",
                "Personal relationships",
                "Language",
                "Communication",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsy-silicone-maptask": {
        "Unique Dataset Identifier": "tsy-silicone-maptask",
        "Dataset Name": "silicone-maptask",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://groups.inf.ed.ac.uk/maptask/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2303,
            "Mean Inputs Length": 389.1776,
            "Mean Targets Length": 6.6261,
            "Max Inputs Length": 999,
            "Max Targets Length": 15,
            "Min Inputs Length": 161,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://groups.inf.ed.ac.uk/maptask/maptasknxt.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "silicone/maptask"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Language and communication",
                "Linguistics",
                "Travel",
                "Language understanding",
                "Outdoor activities",
                "Conversation etiquette",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsy-silicone-dyda_da": {
        "Unique Dataset Identifier": "tsy-silicone-dyda_da",
        "Dataset Name": "silicone-dyda_da",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://yanran.li/dailydialog.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 679.8598,
            "Mean Targets Length": 6.6292,
            "Max Inputs Length": 1543,
            "Max Targets Length": 18,
            "Min Inputs Length": 334,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "http://yanran.li/dailydialog.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "silicone/dyda_da"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "Daily routine",
                "Travel",
                "Language",
                "Time management",
                "Language understanding",
                "Communication",
                "Social plans",
                "Customer service",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsy-silicone-sem": {
        "Unique Dataset Identifier": "tsy-silicone-sem",
        "Dataset Name": "silicone-sem",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://ieeexplore.ieee.org/document/5959155",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Dialogue Understanding",
            "Open-Domain Greeting Response Generation",
            "Speech Recognition",
            "Open-Ended Question Answering",
            "Multiple Choice Question Answering",
            "Information Retrieval",
            "Dialogue Act Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 466,
            "Mean Inputs Length": 688.0558,
            "Mean Targets Length": 6.5987,
            "Max Inputs Length": 2105,
            "Max Targets Length": 13,
            "Min Inputs Length": 259,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/silicone#licensing-information"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "silicone/sem"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "Language understanding",
                "Social interaction",
                "Personal relationships",
                "Daily routine",
                "General knowledge",
                "Emotions",
                "Communication",
                "Language",
                "Travel",
                "Time management"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsy-silicone-iemocap": {
        "Unique Dataset Identifier": "tsy-silicone-iemocap",
        "Dataset Name": "silicone-iemocap",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://sail.usc.edu/iemocap/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 754,
            "Mean Inputs Length": 671.9191,
            "Mean Targets Length": 6.5981,
            "Max Inputs Length": 1569,
            "Max Targets Length": 14,
            "Min Inputs Length": 274,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "http://sail.usc.edu/iemocap/Data_Release_Form_IEMOCAP.pdf, https://docs.google.com/forms/d/e/1FAIpQLScBecgI2K5bFTrXi_-05IYSSwOcqL5mX7dh57xcJV1m_NoznA/viewform?usp=sf_link"
            },
            {
                "License": "Request Form",
                "License URL": "http://sail.usc.edu/iemocap/Data_Release_Form_IEMOCAP.pdf, https://docs.google.com/forms/d/e/1FAIpQLScBecgI2K5bFTrXi_-05IYSSwOcqL5mX7dh57xcJV1m_NoznA/viewform?usp=sf_link"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "silicone/iemocap"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Communication",
                "Travel",
                "General knowledge",
                "Daily routine",
                "Social interaction",
                "Language",
                "Emotions",
                "Language understanding",
                "Relationships"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsy-lex_glue-ledgar": {
        "Unique Dataset Identifier": "tsy-lex_glue-ledgar",
        "Dataset Name": "lex_glue-ledgar",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://metatext.io/datasets/ledgar",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/lex_glue",
        "Paper Title": "LexGLUE: A Benchmark Dataset for Legal Language Understanding in English",
        "Papers with Code URL": "https://paperswithcode.com/dataset/lexglue",
        "ArXiv URL": "https://arxiv.org/abs/2110.00976",
        "Semantic Scholar Corpus ID": 238259595,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5417,
            "Mean Inputs Length": 6490.1015,
            "Mean Targets Length": 6.5946,
            "Max Inputs Length": 19782,
            "Max Targets Length": 15,
            "Min Inputs Length": 1738,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "University of Copenhagen",
            "Universitat Hamburg",
            "Athens University of Economics and Business",
            "University of Sheffield",
            "Illinois Tech  Chicago Kent College of Law",
            "Bucerius Law School",
            "CodeX",
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://metatext.io/datasets/ledgar"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lex_glue/ledgar"
        ],
        "Inferred Metadata": {
            "HF Dataset": "lex_glue",
            "HF Config": "ecthr_a",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2021-10-03",
            "S2 Date": "2021-10-03",
            "GitHub License": "",
            "Text Topics": [
                "Contract law",
                "Contractual obligations",
                "Legal contracts",
                "Legal terminology",
                "Business transactions",
                "Finance",
                "Contractual agreements",
                "Business operations",
                "Legal agreements",
                "Corporate governance"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 53914,
            "HF Likes (September 2023)": 27,
            "PwC Description": "Legal General Language Understanding Evaluation (LexGLUE) benchmark is a collection of datasets for evaluating model performance across a diverse set of legal NLU tasks in a standardized way.",
            "S2 Citation Count (September 2023)": 84,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Chalkidis2021LexGLUEAB,\n author = {Ilias Chalkidis and Abhik Jana and D. Hartung and M. Bommarito and Ion Androutsopoulos and D. Katz and Nikolaos Aletras},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {4310-4330},\n title = {LexGLUE: A Benchmark Dataset for Legal Language Understanding in English},\n year = {2021}\n}\n"
    },
    "tsy-language_identification": {
        "Unique Dataset Identifier": "tsy-language_identification",
        "Dataset Name": "language_identification",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/papluca/language-identification",
        "GitHub URL": "https://github.com/LucaPapariello",
        "Hugging Face URL": "https://huggingface.co/datasets/papluca/language-identification",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5545,
            "Mean Inputs Length": 1141.0085,
            "Mean Targets Length": 6.6256,
            "Max Inputs Length": 4156,
            "Max Targets Length": 16,
            "Min Inputs Length": 447,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://docs.opendata.aws/amazon-reviews-ml/license.txt, https://dl.fbaipublicfiles.com/glue/data/STS-B.zip, https://github.com/facebookresearch/XNLI/blob/main/LICENSE"
            },
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://docs.opendata.aws/amazon-reviews-ml/license.txt, https://dl.fbaipublicfiles.com/glue/data/STS-B.zip, https://github.com/facebookresearch/XNLI/blob/main/LICENSE"
            },
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://docs.opendata.aws/amazon-reviews-ml/license.txt, https://dl.fbaipublicfiles.com/glue/data/STS-B.zip, https://github.com/facebookresearch/XNLI/blob/main/LICENSE"
            }
        ],
        "License Notes": "Derived from Amazon reviews, XNLI, and STS-B",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "language-identification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "papluca/language-identification",
            "HF Config": "papluca--language-identification",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Cultural exchange",
                "Cultural understanding",
                "Product review",
                "Language proficiency",
                "Language and communication",
                "Multilingualism",
                "Translation",
                "Language identification"
            ],
            "Github Date": "",
            "HF Date": "2021-11-24",
            "HF Downloads (September 2023)": 499,
            "HF Likes (September 2023)": 13,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-rotten_tomatoes": {
        "Unique Dataset Identifier": "tsy-rotten_tomatoes",
        "Dataset Name": "rotten_tomatoes",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://www.cs.cornell.edu/people/pabo/movie-review-data/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/rotten_tomatoes",
        "Paper Title": "Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mr",
        "ArXiv URL": "https://arxiv.org/abs/cs/0506075",
        "Semantic Scholar Corpus ID": 3264224,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 853,
            "Mean Inputs Length": 1166.9062,
            "Mean Targets Length": 6.5955,
            "Max Inputs Length": 1692,
            "Max Targets Length": 15,
            "Min Inputs Length": 728,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "rottentomatoes.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Cornell University",
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "rotten_tomatoes"
        ],
        "Inferred Metadata": {
            "HF Dataset": "rotten_tomatoes",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2004-01-01",
            "S2 Date": "2005-06-17",
            "GitHub License": "",
            "Text Topics": [
                "Literature",
                "Entertainment",
                "Film criticism",
                "Comedy",
                "Film analysis",
                "Film and entertainment",
                "Emotions",
                "Aesthetics",
                "Acting",
                "Film critique"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 58503,
            "HF Likes (September 2023)": 26,
            "PwC Description": "MR Movie Reviews is a dataset for use in sentiment-analysis experiments. Available are collections of movie-review documents labeled with respect to their overall sentiment polarity (positive or negative) or subjective rating (e.g., \"two and a half stars\") and sentences labeled with respect to their subjectivity status (subjective or objective) or polarity.",
            "S2 Citation Count (September 2023)": 2631,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Pang2005SeeingSE,\n author = {B. Pang and Lillian Lee},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {115-124},\n title = {Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales},\n year = {2005}\n}\n"
    },
    "tsy-hate_speech18": {
        "Unique Dataset Identifier": "tsy-hate_speech18",
        "Dataset Name": "hate_speech18",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Vicomtech/hate-speech-dataset",
        "GitHub URL": "https://github.com/Vicomtech/hate-speech-dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/hate_speech18",
        "Paper Title": "Hate Speech Dataset from a White Supremacy Forum",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hate-speech",
        "ArXiv URL": "https://arxiv.org/abs/1809.04444",
        "Semantic Scholar Corpus ID": 52194540,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 326,
            "Mean Inputs Length": 1009.8528,
            "Mean Targets Length": 6.7393,
            "Max Inputs Length": 2394,
            "Max Targets Length": 16,
            "Min Inputs Length": 568,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "stormfront.org"
        ],
        "Model Generated": [],
        "Creators": [
            "HSLT Group at Vicomtech"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 3.0",
                "License URL": "https://github.com/Vicomtech/hate-speech-dataset/blob/master/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "hate_speech18"
        ],
        "Inferred Metadata": {
            "HF Dataset": "hate_speech18",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/3.0/es/",
            "PwC Date": "",
            "S2 Date": "2018-09-12",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Culture",
                "Social issues",
                "Geography",
                "Religion",
                "Identity",
                "Personal preferences",
                "Communication",
                "History",
                "Education"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 40578,
            "HF Likes (September 2023)": 13,
            "PwC Description": "Dataset of hate speech annotated on Internet forum posts in English at sentence-level. The source forum in Stormfront, a large online community of white nacionalists. A total of 10,568 sentence have been been extracted from Stormfront and classified as conveying hate speech or not.",
            "S2 Citation Count (September 2023)": 270,
            "GitHub Stars": 133,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Gibert2018HateSD,\n author = {Ona de Gibert and Naiara Prez and Aitor Garca-Pablos and Montse Cuadros},\n booktitle = {Workshop on Abusive Language Online},\n journal = {ArXiv},\n title = {Hate Speech Dataset from a White Supremacy Forum},\n volume = {abs/1809.04444},\n year = {2018}\n}\n"
    },
    "tsy-sms_spam": {
        "Unique Dataset Identifier": "tsy-sms_spam",
        "Dataset Name": "sms_spam",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sms_spam",
        "Paper Title": "Contributions to the Study of SMS Spam Filtering: New Collection and Results",
        "Papers with Code URL": "https://paperswithcode.com/dataset/sms-spam-collection-data-set",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 13871930,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Open-Domain Conversation Generation",
            "Natural Language Understanding",
            "Natural Language Classification",
            "Binary Classification",
            "Binary Classification Question Answering",
            "Open-Ended Question Answering",
            "Open-Domain Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 169,
            "Mean Inputs Length": 1079.5917,
            "Mean Targets Length": 6.6627,
            "Max Inputs Length": 1843,
            "Max Targets Length": 13,
            "Min Inputs Length": 791,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grumbletext"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "http://archive.ics.uci.edu/dataset/228/sms+spam+collection"
            }
        ],
        "License Notes": "There are more sources listed on the document, but this was the main one that I saw",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "sms_spam"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sms_spam",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2011-09-19",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Time management",
                "Communication",
                "Personal relationships",
                "Travel",
                "Language and communication",
                "Social plans",
                "Daily routine",
                "Relationships",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1974,
            "HF Likes (September 2023)": 11,
            "PwC Description": "This corpus has been collected from free or free for research sources at the Internet:\n\n\nA collection of 425 SMS spam messages was manually extracted from the Grumbletext Web site. This is a UK forum in which cell phone users make public claims about SMS spam messages, most of them without reporting the very spam message received. The identification of the text of spam messages in the claims is a very hard and time-consuming task, and it involved carefully scanning hundreds of web pages.\nA subset of 3,375 SMS randomly chosen ham messages of the NUS SMS Corpus (NSC), which is a dataset of about 10,000 legitimate messages collected for research at the Department of Computer Science at the National University of Singapore. The messages largely originate from Singaporeans and mostly from students attending the University. These messages were collected from volunteers who were made aware that their contributions were going to be made publicly available.\nA list of 450 SMS ham messages collected from Caroline Tag's PhD Thesis.\nthe SMS Spam Corpus v.0.1 Big. It has 1,002 SMS ham messages and 322 spam messages.",
            "S2 Citation Count (September 2023)": 386,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Almeida2011ContributionsTT,\n author = {Tiago A. Almeida and J. M. G. Hidalgo and A. Yamakami},\n booktitle = {ACM Symposium on Document Engineering},\n pages = {259-262},\n title = {Contributions to the study of SMS spam filtering: new collection and results},\n year = {2011}\n}\n"
    },
    "tsy-humicroedit-subtask_2": {
        "Unique Dataset Identifier": "tsy-humicroedit-subtask_2",
        "Dataset Name": "humicroedit-subtask_2",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://www.cs.rochester.edu/u/nhossain/humicroedit.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/humicroedit",
        "Paper Title": "President Vows to Cut  Hair: Dataset and Analysis of Creative Text Editing for Humorous Headlines",
        "Papers with Code URL": "https://paperswithcode.com/dataset/humicroedit",
        "ArXiv URL": "https://arxiv.org/abs/2002.02031",
        "Semantic Scholar Corpus ID": 173990506,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Span Selection Question Answering",
            "Named Entity Recognition",
            "Text Matching",
            "Semantic Similarity Detection",
            "Semantic Similarity Identification",
            "Multiple Choice Question Answering",
            "Sentence Similarity Detection",
            "Sentence Completion",
            "Sentence Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1041,
            "Mean Inputs Length": 1711.4813,
            "Mean Targets Length": 6.7445,
            "Max Inputs Length": 2355,
            "Max Targets Length": 15,
            "Min Inputs Length": 1155,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "headlines"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "humicroedit/subtask-2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "humicroedit",
            "HF Config": "subtask-1",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-01",
            "GitHub License": "",
            "Text Topics": [
                "Religion",
                "Healthcare",
                "Politics",
                "International relations",
                "Natural disasters",
                "Geography",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1954,
            "HF Likes (September 2023)": 1,
            "PwC Description": "Humicroedit is a humorous headline dataset. The data consists of regular English news headlines paired with versions of the same headlines that contain simple replacement edits designed to make them funny. The authors carefully curated crowdsourced editors to create funny headlines and judges to score a to a total of 15,095 edited headlines, with five judges per headline.",
            "S2 Citation Count (September 2023)": 73,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hossain2019PresidentVT,\n author = {Nabil Hossain and John Krumm and Michael Gamon},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {President Vows to Cut  Hair: Dataset and Analysis of Creative Text Editing for Humorous Headlines},\n volume = {abs/1906.00274},\n year = {2019}\n}\n"
    },
    "tsy-snips_built_in_intents": {
        "Unique Dataset Identifier": "tsy-snips_built_in_intents",
        "Dataset Name": "snips_built_in_intents",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sonos/nlu-benchmark/tree/master/2016-12-built-in-intents",
        "GitHub URL": "https://github.com/sonos/nlu-benchmark/tree/master/2016-12-built-in-intents",
        "Hugging Face URL": "https://huggingface.co/datasets/snips_built_in_intents",
        "Paper Title": "Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces",
        "Papers with Code URL": "https://paperswithcode.com/dataset/snips",
        "ArXiv URL": "https://arxiv.org/abs/1805.10190",
        "Semantic Scholar Corpus ID": 44061213,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 22,
            "Mean Inputs Length": 573.3636,
            "Mean Targets Length": 6.9091,
            "Max Inputs Length": 655,
            "Max Targets Length": 12,
            "Min Inputs Length": 466,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "original"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Snips"
        ],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://huggingface.co/datasets/snips_built_in_intents#source-data"
            }
        ],
        "License Notes": "Unclear how the data was made/collected even in the article: https://huggingface.co/datasets/snips_built_in_intents#source-data. Paper may provide more insight",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "snips_built_in_intents"
        ],
        "Inferred Metadata": {
            "HF Dataset": "snips_built_in_intents",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC0 1.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-05-25",
            "GitHub License": "CC0 1.0",
            "Text Topics": [
                "Navigation",
                "Geography",
                "Transportation",
                "Restaurant reservations",
                "Communication",
                "Weather",
                "Location-based services",
                "Travel",
                "Food and dining",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1496,
            "HF Likes (September 2023)": 4,
            "PwC Description": "The SNIPS Natural Language Understanding benchmark is a dataset of over 16,000 crowdsourced queries distributed among 7 user intents of various complexity:\n\n\nSearchCreativeWork (e.g. Find me the I, Robot television show),\nGetWeather (e.g. Is it windy in Boston, MA right now?),\nBookRestaurant (e.g. I want to book a highly rated restaurant in Paris tomorrow night),\nPlayMusic (e.g. Play the last track from Beyonc off Spotify),\nAddToPlaylist (e.g. Add Diamonds to my roadtrip playlist),\nRateBook (e.g. Give 6 stars to Of Mice and Men),\nSearchScreeningEvent (e.g. Check the showtimes for Wonder Woman in Paris).\nThe training set contains of 13,084 utterances, the validation set and the test set contain 700 utterances each, with 100 queries per intent.",
            "S2 Citation Count (September 2023)": 604,
            "GitHub Stars": 484,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Coucke2018SnipsVP,\n author = {A. Coucke and Alaa Saade and Adrien Ball and Thodore Bluche and A. Caulier and David Leroy and Clment Doumouro and Thibault Gisselbrecht and F. Caltagirone and Thibaut Lavril and Mal Primet and J. Dureau},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces},\n volume = {abs/1805.10190},\n year = {2018}\n}\n"
    },
    "tsy-hate_speech_offensive": {
        "Unique Dataset Identifier": "tsy-hate_speech_offensive",
        "Dataset Name": "hate_speech_offensive",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/t-davidson/hate-speech-and-offensive-language",
        "GitHub URL": "https://github.com/Vicomtech/hate-speech-dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/hate_speech_offensive",
        "Paper Title": "Hate Speech Dataset from a White Supremacy Forum",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hate-speech",
        "ArXiv URL": "https://arxiv.org/abs/1809.04444",
        "Semantic Scholar Corpus ID": 52194540,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1252,
            "Mean Inputs Length": 925.345,
            "Mean Targets Length": 6.5679,
            "Max Inputs Length": 1652,
            "Max Targets Length": 16,
            "Min Inputs Length": 585,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "stormfront.org"
        ],
        "Model Generated": [],
        "Creators": [
            "HSLT Group at Vicomtech"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "States it is a curated list of tweets: https://huggingface.co/datasets/hate_speech_offensive#dataset-summary",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "hate_speech_offensive"
        ],
        "Inferred Metadata": {
            "HF Dataset": "hate_speech18",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/3.0/es/",
            "PwC Date": "",
            "S2 Date": "2018-09-12",
            "GitHub License": "",
            "Text Topics": [
                "Offensive language and its impact",
                "Offensive language",
                "Social media etiquette",
                "Language and communication",
                "Offensive language and hate speech",
                "Social media and online interactions",
                "Social media",
                "Social norms and etiquette",
                "Social interactions",
                "Language and Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 6310,
            "HF Likes (September 2023)": 5,
            "PwC Description": "Dataset of hate speech annotated on Internet forum posts in English at sentence-level. The source forum in Stormfront, a large online community of white nacionalists. A total of 10,568 sentence have been been extracted from Stormfront and classified as conveying hate speech or not.",
            "S2 Citation Count (September 2023)": 270,
            "GitHub Stars": 133,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Gibert2018HateSD,\n author = {Ona de Gibert and Naiara Prez and Aitor Garca-Pablos and Montse Cuadros},\n booktitle = {Workshop on Abusive Language Online},\n journal = {ArXiv},\n title = {Hate Speech Dataset from a White Supremacy Forum},\n volume = {abs/1809.04444},\n year = {2018}\n}\n"
    },
    "tsy-hyperpartisan_news": {
        "Unique Dataset Identifier": "tsy-hyperpartisan_news",
        "Dataset Name": "hyperpartisan_news",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/hyperpartisan_news_detection",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/hyperpartisan_news_detection",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Open-Domain Question Answering",
            "Sentiment Analysis",
            "Fact Verification",
            "Multiple Choice Question Answering",
            "Fact Checking",
            "Natural Language Understanding",
            "Factual Statement Verification",
            "Image Caption Generation"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 46,
            "Mean Inputs Length": 30652.413,
            "Mean Targets Length": 6.4783,
            "Max Inputs Length": 50692,
            "Max Targets Length": 11,
            "Min Inputs Length": 17617,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": null
            }
        ],
        "License Notes": "https://huggingface.co/datasets/hyperpartisan_news_detection#licensing-information",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "hyperpartisan_news"
        ],
        "Inferred Metadata": {
            "HF Dataset": "zapsdcn/hyperpartisan_news",
            "HF Config": "zapsdcn--hyperpartisan_news",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Politics",
                "Social media",
                "Current events",
                "Sports",
                "Public opinion",
                "Social activism",
                "Social issues",
                "Journalism",
                "International relations"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2585,
            "HF Likes (September 2023)": 8,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-sciie": {
        "Unique Dataset Identifier": "tsy-sciie",
        "Dataset Name": "sciie",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://nlp.cs.washington.edu/sciIE/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/zapsdcn/sciie",
        "Paper Title": "Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction",
        "Papers with Code URL": "https://paperswithcode.com/dataset/scierc",
        "ArXiv URL": "https://arxiv.org/abs/1808.09602",
        "Semantic Scholar Corpus ID": 52118895,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 354,
            "Mean Inputs Length": 1872.1384,
            "Mean Targets Length": 6.3644,
            "Max Inputs Length": 3821,
            "Max Targets Length": 14,
            "Min Inputs Length": 1175,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semantic scholar articles"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "sciie"
        ],
        "Inferred Metadata": {
            "HF Dataset": "zapsdcn/sciie",
            "HF Config": "zapsdcn--sciie",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-08-29",
            "GitHub License": "",
            "Text Topics": [
                "Machine Learning",
                "Natural Language Processing",
                "Artificial intelligence",
                "Machine learning",
                "Linguistics",
                "Artificial Intelligence",
                "Image processing"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 354,
            "HF Likes (September 2023)": 0,
            "PwC Description": "SciERC dataset is a collection of 500 scientific abstract annotated with scientific entities, their relations, and coreference clusters. The abstracts are taken from 12 AI conference/workshop proceedings in four AI communities, from the Semantic Scholar Corpus. SciERC extends previous datasets in scientific articles SemEval 2017 Task 10 and SemEval 2018 Task 7 by extending entity types, relation types, relation coverage, and adding cross-sentence relations using coreference links.",
            "S2 Citation Count (September 2023)": 449,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Luan2018MultiTaskIO,\n author = {Yi Luan and Luheng He and Mari Ostendorf and Hannaneh Hajishirzi},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {3219-3232},\n title = {Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction},\n year = {2018}\n}\n"
    },
    "tsy-citation_intent": {
        "Unique Dataset Identifier": "tsy-citation_intent",
        "Dataset Name": "citation_intent",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/zapsdcn/citation_intent",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/zapsdcn/citation_intent",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 187,
            "Mean Inputs Length": 2150.016,
            "Mean Targets Length": 6.754,
            "Max Inputs Length": 3582,
            "Max Targets Length": 14,
            "Min Inputs Length": 1360,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "citation_intent"
        ],
        "Inferred Metadata": {
            "HF Dataset": "zapsdcn/citation_intent",
            "HF Config": "zapsdcn--citation_intent",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Natural language processing",
                "Machine Learning",
                "Natural Language Processing",
                "Linguistics",
                "Computational linguistics",
                "Information Extraction",
                "Machine Translation",
                "Computational Linguistics",
                "Information retrieval",
                "Machine learning"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 318,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-scicite": {
        "Unique Dataset Identifier": "tsy-scicite",
        "Dataset Name": "scicite",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/allenai/scicite",
        "GitHub URL": "https://github.com/allenai/scicite",
        "Hugging Face URL": "https://huggingface.co/datasets/scicite",
        "Paper Title": "Structural Scaffolds for Citation Intent Classification in Scientific Publications",
        "Papers with Code URL": "https://paperswithcode.com/dataset/scicite",
        "ArXiv URL": "https://arxiv.org/abs/1904.01608",
        "Semantic Scholar Corpus ID": 102483154,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Document Classification",
            "Multiple Choice Question Answering",
            "Discourse Analysis",
            "Systematic Review Summarization",
            "Retrospective Study Classification",
            "Information Retrieval",
            "Document Retrieval",
            "Critical Review Summarization",
            "Citation Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 838,
            "Mean Inputs Length": 2130.8532,
            "Mean Targets Length": 6.6026,
            "Max Inputs Length": 5558,
            "Max Targets Length": 15,
            "Min Inputs Length": 1393,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semantic scholar articles"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "scicite"
        ],
        "Inferred Metadata": {
            "HF Dataset": "scicite",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2019-01-01",
            "S2 Date": "2019-04-01",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Genetics",
                "Cell biology",
                "Biology",
                "Molecular biology",
                "Medicine",
                "Research methodology",
                "Data analysis",
                "Bioinformatics"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 690,
            "HF Likes (September 2023)": 3,
            "PwC Description": "SciCite is a dataset of citation intents that addresses multiple scientific domains and is more than five times larger than ACL-ARC.",
            "S2 Citation Count (September 2023)": 160,
            "GitHub Stars": 106,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Cohan2019StructuralSF,\n author = {Arman Cohan and Waleed Ammar and Madeleine van Zuylen and Field Cady},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Structural Scaffolds for Citation Intent Classification in Scientific Publications},\n volume = {abs/1904.01608},\n year = {2019}\n}\n"
    },
    "tsy-lexical_relation_classification-root09": {
        "Unique Dataset Identifier": "tsy-lexical_relation_classification-root09",
        "Dataset Name": "lexical_relation_classification-root09",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/asahi417/relbert",
        "GitHub URL": "https://github.com/asahi417/relbert",
        "Hugging Face URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification",
        "Paper Title": "SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2110.15705",
        "Semantic Scholar Corpus ID": 196172347,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Necessity Classification",
            "Multiple Choice Question Answering",
            "Word Association",
            "Lexical Semantic Relation Classification",
            "Word Sense Disambiguation",
            "Hypernym Classification",
            "Open-Domain Conversation Generation",
            "Open-Domain Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 988,
            "Mean Inputs Length": 295.0547,
            "Mean Targets Length": 6.5881,
            "Max Inputs Length": 354,
            "Max Targets Length": 16,
            "Min Inputs Length": 249,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semeval 2012 task 2",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification#license"
            }
        ],
        "License Notes": "License from huggingface but looks legit. The datasets the data is from is listed at the top so we can also go through the licensing on those if need be to confirm",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lexical_relation_classification/ROOT09"
        ],
        "Inferred Metadata": {
            "HF Dataset": "relbert/lexical_relation_classification",
            "HF Config": "BLESS",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-01",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Biology",
                "Vocabulary",
                "Weapons",
                "Word association",
                "Food",
                "Randomness",
                "Clothing"
            ],
            "Github Date": "",
            "HF Date": "2022-07-20",
            "HF Downloads (September 2023)": 140,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": 39,
            "GitHub Topics": [
                "bert",
                "nlp",
                "relation-extraction"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wang2019SphereREDL,\n author = {Chengyu Wang and Xiaofeng He and Aoying Zhou},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1727-1737},\n title = {SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings},\n year = {2019}\n}\n"
    },
    "tsy-lexical_relation_classification-cogalexv": {
        "Unique Dataset Identifier": "tsy-lexical_relation_classification-cogalexv",
        "Dataset Name": "lexical_relation_classification-cogalexv",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/asahi417/relbert",
        "GitHub URL": "https://github.com/asahi417/relbert",
        "Hugging Face URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification",
        "Paper Title": "SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2110.15705",
        "Semantic Scholar Corpus ID": 196172347,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 187,
            "Mean Inputs Length": 283.7219,
            "Mean Targets Length": 6.2567,
            "Max Inputs Length": 342,
            "Max Targets Length": 15,
            "Min Inputs Length": 239,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semeval 2012 task 2",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification#license"
            }
        ],
        "License Notes": "License from huggingface but looks legit. The datasets the data is from is listed at the top so we can also go through the licensing on those if need be to confirm",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lexical_relation_classification/CogALexV"
        ],
        "Inferred Metadata": {
            "HF Dataset": "relbert/lexical_relation_classification",
            "HF Config": "BLESS",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-01",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Word association",
                "Vocabulary",
                "Language",
                "Communication",
                "Language and semantics",
                "Linguistics",
                "General knowledge",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2022-07-20",
            "HF Downloads (September 2023)": 140,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": 39,
            "GitHub Topics": [
                "bert",
                "nlp",
                "relation-extraction"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wang2019SphereREDL,\n author = {Chengyu Wang and Xiaofeng He and Aoying Zhou},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1727-1737},\n title = {SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings},\n year = {2019}\n}\n"
    },
    "tsy-lexical_relation_classification-k&h+n": {
        "Unique Dataset Identifier": "tsy-lexical_relation_classification-k&h+n",
        "Dataset Name": "lexical_relation_classification-k&h+n",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/asahi417/relbert",
        "GitHub URL": "https://github.com/asahi417/relbert",
        "Hugging Face URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification",
        "Paper Title": "SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2110.15705",
        "Semantic Scholar Corpus ID": 196172347,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4472,
            "Mean Inputs Length": 311.2652,
            "Mean Targets Length": 6.646,
            "Max Inputs Length": 378,
            "Max Targets Length": 22,
            "Min Inputs Length": 253,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semeval 2012 task 2",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification#license"
            }
        ],
        "License Notes": "License from huggingface but looks legit. The datasets the data is from is listed at the top so we can also go through the licensing on those if need be to confirm",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lexical_relation_classification/K&H+N"
        ],
        "Inferred Metadata": {
            "HF Dataset": "relbert/lexical_relation_classification",
            "HF Config": "BLESS",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-01",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Linguistics",
                "Categorization and classification",
                "Botanical knowledge",
                "Animal classification",
                "Language and semantics",
                "Zoology",
                "Taxonomy",
                "Biology",
                "Vocabulary"
            ],
            "Github Date": "",
            "HF Date": "2022-07-20",
            "HF Downloads (September 2023)": 140,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": 39,
            "GitHub Topics": [
                "bert",
                "nlp",
                "relation-extraction"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wang2019SphereREDL,\n author = {Chengyu Wang and Xiaofeng He and Aoying Zhou},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1727-1737},\n title = {SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings},\n year = {2019}\n}\n"
    },
    "tsy-lexical_relation_classification-bless": {
        "Unique Dataset Identifier": "tsy-lexical_relation_classification-bless",
        "Dataset Name": "lexical_relation_classification-bless",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/asahi417/relbert",
        "GitHub URL": "https://github.com/asahi417/relbert",
        "Hugging Face URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification",
        "Paper Title": "SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2110.15705",
        "Semantic Scholar Corpus ID": 196172347,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2064,
            "Mean Inputs Length": 293.0102,
            "Mean Targets Length": 6.5916,
            "Max Inputs Length": 361,
            "Max Targets Length": 15,
            "Min Inputs Length": 240,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semeval 2012 task 2",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification#license"
            }
        ],
        "License Notes": "License from huggingface but looks legit. The datasets the data is from is listed at the top so we can also go through the licensing on those if need be to confirm",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lexical_relation_classification/BLESS"
        ],
        "Inferred Metadata": {
            "HF Dataset": "relbert/lexical_relation_classification",
            "HF Config": "BLESS",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-01",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Food",
                "Biology",
                "Animals",
                "Transportation",
                "Linguistics",
                "Music",
                "Cooking"
            ],
            "Github Date": "",
            "HF Date": "2022-07-20",
            "HF Downloads (September 2023)": 140,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": 39,
            "GitHub Topics": [
                "bert",
                "nlp",
                "relation-extraction"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wang2019SphereREDL,\n author = {Chengyu Wang and Xiaofeng He and Aoying Zhou},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1727-1737},\n title = {SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings},\n year = {2019}\n}\n"
    },
    "tsy-lexical_relation_classification-evalution": {
        "Unique Dataset Identifier": "tsy-lexical_relation_classification-evalution",
        "Dataset Name": "lexical_relation_classification-evalution",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/asahi417/relbert",
        "GitHub URL": "https://github.com/asahi417/relbert",
        "Hugging Face URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification",
        "Paper Title": "SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2110.15705",
        "Semantic Scholar Corpus ID": 196172347,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 572,
            "Mean Inputs Length": 281.6434,
            "Mean Targets Length": 6.5402,
            "Max Inputs Length": 356,
            "Max Targets Length": 14,
            "Min Inputs Length": 237,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semeval 2012 task 2",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification#license"
            }
        ],
        "License Notes": "License from huggingface but looks legit. The datasets the data is from is listed at the top so we can also go through the licensing on those if need be to confirm",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lexical_relation_classification/EVALution"
        ],
        "Inferred Metadata": {
            "HF Dataset": "relbert/lexical_relation_classification",
            "HF Config": "BLESS",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-01",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Language and semantics",
                "Linguistics",
                "Language",
                "General knowledge",
                "Word Relationships",
                "Anatomy",
                "Vocabulary",
                "Biology"
            ],
            "Github Date": "",
            "HF Date": "2022-07-20",
            "HF Downloads (September 2023)": 140,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": 39,
            "GitHub Topics": [
                "bert",
                "nlp",
                "relation-extraction"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wang2019SphereREDL,\n author = {Chengyu Wang and Xiaofeng He and Aoying Zhou},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1727-1737},\n title = {SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings},\n year = {2019}\n}\n"
    },
    "tsy-crowdflower-political_media_bias": {
        "Unique Dataset Identifier": "tsy-crowdflower-political_media_bias",
        "Dataset Name": "crowdflower-political_media_bias",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Sentiment Analysis",
            "Open-Ended Question Answering",
            "Open-Domain Question Answering",
            "Dialogue Generation",
            "Binary Classification",
            "Information Retrieval"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 298,
            "Mean Inputs Length": 2026.4832,
            "Mean Targets Length": 6.6745,
            "Max Inputs Length": 17036,
            "Max Targets Length": 14,
            "Min Inputs Length": 901,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/political-media-bias"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Healthcare policy",
                "Politics",
                "Social media",
                "Economics",
                "Government",
                "Education",
                "Political discourse",
                "Current events",
                "Media",
                "Healthcare"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsy-crowdflower-tweet_global_warming": {
        "Unique Dataset Identifier": "tsy-crowdflower-tweet_global_warming",
        "Dataset Name": "crowdflower-tweet_global_warming",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Binary Classification",
            "Sentiment Analysis",
            "Multiple Choice Question Answering",
            "Binary Classification Question Answering",
            "Open-Domain Question Answering",
            "Text Classification",
            "Fact Verification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 247,
            "Mean Inputs Length": 1151.1862,
            "Mean Targets Length": 6.5142,
            "Max Inputs Length": 1348,
            "Max Targets Length": 14,
            "Min Inputs Length": 892,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/tweet_global_warming"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Environmental issues",
                "Global warming",
                "Environmental activism",
                "Climate change",
                "Environmental sustainability",
                "Economics",
                "Environmental science",
                "Social media",
                "Environmental impact",
                "Politics"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsy-crowdflower-text_emotion": {
        "Unique Dataset Identifier": "tsy-crowdflower-text_emotion",
        "Dataset Name": "crowdflower-text_emotion",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3869,
            "Mean Inputs Length": 798.4888,
            "Mean Targets Length": 6.6048,
            "Max Inputs Length": 1133,
            "Max Targets Length": 22,
            "Min Inputs Length": 456,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/text_emotion"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Music",
                "Entertainment",
                "Relationships",
                "Emotional well-being",
                "Emotions",
                "Communication",
                "Personal experiences",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsy-crowdflower-political_media_message": {
        "Unique Dataset Identifier": "tsy-crowdflower-political_media_message",
        "Dataset Name": "crowdflower-political_media_message",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 476,
            "Mean Inputs Length": 1946.6702,
            "Mean Targets Length": 6.5231,
            "Max Inputs Length": 16143,
            "Max Targets Length": 15,
            "Min Inputs Length": 897,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/political-media-message"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Government and politics",
                "Social media",
                "Healthcare",
                "Communication",
                "Government",
                "Current events",
                "Legislative process",
                "History"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsy-crowdflower-political_media_audience": {
        "Unique Dataset Identifier": "tsy-crowdflower-political_media_audience",
        "Dataset Name": "crowdflower-political_media_audience",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Open-Ended Question Answering",
            "Classification",
            "Sentiment Analysis",
            "Sentence Classification",
            "Natural Language Understanding",
            "Span Selection Question Answering",
            "Open-Domain Question Answering",
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 232,
            "Mean Inputs Length": 1969.9957,
            "Mean Targets Length": 6.5603,
            "Max Inputs Length": 4722,
            "Max Targets Length": 16,
            "Min Inputs Length": 961,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/political-media-audience"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "History",
                "Healthcare",
                "Government",
                "Public policy",
                "Current events",
                "Education",
                "Immigration policy",
                "Social media",
                "Politics"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsy-crowdflower-economic_news": {
        "Unique Dataset Identifier": "tsy-crowdflower-economic_news",
        "Dataset Name": "crowdflower-economic_news",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Stock Market Analysis",
            "News Article Summarization",
            "Price Prediction",
            "Open-Ended Question Answering",
            "Summarization",
            "Information Extraction",
            "Sentiment Analysis",
            "Demographic Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 309,
            "Mean Inputs Length": 12616.3657,
            "Mean Targets Length": 6.5761,
            "Max Inputs Length": 17017,
            "Max Targets Length": 14,
            "Min Inputs Length": 9423,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/economic-news"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Financial news",
                "Financial markets",
                "Stock market",
                "Monetary policy",
                "Government policies",
                "Economic indicators",
                "Stock market analysis",
                "Finance",
                "Economics"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsy-crowdflower-corporate_messaging": {
        "Unique Dataset Identifier": "tsy-crowdflower-corporate_messaging",
        "Dataset Name": "crowdflower-corporate_messaging",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 222,
            "Mean Inputs Length": 1225.8243,
            "Mean Targets Length": 6.6081,
            "Max Inputs Length": 1390,
            "Max Targets Length": 14,
            "Min Inputs Length": 1032,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/corporate-messaging"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Corporate social responsibility",
                "Social media",
                "Banking industry",
                "Product recall",
                "Food safety",
                "Health",
                "Health and wellness",
                "Social media communication",
                "Finance",
                "Healthcare"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsy-crowdflower-airline_sentiment": {
        "Unique Dataset Identifier": "tsy-crowdflower-airline_sentiment",
        "Dataset Name": "crowdflower-airline_sentiment",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1232,
            "Mean Inputs Length": 1054.0479,
            "Mean Targets Length": 6.6169,
            "Max Inputs Length": 1332,
            "Max Targets Length": 15,
            "Min Inputs Length": 716,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/airline-sentiment"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Social media communication",
                "Airline industry",
                "Customer service",
                "Customer service experience",
                "Air travel",
                "Communication",
                "Travel",
                "Baggage handling",
                "Complaints"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsy-crowdflower-sentiment_nuclear_power": {
        "Unique Dataset Identifier": "tsy-crowdflower-sentiment_nuclear_power",
        "Dataset Name": "crowdflower-sentiment_nuclear_power",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6,
            "Mean Inputs Length": 1151.8333,
            "Mean Targets Length": 7.1667,
            "Max Inputs Length": 1217,
            "Max Targets Length": 11,
            "Min Inputs Length": 1074,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/sentiment_nuclear_power"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Nuclear power",
                "Nuclear energy",
                "Environmental impact",
                "Social media",
                "Technology",
                "Energy sources",
                "Science"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsy-ethics-commonsense": {
        "Unique Dataset Identifier": "tsy-ethics-commonsense",
        "Dataset Name": "ethics-commonsense",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/hendrycks/ethics",
        "GitHub URL": "https://github.com/hendrycks/ethics",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/ethics",
        "Paper Title": "ALIGNING AI WITH SHARED HUMAN VALUES",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ethics-1",
        "ArXiv URL": "https://arxiv.org/abs/2008.02275",
        "Semantic Scholar Corpus ID": 220968818,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Binary Classification Question Answering",
            "Polite Response Generation",
            "Offensive Language Detection",
            "Sentiment Analysis",
            "Natural Language Understanding",
            "Argument Resolution",
            "Cooking Instruction Understanding",
            "Binary Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1544,
            "Mean Inputs Length": 9310.5551,
            "Mean Targets Length": 6.7027,
            "Max Inputs Length": 30000,
            "Max Targets Length": 22,
            "Min Inputs Length": 421,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Berkeley",
            "Columbia University",
            "University of Chicago",
            "Microsoft"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ethics/commonsense"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/ethics",
            "HF Config": "commonsense",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-08-05",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Relationships",
                "Family dynamics",
                "Ethics and morality",
                "Ethics",
                "Communication and conflict resolution",
                "Social etiquette",
                "Family dynamics and relationships",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 447,
            "HF Likes (September 2023)": 4,
            "PwC Description": "A new benchmark that spans concepts in justice, well-being, duties, virtues, and commonsense morality.",
            "S2 Citation Count (September 2023)": 147,
            "GitHub Stars": 150,
            "GitHub Topics": [
                "ai-safety",
                "ethical-ai",
                "gpt-3",
                "machine-ethics",
                "ml-safety"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hendrycks2020AligningAW,\n author = {Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and J. Li and D. Song and J. Steinhardt},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Aligning AI With Shared Human Values},\n volume = {abs/2008.02275},\n year = {2020}\n}\n"
    },
    "tsy-ethics-deontology": {
        "Unique Dataset Identifier": "tsy-ethics-deontology",
        "Dataset Name": "ethics-deontology",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/hendrycks/ethics",
        "GitHub URL": "https://github.com/hendrycks/ethics",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/ethics",
        "Paper Title": "ALIGNING AI WITH SHARED HUMAN VALUES",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ethics-1",
        "ArXiv URL": "https://arxiv.org/abs/2008.02275",
        "Semantic Scholar Corpus ID": 220968818,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Binary Classification Question Answering",
            "Natural Language Understanding",
            "Open-Domain Question Answering",
            "Binary Classification",
            "Open-Domain Conversation Generation",
            "Binary Question Answering",
            "Request Fulfillment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2018,
            "Mean Inputs Length": 557.2314,
            "Mean Targets Length": 6.6571,
            "Max Inputs Length": 916,
            "Max Targets Length": 16,
            "Min Inputs Length": 407,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Berkeley",
            "Columbia University",
            "University of Chicago",
            "Microsoft"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ethics/deontology"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/ethics",
            "HF Config": "commonsense",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-08-05",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Customer service",
                "Cooking",
                "Home maintenance",
                "Travel",
                "Communication",
                "Household chores",
                "Time management"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 447,
            "HF Likes (September 2023)": 4,
            "PwC Description": "A new benchmark that spans concepts in justice, well-being, duties, virtues, and commonsense morality.",
            "S2 Citation Count (September 2023)": 147,
            "GitHub Stars": 150,
            "GitHub Topics": [
                "ai-safety",
                "ethical-ai",
                "gpt-3",
                "machine-ethics",
                "ml-safety"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hendrycks2020AligningAW,\n author = {Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and J. Li and D. Song and J. Steinhardt},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Aligning AI With Shared Human Values},\n volume = {abs/2008.02275},\n year = {2020}\n}\n"
    },
    "tsy-ethics-justice": {
        "Unique Dataset Identifier": "tsy-ethics-justice",
        "Dataset Name": "ethics-justice",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/hendrycks/ethics",
        "GitHub URL": "https://github.com/hendrycks/ethics",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/ethics",
        "Paper Title": "ALIGNING AI WITH SHARED HUMAN VALUES",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ethics-1",
        "ArXiv URL": "https://arxiv.org/abs/2008.02275",
        "Semantic Scholar Corpus ID": 220968818,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Binary Classification Question Answering",
            "Sentiment Analysis",
            "Natural Language Inference",
            "Binary Classification",
            "Multiple Choice Question Answering",
            "Open-Domain Question Answering",
            "Age-based Restriction Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2421,
            "Mean Inputs Length": 1069.007,
            "Mean Targets Length": 6.5898,
            "Max Inputs Length": 1732,
            "Max Targets Length": 15,
            "Min Inputs Length": 712,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Berkeley",
            "Columbia University",
            "University of Chicago",
            "Microsoft"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ethics/justice"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/ethics",
            "HF Config": "commonsense",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-08-05",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Health",
                "Communication",
                "Ethics and morality",
                "Social interactions",
                "Etiquette",
                "Family dynamics",
                "Parenting"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 447,
            "HF Likes (September 2023)": 4,
            "PwC Description": "A new benchmark that spans concepts in justice, well-being, duties, virtues, and commonsense morality.",
            "S2 Citation Count (September 2023)": 147,
            "GitHub Stars": 150,
            "GitHub Topics": [
                "ai-safety",
                "ethical-ai",
                "gpt-3",
                "machine-ethics",
                "ml-safety"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hendrycks2020AligningAW,\n author = {Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and J. Li and D. Song and J. Steinhardt},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Aligning AI With Shared Human Values},\n volume = {abs/2008.02275},\n year = {2020}\n}\n"
    },
    "tsy-ethics-virtue": {
        "Unique Dataset Identifier": "tsy-ethics-virtue",
        "Dataset Name": "ethics-virtue",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/hendrycks/ethics",
        "GitHub URL": "https://github.com/hendrycks/ethics",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/ethics",
        "Paper Title": "ALIGNING AI WITH SHARED HUMAN VALUES",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ethics-1",
        "ArXiv URL": "https://arxiv.org/abs/2008.02275",
        "Semantic Scholar Corpus ID": 220968818,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Sentence Classification",
            "Natural Language Classification",
            "Natural Language Inference",
            "Multiple Choice Question Answering",
            "Binary Classification",
            "Fact Verification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 603,
            "Mean Inputs Length": 901.5224,
            "Mean Targets Length": 6.6517,
            "Max Inputs Length": 1271,
            "Max Targets Length": 15,
            "Min Inputs Length": 704,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Berkeley",
            "Columbia University",
            "University of Chicago",
            "Microsoft"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ethics/virtue"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/ethics",
            "HF Config": "commonsense",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-08-05",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Ethics and morality",
                "Ethics",
                "Daily routine",
                "Relationships",
                "Parenting",
                "Social interactions",
                "Study habits",
                "Health",
                "Emotional intelligence"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 447,
            "HF Likes (September 2023)": 4,
            "PwC Description": "A new benchmark that spans concepts in justice, well-being, duties, virtues, and commonsense morality.",
            "S2 Citation Count (September 2023)": 147,
            "GitHub Stars": 150,
            "GitHub Topics": [
                "ai-safety",
                "ethical-ai",
                "gpt-3",
                "machine-ethics",
                "ml-safety"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hendrycks2020AligningAW,\n author = {Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and J. Li and D. Song and J. Steinhardt},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Aligning AI With Shared Human Values},\n volume = {abs/2008.02275},\n year = {2020}\n}\n"
    },
    "tsy-tweets_hate_speech_detection": {
        "Unique Dataset Identifier": "tsy-tweets_hate_speech_detection",
        "Dataset Name": "tweets_hate_speech_detection",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sharmaroshan/Twitter-Sentiment-Analysis",
        "GitHub URL": "https://github.com/sharmaroshan/Twitter-Sentiment-Analysis",
        "Hugging Face URL": "https://huggingface.co/datasets/tweets_hate_speech_detection",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 502,
            "Mean Inputs Length": 922.4143,
            "Mean Targets Length": 6.4183,
            "Max Inputs Length": 1131,
            "Max Targets Length": 16,
            "Min Inputs Length": 691,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Github readme is an article on the dataset which doesn't seem to have an actual paper",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweets_hate_speech_detection"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweets_hate_speech_detection",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "GNU General Public License v3.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "Daily routine",
                "Social media",
                "Emotions",
                "Social media etiquette",
                "Online communication",
                "Travel",
                "Education",
                "Social media and online communication",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 927,
            "HF Likes (September 2023)": 12,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 162,
            "GitHub Topics": [
                "bag-of-words",
                "classification",
                "count-vectorizer",
                "cross-validation",
                "data-analysis",
                "data-visualization",
                "datacleaning",
                "eda",
                "evaluation-metrics",
                "hashtags",
                "machine-learning",
                "nlp",
                "sentiment-analysis",
                "wordcloud"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-blog_authorship_corpus-gender": {
        "Unique Dataset Identifier": "tsy-blog_authorship_corpus-gender",
        "Dataset Name": "blog_authorship_corpus-gender",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://lingcog.blogspot.com/p/datasets.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/blog_authorship_corpus",
        "Paper Title": "Effects of Age and Gender on Blogging",
        "Papers with Code URL": "https://paperswithcode.com/dataset/blog-authorship-corpus",
        "ArXiv URL": "https://arxiv.org/abs/2306.02488",
        "Semantic Scholar Corpus ID": 2075411,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Text Classification",
            "Natural Language Understanding",
            "Multiple Choice Question Answering",
            "Open-Domain Conversation Generation",
            "Dialogue Generation",
            "Named Entity Recognition",
            "Guestlist Generation",
            "Dialogue Understanding",
            "Summarization"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 269,
            "Mean Inputs Length": 9146.0335,
            "Mean Targets Length": 6.4461,
            "Max Inputs Length": 26319,
            "Max Targets Length": 14,
            "Min Inputs Length": 2250,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "blogger.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Pennsylvania State University",
            "Wright State University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://u.cs.biu.ac.il/~koppel/BlogCorpus.htm"
            }
        ],
        "License Notes": "Academic Research Purposes Only",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "blog_authorship_corpus/gender"
        ],
        "Inferred Metadata": {
            "HF Dataset": "blog_authorship_corpus",
            "HF Config": "blog_authorship_corpus",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Music",
                "Personal experiences",
                "Gender identity",
                "Technology",
                "Gender stereotypes",
                "Daily routine",
                "Health",
                "Social media",
                "Gender and identity"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 917,
            "HF Likes (September 2023)": 4,
            "PwC Description": "The Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or approximately 35 posts and 7250 words per person.",
            "S2 Citation Count (September 2023)": 765,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Schler2006EffectsOA,\n author = {Jonathan Schler and Moshe Koppel and S. Argamon and J. Pennebaker},\n booktitle = {AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs},\n pages = {199-205},\n title = {Effects of Age and Gender on Blogging},\n year = {2006}\n}\n"
    },
    "tsy-blog_authorship_corpus-horoscope": {
        "Unique Dataset Identifier": "tsy-blog_authorship_corpus-horoscope",
        "Dataset Name": "blog_authorship_corpus-horoscope",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://lingcog.blogspot.com/p/datasets.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/blog_authorship_corpus",
        "Paper Title": "Effects of Age and Gender on Blogging",
        "Papers with Code URL": "https://paperswithcode.com/dataset/blog-authorship-corpus",
        "ArXiv URL": "https://arxiv.org/abs/2306.02488",
        "Semantic Scholar Corpus ID": 2075411,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 270,
            "Mean Inputs Length": 9164.2037,
            "Mean Targets Length": 6.7333,
            "Max Inputs Length": 31479,
            "Max Targets Length": 14,
            "Min Inputs Length": 2008,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "blogger.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Pennsylvania State University",
            "Wright State University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://u.cs.biu.ac.il/~koppel/BlogCorpus.htm"
            }
        ],
        "License Notes": "Non-commercial research only",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "blog_authorship_corpus/horoscope"
        ],
        "Inferred Metadata": {
            "HF Dataset": "blog_authorship_corpus",
            "HF Config": "blog_authorship_corpus",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Travel",
                "Astrology and zodiac signs",
                "Zodiac signs",
                "Music",
                "Communication",
                "Literature",
                "Personality traits",
                "Personal experiences",
                "Astrology",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 917,
            "HF Likes (September 2023)": 4,
            "PwC Description": "The Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or approximately 35 posts and 7250 words per person.",
            "S2 Citation Count (September 2023)": 765,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Schler2006EffectsOA,\n author = {Jonathan Schler and Moshe Koppel and S. Argamon and J. Pennebaker},\n booktitle = {AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs},\n pages = {199-205},\n title = {Effects of Age and Gender on Blogging},\n year = {2006}\n}\n"
    },
    "tsy-blog_authorship_corpus-job": {
        "Unique Dataset Identifier": "tsy-blog_authorship_corpus-job",
        "Dataset Name": "blog_authorship_corpus-job",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://lingcog.blogspot.com/p/datasets.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/blog_authorship_corpus",
        "Paper Title": "Effects of Age and Gender on Blogging",
        "Papers with Code URL": "https://paperswithcode.com/dataset/blog-authorship-corpus",
        "ArXiv URL": "https://arxiv.org/abs/2306.02488",
        "Semantic Scholar Corpus ID": 2075411,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 272,
            "Mean Inputs Length": 9252.1103,
            "Mean Targets Length": 6.6471,
            "Max Inputs Length": 36001,
            "Max Targets Length": 14,
            "Min Inputs Length": 2787,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "blogger.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Pennsylvania State University",
            "Wright State University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://u.cs.biu.ac.il/~koppel/BlogCorpus.htm"
            }
        ],
        "License Notes": "Non-commercial research only",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "blog_authorship_corpus/job"
        ],
        "Inferred Metadata": {
            "HF Dataset": "blog_authorship_corpus",
            "HF Config": "blog_authorship_corpus",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Music",
                "Film and entertainment",
                "Technology",
                "Daily routine",
                "Travel",
                "Education",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 917,
            "HF Likes (September 2023)": 4,
            "PwC Description": "The Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or approximately 35 posts and 7250 words per person.",
            "S2 Citation Count (September 2023)": 765,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Schler2006EffectsOA,\n author = {Jonathan Schler and Moshe Koppel and S. Argamon and J. Pennebaker},\n booktitle = {AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs},\n pages = {199-205},\n title = {Effects of Age and Gender on Blogging},\n year = {2006}\n}\n"
    },
    "tsy-open_question_type": {
        "Unique Dataset Identifier": "tsy-open_question_type",
        "Dataset Name": "open_question_type",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://shuyangcao.github.io/projects/ontology_open_ended_question/",
        "GitHub URL": "https://shuyangcao.github.io/projects/ontology_open_ended_question/",
        "Hugging Face URL": "https://huggingface.co/datasets/launch/open_question_type",
        "Paper Title": "Controllable Open-ended Question Generation with A New Question Type Ontology",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2107.00152",
        "Semantic Scholar Corpus ID": 235678938,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 383,
            "Mean Inputs Length": 717.0992,
            "Mean Targets Length": 6.5744,
            "Max Inputs Length": 1204,
            "Max Targets Length": 14,
            "Min Inputs Length": 487,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reddit",
            "yahoo"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Michigan"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "open_question_type"
        ],
        "Inferred Metadata": {
            "HF Dataset": "launch/open_question_type",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-07-01",
            "GitHub License": "",
            "Text Topics": [
                "Personal experiences",
                "Health",
                "Music",
                "Technology",
                "History",
                "Religion",
                "User interface design",
                "Communication",
                "Philosophy"
            ],
            "Github Date": "",
            "HF Date": "2022-06-28",
            "HF Downloads (September 2023)": 99,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 24,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Cao2021ControllableOQ,\n author = {Shuyang Cao and Lu Wang},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Controllable Open-ended Question Generation with A New Question Type Ontology},\n volume = {abs/2107.00152},\n year = {2021}\n}\n"
    },
    "tsy-mc_taco": {
        "Unique Dataset Identifier": "tsy-mc_taco",
        "Dataset Name": "mc_taco",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://cogcomp.seas.upenn.edu/page/resource_view/125",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/mc_taco",
        "Paper Title": "Going on a vacation takes longer than Going for a walk: A Study of Temporal Commonsense Understanding",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mc-taco",
        "ArXiv URL": "https://arxiv.org/abs/1909.03065",
        "Semantic Scholar Corpus ID": 202541184,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Natural Language Understanding",
            "Open-Domain Question Answering",
            "Factoid Question Answering",
            "Open-Ended Question Answering",
            "Span Selection Question Answering",
            "Binary Classification Question Answering",
            "Binary Question Answering",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 274,
            "Mean Inputs Length": 1598.3686,
            "Mean Targets Length": 6.7445,
            "Max Inputs Length": 1935,
            "Max Targets Length": 14,
            "Min Inputs Length": 1271,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "cnn.com",
            "wsj",
            "nytmes",
            "wikipedia.org",
            "project gutenberg",
            "9/11 reports",
            "textbooks",
            "mctest",
            "anc corpus",
            "masc dataset"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Pennsylvania",
            "AI2",
            "University of Illinois Urbana-Champaign"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mc_taco"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mc_taco",
            "HF Config": "plain_text",
            "HF Config License": "Unspecified",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2019-09-06",
            "S2 Date": "2019-09-06",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "International relations",
                "Literature",
                "Time",
                "Health",
                "Time measurement",
                "Education"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1739,
            "HF Likes (September 2023)": 0,
            "PwC Description": "MC-TACO is a dataset of 13k question-answer pairs that require temporal commonsense comprehension. The dataset contains five temporal properties, (1) duration (how long an event takes), (2) temporal ordering (typical order of events), (3) typical time (when an event occurs), (4) frequency (how often an event occurs), and (5) stationarity (whether a state is maintained for a very long time or indefinitely).",
            "S2 Citation Count (September 2023)": 129,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "MultiRC"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zhou2019GoingOA,\n author = {Ben Zhou and Daniel Khashabi and Qiang Ning and D. Roth},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Going on a vacation takes longer than Going for a walk: A Study of Temporal Commonsense Understanding},\n volume = {abs/1909.03065},\n year = {2019}\n}\n"
    },
    "tsy-phrase_similarity": {
        "Unique Dataset Identifier": "tsy-phrase_similarity",
        "Dataset Name": "phrase_similarity",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://phrase-in-context.github.io/",
        "GitHub URL": "https://phrase-in-context.github.io/",
        "Hugging Face URL": "https://huggingface.co/datasets/PiC/phrase_similarity",
        "Paper Title": "PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic Search",
        "Papers with Code URL": "https://paperswithcode.com/dataset/phrase-in-context",
        "ArXiv URL": "https://arxiv.org/abs/2207.09068",
        "Semantic Scholar Corpus ID": 250462558,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 778,
            "Mean Inputs Length": 2687.8817,
            "Mean Targets Length": 6.6748,
            "Max Inputs Length": 3161,
            "Max Targets Length": 14,
            "Min Inputs Length": 2191,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Auburn University",
            "Adobe Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://phrase-in-context.github.io/"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "phrase_similarity"
        ],
        "Inferred Metadata": {
            "HF Dataset": "PiC/phrase_similarity",
            "HF Config": "PS-hard",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "CC BY-NC 4.0",
            "PwC License Name": "CC BY-NC 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-nc/4.0/",
            "PwC Date": "2022-06-10",
            "S2 Date": "2022-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "Business and entrepreneurship",
                "Language and communication",
                "History",
                "Communication",
                "Cultural traditions and customs",
                "Sports"
            ],
            "Github Date": "",
            "HF Date": "2022-06-14",
            "HF Downloads (September 2023)": 394,
            "HF Likes (September 2023)": 6,
            "PwC Description": "Phrase in Context is a curated benchmark for phrase understanding and semantic search, consisting of three tasks of increasing difficulty: Phrase Similarity (PS), Phrase Retrieval (PR) and Phrase Sense Disambiguation (PSD). The datasets are annotated by 13 linguistic experts on Upwork and verified by two groups: ~1000 AMT crowdworkers and another set of 5 linguistic experts. PiC benchmark is distributed under CC-BY-NC 4.0.",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Pham2022PiCAP,\n author = {Thang M. Pham and Seunghyun Yoon and Trung Bui and Anh M Nguyen},\n booktitle = {Conference of the European Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic Search},\n volume = {abs/2207.09068},\n year = {2022}\n}\n"
    },
    "tsy-scientific_exaggeration_detection": {
        "Unique Dataset Identifier": "tsy-scientific_exaggeration_detection",
        "Dataset Name": "scientific_exaggeration_detection",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/copenlu/scientific-exaggeration-detection",
        "GitHub URL": "https://github.com/copenlu/scientific-exaggeration-detection",
        "Hugging Face URL": "https://huggingface.co/datasets/copenlu/scientific-exaggeration-detection",
        "Paper Title": "Semi-Supervised Exaggeration Detection of Health Science Press Releases",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2108.13493",
        "Semantic Scholar Corpus ID": 237363790,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentence Classification",
            "Paraphrase Detection",
            "Comparative Sentence Classification",
            "Multiple Choice Question Answering",
            "Factual Statement Verification",
            "Information Retrieval",
            "Factual Question Answering",
            "Scientific Knowledge Retrieval",
            "Span Selection Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7,
            "Mean Inputs Length": 3297.4286,
            "Mean Targets Length": 7.7143,
            "Max Inputs Length": 3986,
            "Max Targets Length": 13,
            "Min Inputs Length": 2755,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "press releases",
            "sciencedaily"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Copenhagen"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "scientific-exaggeration-detection"
        ],
        "Inferred Metadata": {
            "HF Dataset": "copenlu/scientific-exaggeration-detection",
            "HF Config": "copenlu--scientific-exaggeration-detection",
            "HF Config License": "",
            "HF Yaml License": "GNU General Public License v3.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-08-30",
            "GitHub License": "",
            "Text Topics": [
                "Medical research",
                "Genetics",
                "Biology",
                "Medicine/Health",
                "Health",
                "Science",
                "Scientific research",
                "Research methods",
                "Psychology"
            ],
            "Github Date": "",
            "HF Date": "2022-08-17",
            "HF Downloads (September 2023)": 101,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 8,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "Sumner et al 2014",
            "Bratton et al 2019"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Wright2021SemiSupervisedED,\n author = {Dustin Wright and Isabelle Augenstein},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {10824-10836},\n title = {Semi-Supervised Exaggeration Detection of Health Science Press Releases},\n year = {2021}\n}\n"
    },
    "tsy-fever_evidence_related-mwong__fever_related": {
        "Unique Dataset Identifier": "tsy-fever_evidence_related-mwong__fever_related",
        "Dataset Name": "fever_evidence_related-mwong__fever_related",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/mwong/fever-evidence-related",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/mwong/fever-evidence-related",
        "Paper Title": "FEVER: a large-scale dataset for Fact Extraction and VERification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/fever",
        "ArXiv URL": "https://arxiv.org/abs/1803.05355",
        "Semantic Scholar Corpus ID": 4711425,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Information Retrieval",
            "Binary Classification",
            "Multiple Choice Question Answering",
            "Advertising Slogan Generation",
            "Fact Verification",
            "Knowledge Base Question Answering",
            "Entity Linking",
            "Named Entity Recognition",
            "Historical Event Extraction"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3676,
            "Mean Inputs Length": 15995.0264,
            "Mean Targets Length": 6.5389,
            "Max Inputs Length": 39133,
            "Max Targets Length": 16,
            "Min Inputs Length": 5292,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Sheffield",
            "Amazon"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://fever.ai/download/feverous/license.html"
            }
        ],
        "License Notes": "States that it is data extracted from the fever database: https://fever.ai/. However, it doesn't clearly state which fever dataset the data is from",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "fever-evidence-related/mwong--fever-related"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mwong/fever-evidence-related",
            "HF Config": "mwong--fever-related",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "Custom",
            "PwC License URL": "https://s3-eu-west-1.amazonaws.com/fever.public/license.html",
            "PwC Date": "2018-03-14",
            "S2 Date": "2018-03-14",
            "GitHub License": "",
            "Text Topics": [
                "Culture",
                "History",
                "Biography",
                "Film industry",
                "Entertainment",
                "General knowledge",
                "Geography"
            ],
            "Github Date": "",
            "HF Date": "2022-04-12",
            "HF Downloads (September 2023)": 273,
            "HF Likes (September 2023)": 1,
            "PwC Description": "FEVER is a publicly available dataset for fact extraction and verification against textual sources.\n\nIt consists of 185,445 claims manually verified against the introductory sections of Wikipedia pages and classified as SUPPORTED, REFUTED or NOTENOUGHINFO. For the first two classes, systems and annotators need to also return the combination of sentences forming the necessary evidence supporting or refuting the claim.\n\nThe claims were generated by human annotators extracting claims from Wikipedia and mutating them in a variety of ways, some of which were meaning-altering. The verification of each claim was conducted in a separate annotation process by annotators who were aware of the page but not the sentence from which original claim was\nextracted and thus in 31.75% of the claims more than one sentence was considered appropriate evidence. Claims require composition of evidence from multiple sentences in 16.82% of cases. Furthermore, in 12.15% of the claims, this evidence was taken from multiple pages.",
            "S2 Citation Count (September 2023)": 934,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Thorne2018FEVERAL,\n author = {James Thorne and Andreas Vlachos and Christos Christodoulopoulos and Arpit Mittal},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {FEVER: a Large-scale Dataset for Fact Extraction and VERification},\n volume = {abs/1803.05355},\n year = {2018}\n}\n"
    },
    "tsy-numer_sense": {
        "Unique Dataset Identifier": "tsy-numer_sense",
        "Dataset Name": "numer_sense",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://inklab.usc.edu/NumerSense/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/numer_sense",
        "Paper Title": "Birds Have Four Legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-trained Language Models",
        "Papers with Code URL": "https://paperswithcode.com/dataset/numersense",
        "ArXiv URL": "https://arxiv.org/abs/2005.00683",
        "Semantic Scholar Corpus ID": 218486812,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1028,
            "Mean Inputs Length": 746.0924,
            "Mean Targets Length": 6.4825,
            "Max Inputs Length": 929,
            "Max Targets Length": 16,
            "Min Inputs Length": 553,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "github.com/commonsense/omcs",
            "conceptnet"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "numer_sense"
        ],
        "Inferred Metadata": {
            "HF Dataset": "numer_sense",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-02",
            "GitHub License": "",
            "Text Topics": [
                "Health",
                "General knowledge",
                "Biology",
                "Entomology",
                "Medical conditions",
                "Nutrition",
                "Chemistry",
                "Animal behavior",
                "Animal anatomy"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1373,
            "HF Likes (September 2023)": 1,
            "PwC Description": "Contains 13.6k masked-word-prediction probes, 10.5k for fine-tuning and 3.1k for testing.",
            "S2 Citation Count (September 2023)": 107,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lin2020BirdsHF,\n author = {Bill Yuchen Lin and Seyeon Lee and Rahul Khanna and Xiang Ren},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {6862-6868},\n title = {Birds Have Four Legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-trained Language Models},\n year = {2020}\n}\n"
    },
    "tsy-dynasent-dynabench.dynasent.r1.all-r1": {
        "Unique Dataset Identifier": "tsy-dynasent-dynabench.dynasent.r1.all-r1",
        "Dataset Name": "dynasent-dynabench.dynasent.r1.all-r1",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://dynabench.org/tasks/3",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/dynabench/dynasent",
        "Paper Title": "DynaSent: A Dynamic Benchmark for Sentiment Analysis",
        "Papers with Code URL": "https://paperswithcode.com/dataset/dynasent",
        "ArXiv URL": "https://arxiv.org/abs/2012.15349",
        "Semantic Scholar Corpus ID": 229923903,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5502,
            "Mean Inputs Length": 763.1607,
            "Mean Targets Length": 6.5525,
            "Max Inputs Length": 2176,
            "Max Targets Length": 18,
            "Min Inputs Length": 380,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://huggingface.co/datasets/dynabench/dynasent#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "dynasent/dynabench.dynasent.r1.all/r1"
        ],
        "Inferred Metadata": {
            "HF Dataset": "dynabench/dynasent",
            "HF Config": "dynabench.dynasent.r1.all",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-12-30",
            "GitHub License": "",
            "Text Topics": [
                "Customer service",
                "Daily routine",
                "Communication",
                "Personal experiences",
                "Time management",
                "Travel",
                "Food and dining",
                "Food",
                "Culinary experiences"
            ],
            "Github Date": "",
            "HF Date": "2021-04-29",
            "HF Downloads (September 2023)": 3998,
            "HF Likes (September 2023)": 3,
            "PwC Description": "DynaSent is an English-language benchmark task for ternary (positive/negative/neutral) sentiment analysis. DynaSent combines naturally occurring sentences with sentences created using the open-source Dynabench Platform, which facilities human-and-model-in-the-loop dataset creation. DynaSent has a total of 121,634 sentences, each validated by five crowdworkers.",
            "S2 Citation Count (September 2023)": 49,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Potts2020DynaSentAD,\n author = {Christopher Potts and Zhengxuan Wu and Atticus Geiger and Douwe Kiela},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {DynaSent: A Dynamic Benchmark for Sentiment Analysis},\n volume = {abs/2012.15349},\n year = {2020}\n}\n"
    },
    "tsy-dynasent-dynabench.dynasent.r2.all-r2": {
        "Unique Dataset Identifier": "tsy-dynasent-dynabench.dynasent.r2.all-r2",
        "Dataset Name": "dynasent-dynabench.dynasent.r2.all-r2",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://dynabench.org/tasks/3",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/dynabench/dynasent",
        "Paper Title": "DynaSent: A Dynamic Benchmark for Sentiment Analysis",
        "Papers with Code URL": "https://paperswithcode.com/dataset/dynasent",
        "ArXiv URL": "https://arxiv.org/abs/2012.15349",
        "Semantic Scholar Corpus ID": 229923903,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1450,
            "Mean Inputs Length": 727.0372,
            "Mean Targets Length": 6.5759,
            "Max Inputs Length": 1151,
            "Max Targets Length": 15,
            "Min Inputs Length": 436,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://huggingface.co/datasets/dynabench/dynasent#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "dynasent/dynabench.dynasent.r2.all/r2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "dynabench/dynasent",
            "HF Config": "dynabench.dynasent.r1.all",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-12-30",
            "GitHub License": "",
            "Text Topics": [
                "Food",
                "Personal preferences",
                "Communication",
                "Customer service",
                "Customer satisfaction",
                "Emotions",
                "Travel"
            ],
            "Github Date": "",
            "HF Date": "2021-04-29",
            "HF Downloads (September 2023)": 3998,
            "HF Likes (September 2023)": 3,
            "PwC Description": "DynaSent is an English-language benchmark task for ternary (positive/negative/neutral) sentiment analysis. DynaSent combines naturally occurring sentences with sentences created using the open-source Dynabench Platform, which facilities human-and-model-in-the-loop dataset creation. DynaSent has a total of 121,634 sentences, each validated by five crowdworkers.",
            "S2 Citation Count (September 2023)": 49,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Potts2020DynaSentAD,\n author = {Christopher Potts and Zhengxuan Wu and Atticus Geiger and Douwe Kiela},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {DynaSent: A Dynamic Benchmark for Sentiment Analysis},\n volume = {abs/2012.15349},\n year = {2020}\n}\n"
    },
    "tsy-sem_eval_2010_task_8": {
        "Unique Dataset Identifier": "tsy-sem_eval_2010_task_8",
        "Dataset Name": "sem_eval_2010_task_8",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://semeval2.fbk.eu/semeval2.php?location=tasks&taskid=11",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sem_eval_2010_task_8",
        "Paper Title": "SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations between Pairs of Nominals",
        "Papers with Code URL": "https://paperswithcode.com/dataset/semeval-2010-task-8",
        "ArXiv URL": "https://arxiv.org/abs/1911.10422",
        "Semantic Scholar Corpus ID": 436023,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 766,
            "Mean Inputs Length": 1215.3695,
            "Mean Targets Length": 6.6292,
            "Max Inputs Length": 1836,
            "Max Targets Length": 16,
            "Min Inputs Length": 834,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Lisbon",
            "University of Melbourne",
            "University of Alicante",
            "National University of Singapore",
            "University of Cambridge",
            "University of Stuttgart",
            "Yahoo! Inc.",
            "Fondazione Bruno Kessler",
            "University of Ottawa",
            "Polish Academy of Sciences"
        ],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://semeval2.fbk.eu/semeval2.php?location=tasks&taskid=11"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "sem_eval_2010_task_8"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sem_eval_2010_task_8",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/3.0/",
            "PwC Date": "2019-11-23",
            "S2 Date": "2009-06-04",
            "GitHub License": "",
            "Text Topics": [
                "Mechanics",
                "Communication",
                "Politics",
                "Physics",
                "Engineering",
                "Biology",
                "Travel",
                "Health"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2110,
            "HF Likes (September 2023)": 4,
            "PwC Description": "The dataset for the SemEval-2010 Task 8 is a dataset for multi-way classification of mutually exclusive semantic relations between pairs of nominals.",
            "S2 Citation Count (September 2023)": 664,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hendrickx2009SemEval2010T8,\n author = {Iris Hendrickx and Su Nam Kim and Zornitsa Kozareva and Preslav Nakov and Diarmuid  Saghdha and Sebastian Pad and M. Pennacchiotti and Lorenza Romano and Stan Szpakowicz},\n booktitle = {SEW@NAACL-HLT},\n pages = {94-99},\n title = {SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations Between Pairs of Nominals},\n year = {2009}\n}\n"
    },
    "tsy-cycic_classification": {
        "Unique Dataset Identifier": "tsy-cycic_classification",
        "Dataset Name": "cycic_classification",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/cycic_classification",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/cycic_classification",
        "Paper Title": "Do Fine-tuned Commonsense Language Models Really Generalize?",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2011.09159",
        "Semantic Scholar Corpus ID": 227012557,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Binary Classification Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 427,
            "Mean Inputs Length": 1639.4848,
            "Mean Targets Length": 6.5948,
            "Max Inputs Length": 2100,
            "Max Targets Length": 16,
            "Min Inputs Length": 1200,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "cyc.com"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "cycic_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/cycic_classification",
            "HF Config": "metaeval--cycic_classification",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-18",
            "GitHub License": "",
            "Text Topics": [
                "Gift giving",
                "Perception and observation",
                "General knowledge",
                "Logic",
                "Geography",
                "Gift-giving",
                "Fire safety",
                "Animals",
                "Personal preferences",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2023-01-18",
            "HF Downloads (September 2023)": 36,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 7,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Kejriwal2020DoFC,\n author = {M. Kejriwal and Ke Shen},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Do Fine-tuned Commonsense Language Models Really Generalize?},\n volume = {abs/2011.09159},\n year = {2020}\n}\n"
    },
    "tsy-commonsense_qa_2.0": {
        "Unique Dataset Identifier": "tsy-commonsense_qa_2.0",
        "Dataset Name": "commonsense_qa_2.0",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/commonsense_qa_2.0",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/commonsense_qa_2.0",
        "Paper Title": "CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/commonsenseqa",
        "ArXiv URL": "https://arxiv.org/abs/2201.05320",
        "Semantic Scholar Corpus ID": 53296520,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Binary Classification Question Answering",
            "Binary Classification",
            "Binary Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1018,
            "Mean Inputs Length": 672.28,
            "Mean Targets Length": 6.5472,
            "Max Inputs Length": 1052,
            "Max Targets Length": 22,
            "Min Inputs Length": 469,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Tel Aviv University",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "commonsense_qa_2.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/commonsense_qa_2.0",
            "HF Config": "metaeval--commonsense_qa_2.0",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2019-01-01",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Biology",
                "Logic",
                "Geography",
                "Daily routine",
                "General knowledge",
                "Music",
                "Philosophy"
            ],
            "Github Date": "",
            "HF Date": "2023-01-24",
            "HF Downloads (September 2023)": 40,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The CommonsenseQA is a dataset for commonsense question answering task. The dataset consists of 12,247 questions with 5 choices each.\nThe dataset was generated by Amazon Mechanical Turk workers in the following process (an example is provided in parentheses):\n\n\na crowd worker observes a source concept from ConceptNet (River) and three target concepts (Waterfall, Bridge, Valley) that are all related by the same ConceptNet relation (AtLocation),\nthe worker authors three questions, one per target concept, such that only that particular target concept is the answer, while the other two distractor concepts are not, (Where on a river can you hold a cup upright to catch water on a sunny day?, Where can I stand on a river to see water falling without getting wet?, Im crossing the river, my feet are wet but my body is dry, where am I?)\nfor each question, another worker chooses one additional distractor from Concept Net (pebble, stream, bank), and the author another distractor (mountain, bottom, island) manually.",
            "S2 Citation Count (September 2023)": 685,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Talmor2019CommonsenseQAAQ,\n author = {Alon Talmor and Jonathan Herzig and Nicholas Lourie and Jonathan Berant},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n volume = {abs/1811.00937},\n year = {2019}\n}\n"
    },
    "tsy-lingnli": {
        "Unique Dataset Identifier": "tsy-lingnli",
        "Dataset Name": "lingnli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Alicia-Parrish/ling_in_loop/",
        "GitHub URL": "https://github.com/Alicia-Parrish/ling_in_loop/",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/lingnli",
        "Paper Title": "Does Putting a Linguist in the Loop Improve NLU Data Collection?",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2104.07179",
        "Semantic Scholar Corpus ID": 233240777,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4997,
            "Mean Inputs Length": 1747.251,
            "Mean Targets Length": 6.618,
            "Max Inputs Length": 2766,
            "Max Targets Length": 22,
            "Min Inputs Length": 1025,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced (amt)"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University",
            "Indian Institute of Technology",
            "Columbia University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lingnli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/lingnli",
            "HF Config": "metaeval--lingnli",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-04-15",
            "GitHub License": "",
            "Text Topics": [
                "Journalism",
                "Communication",
                "Entertainment industry",
                "Technology",
                "Economics",
                "Politics",
                "Current events",
                "Literature"
            ],
            "Github Date": "",
            "HF Date": "2023-01-11",
            "HF Downloads (September 2023)": 35,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 21,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Parrish2021DoesPA,\n author = {Alicia Parrish and William Huang and Omar Agha and Soo-hwan Lee and Nikita Nangia and Alex Warstadt and Karmanya Aggarwal and Emily Allaway and Tal Linzen and Samuel R. Bowman},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Does Putting a Linguist in the Loop Improve NLU Data Collection?},\n volume = {abs/2104.07179},\n year = {2021}\n}\n"
    },
    "tsy-monotonicity_entailment": {
        "Unique Dataset Identifier": "tsy-monotonicity_entailment",
        "Dataset Name": "monotonicity_entailment",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/monotonicity-entailment",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/monotonicity-entailment",
        "Paper Title": "Can Neural Networks Understand Monotonicity Reasoning?",
        "Papers with Code URL": "https://paperswithcode.com/dataset/med",
        "ArXiv URL": "https://arxiv.org/abs/1906.06448",
        "Semantic Scholar Corpus ID": 189927911,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 538,
            "Mean Inputs Length": 916.5669,
            "Mean Targets Length": 6.6413,
            "Max Inputs Length": 1373,
            "Max Targets Length": 14,
            "Min Inputs Length": 670,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "parallel meaning bank",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "RIKEN",
            "Ochanomizu University",
            "Tohoku University",
            "University of Groningen"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "monotonicity-entailment"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/monotonicity-entailment",
            "HF Config": "metaeval--monotonicity-entailment",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-15",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Daily routine",
                "Logic",
                "Linguistics",
                "Food preferences",
                "Language and communication",
                "Education",
                "General knowledge",
                "Language understanding",
                "Language"
            ],
            "Github Date": "",
            "HF Date": "2023-01-24",
            "HF Downloads (September 2023)": 26,
            "HF Likes (September 2023)": 0,
            "PwC Description": "MED is a new evaluation dataset that covers a wide range of monotonicity reasoning that was created by crowdsourcing and collected from linguistics publications. The dataset was constructed by collecting naturally-occurring examples by crowdsourcing and well-designed ones from linguistics publications.\nIt consists of 5,382 examples.",
            "S2 Citation Count (September 2023)": 59,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Yanaka2019CanNN,\n author = {Hitomi Yanaka and K. Mineshima and D. Bekki and Kentaro Inui and S. Sekine and Lasha Abzianidze and Johan Bos},\n booktitle = {BlackboxNLP@ACL},\n pages = {31-40},\n title = {Can Neural Networks Understand Monotonicity Reasoning?},\n year = {2019}\n}\n"
    },
    "tsy-scinli": {
        "Unique Dataset Identifier": "tsy-scinli",
        "Dataset Name": "scinli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/msadat3/SciNLI",
        "GitHub URL": "https://github.com/msadat3/SciNLI",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/scinli",
        "Paper Title": "SciNLI: A Corpus for Natural Language Inference on Scientific Text",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2203.06728",
        "Semantic Scholar Corpus ID": 247447069,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5554,
            "Mean Inputs Length": 2752.2333,
            "Mean Targets Length": 6.5832,
            "Max Inputs Length": 4202,
            "Max Targets Length": 16,
            "Min Inputs Length": 1760,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "aclanthology.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Illinois"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/msadat3/SciNLI#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "scinli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/scinli",
            "HF Config": "metaeval--scinli",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-03-13",
            "GitHub License": "",
            "Text Topics": [
                "Machine learning",
                "Linguistics",
                "Data analysis",
                "Natural Language Processing (NLP)",
                "Artificial intelligence",
                "Computational linguistics",
                "Natural language processing",
                "Information retrieval",
                "Natural Language Processing",
                "Translation"
            ],
            "Github Date": "",
            "HF Date": "2023-01-26",
            "HF Downloads (September 2023)": 82,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 12,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sadat2022SciNLIAC,\n author = {Mobashir Sadat and Cornelia Caragea},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {SciNLI: A Corpus for Natural Language Inference on Scientific Text},\n volume = {abs/2203.06728},\n year = {2022}\n}\n"
    },
    "tsy-naturallogic": {
        "Unique Dataset Identifier": "tsy-naturallogic",
        "Dataset Name": "naturallogic",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/feng-yufei/Neural-Natural-Logic",
        "GitHub URL": "https://github.com/feng-yufei/Neural-Natural-Logic",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/naturallogic",
        "Paper Title": "Exploring End-to-End Differentiable Natural Logic Modeling",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2011.04044",
        "Semantic Scholar Corpus ID": 226282443,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 376,
            "Mean Inputs Length": 983.5691,
            "Mean Targets Length": 6.5213,
            "Max Inputs Length": 1311,
            "Max Targets Length": 13,
            "Min Inputs Length": 751,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "parallel meaning bank"
        ],
        "Model Generated": [],
        "Creators": [
            "Queens University",
            "iFLYTEK Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "naturallogic"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/naturallogic",
            "HF Config": "metaeval--naturallogic",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-08",
            "GitHub License": "",
            "Text Topics": [
                "Logic and reasoning",
                "Language understanding",
                "Food preferences",
                "Family relationships",
                "Linguistics",
                "Language and communication",
                "General knowledge",
                "Logic",
                "Natural language processing",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2023-01-26",
            "HF Downloads (September 2023)": 31,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 9,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "MED Dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Feng2020ExploringED,\n author = {Yufei Feng and Zi'ou Zheng and QUAN LIU and M. Greenspan and Xiaodan Zhu},\n booktitle = {International Conference on Computational Linguistics},\n pages = {1172-1185},\n title = {Exploring End-to-End Differentiable Natural Logic Modeling},\n year = {2020}\n}\n"
    },
    "tsy-dynahate": {
        "Unique Dataset Identifier": "tsy-dynahate",
        "Dataset Name": "dynahate",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://arxiv.org/abs/2012.15761",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/aps/dynahate",
        "Paper Title": "Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2012.15761",
        "Semantic Scholar Corpus ID": 229923220,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4114,
            "Mean Inputs Length": 1349.6548,
            "Mean Targets Length": 6.5474,
            "Max Inputs Length": 4014,
            "Max Targets Length": 22,
            "Min Inputs Length": 493,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Alan Turing Institute",
            "University of Sheffield",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "dynahate"
        ],
        "Inferred Metadata": {
            "HF Dataset": "aps/dynahate",
            "HF Config": "0.2.3",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-01-01",
            "GitHub License": "",
            "Text Topics": [
                "Stereotypes",
                "Communication",
                "Racism",
                "Cultural sensitivity",
                "Language and communication",
                "Social issues",
                "Stereotypes and prejudice"
            ],
            "Github Date": "",
            "HF Date": "2022-04-29",
            "HF Downloads (September 2023)": 62,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 97,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Vidgen2021LearningFT,\n author = {Bertie Vidgen and Tristan Thrush and Zeerak Talat and Douwe Kiela},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection},\n volume = {abs/2012.15761},\n year = {2021}\n}\n"
    },
    "tsy-syntactic_augmentation_nli": {
        "Unique Dataset Identifier": "tsy-syntactic_augmentation_nli",
        "Dataset Name": "syntactic_augmentation_nli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/syntactic-augmentation-nli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/syntactic-augmentation-nli",
        "Paper Title": "Syntactic Data Augmentation Increases Robustness to Inference Heuristics",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2004.11999",
        "Semantic Scholar Corpus ID": 216553149,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 974,
            "Mean Inputs Length": 1435.5955,
            "Mean Targets Length": 6.4846,
            "Max Inputs Length": 2237,
            "Max Targets Length": 15,
            "Min Inputs Length": 854,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "Johns Hopkins University",
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/Aatlantise/syntactic-augmentation-nli#license"
            }
        ],
        "License Notes": "License appears to be for the repository, not the data",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "syntactic-augmentation-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/syntactic-augmentation-nli",
            "HF Config": "metaeval--syntactic-augmentation-nli",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-24",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Cultural heritage",
                "History",
                "Language and semantics",
                "Geography",
                "Language and communication",
                "Language and linguistics",
                "Language understanding",
                "Communication and understanding"
            ],
            "Github Date": "",
            "HF Date": "2023-01-30",
            "HF Downloads (September 2023)": 34,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 119,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "MNLI"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Min2020SyntacticDA,\n author = {Junghyun Min and R. Thomas McCoy and Dipanjan Das and Emily Pitler and Tal Linzen},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {2339-2352},\n title = {Syntactic Data Augmentation Increases Robustness to Inference Heuristics},\n year = {2020}\n}\n"
    },
    "tsy-autotnli": {
        "Unique Dataset Identifier": "tsy-autotnli",
        "Dataset Name": "autotnli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Dibyakanti/AutoTNLI-code",
        "GitHub URL": "https://github.com/Dibyakanti/AutoTNLI-code",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/autotnli",
        "Paper Title": "Realistic Data Augmentation Framework for Enhancing Tabular Reasoning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2210.12795",
        "Semantic Scholar Corpus ID": 253097739,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 8886.2112,
            "Mean Targets Length": 6.5829,
            "Max Inputs Length": 11759,
            "Max Targets Length": 22,
            "Min Inputs Length": 5576,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "crowdsourced"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Indian Institute of Technology",
            "University of Utah",
            "Bloomberg"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "autotnli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/autotnli",
            "HF Config": "metaeval--autotnli",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-10-23",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Entertainment",
                "Entertainment industry",
                "Sports",
                "Family relationships",
                "Film production",
                "Music",
                "History"
            ],
            "Github Date": "",
            "HF Date": "2023-02-07",
            "HF Downloads (September 2023)": 39,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 4,
            "GitHub Topics": [
                "autotnli",
                "emnlp2022",
                "inference",
                "infotabs",
                "nli",
                "nlp",
                "nlp-datasets",
                "nlp-machine-learning",
                "roberta",
                "semi-structured-data",
                "tables",
                "transformer",
                "wikipedia"
            ]
        },
        "Derived from Datasets": [
            "InfoTabs dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Kumar2022RealisticDA,\n author = {D. K. Santhosh Kumar and Vivek Gupta and Soumya Sharma and Shuo Zhang},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Realistic Data Augmentation Framework for Enhancing Tabular Reasoning},\n volume = {abs/2210.12795},\n year = {2022}\n}\n"
    },
    "tsy-condaqa": {
        "Unique Dataset Identifier": "tsy-condaqa",
        "Dataset Name": "condaqa",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/AbhilashaRavichander/CondaQA",
        "GitHub URL": "https://github.com/AbhilashaRavichander/CondaQA",
        "Hugging Face URL": "https://huggingface.co/datasets/lasha-nlp/CONDAQA",
        "Paper Title": "CONDAQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2211.00295",
        "Semantic Scholar Corpus ID": 253244137,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Factual Question Answering",
            "Sentiment Analysis",
            "Binary Question Answering",
            "Binary Classification Question Answering",
            "Academic Cryptography Weakness Identification Question Answering",
            "Span Selection Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 634,
            "Mean Inputs Length": 7713.5899,
            "Mean Targets Length": 6.7539,
            "Max Inputs Length": 13177,
            "Max Targets Length": 16,
            "Min Inputs Length": 2307,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University",
            "Microsoft Semantic Machines",
            "University of Utah"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/AbhilashaRavichander/CondaQA/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "CONDAQA"
        ],
        "Inferred Metadata": {
            "HF Dataset": "lasha-nlp/CONDAQA",
            "HF Config": "lasha-nlp--CONDAQA",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-11-01",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Politics",
                "Mining industry",
                "Climate",
                "Geography",
                "Gemstones",
                "Biology",
                "International relations"
            ],
            "Github Date": "",
            "HF Date": "2022-11-08",
            "HF Downloads (September 2023)": 69,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 8,
            "GitHub Stars": 9,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Ravichander2022CONDAQAAC,\n author = {Abhilasha Ravichander and Matt Gardner and Ana Marasovi},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {CONDAQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation},\n volume = {abs/2211.00295},\n year = {2022}\n}\n"
    },
    "tsy-scruples": {
        "Unique Dataset Identifier": "tsy-scruples",
        "Dataset Name": "scruples",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/scruples",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/scruples",
        "Paper Title": "",
        "Papers with Code URL": "https://paperswithcode.com/dataset/scruples",
        "ArXiv URL": "https://arxiv.org/abs/2008.09094",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Open-Domain Question Answering",
            "Natural Language Understanding",
            "Narrative Understanding",
            "Sentiment Analysis",
            "Relationship Conflict Resolution Question Answering",
            "Long-Distance Relationship Dialogue Generation",
            "Binary Classification Question Answering",
            "Ethical Judgment Question Answering",
            "Moral Dilemma Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1528,
            "Mean Inputs Length": 15828.6099,
            "Mean Targets Length": 6.6839,
            "Max Inputs Length": 37595,
            "Max Targets Length": 18,
            "Min Inputs Length": 7023,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "Paul G. Allen School of Computer Science & Engineering"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://github.com/allenai/scruples#disclaimer"
            }
        ],
        "License Notes": "For research only",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "scruples"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/scruples",
            "HF Config": "metaeval--scruples",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Personal experiences",
                "Relationships",
                "Social interactions",
                "Friendship and relationships",
                "Communication",
                "Travel",
                "Education",
                "Family dynamics",
                "Friendship",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2023-02-03",
            "HF Downloads (September 2023)": 50,
            "HF Likes (September 2023)": 1,
            "PwC Description": "Dataset with 625,000 ethical judgments over 32,000 real-life anecdotes. Each anecdote recounts a complex ethical situation, often posing moral dilemmas, paired with a distribution of judgments contributed by the community members.",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": ""
    },
    "tsy-attempto_nli": {
        "Unique Dataset Identifier": "tsy-attempto_nli",
        "Dataset Name": "attempto_nli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/sileod/attempto-nli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sileod/attempto-nli",
        "Paper Title": "First-Order Reasoning for Attempto Controlled English",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/0807.4623",
        "Semantic Scholar Corpus ID": 357102,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1401,
            "Mean Inputs Length": 1760.449,
            "Mean Targets Length": 6.541,
            "Max Inputs Length": 2648,
            "Max Targets Length": 16,
            "Min Inputs Length": 1128,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Zurich"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "attempto-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sileod/attempto-nli",
            "HF Config": "sileod--attempto-nli",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2010-09-13",
            "GitHub License": "",
            "Text Topics": [
                "Language and semantics",
                "Semantics",
                "Relationships",
                "Language and linguistics",
                "Logic and reasoning",
                "Linguistics",
                "Language understanding",
                "Language and communication",
                "Language",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2023-02-03",
            "HF Downloads (September 2023)": 34,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 27,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Fuchs2010FirstOrderRF,\n author = {Norbert E. Fuchs},\n booktitle = {Controlled Natural Language},\n pages = {73-94},\n title = {First-Order Reasoning for Attempto Controlled English},\n year = {2010}\n}\n"
    },
    "tsy-defeasible_nli-snli": {
        "Unique Dataset Identifier": "tsy-defeasible_nli-snli",
        "Dataset Name": "defeasible_nli-snli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/defeasible-nli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/defeasible-nli",
        "Paper Title": "Thinking Like a Skeptic: Defeasible Inference in Natural Language",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/2020.findings-emnlp.418/",
        "Semantic Scholar Corpus ID": 226283602,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Span Selection Question Answering",
            "Natural Language Inference",
            "Binary Classification",
            "Sentence Classification",
            "Classification",
            "Open-Domain Relation Extraction",
            "Sentence Completion",
            "Multiple Choice Question Answering",
            "Semantic Relation Classification",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 1561.5257,
            "Mean Targets Length": 6.5336,
            "Max Inputs Length": 2060,
            "Max Targets Length": 18,
            "Min Inputs Length": 1193,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "University of Maryland"
        ],
        "Licenses": [
            {
                "License": "MIT License",
                "License URL": "https://github.com/rudinger/defeasible-nli/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "defeasible-nli/snli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/defeasible-nli",
            "HF Config": "atomic",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-01",
            "GitHub License": "",
            "Text Topics": [
                "Culture",
                "Communication",
                "Gender roles",
                "Visual perception",
                "Animal behavior",
                "Sports",
                "Daily routine",
                "Social interactions",
                "Outdoor activities",
                "Travel"
            ],
            "Github Date": "",
            "HF Date": "2023-02-02",
            "HF Downloads (September 2023)": 121,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 51,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "social chemestry",
            "ATOMIC"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Rudinger2020ThinkingLA,\n author = {Rachel Rudinger and Vered Shwartz and Jena D. Hwang and Chandra Bhagavatula and Maxwell Forbes and Ronan Le Bras and Noah A. Smith and Yejin Choi},\n booktitle = {Findings},\n pages = {4661-4675},\n title = {Thinking Like a Skeptic: Defeasible Inference in Natural Language},\n year = {2020}\n}\n"
    },
    "tsy-defeasible_nli-atomic": {
        "Unique Dataset Identifier": "tsy-defeasible_nli-atomic",
        "Dataset Name": "defeasible_nli-atomic",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/defeasible-nli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/defeasible-nli",
        "Paper Title": "Thinking Like a Skeptic: Defeasible Inference in Natural Language",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/2020.findings-emnlp.418/",
        "Semantic Scholar Corpus ID": 226283602,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Natural Language Inference",
            "Sentence Classification",
            "Binary Classification",
            "Sentence Completion",
            "Classification",
            "Sentence Relation Classification",
            "Span Selection Question Answering",
            "Sentence-level Semantic Relationship Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3889,
            "Mean Inputs Length": 1108.2589,
            "Mean Targets Length": 6.5953,
            "Max Inputs Length": 1492,
            "Max Targets Length": 22,
            "Min Inputs Length": 854,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "University of Maryland"
        ],
        "Licenses": [
            {
                "License": "MIT License",
                "License URL": "https://github.com/rudinger/defeasible-nli/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "defeasible-nli/atomic"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/defeasible-nli",
            "HF Config": "atomic",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-01",
            "GitHub License": "",
            "Text Topics": [
                "Personal finance",
                "Interpersonal relationships",
                "Personal preferences",
                "Education",
                "Relationships",
                "Daily routine",
                "Personal development"
            ],
            "Github Date": "",
            "HF Date": "2023-02-02",
            "HF Downloads (September 2023)": 121,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 51,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "social chemestry",
            "ATOMIC"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Rudinger2020ThinkingLA,\n author = {Rachel Rudinger and Vered Shwartz and Jena D. Hwang and Chandra Bhagavatula and Maxwell Forbes and Ronan Le Bras and Noah A. Smith and Yejin Choi},\n booktitle = {Findings},\n pages = {4661-4675},\n title = {Thinking Like a Skeptic: Defeasible Inference in Natural Language},\n year = {2020}\n}\n"
    },
    "tsy-help_nli": {
        "Unique Dataset Identifier": "tsy-help_nli",
        "Dataset Name": "help_nli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/verypluming/HELP",
        "GitHub URL": "https://github.com/verypluming/HELP",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/help-nli",
        "Paper Title": "HELP: A Dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/help",
        "ArXiv URL": "https://arxiv.org/abs/1904.12166",
        "Semantic Scholar Corpus ID": 139105363,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3588,
            "Mean Inputs Length": 1082.8478,
            "Mean Targets Length": 6.5967,
            "Max Inputs Length": 2104,
            "Max Targets Length": 18,
            "Min Inputs Length": 726,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "parallel meaning bank"
        ],
        "Model Generated": [],
        "Creators": [
            "RIKEN",
            "Ochanomizu University",
            "Tohoku University",
            "University of Groningen"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/verypluming/HELP/blob/master/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "help-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/help-nli",
            "HF Config": "metaeval--help-nli",
            "HF Config License": "",
            "HF Yaml License": "CC0 1.0",
            "PwC License Name": "Custom",
            "PwC License URL": "https://github.com/verypluming/HELP",
            "PwC Date": "",
            "S2 Date": "2019-04-27",
            "GitHub License": "CC BY-SA 4.0",
            "Text Topics": [
                "Education",
                "Communication",
                "Food",
                "General knowledge",
                "Linguistics",
                "Language understanding",
                "Geography",
                "Daily routine",
                "Travel",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2023-02-04",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The HELP dataset is an automatically created natural language inference (NLI) dataset that embodies the combination of lexical and logical inferences focusing on monotonicity (i.e., phrase replacement-based reasoning). The HELP (Ver.1.0) has 36K inference pairs consisting of upward monotone, downward monotone, non-monotone, conjunction, and disjunction.",
            "S2 Citation Count (September 2023)": 46,
            "GitHub Stars": 13,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Yanaka2019HELPAD,\n author = {Hitomi Yanaka and K. Mineshima and D. Bekki and Kentaro Inui and S. Sekine and Lasha Abzianidze and Johan Bos},\n booktitle = {International Workshop on Semantic Evaluation},\n journal = {ArXiv},\n title = {HELP: A Dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning},\n volume = {abs/1904.12166},\n year = {2019}\n}\n"
    },
    "tsy-nli_veridicality_transitivity": {
        "Unique Dataset Identifier": "tsy-nli_veridicality_transitivity",
        "Dataset Name": "nli_veridicality_transitivity",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/nli-veridicality-transitivity",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/nli-veridicality-transitivity",
        "Paper Title": "Adversarial NLI: A New Benchmark for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2101.10713",
        "Semantic Scholar Corpus ID": 207756753,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5554,
            "Mean Inputs Length": 1218.6457,
            "Mean Targets Length": 6.5439,
            "Max Inputs Length": 1687,
            "Max Targets Length": 16,
            "Min Inputs Length": 878,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flickr",
            "crowdsourced",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "UNC Chapel Hill",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "nli-veridicality-transitivity"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/nli-veridicality-transitivity",
            "HF Config": "metaeval--nli-veridicality-transitivity",
            "HF Config License": "",
            "HF Yaml License": "CC0 1.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-10-31",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Language understanding",
                "Animal behavior",
                "Animals",
                "Perception and observation",
                "Communication",
                "Communication and language",
                "Perception",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2023-02-04",
            "HF Downloads (September 2023)": 33,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 601,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SICK dataset",
            "MegaVeridicality2",
            "Verb veridicality dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Nie2019AdversarialNA,\n author = {Yixin Nie and Adina Williams and Emily Dinan and Mohit Bansal and J. Weston and Douwe Kiela},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Adversarial NLI: A New Benchmark for Natural Language Understanding},\n volume = {abs/1910.14599},\n year = {2019}\n}\n"
    },
    "tsy-natural_language_satisfiability": {
        "Unique Dataset Identifier": "tsy-natural_language_satisfiability",
        "Dataset Name": "natural_language_satisfiability",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/natural-language-satisfiability",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/natural-language-satisfiability",
        "Paper Title": "Can Transformers Reason in Fragments of Natural Language?",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2211.05417",
        "Semantic Scholar Corpus ID": 253446947,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Boolean Expression Evaluation",
            "Binary Classification",
            "Boolean Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 799,
            "Mean Inputs Length": 6222.1777,
            "Mean Targets Length": 6.6283,
            "Max Inputs Length": 7601,
            "Max Targets Length": 15,
            "Min Inputs Length": 4862,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "ASUS Intelligent Cloud Services (AICS)",
            "University of Manchester",
            "Instytut Informatyki Uniwersytet Opolski"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "natural-language-satisfiability"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/natural-language-satisfiability",
            "HF Config": "metaeval--natural-language-satisfiability",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-11-10",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Language and grammar",
                "Critical thinking",
                "Language understanding",
                "Reasoning",
                "Philosophy",
                "Categorical statements",
                "General knowledge",
                "Categorization"
            ],
            "Github Date": "",
            "HF Date": "2023-02-04",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Schlegel2022CanTR,\n author = {Viktor Schlegel and Kamen V. Pavlov and Ian Pratt-Hartmann},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {11184-11199},\n title = {Can Transformers Reason in Fragments of Natural Language?},\n year = {2022}\n}\n"
    },
    "tsy-lonli": {
        "Unique Dataset Identifier": "tsy-lonli",
        "Dataset Name": "lonli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/microsoft/LoNLI",
        "GitHub URL": "https://github.com/microsoft/LoNLI",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/lonli",
        "Paper Title": "Trusting RoBERTa over BERT: Insights from CheckListing the Natural Language Inference Task",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2107.07229",
        "Semantic Scholar Corpus ID": 235899209,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 941.4229,
            "Mean Targets Length": 6.5874,
            "Max Inputs Length": 1264,
            "Max Targets Length": 22,
            "Min Inputs Length": 684,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "Samsung",
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Trademarks listed at the bottom of github (idk if we need this though): https://github.com/microsoft/LoNLI#trademarks",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lonli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/lonli",
            "HF Config": "metaeval--lonli",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-07-15",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Cultural diversity",
                "Time management",
                "Linguistics",
                "Logic",
                "Daily routine",
                "Language understanding",
                "General knowledge",
                "Communication",
                "Education",
                "Geography"
            ],
            "Github Date": "",
            "HF Date": "2023-02-04",
            "HF Downloads (September 2023)": 33,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": 6,
            "GitHub Topics": [
                "checklist",
                "logic",
                "nli",
                "nlp",
                "reasoning"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Tarunesh2021TrustingRO,\n author = {Ishan Tarunesh and Somak Aditya and M. Choudhury},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Trusting RoBERTa over BERT: Insights from CheckListing the Natural Language Inference Task},\n volume = {abs/2107.07229},\n year = {2021}\n}\n"
    },
    "tsy-dadc_limit_nli": {
        "Unique Dataset Identifier": "tsy-dadc_limit_nli",
        "Dataset Name": "dadc_limit_nli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/dadc-limit",
        "GitHub URL": "https://github.com/facebookresearch/dadc-limit",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/dadc-limit-nli",
        "Paper Title": "Analyzing Dynamic Adversarial Training Data in the Limit",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2110.08514",
        "Semantic Scholar Corpus ID": 239016790,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 75,
            "Mean Inputs Length": 6817.8267,
            "Mean Targets Length": 6.4267,
            "Max Inputs Length": 8096,
            "Max Targets Length": 15,
            "Min Inputs Length": 5085,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "project gutenberg",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Berkeley",
            "Facebook AI Research",
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "dadc-limit-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/dadc-limit-nli",
            "HF Config": "metaeval--dadc-limit-nli",
            "HF Config License": "",
            "HF Yaml License": "CC0 1.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-10-16",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "Physics",
                "Sports",
                "Acoustics",
                "Cage design",
                "Science",
                "Animal behavior",
                "History",
                "Ethics",
                "Biography"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 4,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 16,
            "GitHub Stars": 4,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Wallace2021AnalyzingDA,\n author = {Eric Wallace and Adina Williams and Robin Jia and Douwe Kiela},\n booktitle = {Findings},\n pages = {202-217},\n title = {Analyzing Dynamic Adversarial Training Data in the Limit},\n year = {2021}\n}\n"
    },
    "tsy-flute": {
        "Unique Dataset Identifier": "tsy-flute",
        "Dataset Name": "flute",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://figlang2022sharedtask.github.io/",
        "GitHub URL": "https://figlang2022sharedtask.github.io/",
        "Hugging Face URL": "https://huggingface.co/datasets/ColumbiaNLP/FLUTE",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Natural Language Inference",
            "Metaphor Identification",
            "Sentiment Analysis",
            "Span Selection Question Answering",
            "Semantic Similarity Detection",
            "Open-Domain Question Answering",
            "Paraphrase Detection",
            "Paraphrase Generation"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 713,
            "Mean Inputs Length": 1527.5358,
            "Mean Targets Length": 6.6634,
            "Max Inputs Length": 2283,
            "Max Targets Length": 16,
            "Min Inputs Length": 953,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "FLUTE"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ColumbiaNLP/FLUTE",
            "HF Config": "ColumbiaNLP--FLUTE",
            "HF Config License": "",
            "HF Yaml License": "Academic Free License v3.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Philosophy",
                "Emotions",
                "Ethics",
                "Interpersonal relationships",
                "Daily routine",
                "Language and communication",
                "Communication",
                "Personal experiences"
            ],
            "Github Date": "",
            "HF Date": "2022-07-05",
            "HF Downloads (September 2023)": 168,
            "HF Likes (September 2023)": 4,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-folio": {
        "Unique Dataset Identifier": "tsy-folio",
        "Dataset Name": "folio",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Yale-LILY/FOLIO",
        "GitHub URL": "https://github.com/Yale-LILY/FOLIO",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/folio",
        "Paper Title": "FOLIO: Natural Language Reasoning with First-Order Logic",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2209.00840",
        "Semantic Scholar Corpus ID": 252070866,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Binary Classification Question Answering",
            "Multiple Choice Question Answering",
            "Logical Reasoning Question Answering",
            "Fact Verification",
            "Boolean Question Answering",
            "Factual Knowledge Question Answering",
            "Natural Language Inference",
            "Boolean Expression Evaluation"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 111,
            "Mean Inputs Length": 3573.1622,
            "Mean Targets Length": 7.018,
            "Max Inputs Length": 5957,
            "Max Targets Length": 13,
            "Min Inputs Length": 2141,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "original"
        ],
        "Model Generated": [],
        "Creators": [
            "Yale University",
            "University of Illinois",
            "Iowa City West High School",
            "University of Washington",
            "University of Hong Kong",
            "Penn State University",
            "Meta",
            "Salesforce Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/Yale-LILY/FOLIO/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "folio"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/folio",
            "HF Config": "metaeval--folio",
            "HF Config License": "",
            "HF Yaml License": "CC0 1.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-09-02",
            "GitHub License": "CC BY-SA 4.0",
            "Text Topics": [
                "Reasoning",
                "Categorization",
                "Music",
                "Sports",
                "Education",
                "General knowledge",
                "Philosophy",
                "Logic",
                "Geography",
                "Science"
            ],
            "Github Date": "",
            "HF Date": "2023-02-21",
            "HF Downloads (September 2023)": 14,
            "HF Likes (September 2023)": 4,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 22,
            "GitHub Stars": 70,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Han2022FOLIONL,\n author = {Simeng Han and Hailey Schoelkopf and Yilun Zhao and Zhenting Qi and Martin Riddell and Luke Benson and Lucy Sun and E. Zubova and Yujie Qiao and Matthew Burtell and David Peng and Jonathan Fan and Yixin Liu and Brian Wong and Malcolm Sailor and Ansong Ni and Linyong Nan and Jungo Kasai and Tao Yu and Rui Zhang and Shafiq R. Joty and Alexander R. Fabbri and Wojciech Kryscinski and Xi Victoria Lin and Caiming Xiong and Dragomir R. Radev},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {FOLIO: Natural Language Reasoning with First-Order Logic},\n volume = {abs/2209.00840},\n year = {2022}\n}\n"
    },
    "tsy-tomi_nli": {
        "Unique Dataset Identifier": "tsy-tomi_nli",
        "Dataset Name": "tomi_nli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/tomi-nli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/tomi-nli",
        "Paper Title": "tasksource: Structured Dataset Preprocessing Annotations for Frictionless Extreme Multi-Task Learning and Evaluation",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 255942186,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 665,
            "Mean Inputs Length": 2815.2632,
            "Mean Targets Length": 6.7023,
            "Max Inputs Length": 3683,
            "Max Targets Length": 14,
            "Min Inputs Length": 2147,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tomi-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/tomi-nli",
            "HF Config": "metaeval--tomi-nli",
            "HF Config License": "",
            "HF Yaml License": "GNU General Public License v3.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Daily routine",
                "Language understanding",
                "Object placement",
                "Logic",
                "Location",
                "Relationships",
                "General knowledge",
                "Language and communication",
                "Object manipulation"
            ],
            "Github Date": "",
            "HF Date": "2023-02-05",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 4,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2023tasksourceSD,\n author = {Damien Sileo},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {tasksource: Structured Dataset Preprocessing Annotations for Frictionless Extreme Multi-Task Learning and Evaluation},\n volume = {abs/2301.05948},\n year = {2023}\n}\n"
    },
    "tsy-avicenna": {
        "Unique Dataset Identifier": "tsy-avicenna",
        "Dataset Name": "avicenna",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/avicenna",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/avicenna",
        "Paper Title": "Avicenna: a challenge dataset for natural language generation toward commonsense syllogistic reasoning",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 247115366,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Binary Classification Question Answering",
            "Paraphrase Detection",
            "Open-Domain Question Answering",
            "Factual Statement Classification",
            "Sentence Classification",
            "Comparative Analysis",
            "Open-Ended Question Answering",
            "Binary Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 479,
            "Mean Inputs Length": 1635.4447,
            "Mean Targets Length": 6.737,
            "Max Inputs Length": 2285,
            "Max Targets Length": 15,
            "Min Inputs Length": 1286,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "avicenna"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/avicenna",
            "HF Config": "metaeval--avicenna",
            "HF Config License": "",
            "HF Yaml License": "CC0 1.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-01-02",
            "GitHub License": "",
            "Text Topics": [
                "Science",
                "Health and wellness",
                "Economics",
                "Geography",
                "Business management",
                "Psychology",
                "Biology",
                "Agriculture",
                "Health"
            ],
            "Github Date": "",
            "HF Date": "2023-02-23",
            "HF Downloads (September 2023)": 28,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 3,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Aghahadi2022AvicennaAC,\n author = {Zeinab Aghahadi and A. Talebpour},\n booktitle = {J. Appl. Non Class. Logics},\n journal = {Journal of Applied Non-Classical Logics},\n pages = {55 - 71},\n title = {Avicenna: a challenge dataset for natural language generation toward commonsense syllogistic reasoning},\n volume = {32},\n year = {2022}\n}\n"
    },
    "tsy-puzzte": {
        "Unique Dataset Identifier": "tsy-puzzte",
        "Dataset Name": "puzzte",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/puzzte",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/puzzte",
        "Paper Title": "A Puzzle-Based Dataset for Natural Language Inference",
        "Papers with Code URL": "https://paperswithcode.com/dataset/puzzte",
        "ArXiv URL": "https://arxiv.org/abs/2112.05742",
        "Semantic Scholar Corpus ID": 245117929,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2379,
            "Mean Inputs Length": 2660.1816,
            "Mean Targets Length": 6.5044,
            "Max Inputs Length": 6318,
            "Max Targets Length": 22,
            "Min Inputs Length": 1440,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Technical University of Cluj-Napoca"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "puzzte"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/puzzte",
            "HF Config": "metaeval--puzzte",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/4.0/",
            "PwC Date": "2021-12-10",
            "S2 Date": "2021-12-10",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Comparative height",
                "Reasoning",
                "General knowledge",
                "Philosophy",
                "Relationships",
                "Puzzle",
                "Puzzle-solving",
                "Mathematics"
            ],
            "Github Date": "",
            "HF Date": "2023-03-08",
            "HF Downloads (September 2023)": 30,
            "HF Likes (September 2023)": 1,
            "PwC Description": "Puzzles dataset: comparison, knight&knaves, and zebra puzzles.",
            "S2 Citation Count (September 2023)": 3,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Szomiu2021APD,\n author = {Roxana Szomiu and Adrian Groza},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A Puzzle-Based Dataset for Natural Language Inference},\n volume = {abs/2112.05742},\n year = {2021}\n}\n"
    },
    "tsy-spartqa_yn": {
        "Unique Dataset Identifier": "tsy-spartqa_yn",
        "Dataset Name": "spartqa_yn",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/spartqa-yn",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/spartqa-yn",
        "Paper Title": "SPARTQA: A Textual Question Answering Benchmark for Spatial Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/spartqa-1",
        "ArXiv URL": "https://arxiv.org/abs/2104.05832",
        "Semantic Scholar Corpus ID": 233219660,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Boolean Question Answering",
            "Shape Identification Question Answering",
            "Visual Reasoning Question Answering",
            "Spatial Reasoning Question Answering",
            "Object Detection Question Answering",
            "Object Localization Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2661,
            "Mean Inputs Length": 6216.5509,
            "Mean Targets Length": 6.6434,
            "Max Inputs Length": 8645,
            "Max Targets Length": 18,
            "Min Inputs Length": 4614,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Michigan State University",
            "Amazon"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "spartqa-yn"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/spartqa-mchoice",
            "HF Config": "metaeval--spartqa-mchoice",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2021-06-01",
            "S2 Date": "2021-04-12",
            "GitHub License": "",
            "Text Topics": [
                "Object identification",
                "Object recognition",
                "Visual perception",
                "Puzzle solving",
                "Problem-solving",
                "Spatial relationships",
                "Logic",
                "Object description"
            ],
            "Github Date": "",
            "HF Date": "2023-03-13",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 1,
            "PwC Description": "We take advantage of the ground truth of NLVR images, design CFGs to generate stories, and use spatial reasoning rules to ask and answer spatial reasoning questions. This automatically generated data is called SpaRTQA.   https://aclanthology.org/2021.naacl-main.364/",
            "S2 Citation Count (September 2023)": 21,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "NLVR dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Mirzaee2021SPARTQAAT,\n author = {Roshanak Mirzaee and Hossein Rajaby Faghihi and Qiang Ning and Parisa Kordjmashidi},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {SPARTQA: A Textual Question Answering Benchmark for Spatial Reasoning},\n volume = {abs/2104.05832},\n year = {2021}\n}\n"
    },
    "tsy-temporal_nli": {
        "Unique Dataset Identifier": "tsy-temporal_nli",
        "Dataset Name": "temporal_nli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/temporal-nli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/temporal-nli",
        "Paper Title": "Probing Language Models for Understanding of Temporal Expressions",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2110.01113",
        "Semantic Scholar Corpus ID": 238259493,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5554,
            "Mean Inputs Length": 1028.6795,
            "Mean Targets Length": 6.6088,
            "Max Inputs Length": 1246,
            "Max Targets Length": 22,
            "Min Inputs Length": 845,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "temporal-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/temporal-nli",
            "HF Config": "metaeval--temporal-nli",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-10-03",
            "GitHub License": "",
            "Text Topics": [
                "Business and economics",
                "Time and dates",
                "Coding",
                "Daily routine",
                "Time management",
                "Time and scheduling",
                "Time and duration"
            ],
            "Github Date": "",
            "HF Date": "2023-03-13",
            "HF Downloads (September 2023)": 29,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 7,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Thukral2021ProbingLM,\n author = {Shivin Thukral and Kunal Kukreja and Christian Kavouras},\n booktitle = {BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},\n pages = {396-406},\n title = {Probing Language Models for Understanding of Temporal Expressions},\n year = {2021}\n}\n"
    },
    "tsy-clcd_english": {
        "Unique Dataset Identifier": "tsy-clcd_english",
        "Dataset Name": "clcd_english",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/clcd-english",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/clcd-english",
        "Paper Title": "A logical-based corpus for cross-lingual evaluation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1905.05704",
        "Semantic Scholar Corpus ID": 208101144,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Binary Classification Question Answering",
            "Span Selection Question Answering",
            "Comparative Sentence Classification",
            "Binary Classification",
            "Entity Matching",
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 999,
            "Mean Inputs Length": 1614.6837,
            "Mean Targets Length": 6.6557,
            "Max Inputs Length": 2517,
            "Max Targets Length": 15,
            "Min Inputs Length": 1010,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Sao Paulo"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "clcd-english"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/clcd-english",
            "HF Config": "metaeval--clcd-english",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-05-10",
            "GitHub License": "",
            "Text Topics": [
                "Reasoning",
                "Height comparison",
                "Travel",
                "Cultural experiences",
                "Logic",
                "General knowledge",
                "Geography",
                "Language understanding",
                "Relationships",
                "Mathematics"
            ],
            "Github Date": "",
            "HF Date": "2023-03-21",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 17,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Salvatore2019ALC,\n author = {Felipe Salvatore and M. Finger and R. Hirata},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {22-30},\n title = {A logical-based corpus for cross-lingual evaluation},\n year = {2019}\n}\n"
    },
    "tsy-twentyquestions": {
        "Unique Dataset Identifier": "tsy-twentyquestions",
        "Dataset Name": "twentyquestions",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/huggingface/datasets/blob/main/CONTRIBUTING.md#how-to-contribute-to-the-dataset-cards",
        "GitHub URL": "https://github.com/huggingface/datasets/blob/main/CONTRIBUTING.md#how-to-contribute-to-the-dataset-cards",
        "Hugging Face URL": "https://huggingface.co/datasets/maximedb/twentyquestions",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Open-Domain Question Answering",
            "Natural Language Understanding",
            "Binary Classification",
            "Text Classification",
            "Natural Language Classification",
            "Binary Classification Question Answering",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5173,
            "Mean Inputs Length": 433.357,
            "Mean Targets Length": 6.6066,
            "Max Inputs Length": 622,
            "Max Targets Length": 22,
            "Min Inputs Length": 344,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "twentyquestions"
        ],
        "Inferred Metadata": {
            "HF Dataset": "maximedb/twentyquestions",
            "HF Config": "maximedb--twentyquestions",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Trivia",
                "Categorization",
                "Shopping",
                "Communication",
                "Classification",
                "Biology",
                "Animal classification",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2022-12-18",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-counterfactually_augmented_imdb": {
        "Unique Dataset Identifier": "tsy-counterfactually_augmented_imdb",
        "Dataset Name": "counterfactually_augmented_imdb",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/counterfactually-augmented-imdb",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/counterfactually-augmented-imdb",
        "Paper Title": "Learning the Difference that Makes a Difference with Counterfactually-Augmented Data",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1909.12435",
        "Semantic Scholar Corpus ID": 203591519,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Multiple Choice Question Answering",
            "Video Diary Summarization",
            "Open-Domain Question Answering",
            "Critical Analysis of Traditional Chinese Culture",
            "Fact Checking"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 189,
            "Mean Inputs Length": 8327.9101,
            "Mean Targets Length": 6.3915,
            "Max Inputs Length": 11258,
            "Max Targets Length": 14,
            "Min Inputs Length": 5456,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "imdb.com",
            "flickr"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "counterfactually-augmented-imdb"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/counterfactually-augmented-snli",
            "HF Config": "metaeval--counterfactually-augmented-snli",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-09-26",
            "GitHub License": "",
            "Text Topics": [
                "Movie reviews",
                "Personal preferences in movies",
                "Personal preferences",
                "Film criticism",
                "Entertainment",
                "Film analysis",
                "Film appreciation",
                "Film critique",
                "Acting performance",
                "Entertainment industry"
            ],
            "Github Date": "",
            "HF Date": "2023-03-08",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 401,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "imdb",
            "snli"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Kaushik2019LearningTD,\n author = {Divyansh Kaushik and E. Hovy and Zachary Chase Lipton},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Learning the Difference that Makes a Difference with Counterfactually-Augmented Data},\n volume = {abs/1909.12434},\n year = {2019}\n}\n"
    },
    "tsy-counterfactually_augmented_snli": {
        "Unique Dataset Identifier": "tsy-counterfactually_augmented_snli",
        "Dataset Name": "counterfactually_augmented_snli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/counterfactually-augmented-snli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/counterfactually-augmented-snli",
        "Paper Title": "Learning the Difference that Makes a Difference with Counterfactually-Augmented Data",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1909.12435",
        "Semantic Scholar Corpus ID": 203591519,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 738,
            "Mean Inputs Length": 1140.7033,
            "Mean Targets Length": 6.6951,
            "Max Inputs Length": 2224,
            "Max Targets Length": 15,
            "Min Inputs Length": 773,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "imdb.com",
            "flickr"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "counterfactually-augmented-snli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/counterfactually-augmented-snli",
            "HF Config": "metaeval--counterfactually-augmented-snli",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-09-26",
            "GitHub License": "",
            "Text Topics": [
                "Music",
                "Language understanding",
                "Visual perception",
                "Daily routine",
                "Outdoor activities",
                "Textual entailment",
                "Culture",
                "Sports"
            ],
            "Github Date": "",
            "HF Date": "2023-03-08",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 401,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "imdb",
            "snli"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Kaushik2019LearningTD,\n author = {Divyansh Kaushik and E. Hovy and Zachary Chase Lipton},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Learning the Difference that Makes a Difference with Counterfactually-Augmented Data},\n volume = {abs/1909.12434},\n year = {2019}\n}\n"
    },
    "tsy-cnli": {
        "Unique Dataset Identifier": "tsy-cnli",
        "Dataset Name": "cnli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/cnli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/cnli",
        "Paper Title": "Counterfactually-Augmented SNLI Training Data Does Not Yield Better Generalization Than Unaugmented Data",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.04762",
        "Semantic Scholar Corpus ID": 222291772,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 832,
            "Mean Inputs Length": 1138.4555,
            "Mean Targets Length": 6.6466,
            "Max Inputs Length": 1732,
            "Max Targets Length": 16,
            "Min Inputs Length": 868,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "cnli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/cnli",
            "HF Config": "metaeval--cnli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-09",
            "GitHub License": "",
            "Text Topics": [
                "Language understanding",
                "Visual perception",
                "Gender roles",
                "Daily routine",
                "Animals",
                "Culture",
                "Fashion"
            ],
            "Github Date": "",
            "HF Date": "2023-04-07",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 27,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Huang2020CounterfactuallyAugmentedST,\n author = {William Huang and Haokun Liu and Samuel R. Bowman},\n booktitle = {First Workshop on Insights from Negative Results in NLP},\n pages = {82-87},\n title = {Counterfactually-Augmented SNLI Training Data Does Not Yield Better Generalization Than Unaugmented Data},\n year = {2020}\n}\n"
    },
    "tsy-boolq_natural_perturbations": {
        "Unique Dataset Identifier": "tsy-boolq_natural_perturbations",
        "Dataset Name": "boolq_natural_perturbations",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/boolq-natural-perturbations",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/boolq-natural-perturbations",
        "Paper Title": "Natural Perturbation for Robust Question Answering",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2004.04849",
        "Semantic Scholar Corpus ID": 215737246,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Binary Classification Question Answering",
            "Binary Question Answering",
            "Boolean Question Answering",
            "Fact Verification",
            "Geographical Location Identification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 974,
            "Mean Inputs Length": 562.5462,
            "Mean Targets Length": 6.6386,
            "Max Inputs Length": 720,
            "Max Targets Length": 15,
            "Min Inputs Length": 460,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "boolq-natural-perturbations"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/boolq-natural-perturbations",
            "HF Config": "metaeval--boolq-natural-perturbations",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-09",
            "GitHub License": "",
            "Text Topics": [
                "Government",
                "Pop culture",
                "Sports",
                "General knowledge",
                "Film",
                "Entertainment",
                "Geography",
                "Politics"
            ],
            "Github Date": "",
            "HF Date": "2023-04-07",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 3,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Khashabi2020NaturalPF,\n author = {Daniel Khashabi and Tushar Khot and Ashish Sabharwal},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Natural Perturbation for Robust Question Answering},\n volume = {abs/2004.04849},\n year = {2020}\n}\n"
    },
    "tsy-equate": {
        "Unique Dataset Identifier": "tsy-equate",
        "Dataset Name": "equate",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/equate",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/equate",
        "Paper Title": "EQUATE: A Benchmark Evaluation Framework for Quantitative Reasoning in Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1901.03735",
        "Semantic Scholar Corpus ID": 58004756,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 193,
            "Mean Inputs Length": 1580.057,
            "Mean Targets Length": 6.886,
            "Max Inputs Length": 2178,
            "Max Targets Length": 14,
            "Min Inputs Length": 1110,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "rte",
            "cnn.com",
            "reddit",
            "gmat",
            "gre exams",
            "arithmetic word problems"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "equate"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/equate",
            "HF Config": "metaeval--equate",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-01-11",
            "GitHub License": "",
            "Text Topics": [
                "Quantitative reasoning",
                "Math",
                "Sports",
                "Quantities",
                "Logic",
                "Current events",
                "Mathematics"
            ],
            "Github Date": "",
            "HF Date": "2023-01-30",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 61,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "RTE-Quant",
            "NewNLI",
            "RedditNLI",
            "StressTest",
            "AwpNLI"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Ravichander2019EQUATEAB,\n author = {Abhilasha Ravichander and Aakanksha Naik and C. Ros and E. Hovy},\n booktitle = {Conference on Computational Natural Language Learning},\n pages = {349-361},\n title = {EQUATE: A Benchmark Evaluation Framework for Quantitative Reasoning in Natural Language Inference},\n year = {2019}\n}\n"
    },
    "tsy-implicit_hate_stg1": {
        "Unique Dataset Identifier": "tsy-implicit_hate_stg1",
        "Dataset Name": "implicit_hate_stg1",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/SALT-NLP/implicit-hate",
        "GitHub URL": "https://github.com/SALT-NLP/implicit-hate",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/implicit-hate-stg1",
        "Paper Title": "Latent Hatred: A Benchmark for Understanding Implicit Hate Speech",
        "Papers with Code URL": "https://paperswithcode.com/dataset/implicit-hate",
        "ArXiv URL": "https://arxiv.org/abs/2109.05322",
        "Semantic Scholar Corpus ID": 237490428,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1836,
            "Mean Inputs Length": 947.4853,
            "Mean Targets Length": 6.5289,
            "Max Inputs Length": 1663,
            "Max Targets Length": 15,
            "Min Inputs Length": 579,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "UC San Diego",
            "Georgia Institute of Technology"
        ],
        "Licenses": [
            {
                "License": "Request Form",
                "License URL": "https://forms.gle/QxCpEbVp91Z35hWFA"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "implicit-hate-stg1"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/implicit-hate-stg1",
            "HF Config": "metaeval--implicit-hate-stg1",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2021-09-11",
            "S2 Date": "2021-09-11",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Discrimination",
                "Identity",
                "Social issues",
                "History",
                "Hate speech and discrimination",
                "Religion",
                "Hate speech",
                "Racism",
                "Political discourse"
            ],
            "Github Date": "",
            "HF Date": "2023-04-17",
            "HF Downloads (September 2023)": 94,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The Implicit Hate corpus is a dataset for hate speech detection with fine-grained labels for each message and its implication. This dataset contains 22,056 tweets from the most prominent extremist groups in the United States; 6,346 of these tweets contain implicit hate speech.",
            "S2 Citation Count (September 2023)": 84,
            "GitHub Stars": 26,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Elsherief2021LatentHA,\n author = {Mai Elsherief and Caleb Ziems and D. Muchlinski and Vaishnavi Anupindi and Jordyn Seybolt and M. Choudhury and Diyi Yang},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {345-363},\n title = {Latent Hatred: A Benchmark for Understanding Implicit Hate Speech},\n year = {2021}\n}\n"
    },
    "tsy-logiqa_2.0_nli": {
        "Unique Dataset Identifier": "tsy-logiqa_2.0_nli",
        "Dataset Name": "logiqa_2.0_nli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/csitfun/LogiQA2.0",
        "GitHub URL": "https://github.com/lgw863/LogiQA-dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/logiqa-2.0-nli",
        "Paper Title": "LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/medmcqa",
        "ArXiv URL": "https://arxiv.org/abs/2007.08124",
        "Semantic Scholar Corpus ID": 220483148,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 754,
            "Mean Inputs Length": 5448.4854,
            "Mean Targets Length": 6.5809,
            "Max Inputs Length": 7385,
            "Max Targets Length": 22,
            "Min Inputs Length": 3935,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "national civil servants examination of china"
        ],
        "Model Generated": [],
        "Creators": [
            "Fudan University",
            "Westlake University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "https://github.com/csitfun/LogiQA2.0#logiqa20"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "logiqa-2.0-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "lucasmccabe/logiqa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-03-27",
            "S2 Date": "2020-07-01",
            "GitHub License": "",
            "Text Topics": [
                "Philosophy",
                "Biology",
                "History",
                "Politics",
                "Health",
                "Technology",
                "Psychology"
            ],
            "Github Date": "",
            "HF Date": "2023-04-24",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "MedMCQA is a large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions.\n\nMedMCQA has more than 194k high-quality AIIMS & NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity.",
            "S2 Citation Count (September 2023)": 90,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020LogiQAAC,\n author = {Jian Liu and Leyang Cui and Hanmeng Liu and Dandan Huang and Yile Wang and Yue Zhang},\n booktitle = {International Joint Conference on Artificial Intelligence},\n journal = {ArXiv},\n title = {LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning},\n volume = {abs/2007.08124},\n year = {2020}\n}\n"
    },
    "tsy-pararule_plus": {
        "Unique Dataset Identifier": "tsy-pararule_plus",
        "Dataset Name": "pararule_plus",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Strong-AI-Lab/Multi-Step-Deductive-Reasoning-Over-Natural-Language",
        "GitHub URL": "https://github.com/Strong-AI-Lab/Multi-Step-Deductive-Reasoning-Over-Natural-Language",
        "Hugging Face URL": "https://huggingface.co/datasets/qbao775/PARARULE-Plus",
        "Paper Title": "Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2207.14000",
        "Semantic Scholar Corpus ID": 251135345,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Natural Language Inference",
            "Reasoning over Natural Language",
            "Question Answering",
            "Boolean Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 7986.2526,
            "Mean Targets Length": 6.5908,
            "Max Inputs Length": 10528,
            "Max Targets Length": 22,
            "Min Inputs Length": 5314,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "The University of Auckland"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "PARARULE-Plus"
        ],
        "Inferred Metadata": {
            "HF Dataset": "qbao775/PARARULE-Plus",
            "HF Config": "qbao775--PARARULE-Plus",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-07-28",
            "GitHub License": "",
            "Text Topics": [
                "Animal behavior",
                "General knowledge",
                "Logic and reasoning",
                "Descriptive language",
                "Animal characteristics",
                "Logic",
                "Animal characteristics and behavior",
                "Language understanding",
                "Personality traits and characteristics"
            ],
            "Github Date": "",
            "HF Date": "2023-04-16",
            "HF Downloads (September 2023)": 52,
            "HF Likes (September 2023)": 4,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 4,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Bao2022MultiStepDR,\n author = {Qiming Bao and A. Peng and Tim Hartill and N. Tan and Zhenyun Deng and M. Witbrock and Jiamou Liu},\n booktitle = {International Workshop on Neural-Symbolic Learning and Reasoning},\n journal = {ArXiv},\n title = {Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation},\n volume = {abs/2207.14000},\n year = {2022}\n}\n"
    },
    "tsy-mindgames": {
        "Unique Dataset Identifier": "tsy-mindgames",
        "Dataset Name": "mindgames",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/llm-theory-of-mind",
        "GitHub URL": "https://github.com/sileod/llm-theory-of-mind",
        "Hugging Face URL": "https://huggingface.co/datasets/sileod/mindgames",
        "Paper Title": "MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mindgames",
        "ArXiv URL": "https://arxiv.org/abs/2305.03353",
        "Semantic Scholar Corpus ID": 258547259,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1240,
            "Mean Inputs Length": 3255.8065,
            "Mean Targets Length": 6.4645,
            "Max Inputs Length": 4303,
            "Max Targets Length": 15,
            "Min Inputs Length": 2514,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Lille"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/sileod/llm-theory-of-mind"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mindgames"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sileod/mindgames",
            "HF Config": "all",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "",
            "PwC Date": "2023-05-05",
            "S2 Date": "2023-05-05",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Knowledge",
                "Philosophy",
                "Social dynamics",
                "General knowledge",
                "Logic",
                "Public announcements",
                "Card games",
                "Probability",
                "Epistemology"
            ],
            "Github Date": "",
            "HF Date": "2023-05-03",
            "HF Downloads (September 2023)": 64,
            "HF Likes (September 2023)": 4,
            "PwC Description": "We generate epistemic reasoning problems using modal logic to target theory of mind (tom) in natural language processing models.",
            "S2 Citation Count (September 2023)": 5,
            "GitHub Stars": 6,
            "GitHub Topics": [
                "chatgpt",
                "dataset",
                "english",
                "entailment",
                "epistemic-logic",
                "epistemic-reasoning",
                "gpt-4",
                "language-model",
                "llm",
                "modal-logic",
                "natural-language",
                "natural-language-inference",
                "natural-language-processing",
                "nli",
                "nlp",
                "pal",
                "public-announcement-logic",
                "social-reasoning",
                "theory-of-mind",
                "tom"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sileo2023MindGamesTT,\n author = {Damien Sileo and Antoine Lernould},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic},\n volume = {abs/2305.03353},\n year = {2023}\n}\n"
    },
    "tsy-ambient": {
        "Unique Dataset Identifier": "tsy-ambient",
        "Dataset Name": "ambient",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/ambient",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/ambient",
        "Paper Title": "We're Afraid Language Models Aren't Modeling Ambiguity",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.14399",
        "Semantic Scholar Corpus ID": 258352700,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Natural Language Inference",
            "Binary Classification Question Answering",
            "Binary Classification",
            "Sentence Classification",
            "Comparative Sentence Classification",
            "Multiple Choice Question Answering",
            "Sentence Similarity Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1,
            "Mean Inputs Length": 1273.0,
            "Mean Targets Length": 4.0,
            "Max Inputs Length": 1273,
            "Max Targets Length": 4,
            "Min Inputs Length": 1273,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "textbooks",
            "templates",
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Paul G. Allen School of Computer Science & Engineering",
            "University of Washington",
            "AI2",
            "University of Southern California",
            "Saarland University",
            "New York University",
            "Massachusetts Institute of Technology"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ambient"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/ambient",
            "HF Config": "metaeval--ambient",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-27",
            "GitHub License": "",
            "Text Topics": [
                "Decision-making",
                "Logic",
                "Problem-solving",
                "Time management",
                "Psychology",
                "Communication",
                "Business",
                "Family dynamics",
                "Finance"
            ],
            "Github Date": "",
            "HF Date": "2023-05-04",
            "HF Downloads (September 2023)": 31,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "distNLI",
            "ImpPres",
            "GLUE",
            "MNLI",
            "WaNLI"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Liu2023WereAL,\n author = {Alisa Liu and Zhaofeng Wu and Julian Michael and Alane Suhr and Peter West and Alexander Koller and Swabha Swayamdipta and Noah A. Smith and Yejin Choi},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {We're Afraid Language Models Aren't Modeling Ambiguity},\n volume = {abs/2304.14399},\n year = {2023}\n}\n"
    },
    "tsy-i2d2": {
        "Unique Dataset Identifier": "tsy-i2d2",
        "Dataset Name": "i2d2",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/tasksource/I2D2",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/I2D2",
        "Paper Title": "I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2212.09246",
        "Semantic Scholar Corpus ID": 254854264,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Binary Classification Question Answering",
            "Binary Classification",
            "Natural Language Understanding",
            "Boolean Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1648,
            "Mean Inputs Length": 656.7718,
            "Mean Targets Length": 6.5813,
            "Max Inputs Length": 885,
            "Max Targets Length": 15,
            "Min Inputs Length": 491,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "OpenAI GPT-2"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "AI2",
            "University of Southern California",
            "Tohoku University",
            "Northwestern University",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "I2D2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/I2D2",
            "HF Config": "tasksource--I2D2",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-12-19",
            "GitHub License": "",
            "Text Topics": [
                "Travel",
                "General knowledge",
                "Education",
                "Animals",
                "Communication",
                "Shopping",
                "Furniture"
            ],
            "Github Date": "",
            "HF Date": "2023-05-12",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Bhagavatula2022I2D2IK,\n author = {Chandra Bhagavatula and Jena D. Hwang and Doug Downey and Ronan Le Bras and Ximing Lu and Keisuke Sakaguchi and Swabha Swayamdipta and Peter West and Yejin Choi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {9614-9630},\n title = {I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation},\n year = {2022}\n}\n"
    },
    "tsy-args_me": {
        "Unique Dataset Identifier": "tsy-args_me",
        "Dataset Name": "args_me",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://zenodo.org/record/4139439",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/webis/args_me",
        "Paper Title": "Data Acquisition for Argument Search: The args.me Corpus",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 202559512,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Factual Argumentation Resolution",
            "Multiple Choice Question Answering",
            "Binary Classification",
            "Binary Classification Question Answering",
            "Logical Reasoning",
            "Argumentative Question Answering",
            "Sentiment Analysis",
            "Argument Resolution"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3004,
            "Mean Inputs Length": 15424.9877,
            "Mean Targets Length": 6.6398,
            "Max Inputs Length": 63619,
            "Max Targets Length": 18,
            "Min Inputs Length": 1376,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "debatewise.org",
            "idebate.org",
            "debatepedia.org",
            "debate.org"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://zenodo.org/record/4139439"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "args_me"
        ],
        "Inferred Metadata": {
            "HF Dataset": "webis/args_me",
            "HF Config": "corpus",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-09-23",
            "GitHub License": "",
            "Text Topics": [
                "Debate",
                "Debate and argumentation",
                "Education",
                "Philosophy",
                "Gun control",
                "Argumentation",
                "Communication",
                "Politics",
                "Religion",
                "Economics"
            ],
            "Github Date": "",
            "HF Date": "2021-07-13",
            "HF Downloads (September 2023)": 101,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 70,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Ajjour2019DataAF,\n author = {Yamen Ajjour and Henning Wachsmuth and Johannes Kiesel and Martin Potthast and Matthias Hagen and Benno Stein},\n booktitle = {Deutsche Jahrestagung fr Knstliche Intelligenz},\n pages = {48-59},\n title = {Data Acquisition for Argument Search: The args.me Corpus},\n year = {2019}\n}\n"
    },
    "tsy-touche23_valueeval": {
        "Unique Dataset Identifier": "tsy-touche23_valueeval",
        "Dataset Name": "touche23_valueeval",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://webis.de/data/touche23-valueeval.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/webis/Touche23-ValueEval",
        "Paper Title": "The Touch23-ValueEval Dataset for Identifying Human Values behind Arguments",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2301.13771",
        "Semantic Scholar Corpus ID": 256416203,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Binary Classification Question Answering",
            "Multiple Choice Question Answering",
            "Binary Classification",
            "Sentiment Analysis",
            "Argumentative Essay Generation",
            "Natural Language Inference",
            "Open-Domain Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 579,
            "Mean Inputs Length": 1658.8739,
            "Mean Targets Length": 6.5855,
            "Max Inputs Length": 3960,
            "Max Targets Length": 13,
            "Min Inputs Length": 1131,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "conference on the future of europe",
            "groupdiscussionideas.com",
            "nahj al-balagha",
            "zhihu",
            "nytmes"
        ],
        "Model Generated": [],
        "Creators": [
            "Bauhaus-Universitat Weimar",
            "Leibniz University Hannover",
            "Universitt Leipzig",
            "Technische Universitt Mnchen",
            "CENIA",
            "Shahid Beheshti University",
            "Sharif University of Technology",
            "UC Berkeley",
            "Heinrich Heine-Universitt Dsseldorf"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://zenodo.org/record/7879430"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "Touche23-ValueEval"
        ],
        "Inferred Metadata": {
            "HF Dataset": "webis/Touche23-ValueEval",
            "HF Config": "main",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-01-31",
            "GitHub License": "",
            "Text Topics": [
                "Education",
                "Economic policy",
                "Ethics",
                "Health",
                "Religion",
                "International relations",
                "Environmental conservation",
                "Social issues",
                "Economics",
                "Ethics and morality"
            ],
            "Github Date": "",
            "HF Date": "2023-04-17",
            "HF Downloads (September 2023)": 114,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 23,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Mirzakhmedova2023TheTD,\n author = {Nailia Mirzakhmedova and Johannes Kiesel and Milad Alshomary and Maximilian Heinrich and Nicolas Handke and Xiaoni Cai and Barriere Valentin and D. Dastgheib and Omid Ghahroodi and Mohammad Ali Sadraei and Ehsaneddin Asgari and Lea Kawaletz and Henning Wachsmuth and Benno Stein},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {The Touch23-ValueEval Dataset for Identifying Human Values behind Arguments},\n volume = {abs/2301.13771},\n year = {2023}\n}\n"
    },
    "tsy-starcon": {
        "Unique Dataset Identifier": "tsy-starcon",
        "Dataset Name": "starcon",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/dwslab/StArCon",
        "GitHub URL": "https://github.com/dwslab/StArCon",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/starcon",
        "Paper Title": "Unsupervised Stance Detection for Arguments from Consequences",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/2020.emnlp-main.4/",
        "Semantic Scholar Corpus ID": 226262286,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Binary Classification Question Answering",
            "Binary Classification",
            "Natural Language Inference",
            "Sentiment Analysis",
            "Multiple Choice Question Answering",
            "Span Selection Question Answering",
            "Sentence Classification",
            "Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 149,
            "Mean Inputs Length": 917.0134,
            "Mean Targets Length": 6.7718,
            "Max Inputs Length": 1094,
            "Max Targets Length": 13,
            "Min Inputs Length": 797,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "debatepedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Mannheim"
        ],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://github.com/dwslab/StArCon/tree/master/data"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "starcon"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/starcon",
            "HF Config": "tasksource--starcon",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-01",
            "GitHub License": "",
            "Text Topics": [
                "Ethics and morality",
                "Economics",
                "Environmental sustainability",
                "Religion",
                "Education",
                "International relations",
                "Environmental impact",
                "Renewable energy",
                "Politics"
            ],
            "Github Date": "",
            "HF Date": "2023-05-14",
            "HF Downloads (September 2023)": 56,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 17,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Kobbe2020UnsupervisedSD,\n author = {J. Kobbe and Ioana Hulpus and H. Stuckenschmidt},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {50-60},\n title = {Unsupervised Stance Detection for Arguments from Consequences},\n year = {2020}\n}\n"
    },
    "tsy-banking77": {
        "Unique Dataset Identifier": "tsy-banking77",
        "Dataset Name": "banking77",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/PolyAI-LDN/task-specific-datasets",
        "GitHub URL": "https://github.com/PolyAI-LDN/task-specific-datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/PolyAI/banking77",
        "Paper Title": "Efficient Intent Detection with Dual Sentence Encoders",
        "Papers with Code URL": "https://paperswithcode.com/dataset/banking77",
        "ArXiv URL": "https://arxiv.org/abs/2005.08866",
        "Semantic Scholar Corpus ID": 212645349,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 749,
            "Mean Inputs Length": 673.6355,
            "Mean Targets Length": 6.6075,
            "Max Inputs Length": 1320,
            "Max Targets Length": 14,
            "Min Inputs Length": 445,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "customer service queries"
        ],
        "Model Generated": [],
        "Creators": [
            "PolyAI Limited"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://github.com/PolyAI-LDN/task-specific-datasets#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "banking77"
        ],
        "Inferred Metadata": {
            "HF Dataset": "PolyAI/banking77",
            "HF Config": "default",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://github.com/PolyAI-LDN/task-specific-datasets/blob/master/LICENSE",
            "PwC Date": "2020-03-10",
            "S2 Date": "2020-03-10",
            "GitHub License": "CC BY 4.0",
            "Text Topics": [
                "Banking",
                "Financial transactions",
                "Payment processing",
                "Customer service",
                "Banking and finance",
                "Payment methods",
                "Personal finance",
                "Finance",
                "Currency exchange"
            ],
            "Github Date": "",
            "HF Date": "2022-04-27",
            "HF Downloads (September 2023)": 3164,
            "HF Likes (September 2023)": 13,
            "PwC Description": "Dataset composed of online banking queries annotated with their corresponding intents.\n\nBANKING77 dataset provides a very fine-grained set of intents in a banking domain. It comprises 13,083 customer service queries labeled with 77 intents. It focuses on fine-grained single-domain intent detection.",
            "S2 Citation Count (September 2023)": 211,
            "GitHub Stars": 131,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Casanueva2020EfficientID,\n author = {I. Casanueva and Tadas Temvcinas and D. Gerz and Matthew Henderson and Ivan Vulic},\n booktitle = {NLP4CONVAI},\n journal = {ArXiv},\n title = {Efficient Intent Detection with Dual Sentence Encoders},\n volume = {abs/2003.04807},\n year = {2020}\n}\n"
    },
    "tsy-ruletaker": {
        "Unique Dataset Identifier": "tsy-ruletaker",
        "Dataset Name": "ruletaker",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/allenai/ruletaker",
        "GitHub URL": "https://github.com/allenai/ruletaker",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/ruletaker",
        "Paper Title": "Transformers as Soft Reasoners over Language",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2002.05867",
        "Semantic Scholar Corpus ID": 211126663,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 4612.1287,
            "Mean Targets Length": 6.5559,
            "Max Inputs Length": 7183,
            "Max Targets Length": 22,
            "Min Inputs Length": 2314,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://allenai.org/data/ruletaker"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ruletaker"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/ruletaker",
            "HF Config": "tasksource--ruletaker",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-02-14",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Language and communication",
                "Linguistics",
                "General knowledge",
                "Inference and reasoning",
                "Reasoning",
                "Inference",
                "Logic",
                "Language and semantics"
            ],
            "Github Date": "",
            "HF Date": "2023-05-23",
            "HF Downloads (September 2023)": 44,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 202,
            "GitHub Stars": 32,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Clark2020TransformersAS,\n author = {Peter Clark and Oyvind Tafjord and Kyle Richardson},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {3882-3890},\n title = {Transformers as Soft Reasoners over Language},\n year = {2020}\n}\n"
    },
    "tsy-control_nli": {
        "Unique Dataset Identifier": "tsy-control_nli",
        "Dataset Name": "control_nli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/csitfun/ConTRoL-dataset",
        "GitHub URL": "https://github.com/csitfun/ConTRoL-dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/ConTRoL-nli",
        "Paper Title": "Natural Language Inference in Context - Investigating Contextual Reasoning over Long Texts",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2011.04864",
        "Semantic Scholar Corpus ID": 226289632,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 99,
            "Mean Inputs Length": 18488.4343,
            "Mean Targets Length": 6.6263,
            "Max Inputs Length": 53942,
            "Max Targets Length": 14,
            "Min Inputs Length": 942,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "pirt tests",
            "mcat tests",
            "ucat tests"
        ],
        "Model Generated": [],
        "Creators": [
            "Zhejiang University",
            "Fudan University",
            "Westlake University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "https://github.com/csitfun/ConTRoL-dataset#control-dataset"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ConTRoL-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/ConTRoL-nli",
            "HF Config": "tasksource--ConTRoL-nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-10",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "General knowledge",
                "Economics",
                "History",
                "Psychology",
                "Demographics",
                "Logic",
                "Philosophy"
            ],
            "Github Date": "",
            "HF Date": "2023-05-24",
            "HF Downloads (September 2023)": 34,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 25,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020NaturalLI,\n author = {Hanmeng Liu and Leyang Cui and Jian Liu and Yue Zhang},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {13388-13396},\n title = {Natural Language Inference in Context - Investigating Contextual Reasoning over Long Texts},\n year = {2020}\n}\n"
    },
    "tsy-tracie": {
        "Unique Dataset Identifier": "tsy-tracie",
        "Dataset Name": "tracie",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/allenai/aristo-leaderboard/tree/master/tracie/data",
        "GitHub URL": "https://github.com/allenai/aristo-leaderboard/tree/master/tracie/data",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/tracie",
        "Paper Title": "Temporal Reasoning on Implicit Events from Distant Supervision",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.12753",
        "Semantic Scholar Corpus ID": 225066771,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 116,
            "Mean Inputs Length": 2954.6552,
            "Mean Targets Length": 6.7672,
            "Max Inputs Length": 3314,
            "Max Targets Length": 14,
            "Min Inputs Length": 2577,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "University of Pennsylvania",
            "Amazon"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tracie"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/tracie",
            "HF Config": "tasksource--tracie",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-24",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Decision-making",
                "Communication",
                "Legal proceedings",
                "Parental custody",
                "Sports",
                "Consumer rights",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2023-05-25",
            "HF Downloads (September 2023)": 31,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 46,
            "GitHub Stars": 35,
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "ROCStories dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zhou2020TemporalRO,\n author = {Ben Zhou and Kyle Richardson and Qiang Ning and Tushar Khot and Ashish Sabharwal and D. Roth},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Temporal Reasoning on Implicit Events from Distant Supervision},\n volume = {abs/2010.12753},\n year = {2020}\n}\n"
    },
    "tsy-sherliic": {
        "Unique Dataset Identifier": "tsy-sherliic",
        "Dataset Name": "sherliic",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/mnschmit/SherLIiC",
        "GitHub URL": "https://github.com/mnschmit/SherLIiC",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/sherliic",
        "Paper Title": "SherLIiC: A Typed Event-Focused Lexical Inference Benchmark for Evaluating Natural Language Inference",
        "Papers with Code URL": "https://paperswithcode.com/dataset/sherliic",
        "ArXiv URL": "https://arxiv.org/abs/1906.01393",
        "Semantic Scholar Corpus ID": 174797858,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 74,
            "Mean Inputs Length": 940.5541,
            "Mean Targets Length": 6.5811,
            "Max Inputs Length": 1095,
            "Max Targets Length": 15,
            "Min Inputs Length": 790,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "freebase",
            "crowdsourced",
            "undisclosed web"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "LMU Munich"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "sherliic"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/sherliic",
            "HF Config": "tasksource--sherliic",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/4.0/",
            "PwC Date": "2019-06-04",
            "S2 Date": "2019-06-04",
            "GitHub License": "",
            "Text Topics": [
                "Competition",
                "Business",
                "International relations",
                "Logic",
                "Technology",
                "Current events",
                "Politics"
            ],
            "Github Date": "",
            "HF Date": "2023-05-25",
            "HF Downloads (September 2023)": 49,
            "HF Likes (September 2023)": 0,
            "PwC Description": "SherLIiC is a testbed for lexical inference in context (LIiC), consisting of 3985 manually annotated inference rule candidates (InfCands), accompanied by (i) ~960k unlabeled InfCands, and (ii) ~190k typed textual relations between Freebase entities extracted from the large entity-linked corpus ClueWeb09. Each InfCand consists of one of these relations, expressed as a lemmatized dependency path, and two argument placeholders, each linked to one or more Freebase types.",
            "S2 Citation Count (September 2023)": 14,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "ClueWeb09"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Schmitt2019SherLIiCAT,\n author = {Martin Schmitt and Hinrich Schtze},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {902-914},\n title = {SherLIiC: A Typed Event-Focused Lexical Inference Benchmark for Evaluating Natural Language Inference},\n year = {2019}\n}\n"
    },
    "tsy-winowhy": {
        "Unique Dataset Identifier": "tsy-winowhy",
        "Dataset Name": "winowhy",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/HKUST-KnowComp/WinoWhy",
        "GitHub URL": "https://github.com/HKUST-KnowComp/WinoWhy",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/winowhy",
        "Paper Title": "WinoWhy: A Deep Diagnosis of Essential Commonsense Knowledge for Answering Winograd Schema Challenge",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2005.05763",
        "Semantic Scholar Corpus ID": 218595822,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Coreference Resolution",
            "Natural Language Inference",
            "Multiple Choice Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 283,
            "Mean Inputs Length": 3992.5512,
            "Mean Targets Length": 6.6714,
            "Max Inputs Length": 4830,
            "Max Targets Length": 13,
            "Min Inputs Length": 3468,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "winograd schema challenge dataset",
            "conceptnet",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong University of Science and Technology"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "winowhy"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/winowhy",
            "HF Config": "tasksource--winowhy",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-12",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Contextual understanding",
                "Inference",
                "Communication and understanding",
                "Reading comprehension",
                "Interpersonal relationships",
                "Linguistics",
                "Communication",
                "Pronoun reference"
            ],
            "Github Date": "",
            "HF Date": "2023-05-25",
            "HF Downloads (September 2023)": 46,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 35,
            "GitHub Stars": 16,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zhang2020WinoWhyAD,\n author = {Hongming Zhang and Xinran Zhao and Yangqiu Song},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {5736-5745},\n title = {WinoWhy: A Deep Diagnosis of Essential Commonsense Knowledge for Answering Winograd Schema Challenge},\n year = {2020}\n}\n"
    },
    "tsy-mbib_base-cognitive_bias": {
        "Unique Dataset Identifier": "tsy-mbib_base-cognitive_bias",
        "Dataset Name": "mbib_base-cognitive_bias",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Binary Classification Question Answering",
            "Binary Classification",
            "Fact Checking",
            "Factual Question Answering",
            "Factual Information Retrieval",
            "Comparative Sentence Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 709,
            "Mean Inputs Length": 1074.1791,
            "Mean Targets Length": 6.3371,
            "Max Inputs Length": 1545,
            "Max Targets Length": 13,
            "Min Inputs Length": 716,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/cognitive-bias"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "Education",
                "Cognitive biases",
                "Statistics",
                "Economics",
                "Government policies",
                "Politics",
                "Healthcare",
                "Communication",
                "Finance",
                "Taxation"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsy-mbib_base-fake_news": {
        "Unique Dataset Identifier": "tsy-mbib_base-fake_news",
        "Dataset Name": "mbib_base-fake_news",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Binary Classification Question Answering",
            "Binary Classification",
            "Fact Verification",
            "Multiple Choice Question Answering",
            "Open-Domain Question Answering",
            "Fact Checking",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 853,
            "Mean Inputs Length": 1055.0903,
            "Mean Targets Length": 6.6096,
            "Max Inputs Length": 1509,
            "Max Targets Length": 14,
            "Min Inputs Length": 709,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/fake-news"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "Healthcare",
                "Media literacy",
                "International relations",
                "Politics",
                "News categorization",
                "Terrorism",
                "Economics"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsy-mbib_base-gender_bias": {
        "Unique Dataset Identifier": "tsy-mbib_base-gender_bias",
        "Dataset Name": "mbib_base-gender_bias",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Natural Language Understanding",
            "Multiple Choice Question Answering",
            "Natural Language Classification",
            "Dialogue Generation",
            "Binary Classification",
            "Sentence Classification",
            "Offensive Language Detection",
            "User Interface Design Suggestion"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1794,
            "Mean Inputs Length": 921.7313,
            "Mean Targets Length": 6.5273,
            "Max Inputs Length": 1292,
            "Max Targets Length": 15,
            "Min Inputs Length": 549,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/gender-bias"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "Discrimination",
                "Relationships",
                "Gender stereotypes",
                "Gender bias",
                "Social issues",
                "Communication",
                "Language and communication",
                "Religion",
                "Social media"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsy-mbib_base-hate_speech": {
        "Unique Dataset Identifier": "tsy-mbib_base-hate_speech",
        "Dataset Name": "mbib_base-hate_speech",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Binary Classification",
            "Factual Question Answering",
            "Open-Domain Question Answering",
            "Binary Classification of Hate Speech",
            "Multiple Choice Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5552,
            "Mean Inputs Length": 2602.3037,
            "Mean Targets Length": 6.6001,
            "Max Inputs Length": 5930,
            "Max Targets Length": 18,
            "Min Inputs Length": 784,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/hate-speech"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "Politics",
                "Political discourse",
                "Social interactions",
                "Language and communication",
                "Communication",
                "Social issues and discrimination",
                "Freedom of speech",
                "Discrimination and prejudice"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsy-mbib_base-linguistic_bias": {
        "Unique Dataset Identifier": "tsy-mbib_base-linguistic_bias",
        "Dataset Name": "mbib_base-linguistic_bias",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Binary Classification",
            "Natural Language Understanding",
            "Named Entity Recognition",
            "Span Selection Question Answering",
            "Fact Verification",
            "Ordering Task",
            "Factual Information Retrieval",
            "Classification",
            "Binary Classification Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5555,
            "Mean Inputs Length": 2679.4936,
            "Mean Targets Length": 6.6628,
            "Max Inputs Length": 11476,
            "Max Targets Length": 18,
            "Min Inputs Length": 915,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/linguistic-bias"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "International relations",
                "Entertainment",
                "Music",
                "Sports",
                "Religion",
                "Linguistics",
                "Education",
                "Geography"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsy-mbib_base-political_bias": {
        "Unique Dataset Identifier": "tsy-mbib_base-political_bias",
        "Dataset Name": "mbib_base-political_bias",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Natural Language Understanding",
            "Sentiment Analysis",
            "Multiple Choice Question Answering",
            "Open-Domain Question Answering",
            "Information Retrieval",
            "Binary Classification Question Answering",
            "Binary Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1769,
            "Mean Inputs Length": 2142.0469,
            "Mean Targets Length": 6.6507,
            "Max Inputs Length": 5096,
            "Max Targets Length": 15,
            "Min Inputs Length": 849,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/political-bias"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "Media bias",
                "Gun control",
                "Current events",
                "Religion",
                "Crime and law enforcement",
                "Social issues",
                "Immigration policy",
                "Political bias",
                "Politics",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsy-mbib_base-racial_bias": {
        "Unique Dataset Identifier": "tsy-mbib_base-racial_bias",
        "Dataset Name": "mbib_base-racial_bias",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Natural Language Understanding",
            "Open-Domain Question Answering",
            "Natural Language Classification",
            "Binary Classification",
            "Binary Classification Question Answering",
            "Binary Classification of Racial Bias"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 977,
            "Mean Inputs Length": 1012.1361,
            "Mean Targets Length": 6.6305,
            "Max Inputs Length": 1418,
            "Max Targets Length": 22,
            "Min Inputs Length": 688,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/racial-bias"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "Identity",
                "Cultural sensitivity",
                "Stereotypes",
                "Language and communication",
                "Religion",
                "Discrimination",
                "LGBTQ+ rights",
                "Racism and discrimination"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsy-mbib_base-text_level_bias": {
        "Unique Dataset Identifier": "tsy-mbib_base-text_level_bias",
        "Dataset Name": "mbib_base-text_level_bias",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Binary Classification",
            "Open-Domain Question Answering",
            "Classification",
            "Offensive Language Detection",
            "Natural Language Classification",
            "Bias Detection",
            "Multiple Choice Question Answering",
            "Natural Language Inference",
            "Discourse Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 901,
            "Mean Inputs Length": 1822.0966,
            "Mean Targets Length": 6.6027,
            "Max Inputs Length": 13139,
            "Max Targets Length": 15,
            "Min Inputs Length": 443,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/text-level-bias"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "International relations",
                "Online communities",
                "General knowledge",
                "Language and communication",
                "Social issues",
                "Communication",
                "Social media",
                "Identity",
                "Online communication"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsy-robustlr": {
        "Unique Dataset Identifier": "tsy-robustlr",
        "Dataset Name": "robustlr",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/INK-USC/RobustLR",
        "GitHub URL": "https://github.com/huggingface/datasets/blob/main/CONTRIBUTING.md#how-to-contribute-to-the-dataset-cards",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/robustLR",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2205.12598",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 229,
            "Mean Inputs Length": 9479.7467,
            "Mean Targets Length": 6.6026,
            "Max Inputs Length": 15833,
            "Max Targets Length": 14,
            "Min Inputs Length": 1892,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robustLR"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/robustLR",
            "HF Config": "tasksource--robustLR",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Reasoning",
                "Family relationships",
                "Logic and reasoning",
                "Logic",
                "General knowledge",
                "Linguistics",
                "Relationships",
                "Language understanding",
                "Gender roles"
            ],
            "Github Date": "",
            "HF Date": "2023-05-26",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": ""
    },
    "tsy-v1-gen_train234_test2to10": {
        "Unique Dataset Identifier": "tsy-v1-gen_train234_test2to10",
        "Dataset Name": "v1-gen_train234_test2to10",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://www.cs.mcgill.ca/~ksinha4/clutrr/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/CLUTRR/v1",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1908.06177",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1316,
            "Mean Inputs Length": 2165.0441,
            "Mean Targets Length": 6.5783,
            "Max Inputs Length": 3556,
            "Max Targets Length": 22,
            "Min Inputs Length": 1203,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "McGill University",
            "Universite de Montreal",
            "Montreal Institute of Learning Algorithms (Mila)",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "v1/gen_train234_test2to10"
        ],
        "Inferred Metadata": {
            "HF Dataset": "CLUTRR/v1",
            "HF Config": "gen_train23_test2to10",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Daily routine",
                "Parenting",
                "Social activities",
                "Gift-giving traditions",
                "Family relationships",
                "Childcare",
                "Genealogy",
                "Personal relationships",
                "Gender roles",
                "Social interactions"
            ],
            "Github Date": "",
            "HF Date": "2022-03-09",
            "HF Downloads (September 2023)": 53,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": ""
    },
    "tsy-logical_fallacy": {
        "Unique Dataset Identifier": "tsy-logical_fallacy",
        "Dataset Name": "logical_fallacy",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/causalNLP/logical-fallacy",
        "GitHub URL": "https://github.com/causalNLP/logical-fallacy",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/logical-fallacy",
        "Paper Title": "Logical Fallacy Detection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2202.13758",
        "Semantic Scholar Corpus ID": 247158013,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 244,
            "Mean Inputs Length": 1525.5082,
            "Mean Targets Length": 6.6311,
            "Max Inputs Length": 3365,
            "Max Targets Length": 13,
            "Min Inputs Length": 868,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "quizziz",
            "study.com",
            "proprofs",
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "Max Planck Institute",
            "ETH Zrich",
            "BITS Pilani",
            "Indian Institute of Technology",
            "Saarland University",
            "University of Michigan",
            "University of Hong Kong"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "logical-fallacy"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/logical-fallacy",
            "HF Config": "tasksource--logical-fallacy",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-02-28",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Education",
                "Climate change",
                "Fallacies",
                "Communication",
                "Philosophy",
                "Logical fallacies",
                "Science",
                "Critical thinking"
            ],
            "Github Date": "",
            "HF Date": "2023-05-28",
            "HF Downloads (September 2023)": 47,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 15,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Jin2022LogicalFD,\n author = {Zhijing Jin and Abhinav Lalwani and Tejas Vaidhya and Xiaoyu Shen and Yiwen Ding and Zhiheng Lyu and Mrinmaya Sachan and Rada Mihalcea and B. Scholkopf},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Logical Fallacy Detection},\n volume = {abs/2202.13758},\n year = {2022}\n}\n"
    },
    "tsy-parade": {
        "Unique Dataset Identifier": "tsy-parade",
        "Dataset Name": "parade",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/heyunh2015/PARADE_dataset",
        "GitHub URL": "https://github.com/heyunh2015/PARADE_dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/parade",
        "Paper Title": "PARADE: A New Dataset for Paraphrase Identification Requiring Computer Science Domain Knowledge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/parade",
        "ArXiv URL": "https://arxiv.org/abs/2010.03725",
        "Semantic Scholar Corpus ID": 222209064,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Paraphrase Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 837,
            "Mean Inputs Length": 2141.2748,
            "Mean Targets Length": 6.6762,
            "Max Inputs Length": 3217,
            "Max Targets Length": 15,
            "Min Inputs Length": 1414,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "cluscite",
            "quizzlet"
        ],
        "Model Generated": [],
        "Creators": [
            "Texas A&M University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "parade"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/parade",
            "HF Config": "tasksource--parade",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Data management",
                "Information technology",
                "Statistics",
                "Technology",
                "Database management",
                "Data analysis",
                "Computer programming",
                "Data storage"
            ],
            "Github Date": "",
            "HF Date": "2023-05-30",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 0,
            "PwC Description": "PARADE contains paraphrases that overlap very little at the lexical and syntactic level but are semantically equivalent based on computer science domain knowledge, as well as non-paraphrases that overlap greatly at the lexical and syntactic level but are not semantically equivalent based on this domain knowledge.",
            "S2 Citation Count (September 2023)": 12,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{He2020PARADEAN,\n author = {Yun He and Zhuoer Wang and Yin Zhang and Ruihong Huang and James Caverlee},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {PARADE: A New Dataset for Paraphrase Identification Requiring Computer Science Domain Knowledge},\n volume = {abs/2010.03725},\n year = {2020}\n}\n"
    },
    "tsy-cladder": {
        "Unique Dataset Identifier": "tsy-cladder",
        "Dataset Name": "cladder",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/causalNLP/cladder",
        "GitHub URL": "https://github.com/causalNLP/cladder",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/cladder",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Binary Classification Question Answering",
            "Conditional Probability Inference",
            "Probabilistic Reasoning Question Answering",
            "Comparative Analysis Question Answering",
            "Probabilistic Reasoning",
            "Binary Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1055,
            "Mean Inputs Length": 2617.8806,
            "Mean Targets Length": 6.5545,
            "Max Inputs Length": 4611,
            "Max Targets Length": 22,
            "Min Inputs Length": 1712,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "cladder"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/cladder",
            "HF Config": "tasksource--cladder",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Probability and statistics",
                "Statistical analysis",
                "Data analysis",
                "Mathematics",
                "Logic and reasoning",
                "Decision-making and reasoning",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2023-05-27",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 9,
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsy-subjectivity": {
        "Unique Dataset Identifier": "tsy-subjectivity",
        "Dataset Name": "subjectivity",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/tasksource/subjectivity",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/subjectivity",
        "Paper Title": "A Corpus for Sentence-level Subjectivity Detection on English News Articles",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2305.18034",
        "Semantic Scholar Corpus ID": 258960244,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Span Selection Question Answering",
            "Open-Ended Question Answering",
            "Factual Statement Verification",
            "Sentence Classification",
            "Natural Language Inference",
            "Binary Classification",
            "Multiple Choice Question Answering",
            "Natural Language Understanding",
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 61,
            "Mean Inputs Length": 1379.6066,
            "Mean Targets Length": 6.5246,
            "Max Inputs Length": 2222,
            "Max Targets Length": 15,
            "Min Inputs Length": 824,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "tribunemag.co.uk",
            "spectator.co.uk",
            "shtfplan.com",
            "vdare.com",
            "theweek.com",
            "frontpagemag.com",
            "economist.com",
            "theguardian.com"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Bologna"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "subjectivity"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/subjectivity",
            "HF Config": "tasksource--subjectivity",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-05-29",
            "GitHub License": "",
            "Text Topics": [
                "Finance",
                "Language",
                "Government and politics",
                "Health",
                "Economics",
                "Politics",
                "Grammar",
                "Taxation",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2023-05-30",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Antici2023ACF,\n author = {Francesco Antici and Andrea Galassi and Federico Ruggeri and Katerina Korre and Arianna Muti and Alessandra Bardi and Alice Fedotova and A. Barr'on-Cedeno},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A Corpus for Sentence-level Subjectivity Detection on English News Articles},\n volume = {abs/2305.18034},\n year = {2023}\n}\n"
    },
    "tsy-moh": {
        "Unique Dataset Identifier": "tsy-moh",
        "Dataset Name": "moh",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/tasksource/MOH",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/MOH",
        "Paper Title": "Metaphor as a Medium for Emotion: An Empirical Study",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/S16-2003/",
        "Semantic Scholar Corpus ID": 989439,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Span Selection Question Answering",
            "Binary Classification",
            "Literal/Metaphorical Classification",
            "Word Sense Disambiguation",
            "Natural Language Understanding",
            "Single Word Classification",
            "Binary Classification Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 74,
            "Mean Inputs Length": 612.7432,
            "Mean Targets Length": 6.0541,
            "Max Inputs Length": 742,
            "Max Targets Length": 12,
            "Min Inputs Length": 518,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wordnet"
        ],
        "Model Generated": [],
        "Creators": [
            "National Research Council Canada",
            "University of Cambridge",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "MOH"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/MOH",
            "HF Config": "tasksource--MOH",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2016-08-01",
            "GitHub License": "",
            "Text Topics": [
                "Education",
                "Literary devices",
                "Politics",
                "Communication",
                "Linguistics",
                "Language",
                "Literal interpretation",
                "Figurative language",
                "Literary analysis"
            ],
            "Github Date": "",
            "HF Date": "2023-05-30",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 124,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Mohammad2016MetaphorAA,\n author = {Saif M. Mohammad and Ekaterina Shutova and Peter D. Turney},\n booktitle = {International Workshop on Semantic Evaluation},\n pages = {23-33},\n title = {Metaphor as a Medium for Emotion: An Empirical Study},\n year = {2016}\n}\n"
    },
    "tsy-vuac": {
        "Unique Dataset Identifier": "tsy-vuac",
        "Dataset Name": "vuac",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/tasksource/VUAC",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/VUAC",
        "Paper Title": "A method for linguistic metaphor identification : from MIP to MIPVU",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 60025535,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Span Selection Question Answering",
            "Metaphor Identification",
            "Named Entity Recognition",
            "Natural Language Inference",
            "Contextual Word Sense Disambiguation",
            "Open-Domain Question Answering",
            "Information Retrieval"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1049,
            "Mean Inputs Length": 1479.6778,
            "Mean Targets Length": 6.5176,
            "Max Inputs Length": 2835,
            "Max Targets Length": 14,
            "Min Inputs Length": 752,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "VUAC"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/VUAC",
            "HF Config": "tasksource--VUAC",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2010-06-23",
            "GitHub License": "",
            "Text Topics": [
                "Decision-making",
                "Language and communication",
                "Conversation",
                "Literary analysis",
                "Figurative language",
                "Communication",
                "Daily routine",
                "Politics",
                "Linguistics"
            ],
            "Github Date": "",
            "HF Date": "2023-05-30",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 981,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Inproceedings{Steen2010AMF,\n author = {G. Steen},\n title = {A method for linguistic metaphor identification : from MIP to MIPVU},\n year = {2010}\n}\n"
    },
    "tsy-trofi": {
        "Unique Dataset Identifier": "tsy-trofi",
        "Dataset Name": "trofi",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/tasksource/TroFi",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/TroFi",
        "Paper Title": "Active Learning for the Identification of Nonliteral Language",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/W07-0104/",
        "Semantic Scholar Corpus ID": 14685368,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentence Classification",
            "Span Selection Question Answering",
            "Literal/Metaphorical Classification",
            "News Article Summarization",
            "Part-of-Speech Tagging",
            "Metaphor Explanation Question Answering",
            "Metaphor Identification",
            "Natural Language Inference",
            "Binary Classification",
            "Semantic Role Labeling"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 176,
            "Mean Inputs Length": 1628.5966,
            "Mean Targets Length": 6.2614,
            "Max Inputs Length": 2235,
            "Max Targets Length": 14,
            "Min Inputs Length": 1022,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wsj",
            "wayne magnuson english idioms sayings & slang",
            "george lakoffs conceptual metaphor list"
        ],
        "Model Generated": [],
        "Creators": [
            "Simon Fraser University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://www2.cs.sfu.ca/~anoop/students/jbirke/LICENSE.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "TroFi"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/TroFi",
            "HF Config": "tasksource--TroFi",
            "HF Config License": "",
            "HF Yaml License": "GNU General Public License v3.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2007-04-26",
            "GitHub License": "",
            "Text Topics": [
                "Figurative language",
                "Politics",
                "Language and communication",
                "Communication",
                "Literary devices",
                "Economics",
                "Travel",
                "Business",
                "Aviation",
                "Literary analysis"
            ],
            "Github Date": "",
            "HF Date": "2023-05-30",
            "HF Downloads (September 2023)": 27,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 33,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Birke2007ActiveLF,\n author = {Julia Birke and Anoop Sarkar},\n booktitle = {Proceedings of the Workshop on Computational Approaches to Figurative Language - FigLanguages '07},\n journal = {Proceedings of the Workshop on Computational Approaches to Figurative Language - FigLanguages '07},\n title = {Active Learning for the Identification of Nonliteral Language},\n year = {2007}\n}\n"
    },
    "tsy-sharc_modified-mod": {
        "Unique Dataset Identifier": "tsy-sharc_modified-mod",
        "Dataset Name": "sharc_modified-mod",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/nikhilweee/neural-conv-qa",
        "GitHub URL": "https://github.com/nikhilweee/neural-conv-qa",
        "Hugging Face URL": "https://huggingface.co/datasets/sharc_modified",
        "Paper Title": "QED: A Framework and Dataset for Explanations in Question Answering",
        "Papers with Code URL": "https://paperswithcode.com/dataset/qed",
        "ArXiv URL": "https://arxiv.org/abs/1909.03759",
        "Semantic Scholar Corpus ID": 221655495,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Binary Classification Question Answering",
            "Binary Question Answering",
            "Irrelevant Question Detection",
            "Open-Domain Question Answering",
            "Natural Language Understanding",
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2431,
            "Mean Inputs Length": 3690.7367,
            "Mean Targets Length": 6.6705,
            "Max Inputs Length": 5217,
            "Max Targets Length": 16,
            "Min Inputs Length": 2401,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "IBM",
            "Indian Institute of Technology (BHU)"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "sharc_modified/mod"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sharc_modified",
            "HF Config": "mod",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-09-08",
            "GitHub License": "",
            "Text Topics": [
                "Government programs",
                "Veterans affairs",
                "Government policies",
                "Financial assistance",
                "Social welfare benefits",
                "Taxation",
                "Education",
                "Personal finance",
                "Fraud prevention",
                "Government benefits"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1215,
            "HF Likes (September 2023)": 0,
            "PwC Description": "QED is a linguistically principled framework for explanations in question answering. Given a question and a passage, QED represents an explanation of the answer as a combination of discrete, human-interpretable steps:\nsentence selection := identification of a sentence implying an answer to the question\nreferential equality := identification of noun phrases in the question and the answer sentence that refer to the same thing\npredicate entailment := confirmation that the predicate in the sentence entails the predicate in the question once referential equalities are abstracted away.\nThe QED dataset is an expert-annotated dataset of QED explanations build upon a subset of the Google Natural Questions dataset.",
            "S2 Citation Count (September 2023)": 45,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "ShARC"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lamm2020QEDAF,\n author = {Matthew Lamm and J. Palomaki and Chris Alberti and D. Andor and Eunsol Choi and Livio Baldini Soares and Michael Collins},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {790-806},\n title = {QED: A Framework and Dataset for Explanations in Question Answering},\n volume = {9},\n year = {2020}\n}\n"
    },
    "tsy-conceptrules_v2": {
        "Unique Dataset Identifier": "tsy-conceptrules_v2",
        "Dataset Name": "conceptrules_v2",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Strong-AI-Lab/Multi-Step-Deductive-Reasoning-Over-Natural-Language",
        "GitHub URL": "https://github.com/Strong-AI-Lab/Multi-Step-Deductive-Reasoning-Over-Natural-Language",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/conceptrules_v2",
        "Paper Title": "Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2207.14000",
        "Semantic Scholar Corpus ID": 251135345,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Binary Classification Question Answering",
            "Knowledge Base Question Answering",
            "Boolean Question Answering",
            "Spatial Reasoning Question Answering",
            "Factual Statement Verification",
            "Binary Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5554,
            "Mean Inputs Length": 4431.5103,
            "Mean Targets Length": 6.5934,
            "Max Inputs Length": 5540,
            "Max Targets Length": 22,
            "Min Inputs Length": 3674,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "The University of Auckland"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://drive.google.com/file/d/1lOCbW8bfZxj1RIzKDxn8xKg99XyYNj7z/view?usp=sharing"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "conceptrules_v2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/conceptrules_v2",
            "HF Config": "tasksource--conceptrules_v2",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-07-28",
            "GitHub License": "",
            "Text Topics": [
                "Logic and reasoning",
                "Location and spatial relationships",
                "Logic",
                "General knowledge",
                "Daily routine",
                "Language understanding",
                "Categorization"
            ],
            "Github Date": "",
            "HF Date": "2023-05-30",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 4,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Bao2022MultiStepDR,\n author = {Qiming Bao and A. Peng and Tim Hartill and N. Tan and Zhenyun Deng and M. Witbrock and Jiamou Liu},\n booktitle = {International Workshop on Neural-Symbolic Learning and Reasoning},\n journal = {ArXiv},\n title = {Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation},\n volume = {abs/2207.14000},\n year = {2022}\n}\n"
    },
    "tsy-disrpt-eng.dep.scidtb": {
        "Unique Dataset Identifier": "tsy-disrpt-eng.dep.scidtb",
        "Dataset Name": "disrpt-eng.dep.scidtb",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/disrpt",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/disrpt",
        "Paper Title": "SciDTB: Discourse Dependency TreeBank for Scientific Abstracts",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1806.03653",
        "Semantic Scholar Corpus ID": 47021747,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 614,
            "Mean Inputs Length": 1269.4723,
            "Mean Targets Length": 6.5212,
            "Max Inputs Length": 2048,
            "Max Targets Length": 15,
            "Min Inputs Length": 817,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "aclanthology.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "disrpt/eng.dep.scidtb"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/disrpt",
            "HF Config": "eng.dep.covdtb",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-06-10",
            "GitHub License": "",
            "Text Topics": [
                "Language learning",
                "Computational linguistics",
                "Artificial intelligence",
                "Data analysis",
                "Natural Language Processing",
                "Machine learning",
                "Linguistics",
                "Natural language processing"
            ],
            "Github Date": "",
            "HF Date": "2023-04-18",
            "HF Downloads (September 2023)": 53,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 37,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Yang2018SciDTBDD,\n author = {An Yang and Sujian Li},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {444-449},\n title = {SciDTB: Discourse Dependency TreeBank for Scientific Abstracts},\n year = {2018}\n}\n"
    },
    "tsy-zero_shot_label_nli": {
        "Unique Dataset Identifier": "tsy-zero_shot_label_nli",
        "Dataset Name": "zero_shot_label_nli",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/tasksource",
        "GitHub URL": "https://github.com/sileod/tasksource",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/zero-shot-label-nli",
        "Paper Title": "tasksource: A Dataset Harmonization Framework for Streamlined NLP Multi-Task Learning and Evaluation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tasksource",
        "ArXiv URL": "https://arxiv.org/abs/2301.05948",
        "Semantic Scholar Corpus ID": 258715337,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 34,
            "Mean Inputs Length": 3596.1176,
            "Mean Targets Length": 7.3235,
            "Max Inputs Length": 19728,
            "Max Targets Length": 13,
            "Min Inputs Length": 1166,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Lille"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "zero-shot-label-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/zero-shot-label-nli",
            "HF Config": "tasksource--zero-shot-label-nli",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2023-01-14",
            "S2 Date": "2023-01-14",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Technology",
                "Linguistics",
                "Communication",
                "Politics",
                "Health",
                "Customer service",
                "Language and communication",
                "Social media"
            ],
            "Github Date": "",
            "HF Date": "2023-06-02",
            "HF Downloads (September 2023)": 627,
            "HF Likes (September 2023)": 3,
            "PwC Description": "Huggingface Datasets is a great library, but it lacks standardization, and datasets require preprocessing work to be used interchangeably. tasksource automates this and facilitates reproducible multi-task learning scaling.\n\nEach dataset is standardized to either MultipleChoice, Classification, or TokenClassification dataset with identical fields. We do not support generation tasks as they are addressed by promptsource. All implemented preprocessings are in tasks.py or tasks.md. A preprocessing is a function that accepts a dataset and returns the standardized dataset. Preprocessing code is concise and human-readable.",
            "S2 Citation Count (September 2023)": 0,
            "GitHub Stars": 93,
            "GitHub Topics": [
                "benchmark",
                "bigbench",
                "crossfit",
                "curated-datasets",
                "dataset-collection",
                "discriminative",
                "extreme-mtl",
                "extreme-multi-task-learning",
                "glue",
                "huggingface",
                "instruction-tuning",
                "meta-learning",
                "multi-task-learning",
                "multi-task-learning-scaling",
                "natural-language-inference",
                "nlp",
                "preprocessings",
                "scaling",
                "sentiment-analysis",
                "text-classification"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Inproceedings{Sileo2023tasksourceAD,\n author = {Damien Sileo},\n title = {tasksource: A Dataset Harmonization Framework for Streamlined NLP Multi-Task Learning and Evaluation},\n year = {2023}\n}\n"
    },
    "tsy-com2sense": {
        "Unique Dataset Identifier": "tsy-com2sense",
        "Dataset Name": "com2sense",
        "Collection": "Tasksource Symbol-Tuning",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/PlusLabNLP/Com2Sense",
        "GitHub URL": "https://github.com/PlusLabNLP/Com2Sense",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/com2sense",
        "Paper Title": "COM2SENSE: A Commonsense Reasoning Benchmark with Complementary Sentences",
        "Papers with Code URL": "https://paperswithcode.com/dataset/com2sense",
        "ArXiv URL": "https://arxiv.org/abs/2106.00969",
        "Semantic Scholar Corpus ID": 235293697,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Multiple Choice Question Answering",
            "Binary Classification Question Answering",
            "Question Answering",
            "Natural Language Inference",
            "Preference Comparison Question Answering",
            "Decision Making",
            "Comparative Question Answering",
            "Sentence Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 177,
            "Mean Inputs Length": 1018.113,
            "Mean Targets Length": 6.5537,
            "Max Inputs Length": 1374,
            "Max Targets Length": 13,
            "Min Inputs Length": 777,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced (amt)"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Southern California",
            "Sharif University of Technology",
            "UCLA"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "com2sense"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/com2sense",
            "HF Config": "tasksource--com2sense",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2021-06-02",
            "S2 Date": "2021-06-02",
            "GitHub License": "",
            "Text Topics": [
                "Health",
                "Transportation",
                "Fitness",
                "Diet",
                "Sports",
                "General knowledge",
                "Decision-making",
                "Problem-solving"
            ],
            "Github Date": "",
            "HF Date": "2023-06-02",
            "HF Downloads (September 2023)": 53,
            "HF Likes (September 2023)": 0,
            "PwC Description": "Complementary Commonsense (Com2Sense) is a dataset for benchmarking commonsense reasoning ability of NLP models. This dataset contains 4k statement true/false sentence pairs. The dataset is crowdsourced and enhanced with an adversarial model-in-the-loop setup to incentivize challenging samples. To facilitate a systematic analysis of commonsense capabilities, the dataset is designed along the dimensions of knowledge domains, reasoning scenarios and numeracy.",
            "S2 Citation Count (September 2023)": 22,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Singh2021COM2SENSEAC,\n author = {Shikhar Singh and Nuan Wen and Yu Hou and Pegah Alipoormolabashi and Te-Lin Wu and Xuezhe Ma and Nanyun Peng},\n booktitle = {Findings},\n pages = {883-898},\n title = {COM2SENSE: A Commonsense Reasoning Benchmark with Complementary Sentences},\n year = {2021}\n}\n"
    }
}