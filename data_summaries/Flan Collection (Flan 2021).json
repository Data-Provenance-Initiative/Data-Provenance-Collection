{
    "fc-flan-aeslc": {
        "Unique Dataset Identifier": "fc-flan-aeslc",
        "Dataset Name": "aeslc",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/ryanzhumich/AESLC",
        "GitHub URL": "https://github.com/ryanzhumich/AESLC",
        "Hugging Face URL": "https://huggingface.co/datasets/aeslc",
        "Paper Title": "This Email Could Save Your Life: Introducing the Task of Email Subject Line Generation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/aeslc",
        "ArXiv URL": "https://arxiv.org/abs/1906.03497",
        "Semantic Scholar Corpus ID": 182953152,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Summarization",
            "Inverted Summarization"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 51924,
            "Mean Inputs Length": 1916.877,
            "Mean Targets Length": 132.8782,
            "Max Inputs Length": 41521,
            "Max Targets Length": 35926,
            "Min Inputs Length": 42,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "enron corporation"
        ],
        "Model Generated": [],
        "Creators": [
            "Yale University",
            "Grammarly"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "https://github.com/ryanzhumich/AESLC"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "aeslc:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "aeslc",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-08",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2396,
            "HF Likes (September 2023)": 4,
            "PwC Description": "To study the task of email subject line generation: automatically generating an email subject line from the email body.",
            "S2 Citation Count (September 2023)": 48,
            "GitHub Stars": 22,
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-ag_news_subset": {
        "Unique Dataset Identifier": "fc-flan-ag_news_subset",
        "Dataset Name": "ag_news_subset",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ag_news",
        "Paper Title": "Ranking a stream of news",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ag-news",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 12445509,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Topic Classification",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108707,
            "Mean Inputs Length": 724.7042,
            "Mean Targets Length": 13.4394,
            "Max Inputs Length": 2972,
            "Max Targets Length": 100,
            "Min Inputs Length": 45,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Univerisity of Pisa"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "ag_news_subset:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ag_news",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Non Commercial",
            "PwC License URL": "http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html",
            "PwC Date": "2015-01-01",
            "S2 Date": "2005-05-10",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 76013,
            "HF Likes (September 2023)": 66,
            "PwC Description": "AG News (AG’s News Corpus) is a subdataset of AG's corpus of news articles constructed by assembling titles and description fields of articles from the 4 largest classes (“World”, “Sports”, “Business”, “Sci/Tech”) of AG’s Corpus. The AG News contains 30,000 training and 1,900 test samples per class.",
            "S2 Citation Count (September 2023)": 191,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": []
    },
    "fc-flan-anli_r1": {
        "Unique Dataset Identifier": "fc-flan-anli_r1",
        "Dataset Name": "anli_r1",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/facebookresearch/anli",
        "GitHub URL": "https://github.com/facebookresearch/anli",
        "Hugging Face URL": "https://huggingface.co/datasets/anli",
        "Paper Title": "Adversarial NLI: A New Benchmark for Natural Language Understanding",
        "Papers with Code URL": "https://paperswithcode.com/dataset/anli",
        "ArXiv URL": "https://arxiv.org/abs/1910.14599",
        "Semantic Scholar Corpus ID": 207756753,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Natural Language Inference",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 61455,
            "Mean Inputs Length": 1170.3943,
            "Mean Targets Length": 59.8644,
            "Max Inputs Length": 3513,
            "Max Targets Length": 753,
            "Min Inputs Length": 36,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "commoncrawl.org",
            "wikihow.com",
            "crowdsourced",
            "project gutenberg"
        ],
        "Model Generated": [],
        "Creators": [
            "UNC Chapel Hill",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/anli/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "anli/r1:0.1.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "anli",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-NC 4.0",
            "PwC License URL": "https://github.com/facebookresearch/anli/blob/master/LICENSE",
            "PwC Date": "2019-01-01",
            "S2 Date": "2019-10-31",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 19294,
            "HF Likes (September 2023)": 24,
            "PwC Description": "The Adversarial Natural Language Inference (ANLI, Nie et al.) is a new large-scale NLI benchmark dataset, collected via an iterative, adversarial human-and-model-in-the-loop procedure. Particular, the data is selected to be difficult to the state-of-the-art models, including BERT and RoBERTa.",
            "S2 Citation Count (September 2023)": 601,
            "GitHub Stars": 364,
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "StoryCloze",
            "The Children’s Book Test dataset",
            "RTE5",
            "Manually Annotated Sub-Corpus (MASC) of the Open American National Corpus"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-anli_r2": {
        "Unique Dataset Identifier": "fc-flan-anli_r2",
        "Dataset Name": "anli_r2",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/facebookresearch/anli",
        "GitHub URL": "https://github.com/facebookresearch/anli",
        "Hugging Face URL": "https://huggingface.co/datasets/anli",
        "Paper Title": "Adversarial NLI: A New Benchmark for Natural Language Understanding",
        "Papers with Code URL": "https://paperswithcode.com/dataset/anli",
        "ArXiv URL": "https://arxiv.org/abs/1910.14599",
        "Semantic Scholar Corpus ID": 207756753,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Natural Language Inference",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108838,
            "Mean Inputs Length": 1157.3478,
            "Mean Targets Length": 59.562,
            "Max Inputs Length": 3496,
            "Max Targets Length": 790,
            "Min Inputs Length": 36,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "commoncrawl.org",
            "wikihow.com",
            "crowdsourced",
            "project gutenberg"
        ],
        "Model Generated": [],
        "Creators": [
            "UNC Chapel Hill",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/anli/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "anli/r2:0.1.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "anli",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-NC 4.0",
            "PwC License URL": "https://github.com/facebookresearch/anli/blob/master/LICENSE",
            "PwC Date": "2019-01-01",
            "S2 Date": "2019-10-31",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 19294,
            "HF Likes (September 2023)": 24,
            "PwC Description": "The Adversarial Natural Language Inference (ANLI, Nie et al.) is a new large-scale NLI benchmark dataset, collected via an iterative, adversarial human-and-model-in-the-loop procedure. Particular, the data is selected to be difficult to the state-of-the-art models, including BERT and RoBERTa.",
            "S2 Citation Count (September 2023)": 601,
            "GitHub Stars": 364,
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "StoryCloze",
            "The Children’s Book Test dataset",
            "RTE5",
            "Manually Annotated Sub-Corpus (MASC) of the Open American National Corpus"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-anli_r3": {
        "Unique Dataset Identifier": "fc-flan-anli_r3",
        "Dataset Name": "anli_r3",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/facebookresearch/anli",
        "GitHub URL": "https://github.com/facebookresearch/anli",
        "Hugging Face URL": "https://huggingface.co/datasets/anli",
        "Paper Title": "Adversarial NLI: A New Benchmark for Natural Language Understanding",
        "Papers with Code URL": "https://paperswithcode.com/dataset/anli",
        "ArXiv URL": "https://arxiv.org/abs/1910.14599",
        "Semantic Scholar Corpus ID": 207756753,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Natural Language Inference",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108830,
            "Mean Inputs Length": 1115.9112,
            "Mean Targets Length": 57.2937,
            "Max Inputs Length": 4128,
            "Max Targets Length": 961,
            "Min Inputs Length": 36,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "commoncrawl.org",
            "wikihow.com",
            "crowdsourced",
            "project gutenberg"
        ],
        "Model Generated": [],
        "Creators": [
            "UNC Chapel Hill",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/anli/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "anli/r3:0.1.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "anli",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-NC 4.0",
            "PwC License URL": "https://github.com/facebookresearch/anli/blob/master/LICENSE",
            "PwC Date": "2019-01-01",
            "S2 Date": "2019-10-31",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 19294,
            "HF Likes (September 2023)": 24,
            "PwC Description": "The Adversarial Natural Language Inference (ANLI, Nie et al.) is a new large-scale NLI benchmark dataset, collected via an iterative, adversarial human-and-model-in-the-loop procedure. Particular, the data is selected to be difficult to the state-of-the-art models, including BERT and RoBERTa.",
            "S2 Citation Count (September 2023)": 601,
            "GitHub Stars": 364,
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "StoryCloze",
            "The Children’s Book Test dataset",
            "RTE5",
            "Manually Annotated Sub-Corpus (MASC) of the Open American National Corpus"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-arc_challenge": {
        "Unique Dataset Identifier": "fc-flan-arc_challenge",
        "Dataset Name": "arc_challenge",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://ai2-public-datasets.s3.amazonaws.com/arc/ARC-V1-Feb2018.zip",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ai2_arc",
        "Paper Title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/arc",
        "ArXiv URL": "https://arxiv.org/abs/1803.05457",
        "Semantic Scholar Corpus ID": 3922816,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Closed-Book Question Answering",
            "Inverted Closed-Book QA"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3231,
            "Mean Inputs Length": 479.2185,
            "Mean Targets Length": 75.8954,
            "Max Inputs Length": 2177,
            "Max Targets Length": 683,
            "Min Inputs Length": 25,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "web exams",
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://creativecommons.org/licenses/by-sa/4.0/"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "ai2_arc/ARC-Challenge:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ai2_arc",
            "HF Config": "ARC-Challenge",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://allenai.org/data/arc",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-03-14",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 171232,
            "HF Likes (September 2023)": 21,
            "PwC Description": "The AI2’s Reasoning Challenge (ARC) dataset is a multiple-choice question-answering dataset, containing questions from science exams from grade 3 to grade 9. The dataset is split in two partitions: Easy and Challenge, where the latter partition contains the more difficult questions that require reasoning. Most of the questions have 4 answer choices, with <1% of all the questions having either 3 or 5 answer choices. ARC includes a supporting KB of 14.3M unstructured text passages.",
            "S2 Citation Count (September 2023)": 458,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "fc-flan-arc_easy": {
        "Unique Dataset Identifier": "fc-flan-arc_easy",
        "Dataset Name": "arc_easy",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://ai2-public-datasets.s3.amazonaws.com/arc/ARC-V1-Feb2018.zip",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ai2_arc",
        "Paper Title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/arc",
        "ArXiv URL": "https://arxiv.org/abs/1803.05457",
        "Semantic Scholar Corpus ID": 3922816,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Closed-Book Question Answering",
            "Inverted Closed-Book QA"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7473,
            "Mean Inputs Length": 423.5624,
            "Mean Targets Length": 64.976,
            "Max Inputs Length": 1903,
            "Max Targets Length": 586,
            "Min Inputs Length": 32,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "web exams",
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://creativecommons.org/licenses/by-sa/4.0/"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "ai2_arc/ARC-Easy:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ai2_arc",
            "HF Config": "ARC-Challenge",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://allenai.org/data/arc",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-03-14",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 171232,
            "HF Likes (September 2023)": 21,
            "PwC Description": "The AI2’s Reasoning Challenge (ARC) dataset is a multiple-choice question-answering dataset, containing questions from science exams from grade 3 to grade 9. The dataset is split in two partitions: Easy and Challenge, where the latter partition contains the more difficult questions that require reasoning. Most of the questions have 4 answer choices, with <1% of all the questions having either 3 or 5 answer choices. ARC includes a supporting KB of 14.3M unstructured text passages.",
            "S2 Citation Count (September 2023)": 458,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "fc-flan-bool_q": {
        "Unique Dataset Identifier": "fc-flan-bool_q",
        "Dataset Name": "bool_q",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/google-research-datasets/boolean-questions",
        "GitHub URL": "https://github.com/google-research-datasets/boolean-questions",
        "Hugging Face URL": "https://huggingface.co/datasets/boolq",
        "Paper Title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions",
        "Papers with Code URL": "https://paperswithcode.com/dataset/boolq",
        "ArXiv URL": "https://arxiv.org/abs/1905.10044",
        "Semantic Scholar Corpus ID": 165163607,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Multiple-Choice QA (no trivia knowledge required)",
            "Multiple Choice Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 33293,
            "Mean Inputs Length": 1618.7465,
            "Mean Targets Length": 2.7744,
            "Max Inputs Length": 7696,
            "Max Targets Length": 5,
            "Min Inputs Length": 86,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "google search"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 3.0",
                "License URL": "https://creativecommons.org/licenses/by-sa/3.0/"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "bool_q:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "boolq",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/3.0/",
            "PwC Date": "2019-01-01",
            "S2 Date": "2019-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 12122,
            "HF Likes (September 2023)": 22,
            "PwC Description": "BoolQ is a question answering dataset for yes/no questions containing 15942 examples. These questions are naturally occurring – they are generated in unprompted and unconstrained settings.\nEach example is a triplet of (question, passage, answer), with the title of the page as optional additional context.\n\nQuestions are gathered from anonymized, aggregated queries to the Google search engine. Queries that are likely to be yes/no questions are heuristically identified and questions are only kept if a Wikipedia page is returned as one of the first five results, in which case the question and Wikipedia page are given to a human annotator for further processing. Annotators label question/article pairs in a three-step process. First, they decide if the question is good, meaning it is comprehensible, unambiguous, and requesting factual information. This judgment is made before the annotator sees the Wikipedia page. Next, for good questions, annotators find a passage within the document that contains enough information to answer the question. Annotators can mark questions as “not answerable” if the Wikipedia article does not contain the requested information. Finally, annotators mark whether the question’s answer is “yes” or “no”. Only questions that were marked as having a yes/no answer are used, and each question is paired with the selected passage instead of the entire document.",
            "S2 Citation Count (September 2023)": 457,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-cb": {
        "Unique Dataset Identifier": "fc-flan-cb",
        "Dataset Name": "cb",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/mcdm/CommitmentBank",
        "GitHub URL": "https://github.com/mcdm/CommitmentBank",
        "Hugging Face URL": "https://huggingface.co/datasets/super_glue",
        "Paper Title": "The CommitmentBank: Investigating projection in naturally occurring discourse",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 203595067,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Natural Language Inference",
            "Natural Language Inference",
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 745,
            "Mean Inputs Length": 967.4389,
            "Mean Targets Length": 38.6201,
            "Max Inputs Length": 3749,
            "Max Targets Length": 773,
            "Min Inputs Length": 36,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "The Ohio State University",
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "unknown"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "super_glue/cb:1.0.2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "super_glue",
            "HF Config": "cb",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-25",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 199405,
            "HF Likes (September 2023)": 111,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 216,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": []
    },
    "fc-flan-cnn_dailymail": {
        "Unique Dataset Identifier": "fc-flan-cnn_dailymail",
        "Dataset Name": "cnn_dailymail",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/abisee/cnn-dailymail",
        "GitHub URL": "https://github.com/abisee/cnn-dailymail",
        "Hugging Face URL": "https://huggingface.co/datasets/cnn_dailymail",
        "Paper Title": "Get To The Point: Summarization with Pointer-Generator Networks",
        "Papers with Code URL": "https://paperswithcode.com/dataset/cnn-daily-mail-1",
        "ArXiv URL": "https://arxiv.org/abs/1704.04368",
        "Semantic Scholar Corpus ID": 8314118,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Summarization",
            "Inverted Summarization"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108213,
            "Mean Inputs Length": 4636.1305,
            "Mean Targets Length": 1278.7201,
            "Max Inputs Length": 11429,
            "Max Targets Length": 14588,
            "Min Inputs Length": 84,
            "Min Targets Length": 33,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "cnn.com",
            "dailymail.co.uk"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University",
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "MIT License",
                "License URL": "https://github.com/abisee/cnn-dailymail"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "cnn_dailymail:3.4.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "cnn_dailymail",
            "HF Config": "3.0.0",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "MIT License",
            "PwC License URL": "https://github.com/abisee/cnn-dailymail",
            "PwC Date": "2016-08-16",
            "S2 Date": "2017-04-01",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 69742,
            "HF Likes (September 2023)": 99,
            "PwC Description": "CNN/Daily Mail is a dataset for text summarization. Human generated abstractive summary bullets were generated from news stories in CNN and Daily Mail websites as questions (with one of the entities hidden), and stories as the corresponding passages from which the system is expected to answer the fill-in the-blank question. The authors released the scripts that crawl, extract and generate pairs of passages and questions from these websites.\n\nIn all, the corpus has 286,817 training pairs, 13,368 validation pairs and 11,487 test pairs, as defined by their scripts. The source documents in the training set have 766 words spanning 29.74 sentences on an average while the summaries consist of 53 words and 3.72 sentences.",
            "S2 Citation Count (September 2023)": 3215,
            "GitHub Stars": 601,
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "fc-flan-cola": {
        "Unique Dataset Identifier": "fc-flan-cola",
        "Dataset Name": "cola",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://nyu-mll.github.io/CoLA/",
        "GitHub URL": "https://nyu-mll.github.io/CoLA/",
        "Hugging Face URL": "https://huggingface.co/datasets/linxinyuan/cola",
        "Paper Title": "Neural Network Acceptability Judgments",
        "Papers with Code URL": "https://paperswithcode.com/dataset/cola",
        "ArXiv URL": "https://arxiv.org/abs/1805.12471",
        "Semantic Scholar Corpus ID": 44072099,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Grammatical Acceptability",
            "Grammatical Acceptability",
            "Text Quality Evaluation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30028,
            "Mean Inputs Length": 339.7683,
            "Mean Targets Length": 21.761,
            "Max Inputs Length": 1213,
            "Max Targets Length": 190,
            "Min Inputs Length": 59,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "syntax textbooks"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University",
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://nyu-mll.github.io/CoLA/"
            }
        ],
        "License Notes": "Fair use only",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "glue/cola:2.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "linxinyuan/cola",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Custom",
            "PwC License URL": "https://nyu-mll.github.io/CoLA/",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-05-31",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-06-08",
            "HF Downloads (September 2023)": 427,
            "HF Likes (September 2023)": 1,
            "PwC Description": "The Corpus of Linguistic Acceptability (CoLA) consists of 10657 sentences from 23 linguistics publications, expertly annotated for acceptability (grammaticality) by their original authors. The public version contains 9594 sentences belonging to training and development sets, and excludes 1063 sentences belonging to a held out test set.",
            "S2 Citation Count (September 2023)": 874,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-common_gen": {
        "Unique Dataset Identifier": "fc-flan-common_gen",
        "Dataset Name": "common_gen",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://gem-benchmark.com/data_cards/common_gen",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/common_gen",
        "Paper Title": "CommonGen: A Constrained Text Generation Challenge for Generative Commonsense Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/commongen",
        "ArXiv URL": "https://arxiv.org/abs/1911.03705",
        "Semantic Scholar Corpus ID": 218500588,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Structured Data to Text",
            "Inverted Structured Data to Text"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108647,
            "Mean Inputs Length": 303.826,
            "Mean Targets Length": 52.0416,
            "Max Inputs Length": 945,
            "Max Targets Length": 174,
            "Min Inputs Length": 59,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flickr",
            "crowdsourced",
            "undisclosed web",
            "amazon.com"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Southern California",
            "AI2",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "MIT License",
                "License URL": "https://gem-benchmark.com/data_cards/common_gen"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "gem/common_gen:1.1.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "common_gen",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "Custom",
            "PwC License URL": "https://inklab.usc.edu/CommonGen/",
            "PwC Date": "",
            "S2 Date": "2020-02-14",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 6767,
            "HF Likes (September 2023)": 13,
            "PwC Description": "CommonGen is constructed through a combination of crowdsourced and existing caption corpora, consists of 79k commonsense descriptions over 35k unique concept-sets.",
            "S2 Citation Count (September 2023)": 222,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "Flickr30k",
            "MSCOCO",
            "Conceptual Captions",
            "LSMDC video captions",
            "ActivityNet",
            "VATEX"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-copa": {
        "Unique Dataset Identifier": "fc-flan-copa",
        "Dataset Name": "copa",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://people.ict.usc.edu/~gordon/copa.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/gimmaru/super_glue-copa",
        "Paper Title": "",
        "Papers with Code URL": "https://paperswithcode.com/dataset/copa",
        "ArXiv URL": "https://arxiv.org/abs/1911.03705",
        "Semantic Scholar Corpus ID": 434646,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Next Sentence Prediction",
            "Next Sentence Prediction",
            "Cause Effect Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1302,
            "Mean Inputs Length": 328.4009,
            "Mean Targets Length": 27.2366,
            "Max Inputs Length": 1175,
            "Max Targets Length": 102,
            "Min Inputs Length": 17,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flickr",
            "crowdsourced",
            "undisclosed web",
            "amazon.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Indiana University",
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "BSD 2-Clause License",
                "License URL": "https://people.ict.usc.edu/~gordon/copa.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "super_glue/copa:1.0.2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "gimmaru/super_glue-copa",
            "HF Config": "gimmaru--super_glue-copa",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "BSD 2-Clause License",
            "PwC License URL": "https://people.ict.usc.edu/~gordon/copa.html",
            "PwC Date": "2011-01-01",
            "S2 Date": "2011-03-20",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2023-05-08",
            "HF Downloads (September 2023)": 21,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The Choice Of Plausible Alternatives (COPA) evaluation provides researchers with a tool for assessing progress in open-domain commonsense causal reasoning. COPA consists of 1000 questions, split equally into development and test sets of 500 questions each. Each question is composed of a premise and two alternatives, where the task is to select the alternative that more plausibly has a causal relation with the premise. The correct alternative is randomized so that the expected performance of randomly guessing is 50%.",
            "S2 Citation Count (September 2023)": 442,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "Flickr30k",
            "MSCOCO",
            "Conceptual Captions",
            "LSMDC video captions",
            "ActivityNet",
            "VATEX"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-coqa": {
        "Unique Dataset Identifier": "fc-flan-coqa",
        "Dataset Name": "coqa",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "CoQA",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/coqa",
        "Paper Title": " CoQA: A Conversational Question Answering Challenge ",
        "Papers with Code URL": "https://paperswithcode.com/dataset/coqa",
        "ArXiv URL": "https://arxiv.org/abs/1808.07042",
        "Semantic Scholar Corpus ID": 52055325,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Multiple-Choice QA (no trivia knowledge required)",
            "Multiple Choice Question Answering",
            "Wrong Candidate Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 25808,
            "Mean Inputs Length": 4352.7675,
            "Mean Targets Length": 307.1403,
            "Max Inputs Length": 8711,
            "Max Targets Length": 2159,
            "Min Inputs Length": 774,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mctest",
            "project gutenberg",
            "race exams",
            "cnn.com",
            "wikipedia.org",
            "reddit",
            "ai2 science questions"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://www.cs.cmu.edu/~glai1/data/race/#:~:text=notes"
            }
        ],
        "License Notes": "CoQA contains passages from several domains. Literature and Wikipedia passages are shared under CC BY-SA 4.0 license. Children's stories are collected from MCTest which comes with MSR-LA license. Middle/High school exam passages are collected from RACE which comes with its own license. News passages are collected from the DeepMind CNN dataset which comes with Apache license. Only RACE is non-commercial and research only.",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "coqa:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "coqa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Various",
            "PwC License URL": "https://stanfordnlp.github.io/coqa/#:~:text=License",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-08-21",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1383,
            "HF Likes (September 2023)": 21,
            "PwC Description": "CoQA is a large-scale dataset for building Conversational Question Answering systems. The goal of the CoQA challenge is to measure the ability of machines to understand a text passage and answer a series of interconnected questions that appear in a conversation.\n\nCoQA contains 127,000+ questions with answers collected from 8000+ conversations. Each conversation is collected by pairing two crowdworkers to chat about a passage in the form of questions and answers. The unique features of CoQA include 1) the questions are conversational; 2) the answers can be free-form text; 3) each answer also comes with an evidence subsequence highlighted in the passage; and 4) the passages are collected from seven diverse domains. CoQA has a lot of challenging phenomena not present in existing reading comprehension datasets, e.g., coreference and pragmatic reasoning.",
            "S2 Citation Count (September 2023)": 830,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-cosmos_qa": {
        "Unique Dataset Identifier": "fc-flan-cosmos_qa",
        "Dataset Name": "cosmos_qa",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://wilburone.github.io/cosmos/",
        "GitHub URL": "https://wilburone.github.io/cosmos/",
        "Hugging Face URL": "https://huggingface.co/datasets/cosmos_qa",
        "Paper Title": "Cosmos QA: Machine Reading Comprehension with Contextual Commonsense Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/cosmosqa",
        "ArXiv URL": "https://arxiv.org/abs/1909.00277",
        "Semantic Scholar Corpus ID": 202540590,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Multiple-Choice QA (no trivia knowledge required)",
            "Multiple Choice Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 90432,
            "Mean Inputs Length": 1340.1141,
            "Mean Targets Length": 50.7225,
            "Max Inputs Length": 4922,
            "Max Targets Length": 689,
            "Min Inputs Length": 155,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web",
            "icwsm.org/data"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Illinois Urbana-Champaign",
            "AI2",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://creativecommons.org/licenses/by/4.0/"
            }
        ],
        "License Notes": "https://huggingface.co/datasets/cosmos_qa",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "cosmos_qa:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "cosmos_qa",
            "HF Config": "default",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2019-01-01",
            "S2 Date": "2019-08-31",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 6765,
            "HF Likes (September 2023)": 6,
            "PwC Description": "CosmosQA is a large-scale dataset of 35.6K problems that require commonsense-based reading comprehension, formulated as multiple-choice questions. It focuses on reading between the lines over a diverse collection of people’s everyday narratives, asking questions concerning on the likely causes or effects of events that require reasoning beyond the exact text spans in the context.",
            "S2 Citation Count (September 2023)": 295,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-dart": {
        "Unique Dataset Identifier": "fc-flan-dart",
        "Dataset Name": "dart",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://gem-benchmark.com/data_cards/dart",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/dart",
        "Paper Title": "DART: Open-Domain Structured Data Record to Text Generation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/dart",
        "ArXiv URL": "https://arxiv.org/abs/2007.02871",
        "Semantic Scholar Corpus ID": 220364230,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Structured Data to Text",
            "Inverted Structured Data to Text",
            "Information Extraction"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108557,
            "Mean Inputs Length": 661.0621,
            "Mean Targets Length": 109.5974,
            "Max Inputs Length": 2840,
            "Max Targets Length": 800,
            "Min Inputs Length": 45,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "crowdsourced",
            "dbpedia"
        ],
        "Model Generated": [
            "wikisql"
        ],
        "Creators": [
            "Yale University",
            "Salesforce Research",
            "Penn State University",
            "The University of Hong Kong",
            "Massachusetts Institute of Technology"
        ],
        "Licenses": [
            {
                "License": "MIT License",
                "License URL": "https://gem-benchmark.com/data_cards/dart"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "gem/dart:1.1.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "dart",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-07-06",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2855,
            "HF Likes (September 2023)": 3,
            "PwC Description": "DART is a large dataset for open-domain structured data record to text generation. DART consists of 82,191 examples across different domains with each input being a semantic RDF triple set derived from data records in tables and the tree ontology of the schema, annotated with sentence descriptions that cover all facts in the triple set.",
            "S2 Citation Count (September 2023)": 119,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "WikiSQL",
            "WikiTableQuestions",
            "WebNLG 2017",
            "Cleaned E2E"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-definite_pronoun_resolution": {
        "Unique Dataset Identifier": "fc-flan-definite_pronoun_resolution",
        "Dataset Name": "definite_pronoun_resolution",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.hlt.utdallas.edu/~vince/data/emnlp12/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/definite_pronoun_resolution",
        "Paper Title": "Resolving Complex Cases of Definite Pronouns: The Winograd Schema Challenge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/definite-pronoun-resolution-dataset",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 15274877,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Coreference Resolution",
            "Inverted Coreference Resolution"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4043,
            "Mean Inputs Length": 397.3302,
            "Mean Targets Length": 8.4724,
            "Max Inputs Length": 1354,
            "Max Targets Length": 31,
            "Min Inputs Length": 49,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "The University of Texas at Austin"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "definite_pronoun_resolution:1.1.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "definite_pronoun_resolution",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-07-12",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 594,
            "HF Likes (September 2023)": 3,
            "PwC Description": "Composes sentence pairs (i.e., twin sentences).",
            "S2 Citation Count (September 2023)": 174,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": []
    },
    "fc-flan-drop": {
        "Unique Dataset Identifier": "fc-flan-drop",
        "Dataset Name": "drop",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.org/data/drop",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/drop",
        "Paper Title": "DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs",
        "Papers with Code URL": "https://paperswithcode.com/dataset/drop",
        "ArXiv URL": "https://arxiv.org/abs/1903.00161",
        "Semantic Scholar Corpus ID": 67855846,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Algebraic Expression Evaluation",
            "Inverted Mathematical QA",
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108783,
            "Mean Inputs Length": 3086.2389,
            "Mean Targets Length": 118.9147,
            "Max Inputs Length": 9793,
            "Max Targets Length": 9691,
            "Min Inputs Length": 69,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Irvine",
            "Peking University",
            "AI2",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://allenai.org/data/drop"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "drop:2.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "drop",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/4.0/legalcode",
            "PwC Date": "2019-01-01",
            "S2 Date": "2019-03-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2782,
            "HF Likes (September 2023)": 8,
            "PwC Description": "Discrete Reasoning Over Paragraphs DROP is a crowdsourced, adversarially-created, 96k-question benchmark, in which a system must resolve references in a question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or sorting). These operations require a much more comprehensive understanding of the content of paragraphs than what was necessary for prior datasets. The questions consist of passages extracted from Wikipedia articles. The dataset is split into a training set of about 77,000 questions, a development set of around 9,500 questions and a hidden test set similar in size to the development set.",
            "S2 Citation Count (September 2023)": 552,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-e2e_nlg": {
        "Unique Dataset Identifier": "fc-flan-e2e_nlg",
        "Dataset Name": "e2e_nlg",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://gem-benchmark.com/data_cards/e2e_nlg",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/e2e_nlg",
        "Paper Title": "The E2E Dataset: New Challenges For End-to-End Generation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/e2e",
        "ArXiv URL": "https://arxiv.org/abs/1706.09254",
        "Semantic Scholar Corpus ID": 19662556,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Structured Data to Text",
            "Inverted Structured Data to Text"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108900,
            "Mean Inputs Length": 612.3828,
            "Mean Targets Length": 111.5562,
            "Max Inputs Length": 2111,
            "Max Targets Length": 345,
            "Min Inputs Length": 65,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Heriot-Watt University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://gem-benchmark.com/data_cards/e2e_nlg"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "gem/e2e_nlg:1.1.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "e2e_nlg",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/4.0/",
            "PwC Date": "2017-06-28",
            "S2 Date": "2017-06-28",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 6741,
            "HF Likes (September 2023)": 5,
            "PwC Description": "End-to-End NLG Challenge (E2E) aims to assess whether recent end-to-end NLG systems can generate more complex output by learning from datasets containing higher lexical richness, syntactic complexity and diverse discourse phenomena.",
            "S2 Citation Count (September 2023)": 319,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "fc-flan-fix_punct": {
        "Unique Dataset Identifier": "fc-flan-fix_punct",
        "Dataset Name": "fix_punct",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.paracrawl.eu/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/para_crawl",
        "Paper Title": "ParaCrawl: Web-Scale Acquisition of Parallel Corpora",
        "Papers with Code URL": "https://paperswithcode.com/dataset/paracrawl",
        "ArXiv URL": "https://aclanthology.org/2020.acl-main.417/",
        "Semantic Scholar Corpus ID": 219165306,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Punctuation Fixing",
            "Inverted Punctuation Fixing"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 102101,
            "Mean Inputs Length": 599.4123,
            "Mean Targets Length": 123.5962,
            "Max Inputs Length": 4552,
            "Max Targets Length": 949,
            "Min Inputs Length": 29,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Edinburgh",
            "University of Alicante",
            "Johns Hopkins University",
            "Omniscien Technologies"
        ],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://creativecommons.org/share-your-work/public-domain/cc0/"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "fix_punct"
        ],
        "Inferred Metadata": {
            "HF Dataset": "para_crawl",
            "HF Config": "enbg",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC0 1.0",
            "PwC License URL": "https://creativecommons.org/share-your-work/public-domain/cc0/",
            "PwC Date": "2020-07-01",
            "S2 Date": "2020-07-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 8060,
            "HF Likes (September 2023)": 8,
            "PwC Description": "ParaCrawl v.7.1 is a parallel dataset with 41 language pairs primarily aligned with English (39 out of 41) and mined using the parallel-data-crawling tool Bitextor which includes downloading documents, preprocessing and normalization, aligning documents and segments, and filtering noisy data via Bicleaner. ParaCrawl focuses on European languages, but also includes 9 lower-resource, non-European language pairs in v7.1.",
            "S2 Citation Count (September 2023)": 141,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Translation",
                "Travel",
                "Punctuation",
                "Language and grammar",
                "Religion",
                "Transportation",
                "Business and marketing"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "fc-flan-gigaword": {
        "Unique Dataset Identifier": "fc-flan-gigaword",
        "Dataset Name": "gigaword",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/harvardnlp/sent-summary",
        "GitHub URL": "https://github.com/harvardnlp/sent-summary",
        "Hugging Face URL": "https://huggingface.co/datasets/gigaword",
        "Paper Title": "A Neural Attention Model for Abstractive Sentence Summarization ",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1509.00685",
        "Semantic Scholar Corpus ID": 1918428,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Summarization",
            "Inverted Summarization",
            "Text Matching"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108321,
            "Mean Inputs Length": 635.2803,
            "Mean Targets Length": 74.5999,
            "Max Inputs Length": 2287,
            "Max Targets Length": 443,
            "Min Inputs Length": 47,
            "Min Targets Length": 14,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "agence france-presse",
            "ap news",
            "central news agency of taiwan",
            "los angeles times",
            "washington post",
            "bloomberg news",
            "nytmes",
            "xinhua news agency"
        ],
        "Model Generated": [],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "MIT License",
                "License URL": "https://github.com/harvardnlp/sent-summary"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "gigaword:1.2.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "gigaword",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-09-02",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5083,
            "HF Likes (September 2023)": 17,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2443,
            "GitHub Stars": 296,
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "Gigaword"
        ],
        "Human Annotation": "No"
    },
    "fc-flan-glue_mrpc": {
        "Unique Dataset Identifier": "fc-flan-glue_mrpc",
        "Dataset Name": "glue_mrpc",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.microsoft.com/en-us/download/details.aspx?id=52398",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/glue",
        "Paper Title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
        "Papers with Code URL": "https://paperswithcode.com/dataset/glue",
        "ArXiv URL": "https://arxiv.org/abs/1804.07461",
        "Semantic Scholar Corpus ID": 5034059,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Coreference Resolution",
            "Paraphrase Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12676,
            "Mean Inputs Length": 789.8204,
            "Mean Targets Length": 2.9683,
            "Max Inputs Length": 2354,
            "Max Targets Length": 7,
            "Min Inputs Length": 134,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "videos",
            "glosses",
            "forum posts",
            "twitter",
            "student answers",
            "wikipedia.org",
            "image descriptions"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "DeepMind"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "glue/mrpc:2.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "glue",
            "HF Config": "mrpc",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Various",
            "PwC License URL": "https://gluebenchmark.com/faq",
            "PwC Date": "2019-01-01",
            "S2 Date": "2018-04-20",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1105572,
            "HF Likes (September 2023)": 223,
            "PwC Description": "General Language Understanding Evaluation (GLUE) benchmark is a collection of nine natural language understanding tasks, including single-sentence tasks CoLA and SST-2, similarity and paraphrasing tasks MRPC, STS-B and QQP, and natural language inference tasks MNLI, QNLI, RTE and WNLI.",
            "S2 Citation Count (September 2023)": 4367,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-glue_qqp": {
        "Unique Dataset Identifier": "fc-flan-glue_qqp",
        "Dataset Name": "glue_qqp",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/glue",
        "Paper Title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
        "Papers with Code URL": "https://paperswithcode.com/dataset/glue",
        "ArXiv URL": "https://arxiv.org/abs/1804.07461",
        "Semantic Scholar Corpus ID": 5034059,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Coreference Resolution",
            "Paraphrase Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108175,
            "Mean Inputs Length": 478.9584,
            "Mean Targets Length": 2.5494,
            "Max Inputs Length": 2686,
            "Max Targets Length": 5,
            "Min Inputs Length": 69,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "quora"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "DeepMind"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://www.quora.com/about/tos"
            }
        ],
        "License Notes": "Blog Post mentions non-commercial use",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "glue/qqp:2.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "glue",
            "HF Config": "qqp",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Various",
            "PwC License URL": "https://gluebenchmark.com/faq",
            "PwC Date": "2019-01-01",
            "S2 Date": "2018-04-20",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1105572,
            "HF Likes (September 2023)": 223,
            "PwC Description": "General Language Understanding Evaluation (GLUE) benchmark is a collection of nine natural language understanding tasks, including single-sentence tasks CoLA and SST-2, similarity and paraphrasing tasks MRPC, STS-B and QQP, and natural language inference tasks MNLI, QNLI, RTE and WNLI.",
            "S2 Citation Count (September 2023)": 4367,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-hellaswag": {
        "Unique Dataset Identifier": "fc-flan-hellaswag",
        "Dataset Name": "hellaswag",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://paperswithcode.com/dataset/hellaswag",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/hellaswag",
        "Paper Title": "HellaSwag: Can a Machine Really Finish Your Sentence?",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hellaswag",
        "ArXiv URL": "https://arxiv.org/abs/1905.07830",
        "Semantic Scholar Corpus ID": 159041722,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Next Sentence Prediction",
            "Next Sentence Prediction",
            "Fill in The Blank"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108752,
            "Mean Inputs Length": 1676.192,
            "Mean Targets Length": 109.2056,
            "Max Inputs Length": 8368,
            "Max Targets Length": 436,
            "Min Inputs Length": 50,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "activitynet",
            "wikihow.com",
            "model generated negative candidates using adversarial filtering"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "MIT License",
                "License URL": "https://github.com/rowanz/hellaswag/blob/master/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "hellaswag:1.1.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "hellaswag",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "MIT License",
            "PwC License URL": "https://github.com/rowanz/hellaswag/blob/master/LICENSE",
            "PwC Date": "",
            "S2 Date": "2019-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 193793,
            "HF Likes (September 2023)": 25,
            "PwC Description": "HellaSwag is a challenge dataset for evaluating commonsense NLI that is specially hard for state-of-the-art models, though its questions are trivial for humans (>95% accuracy).",
            "S2 Citation Count (September 2023)": 462,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-imdb_reviews": {
        "Unique Dataset Identifier": "fc-flan-imdb_reviews",
        "Dataset Name": "imdb_reviews",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "http://ai.stanford.edu/~amaas/data/sentiment/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/imdb",
        "Paper Title": "Learning Word Vectors for Sentiment Analysis",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imdb-movie-reviews",
        "ArXiv URL": "https://aclanthology.org/P11-1015/",
        "Semantic Scholar Corpus ID": 1428702,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Sentiment Analysis",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 89321,
            "Mean Inputs Length": 2855.137,
            "Mean Targets Length": 496.3132,
            "Max Inputs Length": 13696,
            "Max Targets Length": 13602,
            "Min Inputs Length": 30,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "imdb.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "imdb_reviews/plain_text:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "imdb",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2011-01-01",
            "S2 Date": "2011-06-19",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 229363,
            "HF Likes (September 2023)": 115,
            "PwC Description": "The IMDb Movie Reviews dataset is a binary sentiment analysis dataset consisting of 50,000 reviews from the Internet Movie Database (IMDb) labeled as positive or negative. The dataset contains an even number of positive and negative reviews. Only highly polarizing reviews are considered. A negative review has a score ≤ 4 out of 10, and a positive review has a score ≥ 7 out of 10. No more than 30 reviews are included per movie. The dataset contains additional unlabeled data.",
            "S2 Citation Count (September 2023)": 3941,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "fc-flan-lambada": {
        "Unique Dataset Identifier": "fc-flan-lambada",
        "Dataset Name": "lambada",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://zenodo.org/record/2630551#.Y9RFsOzMKDV",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/lambada",
        "Paper Title": "The LAMBADA dataset: Word prediction requiring a broad discourse context",
        "Papers with Code URL": "https://paperswithcode.com/dataset/lambada",
        "ArXiv URL": "https://arxiv.org/abs/1606.06031",
        "Semantic Scholar Corpus ID": 2381275,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Language Modeling",
            "Language Modeling"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 17536,
            "Mean Inputs Length": 970.4334,
            "Mean Targets Length": 6.1352,
            "Max Inputs Length": 2938,
            "Max Targets Length": 23,
            "Min Inputs Length": 225,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Trento",
            "University of Amsterdam"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://creativecommons.org/licenses/by/4.0/legalcode"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "lambada:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "lambada",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/4.0/legalcode",
            "PwC Date": "2016-01-01",
            "S2 Date": "2016-06-20",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 36590,
            "HF Likes (September 2023)": 28,
            "PwC Description": "The LAMBADA (LAnguage Modeling Broadened to Account for Discourse Aspects) benchmark is an open-ended cloze task which consists of about 10,000 passages from BooksCorpus where a missing target word is predicted in the last sentence of each passage. The missing word is constrained to always be the last word of the last sentence and there are no candidate words to choose from. Examples were filtered by humans to ensure they were possible to guess given the context, i.e., the sentences in the passage leading up to the last sentence. Examples were further filtered to ensure that missing words could not be guessed without the context, ensuring that models attempting the dataset would need to reason over the entire paragraph to answer questions.",
            "S2 Citation Count (September 2023)": 261,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "Book Corpus dataset"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-math_dataset": {
        "Unique Dataset Identifier": "fc-flan-math_dataset",
        "Dataset Name": "math_dataset",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/deepmind/mathematics_dataset",
        "GitHub URL": "https://github.com/deepmind/mathematics_dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/math_dataset",
        "Paper Title": "Analysing Mathematical Reasoning Abilities of Neural Models",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mathematics",
        "ArXiv URL": "https://arxiv.org/abs/1904.01557",
        "Semantic Scholar Corpus ID": 85504763,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Algebraic Expression Evaluation",
            "Inverted Mathematical QA"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108892,
            "Mean Inputs Length": 178.726,
            "Mean Targets Length": 1.9797,
            "Max Inputs Length": 546,
            "Max Targets Length": 4,
            "Min Inputs Length": 22,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "DeepMind"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://www.apache.org/licenses/LICENSE-2.0.txt"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "math_dataset/algebra__linear_1d:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "math_dataset",
            "HF Config": "algebra__linear_1d",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "https://github.com/deepmind/mathematics_dataset/blob/master/LICENSE",
            "PwC Date": "2019-04-02",
            "S2 Date": "2019-04-02",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 26973,
            "HF Likes (September 2023)": 34,
            "PwC Description": "This dataset code generates mathematical question and answer pairs, from a range of question types at roughly school-level difficulty. This is designed to test the mathematical learning and algebraic reasoning skills of learning models.",
            "S2 Citation Count (September 2023)": 256,
            "GitHub Stars": 1643,
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "fc-flan-mnli": {
        "Unique Dataset Identifier": "fc-flan-mnli",
        "Dataset Name": "mnli",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://cims.nyu.edu/~sbowman/multinli/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/SetFit/mnli",
        "Paper Title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
        "Papers with Code URL": "https://paperswithcode.com/dataset/multinli",
        "ArXiv URL": "https://arxiv.org/abs/1704.05426",
        "Semantic Scholar Corpus ID": 3432876,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Natural Language Inference",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 216560,
            "Mean Inputs Length": 699.9516,
            "Mean Targets Length": 9.3879,
            "Max Inputs Length": 3738,
            "Max Targets Length": 34,
            "Min Inputs Length": 41,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "anc.org"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://cims.nyu.edu/~sbowman/multinli/paper.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "glue/mnli:2.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "SetFit/mnli",
            "HF Config": "SetFit--mnli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Various",
            "PwC License URL": "https://cims.nyu.edu/~sbowman/multinli/paper.pdf",
            "PwC Date": "2018-01-01",
            "S2 Date": "2017-04-18",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-02-28",
            "HF Downloads (September 2023)": 1430,
            "HF Likes (September 2023)": 2,
            "PwC Description": "The Multi-Genre Natural Language Inference (MultiNLI) dataset has 433K sentence pairs. Its size and mode of collection are modeled closely like SNLI. MultiNLI offers ten distinct genres (Face-to-face, Telephone, 9/11, Travel, Letters, Oxford University Press, Slate, Verbatim, Goverment and Fiction) of written and spoken English data. There are matched dev/test sets which are derived from the same sources as those in the training set, and mismatched sets which do not closely resemble any seen at training time.",
            "S2 Citation Count (September 2023)": 3105,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-multi_news": {
        "Unique Dataset Identifier": "fc-flan-multi_news",
        "Dataset Name": "multi_news",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/Alex-Fabbri/Multi-News",
        "GitHub URL": "https://github.com/Alex-Fabbri/Multi-News",
        "Hugging Face URL": "https://huggingface.co/datasets/multi_news",
        "Paper Title": "Multi-News: a Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model.",
        "Papers with Code URL": "https://paperswithcode.com/dataset/multi-news",
        "ArXiv URL": "https://arxiv.org/abs/1906.01749",
        "Semantic Scholar Corpus ID": 174799390,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Summarization",
            "Inverted Summarization"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 58937,
            "Mean Inputs Length": 8951.6456,
            "Mean Targets Length": 3381.8263,
            "Max Inputs Length": 1049066,
            "Max Targets Length": 280744,
            "Min Inputs Length": 158,
            "Min Targets Length": 190,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "news"
        ],
        "Model Generated": [],
        "Creators": [
            "Yale University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://github.com/Alex-Fabbri/Multi-News/blob/master/LICENSE.txt"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "multi_news:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "multi_news",
            "HF Config": "default",
            "HF Config License": "Academic Research Purposes Only",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Custom",
            "PwC License URL": "https://github.com/Alex-Fabbri/Multi-News",
            "PwC Date": "2019-01-01",
            "S2 Date": "2019-06-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 6214,
            "HF Likes (September 2023)": 24,
            "PwC Description": "Multi-News, consists of news articles and human-written summaries of these articles from the site newser.com. Each summary is professionally written by editors and includes links to the original articles cited.",
            "S2 Citation Count (September 2023)": 330,
            "GitHub Stars": 248,
            "GitHub Topics": [
                "multi-document-summarization",
                "multi-news",
                "summarization"
            ],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-multirc": {
        "Unique Dataset Identifier": "fc-flan-multirc",
        "Dataset Name": "multirc",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/CogComp/multirc",
        "GitHub URL": "https://github.com/CogComp/multirc",
        "Hugging Face URL": "https://huggingface.co/datasets/stjokerli/TextToText_multirc_seqio",
        "Paper Title": "Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences",
        "Papers with Code URL": "https://paperswithcode.com/dataset/multirc",
        "ArXiv URL": "https://aclanthology.org/N18-1023/",
        "Semantic Scholar Corpus ID": 5112038,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Multiple-Choice QA (no trivia knowledge required)",
            "Multiple Choice Question Answering",
            "Answer Verification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 97857,
            "Mean Inputs Length": 3965.1976,
            "Mean Targets Length": 17.9376,
            "Max Inputs Length": 9047,
            "Max Targets Length": 280,
            "Min Inputs Length": 550,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "cnn.com",
            "wikipedia.org",
            "wsj",
            "nytmes",
            "articles on society",
            "law and justice",
            "articles on history and anthropology",
            "9/11 reports",
            "project gutenberg",
            "mctest",
            "cmu movie plots",
            "ck12.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Pennsylvania",
            "UC Santa Cruz",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://github.com/CogComp/multirc/blob/master/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "super_glue/multirc:1.0.2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "stjokerli/TextToText_multirc_seqio",
            "HF Config": "stjokerli--TextToText_multirc_seqio",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Academic Research Purposes Only",
            "PwC License URL": "",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-06-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-03-13",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "MultiRC (Multi-Sentence Reading Comprehension) is a dataset of short paragraphs and multi-sentence questions, i.e., questions that can be answered by combining information from multiple sentences of the paragraph.\nThe dataset was designed with three key challenges in mind:\n* The number of correct answer-options for each question is not pre-specified. This removes the over-reliance on answer-options and forces them to decide on the correctness of each candidate answer independently of others. In other words, the task is not to simply identify the best answer-option, but to evaluate the correctness of each answer-option individually.\n* The correct answer(s) is not required to be a span in the text.\n* The paragraphs in the dataset have diverse provenance by being extracted from 7 different domains such as news, fiction, historical text etc., and hence are expected to be more diverse in their contents as compared to single-domain datasets.\nThe entire corpus consists of around 10K questions (including about 6K multiple-sentence questions). The 60% of the data is released as training and development data. The rest of the data is saved for evaluation and every few months a new unseen additional data is included for evaluation to prevent unintentional overfitting over time.",
            "S2 Citation Count (September 2023)": 358,
            "GitHub Stars": 30,
            "GitHub Topics": [
                "natural-language-processing",
                "question-answering",
                "reasoning"
            ],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-natural_questions": {
        "Unique Dataset Identifier": "fc-flan-natural_questions",
        "Dataset Name": "natural_questions",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/google-research-datasets/natural-questions/tree/master/nq_open",
        "GitHub URL": "https://github.com/google-research-datasets/natural-questions/tree/master/nq_open",
        "Hugging Face URL": "https://huggingface.co/datasets/natural_questions",
        "Paper Title": "Natural Questions: A Benchmark for Question Answering Research",
        "Papers with Code URL": "https://paperswithcode.com/dataset/natural-questions",
        "ArXiv URL": "https://aclanthology.org/Q19-1026/?utm_campaign=NLP%20News&utm_medium=email&utm_source=Revue%20newsletter",
        "Semantic Scholar Corpus ID": 86611921,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Closed-Book Question Answering",
            "Inverted Closed-Book QA",
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108494,
            "Mean Inputs Length": 208.3739,
            "Mean Targets Length": 12.82,
            "Max Inputs Length": 675,
            "Max Targets Length": 63,
            "Min Inputs Length": 30,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 3.0",
                "License URL": "https://github.com/google-research-datasets/natural-questions/tree/master/nq_open"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "natural_questions_open:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "natural_questions",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/3.0/",
            "PwC Date": "2019-01-01",
            "S2 Date": "2019-08-01",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1225,
            "HF Likes (September 2023)": 18,
            "PwC Description": "The Natural Questions corpus is a question answering dataset containing 307,373 training examples, 7,830 development examples, and 7,842 test examples. Each example is comprised of a google.com query and a corresponding Wikipedia page. Each Wikipedia page has a passage (or long answer) annotated on the page that answers the question and one or more short spans from the annotated passage containing the actual answer. The long and the short answer annotations can however be empty. If they are both empty, then there is no answer on the page at all. If the long answer annotation is non-empty, but the short answer annotation is empty, then the annotated passage answers the question but no explicit short answer could be found. Finally 1% of the documents have a passage annotated with a short answer that is “yes” or “no”, instead of a list of short spans.",
            "S2 Citation Count (September 2023)": 1523,
            "GitHub Stars": 821,
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-newsroom": {
        "Unique Dataset Identifier": "fc-flan-newsroom",
        "Dataset Name": "newsroom",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://lil.nlp.cornell.edu/newsroom/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/newsroom",
        "Paper Title": "Newsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies",
        "Papers with Code URL": "https://paperswithcode.com/dataset/newsroom",
        "ArXiv URL": "https://arxiv.org/abs/1804.11283",
        "Semantic Scholar Corpus ID": 13752552,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Summarization",
            "Inverted Summarization"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108907,
            "Mean Inputs Length": 4951.5759,
            "Mean Targets Length": 338.7905,
            "Max Inputs Length": 196852,
            "Max Targets Length": 117793,
            "Min Inputs Length": 35,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "Cornell University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "newsroom:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "newsroom",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Non Commercial",
            "PwC License URL": "https://cornell.qualtrics.com/jfe/form/SV_6YA3HQ2p75XH4IR",
            "PwC Date": "2018-04-30",
            "S2 Date": "2018-04-30",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 810,
            "HF Likes (September 2023)": 6,
            "PwC Description": "CORNELL NEWSROOM is a large dataset for training and evaluating summarization systems. It contains 1.3 million articles and summaries written by authors and editors in the newsrooms of 38 major publications. The summaries are obtained from search and social metadata between 1998 and 2017 and use a variety of summarization strategies combining extraction and abstraction.",
            "S2 Citation Count (September 2023)": 409,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "fc-flan-openbookqa": {
        "Unique Dataset Identifier": "fc-flan-openbookqa",
        "Dataset Name": "openbookqa",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.org/data/open-book-qa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/openbookqa",
        "Paper Title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering",
        "Papers with Code URL": "https://paperswithcode.com/dataset/openbookqa",
        "ArXiv URL": "https://arxiv.org/abs/1809.02789",
        "Semantic Scholar Corpus ID": 52183757,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Multiple-Choice QA (no trivia knowledge required)",
            "Multiple Choice Question Answering",
            "Sentence Composition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 18108,
            "Mean Inputs Length": 383.7989,
            "Mean Targets Length": 33.6263,
            "Max Inputs Length": 1642,
            "Max Targets Length": 150,
            "Min Inputs Length": 22,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "web exams"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "Research Training Group AIPHES & Heidelberg University"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/allenai/OpenBookQA/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "openbookqa:0.1.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "openbookqa",
            "HF Config": "main",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Custom",
            "PwC License URL": "https://github.com/allenai/OpenBookQA",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-08-13",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 33711,
            "HF Likes (September 2023)": 23,
            "PwC Description": "OpenBookQA is a new kind of question-answering dataset modeled after open book exams for assessing human understanding of a subject. It consists of 5,957 multiple-choice elementary-level science questions (4,957 train, 500 dev, 500 test), which probe the understanding of a small “book” of 1,326 core science facts and the application of these facts to novel situations. For training, the dataset includes a mapping from each question to the core science fact it was designed to probe. Answering OpenBookQA questions requires additional broad common knowledge, not contained in the book. The questions, by design, are answered incorrectly by both a retrieval-based algorithm and a word co-occurrence algorithm.\nAdditionally, the dataset includes a collection of 5,167 crowd-sourced common knowledge facts, and an expanded version of the train/dev/test questions where each question is associated with its originating core fact, a human accuracy score, a clarity score, and an anonymized crowd-worker ID.",
            "S2 Citation Count (September 2023)": 467,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "WorldTree dataset"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-opinion_abstracts_idebate": {
        "Unique Dataset Identifier": "fc-flan-opinion_abstracts_idebate",
        "Dataset Name": "opinion_abstracts_idebate",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://web.eecs.umich.edu/~wangluxy/data.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ccdv/govreport-summarization",
        "Paper Title": "Efficient Attentions for Long Document Summarization",
        "Papers with Code URL": "https://paperswithcode.com/dataset/govreport",
        "ArXiv URL": "https://arxiv.org/abs/2104.02112",
        "Semantic Scholar Corpus ID": 233033613,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Summarization",
            "Inverted Summarization"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5914,
            "Mean Inputs Length": 2232.2335,
            "Mean Targets Length": 238.1613,
            "Max Inputs Length": 8695,
            "Max Targets Length": 2546,
            "Min Inputs Length": 65,
            "Min Targets Length": 19,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "u.s. government reports"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Michigan",
            "University of Illinois"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "opinion_abstracts_idebate"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ccdv/govreport-summarization",
            "HF Config": "document",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2021-04-05",
            "S2 Date": "2021-04-05",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2021-11-28",
            "HF Downloads (September 2023)": 1241,
            "HF Likes (September 2023)": 9,
            "PwC Description": "GovReport is a dataset for long document summarization, with significantly longer documents and summaries. It consists of reports written by government research agencies including Congressional Research Service and U.S. Government Accountability Office.\n\nCompared with other long document summarization datasets, government report dataset has longer summaries and documents and requires reading in more context to cover salient words to be summarized.",
            "S2 Citation Count (September 2023)": 99,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Politics",
                "Religion",
                "Education",
                "International relations and diplomacy",
                "Economics",
                "Freedom of speech and expression",
                "International relations",
                "Ethics and morality",
                "Sports",
                "Education policy"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-opinion_abstracts_rotten_tomatoes": {
        "Unique Dataset Identifier": "fc-flan-opinion_abstracts_rotten_tomatoes",
        "Dataset Name": "opinion_abstracts_rotten_tomatoes",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://web.eecs.umich.edu/~wangluxy/data.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ccdv/govreport-summarization",
        "Paper Title": "Efficient Attentions for Long Document Summarization",
        "Papers with Code URL": "https://paperswithcode.com/dataset/govreport",
        "ArXiv URL": "https://arxiv.org/abs/2104.02112",
        "Semantic Scholar Corpus ID": 233033613,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Summarization",
            "Inverted Summarization"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11415,
            "Mean Inputs Length": 2893.4605,
            "Mean Targets Length": 367.9555,
            "Max Inputs Length": 7948,
            "Max Targets Length": 1978,
            "Min Inputs Length": 45,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "u.s. government reports"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Michigan",
            "University of Illinois"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "opinion_abstracts_rotten_tomatoes"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ccdv/govreport-summarization",
            "HF Config": "document",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2021-04-05",
            "S2 Date": "2021-04-05",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2021-11-28",
            "HF Downloads (September 2023)": 1241,
            "HF Likes (September 2023)": 9,
            "PwC Description": "GovReport is a dataset for long document summarization, with significantly longer documents and summaries. It consists of reports written by government research agencies including Congressional Research Service and U.S. Government Accountability Office.\n\nCompared with other long document summarization datasets, government report dataset has longer summaries and documents and requires reading in more context to cover salient words to be summarized.",
            "S2 Citation Count (September 2023)": 99,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Comedy",
                "Film criticism",
                "Film analysis",
                "Acting performance",
                "Acting and performance",
                "Movie reviews",
                "Action movies",
                "Film critique",
                "Film analysis and critique"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-para_crawl_enes": {
        "Unique Dataset Identifier": "fc-flan-para_crawl_enes",
        "Dataset Name": "para_crawl_enes",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.paracrawl.eu/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/yawnick/para_crawl_enen",
        "Paper Title": "ParaCrawl: Web-Scale Acquisition of Parallel Corpora",
        "Papers with Code URL": "https://paperswithcode.com/dataset/paracrawl",
        "ArXiv URL": "https://aclanthology.org/2020.acl-main.417/",
        "Semantic Scholar Corpus ID": 219165306,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Translation",
            "Inverted Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108176,
            "Mean Inputs Length": 607.8348,
            "Mean Targets Length": 136.6116,
            "Max Inputs Length": 4112,
            "Max Targets Length": 1020,
            "Min Inputs Length": 28,
            "Min Targets Length": 13,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Edinburgh",
            "University of Alicante",
            "Johns Hopkins University",
            "Omniscien Technologies"
        ],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://paracrawl.eu/index.php"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "para_crawl_enes"
        ],
        "Inferred Metadata": {
            "HF Dataset": "yawnick/para_crawl_enen",
            "HF Config": "yawnick--para_crawl_enen",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC0 1.0",
            "PwC License URL": "https://creativecommons.org/share-your-work/public-domain/cc0/",
            "PwC Date": "2020-07-01",
            "S2 Date": "2020-07-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2023-04-28",
            "HF Downloads (September 2023)": 20,
            "HF Likes (September 2023)": 0,
            "PwC Description": "ParaCrawl v.7.1 is a parallel dataset with 41 language pairs primarily aligned with English (39 out of 41) and mined using the parallel-data-crawling tool Bitextor which includes downloading documents, preprocessing and normalization, aligning documents and segments, and filtering noisy data via Bicleaner. ParaCrawl focuses on European languages, but also includes 9 lower-resource, non-European language pairs in v7.1.",
            "S2 Citation Count (September 2023)": 141,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Religion",
                "Cultural differences",
                "Translation",
                "Philosophy",
                "Travel",
                "Education",
                "History",
                "Technology"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "fc-flan-paws_wiki": {
        "Unique Dataset Identifier": "fc-flan-paws_wiki",
        "Dataset Name": "paws_wiki",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/google-research-datasets/paws",
        "GitHub URL": "https://github.com/google-research-datasets/paws",
        "Hugging Face URL": "https://huggingface.co/datasets/paws",
        "Paper Title": "PAWS: Paraphrase Adversaries from Word Scrambling",
        "Papers with Code URL": "https://paperswithcode.com/dataset/paws",
        "ArXiv URL": "https://arxiv.org/abs/1904.01130",
        "Semantic Scholar Corpus ID": 91184042,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Coreference Resolution",
            "Paraphrase Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 109019,
            "Mean Inputs Length": 751.2153,
            "Mean Targets Length": 2.7706,
            "Max Inputs Length": 2317,
            "Max Targets Length": 5,
            "Min Inputs Length": 73,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "quora",
            "wikipedia.org"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://github.com/google-research-datasets/paws"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "paws_wiki:1.1.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "paws",
            "HF Config": "labeled_final",
            "HF Config License": "All Uses-Attribution",
            "HF Yaml License": "",
            "PwC License Name": "Custom",
            "PwC License URL": "https://github.com/google-research-datasets/paws",
            "PwC Date": "2019-04-01",
            "S2 Date": "2019-04-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 9253,
            "HF Likes (September 2023)": 16,
            "PwC Description": "Paraphrase Adversaries from Word Scrambling (PAWS) is a dataset contains 108,463 human-labeled and 656k noisily labeled pairs that feature the importance of modeling structure, context, and word order information for the problem of paraphrase identification. The dataset has two subsets, one based on Wikipedia and the other one based on the Quora Question Pairs (QQP) dataset.",
            "S2 Citation Count (September 2023)": 367,
            "GitHub Stars": 498,
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-piqa": {
        "Unique Dataset Identifier": "fc-flan-piqa",
        "Dataset Name": "piqa",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://yonatanbisk.com/piqa/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/piqa",
        "Paper Title": "PIQA: Reasoning about Physical Commonsense in Natural Language",
        "Papers with Code URL": "https://paperswithcode.com/dataset/piqa",
        "ArXiv URL": "https://arxiv.org/abs/1911.11641",
        "Semantic Scholar Corpus ID": 208290939,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Multiple-Choice QA (no trivia knowledge required)",
            "Multiple Choice Question Answering",
            "Wrong Candidate Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 57751,
            "Mean Inputs Length": 659.7451,
            "Mean Targets Length": 71.7193,
            "Max Inputs Length": 7645,
            "Max Targets Length": 2183,
            "Min Inputs Length": 23,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "instructables.com",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "Microsoft Research",
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Academic Free License v3.0",
                "License URL": "https://opensource.org/licenses/AFL-3.0"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "piqa:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "piqa",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2019-11-26",
            "S2 Date": "2019-11-26",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 186395,
            "HF Likes (September 2023)": 41,
            "PwC Description": "PIQA is a dataset for commonsense reasoning, and was created to investigate the physical knowledge of existing models in NLP.",
            "S2 Citation Count (September 2023)": 384,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-qnli": {
        "Unique Dataset Identifier": "fc-flan-qnli",
        "Dataset Name": "qnli",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://rajpurkar.github.io/SQuAD-explorer/",
        "GitHub URL": "https://rajpurkar.github.io/SQuAD-explorer/",
        "Hugging Face URL": "https://huggingface.co/datasets/SetFit/qnli",
        "Paper Title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
        "Papers with Code URL": "https://paperswithcode.com/dataset/qnli",
        "ArXiv URL": "https://arxiv.org/abs/1804.07461",
        "Semantic Scholar Corpus ID": 5034059,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Multiple-Choice QA (no trivia knowledge required)",
            "Multiple Choice Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108853,
            "Mean Inputs Length": 693.3264,
            "Mean Targets Length": 10.0916,
            "Max Inputs Length": 4383,
            "Max Targets Length": 256,
            "Min Inputs Length": 50,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "videos",
            "glosses",
            "forum posts",
            "twitter",
            "student answers",
            "wikipedia.org",
            "image descriptions"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University",
            "University of Washington",
            "DeepMind"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://creativecommons.org/licenses/by-sa/4.0/legalcode"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "glue/qnli:2.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "SetFit/qnli",
            "HF Config": "SetFit--qnli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "",
            "PwC Date": "2019-01-01",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-02-28",
            "HF Downloads (September 2023)": 612,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The QNLI (Question-answering NLI) dataset is a Natural Language Inference dataset automatically derived from the Stanford Question Answering Dataset v1.1 (SQuAD). SQuAD v1.1 consists of question-paragraph pairs, where one of the sentences in the paragraph (drawn from Wikipedia) contains the answer to the corresponding question (written by an annotator). The dataset was converted into sentence pair classification by forming a pair between each question and each sentence in the corresponding context, and filtering out pairs with low lexical overlap between the question and the context sentence. The task is to determine whether the context sentence contains the answer to the question. This modified version of the original task removes the requirement that the model select the exact answer, but also removes the simplifying assumptions that the answer is always present in the input and that lexical overlap is a reliable cue. The QNLI dataset is part of GLEU benchmark.",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-quac": {
        "Unique Dataset Identifier": "fc-flan-quac",
        "Dataset Name": "quac",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://quac.ai/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/quac",
        "Paper Title": "QuAC: Question Answering in Context",
        "Papers with Code URL": "https://paperswithcode.com/dataset/quac",
        "ArXiv URL": "https://arxiv.org/abs/1808.07036",
        "Semantic Scholar Corpus ID": 52057510,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Multiple-Choice QA (no trivia knowledge required)",
            "Multiple Choice Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108711,
            "Mean Inputs Length": 4641.699,
            "Mean Targets Length": 68.0846,
            "Max Inputs Length": 10700,
            "Max Targets Length": 238,
            "Min Inputs Length": 1487,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "University of Washington",
            "Stanford University",
            "UMass Amherst"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://quac.ai/"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "quac:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "quac",
            "HF Config": "plain_text",
            "HF Config License": "MIT License",
            "HF Yaml License": "MIT License",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "http://creativecommons.org/licenses/by-sa/4.0/legalcode",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-08-21",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1313,
            "HF Likes (September 2023)": 11,
            "PwC Description": "Question Answering in Context is a large-scale dataset that consists of around 14K crowdsourced Question Answering dialogs with 98K question-answer pairs in total. Data instances consist of an interactive dialog between two crowd workers: (1) a student who poses a sequence of freeform questions to learn as much as possible about a hidden Wikipedia text, and (2) a teacher who answers the questions by providing short excerpts (spans) from the text.",
            "S2 Citation Count (September 2023)": 596,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-record": {
        "Unique Dataset Identifier": "fc-flan-record",
        "Dataset Name": "record",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://sheng-z.github.io/ReCoRD-explorer/",
        "GitHub URL": "https://sheng-z.github.io/ReCoRD-explorer/",
        "Hugging Face URL": "https://huggingface.co/datasets/super_glue",
        "Paper Title": "ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension",
        "Papers with Code URL": "https://paperswithcode.com/dataset/record",
        "ArXiv URL": "https://arxiv.org/abs/1810.12885",
        "Semantic Scholar Corpus ID": 53116244,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Span Selection Question Answering",
            "Inverted Extractive QA",
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108413,
            "Mean Inputs Length": 2967.3341,
            "Mean Targets Length": 75.6686,
            "Max Inputs Length": 10209,
            "Max Targets Length": 561,
            "Min Inputs Length": 543,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "cnn.com",
            "dailymail.co.uk"
        ],
        "Model Generated": [],
        "Creators": [
            "Johns Hopkins University",
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://sheng-z.github.io/ReCoRD-explorer/"
            }
        ],
        "License Notes": "Dataset 1 under Apache 2.0. Dataset 2 under Internet Archive ToS. IA ToS includes this requirement: \"Access to the Archive’s Collections is provided at no cost to you and is granted for scholarship and research purposes only.\"",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "super_glue/record:1.0.2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "super_glue",
            "HF Config": "record",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Custom",
            "PwC License URL": "https://sheng-z.github.io/ReCoRD-explorer/",
            "PwC Date": "2018-10-30",
            "S2 Date": "2018-10-30",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 199405,
            "HF Likes (September 2023)": 111,
            "PwC Description": "Reading Comprehension with Commonsense Reasoning Dataset (ReCoRD) is a large-scale reading comprehension dataset which requires commonsense reasoning. ReCoRD consists of queries automatically generated from CNN/Daily Mail news articles; the answer to each query is a text span from a summarizing passage of the corresponding news. The goal of ReCoRD is to evaluate a machine's ability of commonsense reasoning in reading comprehension. ReCoRD is pronounced as [ˈrɛkərd].",
            "S2 Citation Count (September 2023)": 227,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-rte": {
        "Unique Dataset Identifier": "fc-flan-rte",
        "Dataset Name": "rte",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://aclweb.org/aclwiki/Recognizing_Textual_Entailment",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/SetFit/rte",
        "Paper Title": "",
        "Papers with Code URL": "https://paperswithcode.com/dataset/rte",
        "ArXiv URL": "https://arxiv.org/abs/1804.07461",
        "Semantic Scholar Corpus ID": 5034059,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Natural Language Inference",
            "Natural Language Inference",
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8280,
            "Mean Inputs Length": 970.3819,
            "Mean Targets Length": 21.2481,
            "Max Inputs Length": 4540,
            "Max Targets Length": 1010,
            "Min Inputs Length": 36,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "videos",
            "glosses",
            "forum posts",
            "twitter",
            "student answers",
            "wikipedia.org",
            "image descriptions"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University",
            "University of Washington",
            "DeepMind"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://tac.nist.gov/data/forms/index.html"
            }
        ],
        "License Notes": "Non-commercial, research only",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "super_glue/rte:1.0.2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "SetFit/rte",
            "HF Config": "SetFit--rte",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-04-20",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-02-28",
            "HF Downloads (September 2023)": 737,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The Recognizing Textual Entailment (RTE) datasets come from a series of textual entailment challenges. Data from RTE1, RTE2, RTE3 and RTE5 is combined. Examples are constructed based on news and Wikipedia text.",
            "S2 Citation Count (September 2023)": 4367,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-samsum": {
        "Unique Dataset Identifier": "fc-flan-samsum",
        "Dataset Name": "samsum",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/pdf/1911.12237v2.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/samsum",
        "Paper Title": "SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization",
        "Papers with Code URL": "https://paperswithcode.com/dataset/samsum-corpus",
        "ArXiv URL": "https://arxiv.org/abs/1911.12237",
        "Semantic Scholar Corpus ID": 208010268,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Summarization",
            "Inverted Summarization",
            "Coherence Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 53537,
            "Mean Inputs Length": 1471.7292,
            "Mean Targets Length": 212.6876,
            "Max Inputs Length": 9487,
            "Max Targets Length": 3575,
            "Min Inputs Length": 38,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "original"
        ],
        "Model Generated": [],
        "Creators": [
            "Samsung R&D Institute"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-ND 4.0",
                "License URL": "https://arxiv.org/src/1911.12237v2/anc/corpus.7z"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "samsum:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "CC BY-NC-ND 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-11-27",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 75087,
            "HF Likes (September 2023)": 126,
            "PwC Description": "A new dataset with abstractive dialogue summaries.",
            "S2 Citation Count (September 2023)": 289,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-sentiment140": {
        "Unique Dataset Identifier": "fc-flan-sentiment140",
        "Dataset Name": "sentiment140",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "http://help.sentiment140.com/home",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sentiment140",
        "Paper Title": "Twitter Sentiment Classification using Distant Supervision",
        "Papers with Code URL": "https://paperswithcode.com/dataset/sentiment140",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 18635269,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Sentiment Analysis",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108401,
            "Mean Inputs Length": 307.2439,
            "Mean Targets Length": 48.6667,
            "Max Inputs Length": 1090,
            "Max Targets Length": 214,
            "Min Inputs Length": 23,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "http://help.sentiment140.com/for-students"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "sentiment140:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sentiment140",
            "HF Config": "sentiment140",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 819,
            "HF Likes (September 2023)": 8,
            "PwC Description": "Sentiment140 is a dataset that allows you to discover the sentiment of a brand, product, or topic on Twitter.",
            "S2 Citation Count (September 2023)": 961,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": []
    },
    "fc-flan-snli": {
        "Unique Dataset Identifier": "fc-flan-snli",
        "Dataset Name": "snli",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://nlp.stanford.edu/projects/snli/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/snli",
        "Paper Title": "A large annotated corpus for learning natural language inference",
        "Papers with Code URL": "https://paperswithcode.com/dataset/snli",
        "ArXiv URL": "https://arxiv.org/abs/1508.05326",
        "Semantic Scholar Corpus ID": 14604520,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Natural Language Inference",
            "Natural Language Inference",
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108351,
            "Mean Inputs Length": 463.1776,
            "Mean Targets Length": 12.5886,
            "Max Inputs Length": 1809,
            "Max Targets Length": 177,
            "Min Inputs Length": 23,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flickr",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://creativecommons.org/licenses/by-sa/4.0/"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "snli:1.1.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "snli",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/4.0/",
            "PwC Date": "2015-01-01",
            "S2 Date": "2015-08-21",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 9891,
            "HF Likes (September 2023)": 29,
            "PwC Description": "The SNLI dataset (Stanford Natural Language Inference) consists of 570k sentence-pairs manually labeled as entailment, contradiction, and neutral. Premises are image captions from Flickr30k, while hypotheses were generated by crowd-sourced annotators who were shown a premise and asked to generate entailing, contradicting, and neutral sentences. Annotators were instructed to judge the relation between sentences given that they describe the same event. Each pair is labeled as “entailment”, “neutral”, “contradiction” or “-”, where “-” indicates that an agreement could not be reached.",
            "S2 Citation Count (September 2023)": 3334,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "SNLI"
        ],
        "Human Annotation": "No"
    },
    "fc-flan-squad_v1": {
        "Unique Dataset Identifier": "fc-flan-squad_v1",
        "Dataset Name": "squad_v1",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://rajpurkar.github.io/SQuAD-explorer/",
        "GitHub URL": "https://rajpurkar.github.io/SQuAD-explorer/",
        "Hugging Face URL": "https://huggingface.co/datasets/squad",
        "Paper Title": "Know What You Don't Know: Unanswerable Questions for SQuAD",
        "Papers with Code URL": "https://paperswithcode.com/dataset/squad",
        "ArXiv URL": "https://arxiv.org/abs/1806.03822",
        "Semantic Scholar Corpus ID": 47018994,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Span Selection Question Answering",
            "Inverted Extractive QA"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108010,
            "Mean Inputs Length": 2129.679,
            "Mean Targets Length": 23.4694,
            "Max Inputs Length": 31644,
            "Max Targets Length": 193,
            "Min Inputs Length": 25,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced (daemo)"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://creativecommons.org/licenses/by-sa/4.0/legalcode"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "squad/v1.1:3.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "squad",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/4.0/",
            "PwC Date": "2016-01-01",
            "S2 Date": "2018-06-11",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 153870,
            "HF Likes (September 2023)": 128,
            "PwC Description": "The Stanford Question Answering Dataset (SQuAD) is a collection of question-answer pairs derived from Wikipedia articles. In SQuAD, the correct answers of questions can be any sequence of tokens in the given text. Because the questions and answers are produced by humans through crowdsourcing, it is more diverse than some other question-answering datasets. SQuAD 1.1 contains 107,785 question-answer pairs on 536 articles. SQuAD2.0 (open-domain SQuAD, SQuAD-Open), the latest version, combines the 100,000 questions in SQuAD1.1 with over 50,000 un-answerable questions written adversarially by crowdworkers in forms that are similar to the answerable ones.",
            "S2 Citation Count (September 2023)": 1967,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-squad_v2": {
        "Unique Dataset Identifier": "fc-flan-squad_v2",
        "Dataset Name": "squad_v2",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://rajpurkar.github.io/SQuAD-explorer/",
        "GitHub URL": "https://rajpurkar.github.io/SQuAD-explorer/",
        "Hugging Face URL": "https://huggingface.co/datasets/squad_v2",
        "Paper Title": "Know What You Don't Know: Unanswerable Questions for SQuAD",
        "Papers with Code URL": "https://paperswithcode.com/dataset/squad",
        "ArXiv URL": "https://arxiv.org/abs/1806.03822",
        "Semantic Scholar Corpus ID": 47018994,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Span Selection Question Answering",
            "Inverted Extractive QA"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108495,
            "Mean Inputs Length": 2309.7636,
            "Mean Targets Length": 17.4244,
            "Max Inputs Length": 29947,
            "Max Targets Length": 160,
            "Min Inputs Length": 242,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced (daemo)"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://creativecommons.org/licenses/by-sa/4.0/legalcode"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "squad/v2.0:3.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "squad_v2",
            "HF Config": "squad_v2",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/4.0/",
            "PwC Date": "2016-01-01",
            "S2 Date": "2018-06-11",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 8690810,
            "HF Likes (September 2023)": 65,
            "PwC Description": "The Stanford Question Answering Dataset (SQuAD) is a collection of question-answer pairs derived from Wikipedia articles. In SQuAD, the correct answers of questions can be any sequence of tokens in the given text. Because the questions and answers are produced by humans through crowdsourcing, it is more diverse than some other question-answering datasets. SQuAD 1.1 contains 107,785 question-answer pairs on 536 articles. SQuAD2.0 (open-domain SQuAD, SQuAD-Open), the latest version, combines the 100,000 questions in SQuAD1.1 with over 50,000 un-answerable questions written adversarially by crowdworkers in forms that are similar to the answerable ones.",
            "S2 Citation Count (September 2023)": 1967,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-sst2": {
        "Unique Dataset Identifier": "fc-flan-sst2",
        "Dataset Name": "sst2",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://nlp.stanford.edu/sentiment/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sst2",
        "Paper Title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
        "Papers with Code URL": "https://paperswithcode.com/dataset/sst-2",
        "ArXiv URL": "https://aclanthology.org/D13-1170/",
        "Semantic Scholar Corpus ID": 990233,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Sentiment Analysis",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108023,
            "Mean Inputs Length": 320.0962,
            "Mean Targets Length": 24.4253,
            "Max Inputs Length": 1223,
            "Max Targets Length": 267,
            "Min Inputs Length": 30,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "rottentomatoes.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://creativecommons.org/publicdomain/zero/1.0/"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "glue/sst2:2.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sst2",
            "HF Config": "default",
            "HF Config License": "Unspecified",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2013-10-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-06-13",
            "HF Downloads (September 2023)": 63152,
            "HF Likes (September 2023)": 24,
            "PwC Description": "Click to add a brief description of the dataset (Markdown and LaTeX enabled).\n\nProvide:\n\n\na high-level explanation of the dataset characteristics\nexplain motivations and summary of its content\npotential use cases of the dataset",
            "S2 Citation Count (September 2023)": 6668,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "Movie Review Dataset (Pang & Lee 2005)"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-story_cloze": {
        "Unique Dataset Identifier": "fc-flan-story_cloze",
        "Dataset Name": "story_cloze",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.cs.rochester.edu/nlp/rocstories/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/story_cloze",
        "Paper Title": "A Corpus and Evaluation Framework for Deeper Understanding of Commonsense Stories",
        "Papers with Code URL": "https://paperswithcode.com/dataset/storycloze",
        "ArXiv URL": "https://arxiv.org/abs/1604.01696",
        "Semantic Scholar Corpus ID": 15337246,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Next Sentence Prediction",
            "Next Sentence Prediction"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5973,
            "Mean Inputs Length": 744.6392,
            "Mean Targets Length": 97.257,
            "Max Inputs Length": 2547,
            "Max Targets Length": 331,
            "Min Inputs Length": 58,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Rochester",
            "United States Naval Academy",
            "Microsoft Research",
            "Virginia Tech",
            "The Institute for Human & Machine Cognition"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://www.cs.rochester.edu/nlp/rocstories/"
            }
        ],
        "License Notes": "Says its free and open to use",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "story_cloze/2016:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "story_cloze",
            "HF Config": "2016",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2016-04-06",
            "S2 Date": "2016-04-06",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3206,
            "HF Likes (September 2023)": 5,
            "PwC Description": "Representation and learning of commonsense knowledge is one of the foundational problems in the quest to enable deep language understanding. This issue is particularly challenging for understanding casual and correlational relationships between events. While this topic has received a lot of interest in the NLP community, research has been hindered by the lack of a proper evaluation framework. This paper attempts to address this problem with a new framework for evaluating story understanding and script learning: the 'Story Cloze Test'. This test requires a system to choose the correct ending to a four-sentence story. We created a new corpus of ~50k five-sentence commonsense stories, ROCStories, to enable this evaluation. This corpus is unique in two ways: (1) it captures a rich set of causal and temporal commonsense relations between daily events, and (2) it is a high quality collection of everyday life stories that can also be used for story generation. Experimental evaluation shows that a host of baselines and state-of-the-art models based on shallow language understanding struggle to achieve a high score on the Story Cloze Test. We discuss these implications for script and story learning, and offer suggestions for deeper language understanding.",
            "S2 Citation Count (September 2023)": 158,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-stsb": {
        "Unique Dataset Identifier": "fc-flan-stsb",
        "Dataset Name": "stsb",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "http://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/SetFit/stsb",
        "Paper Title": "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Cross-lingual Focused Evaluation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/snli",
        "ArXiv URL": "https://arxiv.org/abs/1708.00055",
        "Semantic Scholar Corpus ID": 4421747,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Sentiment Analysis",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 20456,
            "Mean Inputs Length": 578.0957,
            "Mean Targets Length": 15.5148,
            "Max Inputs Length": 2215,
            "Max Targets Length": 315,
            "Min Inputs Length": 123,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flickr"
        ],
        "Model Generated": [
            "Google Translate"
        ],
        "Creators": [
            "Google Research",
            "George Washington University",
            "University of the Basque Country",
            "University of Sheffield"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "unknown"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "glue/stsb:2.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "SetFit/stsb",
            "HF Config": "SetFit--stsb",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/4.0/",
            "PwC Date": "2015-01-01",
            "S2 Date": "2017-07-31",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-02-28",
            "HF Downloads (September 2023)": 702,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The SNLI dataset (Stanford Natural Language Inference) consists of 570k sentence-pairs manually labeled as entailment, contradiction, and neutral. Premises are image captions from Flickr30k, while hypotheses were generated by crowd-sourced annotators who were shown a premise and asked to generate entailing, contradicting, and neutral sentences. Annotators were instructed to judge the relation between sentences given that they describe the same event. Each pair is labeled as “entailment”, “neutral”, “contradiction” or “-”, where “-” indicates that an agreement could not be reached.",
            "S2 Citation Count (September 2023)": 1346,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "SNLI"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-trec": {
        "Unique Dataset Identifier": "fc-flan-trec",
        "Dataset Name": "trec",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://cogcomp.seas.upenn.edu/Data/QA/QC/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/trec",
        "Paper Title": "Learning Question Classifiers",
        "Papers with Code URL": "https://paperswithcode.com/dataset/trec-10",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 11039301,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Topic Classification",
            "Text Classification",
            "Question Understanding"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 19000,
            "Mean Inputs Length": 435.1429,
            "Mean Targets Length": 12.2991,
            "Max Inputs Length": 1507,
            "Max Targets Length": 160,
            "Min Inputs Length": 25,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "University of Illinois"
        ],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://www.kaggle.com/datasets/thedevastator/the-trec-question-classification-dataset-a-longi"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "trec:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "trec",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2002-08-01",
            "S2 Date": "2002-08-24",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 16100,
            "HF Likes (September 2023)": 31,
            "PwC Description": "A question type classification dataset with 6 classes for questions about a person, location, numeric information, etc. The test split has 500 questions, and the training split has 5452 questions.\n\nPaper: Learning Question Classifiers",
            "S2 Citation Count (September 2023)": 1359,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": []
    },
    "fc-flan-trivia_qa": {
        "Unique Dataset Identifier": "fc-flan-trivia_qa",
        "Dataset Name": "trivia_qa",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/mandarjoshi90/triviaqa",
        "GitHub URL": "https://github.com/mandarjoshi90/triviaqa",
        "Hugging Face URL": "https://huggingface.co/datasets/trivia_qa",
        "Paper Title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
        "Papers with Code URL": "https://paperswithcode.com/dataset/triviaqa",
        "ArXiv URL": "https://arxiv.org/abs/1705.03551",
        "Semantic Scholar Corpus ID": 26501419,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Span Selection Question Answering",
            "Inverted Extractive QA"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 109120,
            "Mean Inputs Length": 291.6294,
            "Mean Targets Length": 9.9382,
            "Max Inputs Length": 1931,
            "Max Targets Length": 134,
            "Min Inputs Length": 22,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/mandarjoshi90/triviaqa/blob/master/LICENSE"
            }
        ],
        "License Notes": "No commercial use. Scraped from multiple trivia/quizz websites.",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "trivia_qa/rc:1.1.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "trivia_qa",
            "HF Config": "rc",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Unspecified",
            "PwC License URL": "http://nlp.cs.washington.edu/triviaqa/#:~:text=copyright",
            "PwC Date": "2017-01-01",
            "S2 Date": "2017-05-01",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 93735,
            "HF Likes (September 2023)": 23,
            "PwC Description": "TriviaQA is a realistic text-based question answering dataset which includes 950K question-answer pairs from 662K documents collected from Wikipedia and the web. This dataset is more challenging than standard QA benchmark datasets such as Stanford Question Answering Dataset (SQuAD), as the answers for a question may not be directly obtained by span prediction and the context is very long. TriviaQA dataset consists of both human-verified and machine-generated QA subsets.",
            "S2 Citation Count (September 2023)": 1045,
            "GitHub Stars": 220,
            "GitHub Topics": [
                "acl2017",
                "machine-reading",
                "nlp",
                "question-answering",
                "reading-comprehension",
                "triviaqa"
            ],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-true_case": {
        "Unique Dataset Identifier": "fc-flan-true_case",
        "Dataset Name": "true_case",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.paracrawl.eu/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Casing Selection",
            "Inverted Casing Selection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 106135,
            "Mean Inputs Length": 607.2719,
            "Mean Targets Length": 121.3865,
            "Max Inputs Length": 3654,
            "Max Targets Length": 976,
            "Min Inputs Length": 38,
            "Min Targets Length": 15,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://creativecommons.org/share-your-work/public-domain/cc0/"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "true_case"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Religion",
                "Technology",
                "General knowledge",
                "Travel",
                "Transportation",
                "Mathematics",
                "Translation",
                "Geography"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": []
    },
    "fc-flan-unified_qa_science_inst": {
        "Unique Dataset Identifier": "fc-flan-unified_qa_science_inst",
        "Dataset Name": "unified_qa_science_inst",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "http://data.allenai.org/ai2-science-questions",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Inverted Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2135,
            "Mean Inputs Length": 635.3902,
            "Mean Targets Length": 25.4445,
            "Max Inputs Length": 4076,
            "Max Targets Length": 153,
            "Min Inputs Length": 25,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "unified_qa_science_inst"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Chemistry",
                "Earth Science",
                "Physics",
                "Astronomy",
                "Geology",
                "Environmental science",
                "Science",
                "Ecology",
                "Paleontology"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": []
    },
    "fc-flan-web_nlg_en": {
        "Unique Dataset Identifier": "fc-flan-web_nlg_en",
        "Dataset Name": "web_nlg_en",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://gem-benchmark.com/data_cards/web_nlg",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/web_nlg",
        "Paper Title": "Creating Training Corpora for NLG Micro-Planners",
        "Papers with Code URL": "https://paperswithcode.com/dataset/webnlg",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 6702871,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Structured Data to Text",
            "Inverted Structured Data to Text"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108072,
            "Mean Inputs Length": 688.2444,
            "Mean Targets Length": 123.6053,
            "Max Inputs Length": 3115,
            "Max Targets Length": 649,
            "Min Inputs Length": 54,
            "Min Targets Length": 17,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "University of Edinburgh"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://gem-benchmark.com/data_cards/web_nlg"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "gem/web_nlg_en:1.1.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "web_nlg",
            "HF Config": "webnlg_challenge_2017",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-NC-SA 4.0",
            "PwC License URL": "https://gitlab.com/shimorina/webnlg-dataset",
            "PwC Date": "2017-01-01",
            "S2 Date": "2017-08-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 4897,
            "HF Likes (September 2023)": 10,
            "PwC Description": "The WebNLG corpus comprises of sets of triplets describing facts (entities and relations between them) and the corresponding facts in form of natural language text. The corpus contains sets with up to 7 triplets each along with one or more reference texts for each set. The test set is split into two parts: seen, containing inputs created for entities and relations belonging to DBpedia categories that were seen in the training data, and unseen, containing inputs extracted for entities and relations belonging to 5 unseen categories.\n\nInitially, the dataset was used for the WebNLG natural language generation challenge which consists of mapping the sets of triplets to text, including referring expression generation, aggregation, lexicalization, surface realization, and sentence segmentation.\nThe corpus is also used for a reverse task of triplets extraction.\n\nVersioning history of the dataset can be found here.",
            "S2 Citation Count (September 2023)": 285,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": []
    },
    "fc-flan-wic": {
        "Unique Dataset Identifier": "fc-flan-wic",
        "Dataset Name": "wic",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://pilehvar.github.io/wic/",
        "GitHub URL": "https://pilehvar.github.io/wic/",
        "Hugging Face URL": "",
        "Paper Title": "WiC: the Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wic",
        "ArXiv URL": "https://arxiv.org/abs/1808.09121",
        "Semantic Scholar Corpus ID": 102353817,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Coreference Resolution",
            "Word Sense Disambiguation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 18856,
            "Mean Inputs Length": 521.3943,
            "Mean Targets Length": 14.5406,
            "Max Inputs Length": 1728,
            "Max Targets Length": 18,
            "Min Inputs Length": 74,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wordnet",
            "verbnet",
            "wiktionary.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Cambridge",
            "Tehran Institute for Advanced Studies",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://pilehvar.github.io/wic/"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "super_glue/wic:1.0.2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-NC 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-nc/4.0/legalcode",
            "PwC Date": "",
            "S2 Date": "2018-08-28",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "WiC is a benchmark for the evaluation of context-sensitive word embeddings. WiC is framed as a binary classification task. Each instance in WiC has a target word w, either a verb or a noun, for which two contexts are provided. Each of these contexts triggers a specific meaning of w. The task is to identify if the occurrences of w in the two contexts correspond to the same meaning or not. In fact, the dataset can also be viewed as an application of Word Sense Disambiguation in practise.",
            "S2 Citation Count (September 2023)": 285,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-wiki_lingua_english_en": {
        "Unique Dataset Identifier": "fc-flan-wiki_lingua_english_en",
        "Dataset Name": "wiki_lingua_english_en",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://gem-benchmark.com/data_cards/wiki_lingua",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/wiki_lingua",
        "Paper Title": "WikiLingua: A New Benchmark Dataset for Cross-Lingual Abstractive Summarization",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wikilingua",
        "ArXiv URL": "https://arxiv.org/abs/2010.03093",
        "Semantic Scholar Corpus ID": 222177239,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Summarization",
            "Inverted Summarization"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108903,
            "Mean Inputs Length": 3993.6574,
            "Mean Targets Length": 529.9124,
            "Max Inputs Length": 15706,
            "Max Targets Length": 16395,
            "Min Inputs Length": 8,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikihow.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Columbia University",
            "Cornell University"
        ],
        "Licenses": [
            {
                "License": "CC BY 3.0",
                "License URL": "https://creativecommons.org/licenses/by/3.0/"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "gem/wiki_lingua_english_en:1.1.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wiki_lingua",
            "HF Config": "arabic",
            "HF Config License": "CC BY-NC-SA 3.0",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-07",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5621,
            "HF Likes (September 2023)": 20,
            "PwC Description": "WikiLingua includes ~770k article and summary pairs in 18 languages from WikiHow. Gold-standard article-summary alignments across languages are extracted by aligning the images that are used to describe each how-to step in an article.",
            "S2 Citation Count (September 2023)": 125,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "fc-flan-winogrande": {
        "Unique Dataset Identifier": "fc-flan-winogrande",
        "Dataset Name": "winogrande",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/allenai/winogrande",
        "GitHub URL": "https://github.com/allenai/winogrande",
        "Hugging Face URL": "https://huggingface.co/datasets/winogrande/",
        "Paper Title": "WinoGrande: An Adversarial Winograd Schema Challenge at Scale",
        "Papers with Code URL": "https://paperswithcode.com/dataset/winogrande",
        "ArXiv URL": "https://arxiv.org/abs/1907.10641",
        "Semantic Scholar Corpus ID": 198893658,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Coreference Resolution",
            "Inverted Coreference Resolution"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108678,
            "Mean Inputs Length": 452.0497,
            "Mean Targets Length": 26.3727,
            "Max Inputs Length": 1664,
            "Max Targets Length": 154,
            "Min Inputs Length": 26,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://github.com/allenai/winogrande"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "winogrande:1.1.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "winogrande",
            "HF Config": "winogrande_xs",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://github.com/allenai/winogrande",
            "PwC Date": "",
            "S2 Date": "2019-07-24",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": 97059,
            "HF Likes (September 2023)": 21,
            "PwC Description": "WinoGrande is a large-scale dataset of 44k problems, inspired by the original WSC design, but adjusted to improve both the scale and the hardness of the dataset. The key steps of the dataset construction consist of (1) a carefully designed crowdsourcing procedure, followed by (2) systematic bias reduction using a novel AfLite algorithm that generalizes human-detectable word associations to machine-detectable embedding associations.",
            "S2 Citation Count (September 2023)": 495,
            "GitHub Stars": 67,
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes"
    },
    "fc-flan-wmt14_enfr": {
        "Unique Dataset Identifier": "fc-flan-wmt14_enfr",
        "Dataset Name": "wmt14_enfr",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.statmt.org/wmt14/translation-task.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/wmt14",
        "Paper Title": "Findings of the 2014 Workshop on Statistical Machine Translation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wmt-2014",
        "ArXiv URL": "https://aclanthology.org/W14-3302/",
        "Semantic Scholar Corpus ID": 15535376,
        "Languages": [
            "English",
            "French"
        ],
        "Task Categories": [
            "Translation",
            "Inverted Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 109197,
            "Mean Inputs Length": 754.8683,
            "Mean Targets Length": 162.3348,
            "Max Inputs Length": 7426,
            "Max Targets Length": 4858,
            "Min Inputs Length": 23,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "commoncrawl.org",
            "wikipedia.org",
            "united nations",
            "commoncrawl.org",
            "yandex",
            "news commentary",
            "european parliament proceedings"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "Charles University",
            "Christian Buck University of Edinburgh",
            "Microsoft Research",
            "Dublin City University",
            "University of Amsterdam",
            "Johns Hopkins University",
            "Google",
            "University of Sheffield"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "wmt14_translate/fr-en:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wmt14",
            "HF Config": "cs-en",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2014-01-01",
            "S2 Date": "2014-06-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 47479,
            "HF Likes (September 2023)": 4,
            "PwC Description": "WMT 2014 is a collection of datasets used in shared tasks of the Ninth Workshop on Statistical Machine Translation. The workshop featured four tasks:\n\n\na news translation task,\na quality estimation task,\na metrics task,\na medical text translation task.",
            "S2 Citation Count (September 2023)": 580,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "Europarl Parallel Corpus",
            "News Commentary Parallel Corpus",
            "Common Crawl Parallel Corpus",
            "United Nations Parallel Corpus",
            "10^9 Word Parallel Corpus",
            "CzEng Parallel Corpus",
            "Hindi-English Parallel Corpus",
            "Yandex 1M Parallel Corpus",
            "Wiki Headlines Parallel Corpus",
            "Europarl Language Model Data",
            "News Language Model data"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-wmt16_translate_csen": {
        "Unique Dataset Identifier": "fc-flan-wmt16_translate_csen",
        "Dataset Name": "wmt16_translate_csen",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.statmt.org/wmt16/translation-task.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/wmt16",
        "Paper Title": "Findings of the 2016 Conference on Machine Translation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wmt-2016",
        "ArXiv URL": "https://aclanthology.org/W16-2301/",
        "Semantic Scholar Corpus ID": 14421595,
        "Languages": [
            "English",
            "Czech"
        ],
        "Task Categories": [
            "Translation",
            "Inverted Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108185,
            "Mean Inputs Length": 326.262,
            "Mean Targets Length": 55.5622,
            "Max Inputs Length": 7553,
            "Max Targets Length": 7519,
            "Min Inputs Length": 23,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "united nations",
            "commoncrawl.org",
            "yandex",
            "wikipedia headlines",
            "czeng v1.6pre",
            "opus news-commentary",
            "opensubtitles.org",
            "european parliament proceedings"
        ],
        "Model Generated": [],
        "Creators": [
            "Charles University",
            "Microsoft Research",
            "Dublin City University",
            "University of Edinburgh",
            "IBM",
            "Johns Hopkins University",
            "University of Sheffield",
            "University of Amsterdam",
            "Hasso Plattner Institute - Potsdam",
            "Charles University",
            "Johns Hopkins University",
            "Saarland University",
            "University of Melbourne"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "wmt16_translate/cs-en:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wmt16",
            "HF Config": "cs-en",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2016-01-01",
            "S2 Date": "2016-08-12",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 35204,
            "HF Likes (September 2023)": 12,
            "PwC Description": "WMT 2016 is a collection of datasets used in shared tasks of the First Conference on Machine Translation. The conference builds on ten previous Workshops on statistical Machine Translation.\n\nThe conference featured ten shared tasks:\n\n\na news translation task,\nan IT domain translation task,\na biomedical translation task,\nan automatic post-editing task,\na metrics task (assess MT quality given reference translation).\na quality estimation task (assess MT quality without access to any reference),\na tuning task (optimize a given MT system),\na pronoun translation task,\na bilingual document alignment task,\na multimodal translation task.",
            "S2 Citation Count (September 2023)": 627,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "Europarl",
            "Europarl3"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-wmt16_translate_deen": {
        "Unique Dataset Identifier": "fc-flan-wmt16_translate_deen",
        "Dataset Name": "wmt16_translate_deen",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.statmt.org/wmt16/translation-task.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/wmt16",
        "Paper Title": "Findings of the 2016 Conference on Machine Translation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wmt-2016",
        "ArXiv URL": "https://aclanthology.org/W16-2301/",
        "Semantic Scholar Corpus ID": 14421595,
        "Languages": [
            "English",
            "German"
        ],
        "Task Categories": [
            "Translation",
            "Inverted Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108628,
            "Mean Inputs Length": 655.2876,
            "Mean Targets Length": 134.6521,
            "Max Inputs Length": 5213,
            "Max Targets Length": 2365,
            "Min Inputs Length": 22,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "united nations",
            "commoncrawl.org",
            "yandex",
            "wikipedia headlines",
            "czeng v1.6pre",
            "opus news-commentary",
            "opensubtitles.org",
            "european parliament proceedings"
        ],
        "Model Generated": [],
        "Creators": [
            "Charles University",
            "Microsoft Research",
            "Dublin City University",
            "University of Edinburgh",
            "IBM",
            "Johns Hopkins University",
            "University of Sheffield",
            "University of Amsterdam",
            "Hasso Plattner Institute - Potsdam",
            "Charles University",
            "Johns Hopkins University",
            "Saarland University",
            "University of Melbourne"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "wmt16_translate/de-en:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wmt16",
            "HF Config": "cs-en",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2016-01-01",
            "S2 Date": "2016-08-12",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 35204,
            "HF Likes (September 2023)": 12,
            "PwC Description": "WMT 2016 is a collection of datasets used in shared tasks of the First Conference on Machine Translation. The conference builds on ten previous Workshops on statistical Machine Translation.\n\nThe conference featured ten shared tasks:\n\n\na news translation task,\nan IT domain translation task,\na biomedical translation task,\nan automatic post-editing task,\na metrics task (assess MT quality given reference translation).\na quality estimation task (assess MT quality without access to any reference),\na tuning task (optimize a given MT system),\na pronoun translation task,\na bilingual document alignment task,\na multimodal translation task.",
            "S2 Citation Count (September 2023)": 627,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "Europarl",
            "Europarl3"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-wmt16_translate_fien": {
        "Unique Dataset Identifier": "fc-flan-wmt16_translate_fien",
        "Dataset Name": "wmt16_translate_fien",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.statmt.org/wmt16/translation-task.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/wmt16",
        "Paper Title": "Findings of the 2016 Conference on Machine Translation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wmt-2016",
        "ArXiv URL": "https://aclanthology.org/W16-2301/",
        "Semantic Scholar Corpus ID": 14421595,
        "Languages": [
            "English",
            "Finnish"
        ],
        "Task Categories": [
            "Translation",
            "Inverted Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108923,
            "Mean Inputs Length": 628.5495,
            "Mean Targets Length": 127.6058,
            "Max Inputs Length": 4623,
            "Max Targets Length": 1125,
            "Min Inputs Length": 23,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "united nations",
            "commoncrawl.org",
            "yandex",
            "wikipedia headlines",
            "czeng v1.6pre",
            "opus news-commentary",
            "opensubtitles.org",
            "european parliament proceedings"
        ],
        "Model Generated": [],
        "Creators": [
            "Charles University",
            "Microsoft Research",
            "Dublin City University",
            "University of Edinburgh",
            "IBM",
            "Johns Hopkins University",
            "University of Sheffield",
            "University of Amsterdam",
            "Hasso Plattner Institute - Potsdam",
            "Saarland University",
            "University of Melbourne"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "wmt16_translate/fi-en:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wmt16",
            "HF Config": "cs-en",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2016-01-01",
            "S2 Date": "2016-08-12",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 35204,
            "HF Likes (September 2023)": 12,
            "PwC Description": "WMT 2016 is a collection of datasets used in shared tasks of the First Conference on Machine Translation. The conference builds on ten previous Workshops on statistical Machine Translation.\n\nThe conference featured ten shared tasks:\n\n\na news translation task,\nan IT domain translation task,\na biomedical translation task,\nan automatic post-editing task,\na metrics task (assess MT quality given reference translation).\na quality estimation task (assess MT quality without access to any reference),\na tuning task (optimize a given MT system),\na pronoun translation task,\na bilingual document alignment task,\na multimodal translation task.",
            "S2 Citation Count (September 2023)": 627,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "Europarl",
            "Europarl3"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-wmt16_translate_roen": {
        "Unique Dataset Identifier": "fc-flan-wmt16_translate_roen",
        "Dataset Name": "wmt16_translate_roen",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.statmt.org/wmt16/translation-task.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/wmt16",
        "Paper Title": "Findings of the 2016 Conference on Machine Translation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wmt-2016",
        "ArXiv URL": "https://aclanthology.org/W16-2301/",
        "Semantic Scholar Corpus ID": 14421595,
        "Languages": [
            "English",
            "Romanian"
        ],
        "Task Categories": [
            "Translation",
            "Inverted Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108611,
            "Mean Inputs Length": 664.8995,
            "Mean Targets Length": 136.3313,
            "Max Inputs Length": 4512,
            "Max Targets Length": 1110,
            "Min Inputs Length": 24,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "united nations",
            "commoncrawl.org",
            "yandex",
            "wikipedia headlines",
            "czeng v1.6pre",
            "opus news-commentary",
            "opensubtitles.org",
            "european parliament proceedings"
        ],
        "Model Generated": [],
        "Creators": [
            "Charles University",
            "Microsoft Research",
            "Dublin City University",
            "University of Edinburgh",
            "IBM",
            "Johns Hopkins University",
            "University of Sheffield",
            "University of Amsterdam",
            "Hasso Plattner Institute - Potsdam",
            "Charles University",
            "Johns Hopkins University",
            "Saarland University",
            "University of Melbourne"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "wmt16_translate/ro-en:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wmt16",
            "HF Config": "cs-en",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2016-01-01",
            "S2 Date": "2016-08-12",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 35204,
            "HF Likes (September 2023)": 12,
            "PwC Description": "WMT 2016 is a collection of datasets used in shared tasks of the First Conference on Machine Translation. The conference builds on ten previous Workshops on statistical Machine Translation.\n\nThe conference featured ten shared tasks:\n\n\na news translation task,\nan IT domain translation task,\na biomedical translation task,\nan automatic post-editing task,\na metrics task (assess MT quality given reference translation).\na quality estimation task (assess MT quality without access to any reference),\na tuning task (optimize a given MT system),\na pronoun translation task,\na bilingual document alignment task,\na multimodal translation task.",
            "S2 Citation Count (September 2023)": 627,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "Europarl",
            "Europarl3"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-wmt16_translate_ruen": {
        "Unique Dataset Identifier": "fc-flan-wmt16_translate_ruen",
        "Dataset Name": "wmt16_translate_ruen",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.statmt.org/wmt16/translation-task.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/wmt16",
        "Paper Title": "Findings of the 2016 Conference on Machine Translation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wmt-2016",
        "ArXiv URL": "https://aclanthology.org/W16-2301/",
        "Semantic Scholar Corpus ID": 14421595,
        "Languages": [
            "English",
            "Russian"
        ],
        "Task Categories": [
            "Translation",
            "Inverted Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108682,
            "Mean Inputs Length": 543.9277,
            "Mean Targets Length": 107.3493,
            "Max Inputs Length": 3896,
            "Max Targets Length": 1749,
            "Min Inputs Length": 23,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "united nations",
            "commoncrawl.org",
            "yandex",
            "wikipedia headlines",
            "czeng v1.6pre",
            "opus news-commentary",
            "opensubtitles.org",
            "european parliament proceedings"
        ],
        "Model Generated": [],
        "Creators": [
            "Charles University",
            "Microsoft Research",
            "Dublin City University",
            "University of Edinburgh",
            "IBM",
            "Johns Hopkins University",
            "University of Sheffield",
            "University of Amsterdam",
            "Hasso Plattner Institute - Potsdam",
            "Charles University",
            "Johns Hopkins University",
            "Saarland University",
            "University of Melbourne"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "wmt16_translate/ru-en:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wmt16",
            "HF Config": "cs-en",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2016-01-01",
            "S2 Date": "2016-08-12",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 35204,
            "HF Likes (September 2023)": 12,
            "PwC Description": "WMT 2016 is a collection of datasets used in shared tasks of the First Conference on Machine Translation. The conference builds on ten previous Workshops on statistical Machine Translation.\n\nThe conference featured ten shared tasks:\n\n\na news translation task,\nan IT domain translation task,\na biomedical translation task,\nan automatic post-editing task,\na metrics task (assess MT quality given reference translation).\na quality estimation task (assess MT quality without access to any reference),\na tuning task (optimize a given MT system),\na pronoun translation task,\na bilingual document alignment task,\na multimodal translation task.",
            "S2 Citation Count (September 2023)": 627,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "Europarl",
            "Europarl3"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-wmt16_translate_tren": {
        "Unique Dataset Identifier": "fc-flan-wmt16_translate_tren",
        "Dataset Name": "wmt16_translate_tren",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.statmt.org/wmt16/translation-task.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/wmt16",
        "Paper Title": "Findings of the 2016 Conference on Machine Translation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wmt-2016",
        "ArXiv URL": "https://aclanthology.org/W16-2301/",
        "Semantic Scholar Corpus ID": 14421595,
        "Languages": [
            "English",
            "Turkish"
        ],
        "Task Categories": [
            "Translation",
            "Inverted Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108442,
            "Mean Inputs Length": 620.1376,
            "Mean Targets Length": 124.9894,
            "Max Inputs Length": 3005,
            "Max Targets Length": 607,
            "Min Inputs Length": 25,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "united nations",
            "commoncrawl.org",
            "yandex",
            "wikipedia headlines",
            "czeng v1.6pre",
            "opus news-commentary",
            "opensubtitles.org",
            "european parliament proceedings"
        ],
        "Model Generated": [],
        "Creators": [
            "Charles University",
            "Microsoft Research",
            "Dublin City University",
            "University of Edinburgh",
            "IBM",
            "Johns Hopkins University",
            "University of Sheffield",
            "University of Amsterdam",
            "Hasso Plattner Institute - Potsdam",
            "Charles University",
            "Johns Hopkins University",
            "Saarland University",
            "University of Melbourne"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "wmt16_translate/tr-en:1.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wmt16",
            "HF Config": "cs-en",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2016-01-01",
            "S2 Date": "2016-08-12",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 35204,
            "HF Likes (September 2023)": 12,
            "PwC Description": "WMT 2016 is a collection of datasets used in shared tasks of the First Conference on Machine Translation. The conference builds on ten previous Workshops on statistical Machine Translation.\n\nThe conference featured ten shared tasks:\n\n\na news translation task,\nan IT domain translation task,\na biomedical translation task,\nan automatic post-editing task,\na metrics task (assess MT quality given reference translation).\na quality estimation task (assess MT quality without access to any reference),\na tuning task (optimize a given MT system),\na pronoun translation task,\na bilingual document alignment task,\na multimodal translation task.",
            "S2 Citation Count (September 2023)": 627,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "Europarl",
            "Europarl3"
        ],
        "Human Annotation": "Yes"
    },
    "fc-flan-wnli": {
        "Unique Dataset Identifier": "fc-flan-wnli",
        "Dataset Name": "wnli",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/SetFit/wnli",
        "Paper Title": "The Winograd Schema Challenge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wsc",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 15710851,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Coreference Resolution",
            "Inverted Coreference Resolution"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2111,
            "Mean Inputs Length": 567.7494,
            "Mean Targets Length": 2.8626,
            "Max Inputs Length": 2024,
            "Max Targets Length": 8,
            "Min Inputs Length": 80,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "University of Toronto",
            "New York University",
            "S.A.I.C"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://creativecommons.org/licenses/by/4.0/"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "glue/wnli:2.0.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "SetFit/wnli",
            "HF Config": "SetFit--wnli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/4.0/",
            "PwC Date": "2012-01-01",
            "S2 Date": "2011-03-20",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-02-28",
            "HF Downloads (September 2023)": 567,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The Winograd Schema Challenge was introduced both as an alternative to the Turing Test and as a test of a system’s ability to do commonsense reasoning. A Winograd schema is a pair of sentences differing in one or two words with a highly ambiguous pronoun, resolved differently in the two sentences, that appears to require commonsense knowledge to be resolved correctly. The examples were designed to be easily solvable by humans but difficult for machines, in principle requiring a deep understanding of the content of the text and the situation it describes.\n\nThe original Winograd Schema Challenge dataset consisted of 100 Winograd schemas constructed manually by AI experts. As of 2020 there are 285 examples available; however, the last 12 examples were only added recently. To ensure consistency with earlier models, several authors often prefer to report the performance on the first 273 examples only. These datasets are usually referred to as WSC285 and WSC273, respectively.",
            "S2 Citation Count (September 2023)": 1000,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": []
    },
    "fc-flan-word_segment": {
        "Unique Dataset Identifier": "fc-flan-word_segment",
        "Dataset Name": "word_segment",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.paracrawl.eu/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Word Segmentation",
            "Inverted Word Segmentation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108728,
            "Mean Inputs Length": 562.4387,
            "Mean Targets Length": 116.4661,
            "Max Inputs Length": 3821,
            "Max Targets Length": 1016,
            "Min Inputs Length": 21,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://creativecommons.org/share-your-work/public-domain/cc0/"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "word_segment"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Communication",
                "Text manipulation",
                "Text editing",
                "Transportation",
                "Translation",
                "Text formatting",
                "Religion",
                "Language processing",
                "Travel"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": []
    },
    "fc-flan-wsc": {
        "Unique Dataset Identifier": "fc-flan-wsc",
        "Dataset Name": "wsc",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/winograd_wsc",
        "Paper Title": "The Winograd Schema Challenge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wsc",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 15710851,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Coreference Resolution",
            "Inverted Coreference Resolution"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1832,
            "Mean Inputs Length": 518.5437,
            "Mean Targets Length": 2.6572,
            "Max Inputs Length": 2005,
            "Max Targets Length": 5,
            "Min Inputs Length": 78,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "University of Toronto",
            "New York University",
            "S.A.I.C"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "super_glue/wsc.fixed:1.0.2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "winograd_wsc",
            "HF Config": "wsc285",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/4.0/",
            "PwC Date": "2012-01-01",
            "S2 Date": "2011-03-20",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3264,
            "HF Likes (September 2023)": 5,
            "PwC Description": "The Winograd Schema Challenge was introduced both as an alternative to the Turing Test and as a test of a system’s ability to do commonsense reasoning. A Winograd schema is a pair of sentences differing in one or two words with a highly ambiguous pronoun, resolved differently in the two sentences, that appears to require commonsense knowledge to be resolved correctly. The examples were designed to be easily solvable by humans but difficult for machines, in principle requiring a deep understanding of the content of the text and the situation it describes.\n\nThe original Winograd Schema Challenge dataset consisted of 100 Winograd schemas constructed manually by AI experts. As of 2020 there are 285 examples available; however, the last 12 examples were only added recently. To ensure consistency with earlier models, several authors often prefer to report the performance on the first 273 examples only. These datasets are usually referred to as WSC285 and WSC273, respectively.",
            "S2 Citation Count (September 2023)": 1000,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": []
    },
    "fc-flan-xsum": {
        "Unique Dataset Identifier": "fc-flan-xsum",
        "Dataset Name": "xsum",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/EdinburghNLP/XSum/tree/master/XSum-Dataset",
        "GitHub URL": "https://github.com/EdinburghNLP/XSum/tree/master/XSum-Dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/xsum",
        "Paper Title": "Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization",
        "Papers with Code URL": "https://paperswithcode.com/dataset/xsum",
        "ArXiv URL": "https://arxiv.org/abs/1808.08745",
        "Semantic Scholar Corpus ID": 215768182,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Summarization",
            "Inverted Summarization"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 108628,
            "Mean Inputs Length": 3919.1134,
            "Mean Targets Length": 499.6831,
            "Max Inputs Length": 41434,
            "Max Targets Length": 30927,
            "Min Inputs Length": 10,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "bbc"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Edinburgh"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "Data derived from BBC articles",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "huggingface:xsum"
        ],
        "Inferred Metadata": {
            "HF Dataset": "xsum",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-08-27",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 22832,
            "HF Likes (September 2023)": 38,
            "PwC Description": "The Extreme Summarization (XSum) dataset is a dataset for evaluation of abstractive single-document summarization systems. The goal is to create a short, one-sentence new summary answering the question “What is the article about?”. The dataset consists of 226,711 news articles accompanied with a one-sentence summary. The articles are collected from BBC articles (2010 to 2017) and cover a wide variety of domains (e.g., News, Politics, Sports, Weather, Business, Technology, Science, Health, Family, Education, Entertainment and Arts). The official random split contains 204,045 (90%), 11,332 (5%) and 11,334 (5) documents in training, validation and test sets, respectively.",
            "S2 Citation Count (September 2023)": 892,
            "GitHub Stars": 316,
            "GitHub Topics": [
                "abstractive-summarization",
                "convolutional-neural-networks",
                "extreme-summarization",
                "topic-aware"
            ],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    },
    "fc-flan-yelp_polarity_reviews": {
        "Unique Dataset Identifier": "fc-flan-yelp_polarity_reviews",
        "Dataset Name": "yelp_polarity_reviews",
        "Collection": "Flan Collection (Flan 2021)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.yelp.com/dataset",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/yelp_review_full",
        "Paper Title": "Character-level Convolutional Networks for Text Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/yahoo-answers",
        "ArXiv URL": "https://arxiv.org/abs/1509.01626",
        "Semantic Scholar Corpus ID": 368182,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Inverted Sentiment Analysis",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 107871,
            "Mean Inputs Length": 1665.2251,
            "Mean Targets Length": 365.5927,
            "Max Inputs Length": 8354,
            "Max Targets Length": 5033,
            "Min Inputs Length": 29,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web",
            "amazon.com",
            "yelp",
            "sogou news",
            "dbpedia",
            "yahoo! answers",
            "ag news"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://s3-media0.fl.yelpcdn.com/assets/srv0/engineering_pages/dc1cabe7cb95/assets/vendor/Dataset_User_Agreement.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "yelp_polarity_reviews:0.2.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "yelp_review_full",
            "HF Config": "yelp_review_full",
            "HF Config License": "Custom",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2015-09-04",
            "S2 Date": "2015-09-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 24020,
            "HF Likes (September 2023)": 27,
            "PwC Description": "The Yahoo! Answers topic classification dataset is constructed using 10 largest main categories. Each class contains 140,000 training samples and 6,000 testing samples. Therefore, the total number of training samples is 1,400,000 and testing samples 60,000 in this dataset. From all the answers and other meta-information, we only used the best answer content and the main category information.",
            "S2 Citation Count (September 2023)": 4622,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No"
    }
}