{
    "tsi-babi_nli-two_arg_relations": {
        "Unique Dataset Identifier": "tsi-babi_nli-two_arg_relations",
        "Dataset Name": "babi_nli-two_arg_relations",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 182.565,
            "Mean Targets Length": 10.988,
            "Max Inputs Length": 189,
            "Max Targets Length": 13,
            "Min Inputs Length": 177,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/two-arg-relations"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Spatial relationships",
                "Logical reasoning",
                "Language",
                "Translation",
                "Directions",
                "Linguistics",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-three_supporting_facts": {
        "Unique Dataset Identifier": "tsi-babi_nli-three_supporting_facts",
        "Dataset Name": "babi_nli-three_supporting_facts",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 1539.097,
            "Mean Targets Length": 10.988,
            "Max Inputs Length": 6486,
            "Max Targets Length": 13,
            "Min Inputs Length": 233,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/three-supporting-facts"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Object possession",
                "Travel",
                "Object manipulation",
                "Logic",
                "Daily routine",
                "Actions",
                "Sports"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-indefinite_knowledge": {
        "Unique Dataset Identifier": "tsi-babi_nli-indefinite_knowledge",
        "Dataset Name": "babi_nli-indefinite_knowledge",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 287.391,
            "Mean Targets Length": 11.352,
            "Max Inputs Length": 480,
            "Max Targets Length": 13,
            "Min Inputs Length": 144,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/indefinite-knowledge"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Reasoning",
                "General knowledge",
                "Travel",
                "Daily routine",
                "Deductive reasoning",
                "Location",
                "Inference and reasoning",
                "Language understanding"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-time_reasoning": {
        "Unique Dataset Identifier": "tsi-babi_nli-time_reasoning",
        "Dataset Name": "babi_nli-time_reasoning",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 439.567,
            "Mean Targets Length": 10.988,
            "Max Inputs Length": 707,
            "Max Targets Length": 13,
            "Min Inputs Length": 189,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/time-reasoning"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Location",
                "Language",
                "Identity",
                "Language understanding",
                "Daily routine",
                "Inference",
                "Travel",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-two_supporting_facts": {
        "Unique Dataset Identifier": "tsi-babi_nli-two_supporting_facts",
        "Dataset Name": "babi_nli-two_supporting_facts",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 567.085,
            "Mean Targets Length": 10.988,
            "Max Inputs Length": 1792,
            "Max Targets Length": 13,
            "Min Inputs Length": 164,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/two-supporting-facts"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Travel",
                "Location",
                "Logic",
                "Language and grammar",
                "Daily routine",
                "General knowledge",
                "Sports",
                "Object manipulation",
                "Inference"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-path_finding": {
        "Unique Dataset Identifier": "tsi-babi_nli-path_finding",
        "Dataset Name": "babi_nli-path_finding",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 313.54,
            "Mean Targets Length": 10.988,
            "Max Inputs Length": 319,
            "Max Targets Length": 13,
            "Min Inputs Length": 308,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/path-finding"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "Daily routine",
                "Directions",
                "Logic and reasoning",
                "Spatial reasoning",
                "Directions and navigation",
                "Interior design",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-yes_no_questions": {
        "Unique Dataset Identifier": "tsi-babi_nli-yes_no_questions",
        "Dataset Name": "babi_nli-yes_no_questions",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 290.579,
            "Mean Targets Length": 10.968,
            "Max Inputs Length": 861,
            "Max Targets Length": 13,
            "Min Inputs Length": 154,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/yes-no-questions"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "Location",
                "Logic",
                "Inference",
                "Language understanding",
                "Sports",
                "Travel",
                "Daily routine",
                "Reasoning",
                "Textual entailment"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-basic_coreference": {
        "Unique Dataset Identifier": "tsi-babi_nli-basic_coreference",
        "Dataset Name": "babi_nli-basic_coreference",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 307.359,
            "Mean Targets Length": 10.988,
            "Max Inputs Length": 467,
            "Max Targets Length": 13,
            "Min Inputs Length": 156,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/basic-coreference"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Location",
                "Daily routine",
                "Language understanding",
                "Reasoning",
                "Logic",
                "Geography",
                "Inference",
                "Travel",
                "Sequence of events"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-counting": {
        "Unique Dataset Identifier": "tsi-babi_nli-counting",
        "Dataset Name": "babi_nli-counting",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 385.802,
            "Mean Targets Length": 10.988,
            "Max Inputs Length": 1152,
            "Max Targets Length": 13,
            "Min Inputs Length": 169,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/counting"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Textual entailment",
                "Object identification",
                "Location",
                "Language understanding",
                "Inference",
                "Travel",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-compound_coreference": {
        "Unique Dataset Identifier": "tsi-babi_nli-compound_coreference",
        "Dataset Name": "babi_nli-compound_coreference",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 342.687,
            "Mean Targets Length": 10.988,
            "Max Inputs Length": 525,
            "Max Targets Length": 13,
            "Min Inputs Length": 169,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/compound-coreference"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Relationships",
                "Language understanding",
                "Daily routine",
                "Inference",
                "Geography",
                "Logic",
                "Travel",
                "Location",
                "General knowledge",
                "Social interactions"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-three_arg_relations": {
        "Unique Dataset Identifier": "tsi-babi_nli-three_arg_relations",
        "Dataset Name": "babi_nli-three_arg_relations",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 658.485,
            "Mean Targets Length": 10.988,
            "Max Inputs Length": 3081,
            "Max Targets Length": 13,
            "Min Inputs Length": 157,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/three-arg-relations"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Object possession",
                "Textual entailment",
                "Sports",
                "Language understanding",
                "Travel",
                "Inference",
                "Object manipulation",
                "Communication",
                "Location"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-single_supporting_fact": {
        "Unique Dataset Identifier": "tsi-babi_nli-single_supporting_fact",
        "Dataset Name": "babi_nli-single_supporting_fact",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 283.761,
            "Mean Targets Length": 10.988,
            "Max Inputs Length": 421,
            "Max Targets Length": 13,
            "Min Inputs Length": 153,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/single-supporting-fact"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Location tracking",
                "Location",
                "Daily routine",
                "Travel",
                "Reasoning",
                "General knowledge",
                "Logical reasoning"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-simple_negation": {
        "Unique Dataset Identifier": "tsi-babi_nli-simple_negation",
        "Dataset Name": "babi_nli-simple_negation",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 278.297,
            "Mean Targets Length": 11.532,
            "Max Inputs Length": 439,
            "Max Targets Length": 13,
            "Min Inputs Length": 148,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/simple-negation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Spatial awareness",
                "Inference",
                "Language understanding",
                "Reasoning",
                "Daily routine",
                "Logic",
                "Spatial reasoning",
                "Location"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-lists_sets": {
        "Unique Dataset Identifier": "tsi-babi_nli-lists_sets",
        "Dataset Name": "babi_nli-lists_sets",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 361.224,
            "Mean Targets Length": 10.988,
            "Max Inputs Length": 1491,
            "Max Targets Length": 13,
            "Min Inputs Length": 152,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/lists-sets"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Travel",
                "Object possession",
                "Reasoning",
                "Inference",
                "Language understanding",
                "Location"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-basic_induction": {
        "Unique Dataset Identifier": "tsi-babi_nli-basic_induction",
        "Dataset Name": "babi_nli-basic_induction",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 248.319,
            "Mean Targets Length": 10.988,
            "Max Inputs Length": 255,
            "Max Targets Length": 13,
            "Min Inputs Length": 242,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/basic-induction"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Inference",
                "Color perception",
                "Categorization",
                "Language understanding",
                "Animal colors",
                "General knowledge",
                "Animal characteristics"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-size_reasoning": {
        "Unique Dataset Identifier": "tsi-babi_nli-size_reasoning",
        "Dataset Name": "babi_nli-size_reasoning",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 374.623,
            "Mean Targets Length": 10.98,
            "Max Inputs Length": 731,
            "Max Targets Length": 13,
            "Min Inputs Length": 285,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/size-reasoning"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Spatial relationships",
                "Size comparison",
                "Inference",
                "Reasoning",
                "Size and comparison",
                "Language understanding",
                "Logic",
                "Puzzle-solving",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-conjunction": {
        "Unique Dataset Identifier": "tsi-babi_nli-conjunction",
        "Dataset Name": "babi_nli-conjunction",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 344.487,
            "Mean Targets Length": 10.988,
            "Max Inputs Length": 523,
            "Max Targets Length": 13,
            "Min Inputs Length": 171,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/conjunction"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Relationships",
                "Inference",
                "Daily routine",
                "Textual entailment",
                "Language understanding",
                "Logic",
                "Travel",
                "Social interactions",
                "Location"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-basic_deduction": {
        "Unique Dataset Identifier": "tsi-babi_nli-basic_deduction",
        "Dataset Name": "babi_nli-basic_deduction",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 285.519,
            "Mean Targets Length": 10.988,
            "Max Inputs Length": 294,
            "Max Targets Length": 13,
            "Min Inputs Length": 276,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/basic-deduction"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Fear and phobias",
                "Categorization of animals",
                "Animal classification",
                "Logic",
                "Relationships between different animal species",
                "Logic and reasoning",
                "Predatory instincts",
                "Animal hierarchy",
                "Animal behavior",
                "Classification of animals"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-babi_nli-positional_reasoning": {
        "Unique Dataset Identifier": "tsi-babi_nli-positional_reasoning",
        "Dataset Name": "babi_nli-positional_reasoning",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "GitHub URL": "https://github.com/facebookarchive/bAbI-tasks/blob/master/LICENSE.md",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/babi_nli",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 218.135,
            "Mean Targets Length": 10.98,
            "Max Inputs Length": 243,
            "Max Targets Length": 13,
            "Min Inputs Length": 194,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "babi_nli/positional-reasoning"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/babi_nli",
            "HF Config": "single-supporting-fact",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Text Topics": [
                "Reasoning",
                "Logic",
                "Geometry",
                "Visual perception",
                "Spatial reasoning"
            ],
            "Github Date": "",
            "HF Date": "2023-01-01",
            "HF Downloads (September 2023)": 308,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "tsi-wanli": {
        "Unique Dataset Identifier": "tsi-wanli",
        "Dataset Name": "wanli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/alisawuffles/wanli",
        "GitHub URL": "https://github.com/alisawuffles/wanli",
        "Hugging Face URL": "https://huggingface.co/datasets/alisawuffles/WANLI",
        "Paper Title": "WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2201.05955",
        "Semantic Scholar Corpus ID": 246016339,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 241.0547,
            "Mean Targets Length": 10.0093,
            "Max Inputs Length": 720,
            "Max Targets Length": 14,
            "Min Inputs Length": 111,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "OpenAI GPT-3"
        ],
        "Creators": [
            "University of Washington",
            "AI2",
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Uses the MultiNLI corpus as a starting point for sentence collection and then uses GPT-3 to write sentences that are similar in structure and topic. The corpus says it is crowdsourced but states to check the paper to be sure. Paper on MultiNLI: https://cims.nyu.edu/~sbowman/multinli/",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "WANLI"
        ],
        "Inferred Metadata": {
            "HF Dataset": "alisawuffles/WANLI",
            "HF Config": "alisawuffles--WANLI",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-01-16",
            "GitHub License": "",
            "Text Topics": [
                "Politics",
                "History",
                "Interpersonal relationships",
                "Geography",
                "Economics",
                "Travel",
                "Decision-making",
                "General knowledge",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2022-04-21",
            "HF Downloads (September 2023)": 152,
            "HF Likes (September 2023)": 6,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 104,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "MNLI"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Liu2022WANLIWA,\n author = {Alisa Liu and Swabha Swayamdipta and Noah A. Smith and Yejin Choi},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {6826-6847},\n title = {WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation},\n year = {2022}\n}\n"
    },
    "tsi-recast-recast_verbnet": {
        "Unique Dataset Identifier": "tsi-recast-recast_verbnet",
        "Dataset Name": "recast-recast_verbnet",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://decomp.io/",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/recast",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1398,
            "Mean Inputs Length": 150.6166,
            "Mean Targets Length": 10.6137,
            "Max Inputs Length": 277,
            "Max Targets Length": 13,
            "Min Inputs Length": 104,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/decompositional-semantics-initiative/decomp#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast/recast_verbnet"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Inference",
                "Language understanding",
                "Information transfer",
                "Logic",
                "Interpersonal relationships",
                "Language and communication",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 545,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-recast-recast_verbcorner": {
        "Unique Dataset Identifier": "tsi-recast-recast_verbcorner",
        "Dataset Name": "recast-recast_verbcorner",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/recast",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/recast",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 153.9667,
            "Mean Targets Length": 10.9996,
            "Max Inputs Length": 231,
            "Max Targets Length": 13,
            "Min Inputs Length": 115,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/decompositional-semantics-initiative/decomp#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast/recast_verbcorner"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Logic",
                "Communication and understanding",
                "Semantics",
                "Language and communication",
                "Language understanding",
                "Linguistics"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 545,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-recast-recast_ner": {
        "Unique Dataset Identifier": "tsi-recast-recast_ner",
        "Dataset Name": "recast-recast_ner",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/recast",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/recast",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 251.9004,
            "Mean Targets Length": 10.9937,
            "Max Inputs Length": 550,
            "Max Targets Length": 13,
            "Min Inputs Length": 112,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/decompositional-semantics-initiative/decomp#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast/recast_ner"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Conflict resolution",
                "Middle East conflict",
                "International relations",
                "Politics",
                "Diplomacy",
                "History",
                "Current events"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 545,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-recast-recast_sentiment": {
        "Unique Dataset Identifier": "tsi-recast-recast_sentiment",
        "Dataset Name": "recast-recast_sentiment",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/recast",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/recast",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4800,
            "Mean Inputs Length": 224.1379,
            "Mean Targets Length": 11.0,
            "Max Inputs Length": 636,
            "Max Targets Length": 13,
            "Min Inputs Length": 153,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/decompositional-semantics-initiative/decomp#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast/recast_sentiment"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Communication and language",
                "Consumer preferences",
                "Product reviews",
                "Movie reviews",
                "Communication",
                "Personal opinions",
                "Communication skills",
                "Customer satisfaction",
                "Restaurant reviews"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 545,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-recast-recast_puns": {
        "Unique Dataset Identifier": "tsi-recast-recast_puns",
        "Dataset Name": "recast-recast_puns",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/recast",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/recast",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 14038,
            "Mean Inputs Length": 182.1212,
            "Mean Targets Length": 11.0,
            "Max Inputs Length": 517,
            "Max Targets Length": 13,
            "Min Inputs Length": 127,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/decompositional-semantics-initiative/decomp#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast/recast_puns"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Humor and puns",
                "Communication",
                "Language and communication",
                "Understanding and interpretation",
                "Interpretation and understanding",
                "General knowledge",
                "Language understanding",
                "Information processing",
                "Linguistics"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 545,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-recast-recast_factuality": {
        "Unique Dataset Identifier": "tsi-recast-recast_factuality",
        "Dataset Name": "recast-recast_factuality",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/recast",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/recast",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 233.8633,
            "Mean Targets Length": 11.0019,
            "Max Inputs Length": 916,
            "Max Targets Length": 13,
            "Min Inputs Length": 108,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/decompositional-semantics-initiative/decomp#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast/recast_factuality"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Terrorism",
                "Time management",
                "Communication and understanding",
                "Language understanding",
                "International relations",
                "Customer service",
                "Communication",
                "National security",
                "Politics"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 545,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-recast-recast_megaveridicality": {
        "Unique Dataset Identifier": "tsi-recast-recast_megaveridicality",
        "Dataset Name": "recast-recast_megaveridicality",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/recast",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/recast",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9450,
            "Mean Inputs Length": 174.9866,
            "Mean Targets Length": 11.6667,
            "Max Inputs Length": 207,
            "Max Targets Length": 13,
            "Min Inputs Length": 147,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/decompositional-semantics-initiative/decomp#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast/recast_megaveridicality"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Logic",
                "General knowledge",
                "Reasoning",
                "Epistemology",
                "Inference",
                "Philosophy",
                "Logic and reasoning",
                "Language understanding"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 545,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-probability_words_nli-reasoning_1hop": {
        "Unique Dataset Identifier": "tsi-probability_words_nli-reasoning_1hop",
        "Dataset Name": "probability_words_nli-reasoning_1hop",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/nlp-verbal-probabilities",
        "GitHub URL": "https://github.com/sileod/nlp-verbal-probabilities",
        "Hugging Face URL": "https://huggingface.co/datasets/sileod/probability_words_nli",
        "Paper Title": "Probing neural language models for understanding of words of estimative probability",
        "Papers with Code URL": "https://paperswithcode.com/dataset/probability-words-nli-1",
        "ArXiv URL": "https://arxiv.org/abs/2211.03358v1",
        "Semantic Scholar Corpus ID": 253383825,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Logical Reasoning",
            "Text Classification",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4000,
            "Mean Inputs Length": 286.271,
            "Mean Targets Length": 7.007,
            "Max Inputs Length": 351,
            "Max Targets Length": 8,
            "Min Inputs Length": 225,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "babi",
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Lille",
            "KU Leuven"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": null
            },
            {
                "License": "Apache License 2.0",
                "License URL": null
            }
        ],
        "License Notes": "Derived originally from SNLI (CC BY-SA 4.0) and the authors themselves (Apache 2)",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "probability_words_nli/reasoning_1hop"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sileod/probability_words_nli",
            "HF Config": "reasoning_1hop",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "",
            "PwC Date": "2022-11-07",
            "S2 Date": "2022-11-07",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Logic",
                "Probability and likelihood",
                "Animal classification",
                "Reasoning and inference",
                "Language and semantics",
                "Inference",
                "Reasoning",
                "Probability"
            ],
            "Github Date": "",
            "HF Date": "2022-11-03",
            "HF Downloads (September 2023)": 154,
            "HF Likes (September 2023)": 3,
            "PwC Description": "This dataset tests the capabilities of language models to correctly capture the meaning of words denoting probabilities (WEP, also called verbal probabilities), e.g. words like \"probably\", \"maybe\", \"surely\", \"impossible\".",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 1,
            "GitHub Topics": [
                "benchmark",
                "classification",
                "dataset",
                "english",
                "entailment",
                "language-model",
                "llm",
                "natural-language",
                "natural-language-inference",
                "nli",
                "nlp",
                "probabilities",
                "probably",
                "probing",
                "verbal",
                "verbal-probabilities",
                "wep"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sileo2022ProbingNL,\n author = {Damien Sileo and M. Moens},\n booktitle = {STARSEM},\n pages = {469-476},\n title = {Probing neural language models for understanding of words of estimative probability},\n year = {2022}\n}\n"
    },
    "tsi-probability_words_nli-usnli": {
        "Unique Dataset Identifier": "tsi-probability_words_nli-usnli",
        "Dataset Name": "probability_words_nli-usnli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://sileod.s3.eu-west-3.amazonaws.com/probability_words/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sileod/probability_words_nli",
        "Paper Title": "Probing neural language models for understanding of words of estimative probability",
        "Papers with Code URL": "https://paperswithcode.com/dataset/probability-words-nli-1",
        "ArXiv URL": "https://arxiv.org/abs/2211.03358v1",
        "Semantic Scholar Corpus ID": 253383825,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Text Classification",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 224.659,
            "Mean Targets Length": 7.0027,
            "Max Inputs Length": 568,
            "Max Targets Length": 8,
            "Min Inputs Length": 124,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "babi",
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Lille",
            "KU Leuven"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": null
            },
            {
                "License": "Apache License 2.0",
                "License URL": null
            }
        ],
        "License Notes": "Derived originally from SNLI (CC BY-SA 4.0) and the authors themselves (Apache 2)",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "probability_words_nli/usnli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sileod/probability_words_nli",
            "HF Config": "reasoning_1hop",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "",
            "PwC Date": "2022-11-07",
            "S2 Date": "2022-11-07",
            "GitHub License": "",
            "Text Topics": [
                "Visual perception",
                "Logic",
                "Language understanding",
                "General knowledge",
                "Sports",
                "Observation and perception",
                "Inference"
            ],
            "Github Date": "",
            "HF Date": "2022-11-03",
            "HF Downloads (September 2023)": 154,
            "HF Likes (September 2023)": 3,
            "PwC Description": "This dataset tests the capabilities of language models to correctly capture the meaning of words denoting probabilities (WEP, also called verbal probabilities), e.g. words like \"probably\", \"maybe\", \"surely\", \"impossible\".",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sileo2022ProbingNL,\n author = {Damien Sileo and M. Moens},\n booktitle = {STARSEM},\n pages = {469-476},\n title = {Probing neural language models for understanding of words of estimative probability},\n year = {2022}\n}\n"
    },
    "tsi-probability_words_nli-reasoning_2hop": {
        "Unique Dataset Identifier": "tsi-probability_words_nli-reasoning_2hop",
        "Dataset Name": "probability_words_nli-reasoning_2hop",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://sileod.s3.eu-west-3.amazonaws.com/probability_words/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sileod/probability_words_nli",
        "Paper Title": "Probing neural language models for understanding of words of estimative probability",
        "Papers with Code URL": "https://paperswithcode.com/dataset/probability-words-nli-1",
        "ArXiv URL": "https://arxiv.org/abs/2211.03358v1",
        "Semantic Scholar Corpus ID": 253383825,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Logical Reasoning",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4000,
            "Mean Inputs Length": 605.9475,
            "Mean Targets Length": 6.9745,
            "Max Inputs Length": 713,
            "Max Targets Length": 8,
            "Min Inputs Length": 505,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "babi",
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Lille",
            "KU Leuven"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": null
            },
            {
                "License": "Apache License 2.0",
                "License URL": null
            }
        ],
        "License Notes": "Derived originally from SNLI (CC BY-SA 4.0) and the authors themselves (Apache 2)",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "probability_words_nli/reasoning_2hop"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sileod/probability_words_nli",
            "HF Config": "reasoning_1hop",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "",
            "PwC Date": "2022-11-07",
            "S2 Date": "2022-11-07",
            "GitHub License": "",
            "Text Topics": [
                "Language understanding",
                "Inference",
                "Linguistics",
                "Deductive reasoning",
                "Reasoning",
                "Animal classification",
                "Philosophy",
                "Probability",
                "Logic",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2022-11-03",
            "HF Downloads (September 2023)": 154,
            "HF Likes (September 2023)": 3,
            "PwC Description": "This dataset tests the capabilities of language models to correctly capture the meaning of words denoting probabilities (WEP, also called verbal probabilities), e.g. words like \"probably\", \"maybe\", \"surely\", \"impossible\".",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sileo2022ProbingNL,\n author = {Damien Sileo and M. Moens},\n booktitle = {STARSEM},\n pages = {469-476},\n title = {Probing neural language models for understanding of words of estimative probability},\n year = {2022}\n}\n"
    },
    "tsi-nan_nli-joey234__nan_nli": {
        "Unique Dataset Identifier": "tsi-nan_nli-joey234__nan_nli",
        "Dataset Name": "nan_nli-joey234__nan_nli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/joey234/nan-nli",
        "GitHub URL": "https://github.com/joey234/nan-nli",
        "Hugging Face URL": "https://huggingface.co/datasets/joey234/nan-nli",
        "Paper Title": "Not another Negation Benchmark: The NaN-NLI Test Suite for Sub-clausal Negation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2210.03256",
        "Semantic Scholar Corpus ID": 252762383,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 219,
            "Mean Inputs Length": 181.4018,
            "Mean Targets Length": 11.8767,
            "Max Inputs Length": 293,
            "Max Targets Length": 14,
            "Min Inputs Length": 131,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "human",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Melbourne",
            "RMIT University",
            "MBZUAI"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "nan-nli/joey234--nan-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "joey234/nan-nli",
            "HF Config": "joey234--nan-nli",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-10-06",
            "GitHub License": "",
            "Text Topics": [
                "Communication and understanding",
                "Language use",
                "Linguistics",
                "Logic",
                "Language",
                "Daily routine",
                "Interpersonal relationships",
                "Language understanding",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-10-13",
            "HF Downloads (September 2023)": 78,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 7,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "Pullum and Huddleston 2002"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Truong2022NotAN,\n author = {Thinh Hung Truong and Yulia Otmakhova and Tim Baldwin and Trevor Cohn and Karin M. Verspoor and Jey Han Lau},\n booktitle = {AACL},\n pages = {883-894},\n title = {Not another Negation Benchmark: The NaN-NLI Test Suite for Sub-clausal Negation},\n year = {2022}\n}\n"
    },
    "tsi-nli_fever": {
        "Unique Dataset Identifier": "tsi-nli_fever",
        "Dataset Name": "nli_fever",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/easonnie/combine-FEVER-NSMN/blob/master/other_resources/nli_fever.md",
        "GitHub URL": "https://github.com/easonnie/combine-FEVER-NSMN/blob/master/other_resources/nli_fever.md",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/nli_fever",
        "Paper Title": "Adversarial NLI: A New Benchmark for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1910.14599",
        "Semantic Scholar Corpus ID": 207756753,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 458.8789,
            "Mean Targets Length": 11.1907,
            "Max Inputs Length": 5251,
            "Max Targets Length": 14,
            "Min Inputs Length": 107,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "commoncrawl.org",
            "wikihow.com",
            "crowdsourced",
            "project gutenberg"
        ],
        "Model Generated": [],
        "Creators": [
            "UNC Chapel Hill",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Subset of another dataset: https://arxiv.org/pdf/1803.05355",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "nli_fever"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/nli_fever",
            "HF Config": "pietrolesci--nli_fever",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-10-31",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "Music",
                "Entertainment",
                "Biography",
                "Entertainment industry",
                "Film industry",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2022-03-25",
            "HF Downloads (September 2023)": 477,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 601,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "StoryCloze",
            "The Childrens Book Test dataset",
            "RTE5",
            "Manually Annotated Sub-Corpus (MASC) of the Open American National Corpus"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Nie2019AdversarialNA,\n author = {Yixin Nie and Adina Williams and Emily Dinan and Mohit Bansal and J. Weston and Douwe Kiela},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Adversarial NLI: A New Benchmark for Natural Language Understanding},\n volume = {abs/1910.14599},\n year = {2019}\n}\n"
    },
    "tsi-breaking_nli": {
        "Unique Dataset Identifier": "tsi-breaking_nli",
        "Dataset Name": "breaking_nli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/BIU-NLP/Breaking_NLI",
        "GitHub URL": "https://github.com/BIU-NLP/Breaking_NLI",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/breaking_nli",
        "Paper Title": "Breaking NLI Systems with Sentences that Require Simple Lexical Inferences",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1805.02266",
        "Semantic Scholar Corpus ID": 19204066,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6964,
            "Mean Inputs Length": 212.9413,
            "Mean Targets Length": 13.6162,
            "Max Inputs Length": 848,
            "Max Targets Length": 14,
            "Min Inputs Length": 122,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "TU Darmstadt",
            "Bar-Ilan University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/BIU-NLP/Breaking_NLI#data-source"
            }
        ],
        "License Notes": "Sentences taken from SNLI Corpus which has CC BY-SA 4.0 license as well. Link: https://nlp.stanford.edu/projects/snli/",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "breaking_nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/breaking_nli",
            "HF Config": "pietrolesci--breaking_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-05-06",
            "GitHub License": "",
            "Text Topics": [
                "Travel",
                "Language and communication",
                "Geography",
                "Culture",
                "Visual perception",
                "Language understanding",
                "Daily routine",
                "Cultural differences"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 33,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 324,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Glockner2018BreakingNS,\n author = {Max Glockner and Vered Shwartz and Yoav Goldberg},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Breaking NLI Systems with Sentences that Require Simple Lexical Inferences},\n volume = {abs/1805.02266},\n year = {2018}\n}\n"
    },
    "tsi-conj_nli": {
        "Unique Dataset Identifier": "tsi-conj_nli",
        "Dataset Name": "conj_nli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/swarnaHub/ConjNLI",
        "GitHub URL": "https://github.com/swarnaHub/ConjNLI",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/conj_nli",
        "Paper Title": "ConjNLI: Natural Language Inference over Conjunctive Sentences",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.10418",
        "Semantic Scholar Corpus ID": 224803276,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 14998,
            "Mean Inputs Length": 304.7514,
            "Mean Targets Length": 10.1333,
            "Max Inputs Length": 516,
            "Max Targets Length": 14,
            "Min Inputs Length": 157,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "UNC Chapel Hill"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "conj_nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/conj_nli",
            "HF Config": "pietrolesci--conj_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-20",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Entertainment industry",
                "Education",
                "Tennis",
                "Sports",
                "Music",
                "Biography",
                "History",
                "Basketball"
            ],
            "Github Date": "",
            "HF Date": "2022-03-25",
            "HF Downloads (September 2023)": 50,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 24,
            "GitHub Stars": 9,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Saha2020ConjNLINL,\n author = {Swarnadeep Saha and Yixin Nie and Mohit Bansal},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {8240-8252},\n title = {ConjNLI: Natural Language Inference over Conjunctive Sentences},\n year = {2020}\n}\n"
    },
    "tsi-fracas": {
        "Unique Dataset Identifier": "tsi-fracas",
        "Dataset Name": "fracas",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/felipessalvatore/NLI_datasets",
        "GitHub URL": "https://github.com/felipessalvatore/NLI_datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/fracas",
        "Paper Title": "Using the framework method for the analysis of qualitative data in multi-disciplinary health research",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 92904,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 234,
            "Mean Inputs Length": 196.4573,
            "Mean Targets Length": 10.4231,
            "Max Inputs Length": 398,
            "Max Targets Length": 14,
            "Min Inputs Length": 131,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "A 1996 Stanford dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "fracas"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/fracas",
            "HF Config": "pietrolesci--fracas",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2013-09-18",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Time management",
                "Language understanding",
                "Logic",
                "Geography",
                "Reasoning",
                "Travel",
                "Daily routine",
                "General knowledge",
                "Technology"
            ],
            "Github Date": "",
            "HF Date": "2022-04-22",
            "HF Downloads (September 2023)": 37,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 6030,
            "GitHub Stars": 5,
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Gale2013UsingTF,\n author = {N. Gale and G. Heath and E. Cameron and S. Rashid and S. Redwood},\n booktitle = {BMC Medical Research Methodology},\n journal = {BMC Medical Research Methodology},\n pages = {117 - 117},\n title = {Using the framework method for the analysis of qualitative data in multi-disciplinary health research},\n volume = {13},\n year = {2013}\n}\n"
    },
    "tsi-dialogue_nli": {
        "Unique Dataset Identifier": "tsi-dialogue_nli",
        "Dataset Name": "dialogue_nli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://wellecks.github.io/dialogue_nli/",
        "GitHub URL": "https://wellecks.github.io/dialogue_nli/",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/dialogue_nli",
        "Paper Title": "Dialogue Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1811.00671",
        "Semantic Scholar Corpus ID": 53298765,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 172.2277,
            "Mean Targets Length": 11.1106,
            "Max Inputs Length": 344,
            "Max Targets Length": 14,
            "Min Inputs Length": 117,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "dialogue_nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/dialogue_nli",
            "HF Config": "pietrolesci--dialogue_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-11-01",
            "GitHub License": "",
            "Text Topics": [
                "Personal experiences",
                "Education",
                "Music",
                "Travel",
                "Hobbies",
                "Hobbies and interests",
                "Daily routine",
                "Personal interests and hobbies"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 43,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 182,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "Persona-Chat dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Welleck2018DialogueNL,\n author = {S. Welleck and J. Weston and Arthur Szlam and Kyunghyun Cho},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {3731-3741},\n title = {Dialogue Natural Language Inference},\n year = {2018}\n}\n"
    },
    "tsi-mpe": {
        "Unique Dataset Identifier": "tsi-mpe",
        "Dataset Name": "mpe",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/aylai/MultiPremiseEntailment",
        "GitHub URL": "https://github.com/aylai/MultiPremiseEntailment",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/mpe",
        "Paper Title": "Natural Language Inference from Multiple Premises",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1710.02925",
        "Semantic Scholar Corpus ID": 29033327,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8000,
            "Mean Inputs Length": 371.6101,
            "Mean Targets Length": 11.462,
            "Max Inputs Length": 850,
            "Max Targets Length": 14,
            "Min Inputs Length": 235,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flickr",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Illinois Urbana-Champaign",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mpe"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/mpe",
            "HF Config": "pietrolesci--mpe",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2017-10-09",
            "GitHub License": "",
            "Text Topics": [
                "Music",
                "Visual perception",
                "Fashion",
                "Photography",
                "Cultural diversity",
                "Observation",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2022-04-22",
            "HF Downloads (September 2023)": 44,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 46,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lai2017NaturalLI,\n author = {Alice Lai and Yonatan Bisk and J. Hockenmaier},\n booktitle = {International Joint Conference on Natural Language Processing},\n journal = {ArXiv},\n title = {Natural Language Inference from Multiple Premises},\n volume = {abs/1710.02925},\n year = {2017}\n}\n"
    },
    "tsi-dnc": {
        "Unique Dataset Identifier": "tsi-dnc",
        "Dataset Name": "dnc",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/decompositional-semantics-initiative/DNC",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/dnc",
        "Paper Title": "Collecting Diverse Natural Language Inference Problems for Sentence Representation Evaluation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1804.08207",
        "Semantic Scholar Corpus ID": 52123220,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 175.971,
            "Mean Targets Length": 11.0459,
            "Max Inputs Length": 916,
            "Max Targets Length": 13,
            "Min Inputs Length": 109,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Johns Hopkins University",
            "BITS Pilani",
            "Goa Campus",
            "Brown University",
            "University of Rochester"
        ],
        "Licenses": [
            {
                "License": "Various",
                "License URL": null
            }
        ],
        "License Notes": "A collection of multiple data sets. Link: https://github.com/decompositional-semantics-initiative/DNC/blob/master/additional_references.md. This lists all sub data sets within this dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "dnc"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/dnc",
            "HF Config": "pietrolesci--dnc",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-04-23",
            "GitHub License": "",
            "Text Topics": [
                "Communication and understanding",
                "Language understanding",
                "Language and communication",
                "Inference",
                "Linguistics",
                "Logic",
                "Natural language processing",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 41,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 134,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Poliak2018CollectingDN,\n author = {Adam Poliak and Aparajita Haldar and Rachel Rudinger and J. E. Hu and Ellie Pavlick and Aaron Steven White and Benjamin Van Durme},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {67-81},\n title = {Collecting Diverse Natural Language Inference Problems for Sentence Representation Evaluation},\n year = {2018}\n}\n"
    },
    "tsi-recast_white-fnplus": {
        "Unique Dataset Identifier": "tsi-recast_white-fnplus",
        "Dataset Name": "recast_white-fnplus",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/decompositional-semantics-initiative/DNC/",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/recast_white",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 418.2138,
            "Mean Targets Length": 11.2737,
            "Max Inputs Length": 1452,
            "Max Targets Length": 13,
            "Min Inputs Length": 93,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast_white/fnplus"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Nuclear proliferation",
                "Language and communication",
                "Religion",
                "Communication",
                "Weapons of mass destruction",
                "History",
                "International relations",
                "Politics"
            ],
            "Github Date": "",
            "HF Date": "2022-04-22",
            "HF Downloads (September 2023)": 91,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-recast_white-sprl": {
        "Unique Dataset Identifier": "tsi-recast_white-sprl",
        "Dataset Name": "recast_white-sprl",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/decompositional-semantics-initiative/DNC/",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/recast_white",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 263.4546,
            "Mean Targets Length": 11.6108,
            "Max Inputs Length": 692,
            "Max Targets Length": 13,
            "Min Inputs Length": 110,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast_white/sprl"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Language and semantics",
                "Language understanding",
                "Logic",
                "Finance and investment",
                "Economics",
                "Politics",
                "Finance",
                "Language and communication",
                "International relations",
                "Stock market"
            ],
            "Github Date": "",
            "HF Date": "2022-04-22",
            "HF Downloads (September 2023)": 91,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-recast_white-dpr": {
        "Unique Dataset Identifier": "tsi-recast_white-dpr",
        "Dataset Name": "recast_white-dpr",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/decompositional-semantics-initiative/DNC/",
        "GitHub URL": "https://github.com/decompositional-semantics-initiative/DNC/raw/master/inference_is_everything.zip",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/recast_white",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3112,
            "Mean Inputs Length": 253.1877,
            "Mean Targets Length": 10.9987,
            "Max Inputs Length": 494,
            "Max Targets Length": 13,
            "Min Inputs Length": 138,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "recast_white/dpr"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/recast_white",
            "HF Config": "pietrolesci--recast_white",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Language and communication",
                "Communication",
                "Language comprehension",
                "Language understanding",
                "Entertainment",
                "Linguistics",
                "Animal behavior",
                "Reasoning",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2022-04-22",
            "HF Downloads (September 2023)": 91,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-robust_nli-is_cs": {
        "Unique Dataset Identifier": "tsi-robust_nli-is_cs",
        "Dataset Name": "robust_nli-is_cs",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 557,
            "Mean Inputs Length": 319.079,
            "Mean Targets Length": 11.0592,
            "Max Inputs Length": 868,
            "Max Targets Length": 14,
            "Min Inputs Length": 127,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/easonnie/analyze-compositionality-sensitivity-NLI"
            },
            {
                "License": "MIT License",
                "License URL": "https://github.com/easonnie/analyze-compositionality-sensitivity-NLI"
            },
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/easonnie/analyze-compositionality-sensitivity-NLI"
            }
        ],
        "License Notes": "This subset is originally taken from https://github.com/easonnie/analyze-compositionality-sensitivity-NLI, which is MIT, but is derivative from SNLI (CC BY-SA 4.0) and MNLI (OANC)",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/IS_CS"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Retail industry",
                "Education",
                "Fundraising",
                "Daily routine",
                "Language and linguistics",
                "Linguistics",
                "Communication",
                "International relations",
                "History",
                "Cultural differences"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsi-robust_nli-li_li": {
        "Unique Dataset Identifier": "tsi-robust_nli-li_li",
        "Dataset Name": "robust_nli-li_li",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8437,
            "Mean Inputs Length": 235.444,
            "Mean Targets Length": 13.6768,
            "Max Inputs Length": 1784,
            "Max Targets Length": 14,
            "Min Inputs Length": 116,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/AbhilashaRavichander/NLI_StressTest"
            }
        ],
        "License Notes": "This subset is originally taken from https://github.com/AbhilashaRavichander/NLI_StressTest, derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/LI_LI"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "Daily routine",
                "Cultural diversity",
                "Culture",
                "Communication",
                "Cultural differences",
                "Visual perception",
                "Language and semantics",
                "Language understanding",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsi-robust_nli-st_wo": {
        "Unique Dataset Identifier": "tsi-robust_nli-st_wo",
        "Dataset Name": "robust_nli-st_wo",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8357,
            "Mean Inputs Length": 292.6653,
            "Mean Targets Length": 11.0438,
            "Max Inputs Length": 1071,
            "Max Targets Length": 14,
            "Min Inputs Length": 128,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/AbhilashaRavichander/NLI_StressTest"
            }
        ],
        "License Notes": "This subset is originally taken from https://github.com/AbhilashaRavichander/NLI_StressTest, derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/ST_WO"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Aviation",
                "Language and communication",
                "Personal preferences",
                "Communication",
                "Education",
                "Linguistics",
                "Language and linguistics"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsi-robust_nli-pi_sp": {
        "Unique Dataset Identifier": "tsi-robust_nli-pi_sp",
        "Dataset Name": "robust_nli-pi_sp",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 315,
            "Mean Inputs Length": 296.7143,
            "Mean Targets Length": 9.6476,
            "Max Inputs Length": 819,
            "Max Targets Length": 14,
            "Min Inputs Length": 129,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://aclanthology.org/2020.lrec-1.846/"
            },
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://aclanthology.org/2020.lrec-1.846/"
            }
        ],
        "License Notes": "This subset is originally derived from SNLI and MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/PI_SP"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Language and communication",
                "Aviation",
                "Storytelling",
                "Communication",
                "Language and linguistics",
                "International relations",
                "Politics",
                "Time management",
                "Religion",
                "Decision-making"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsi-robust_nli-pi_cd": {
        "Unique Dataset Identifier": "tsi-robust_nli-pi_cd",
        "Dataset Name": "robust_nli-pi_cd",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2771,
            "Mean Inputs Length": 206.1703,
            "Mean Targets Length": 11.0747,
            "Max Inputs Length": 399,
            "Max Targets Length": 14,
            "Min Inputs Length": 124,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://aclanthology.org/N18-2017/"
            },
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://aclanthology.org/N18-2017/"
            }
        ],
        "License Notes": "This subset is originally derived from SNLI and MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/PI_CD"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Animals",
                "Visual perception",
                "Outdoor activities",
                "Fashion",
                "Daily life",
                "Sports",
                "Physical activities",
                "Daily routine",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsi-robust_nli-st_se": {
        "Unique Dataset Identifier": "tsi-robust_nli-st_se",
        "Dataset Name": "robust_nli-st_se",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 26529,
            "Mean Inputs Length": 272.4168,
            "Mean Targets Length": 10.991,
            "Max Inputs Length": 1167,
            "Max Targets Length": 14,
            "Min Inputs Length": 112,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/AbhilashaRavichander/NLI_StressTest"
            }
        ],
        "License Notes": "This subset is originally taken from https://github.com/AbhilashaRavichander/NLI_StressTest, derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/ST_SE"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Politics",
                "Health",
                "Education",
                "Daily routine",
                "History",
                "Economics",
                "Language understanding",
                "Time management"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsi-robust_nli-st_ne": {
        "Unique Dataset Identifier": "tsi-robust_nli-st_ne",
        "Dataset Name": "robust_nli-st_ne",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8357,
            "Mean Inputs Length": 297.6653,
            "Mean Targets Length": 11.0438,
            "Max Inputs Length": 1076,
            "Max Targets Length": 14,
            "Min Inputs Length": 133,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/AbhilashaRavichander/NLI_StressTest"
            }
        ],
        "License Notes": "This subset is originally taken from https://github.com/AbhilashaRavichander/NLI_StressTest, derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/ST_NE"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Language and linguistics",
                "Language understanding",
                "Communication",
                "Terrorism",
                "Language and communication",
                "Child development",
                "Aviation"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsi-robust_nli-st_lm": {
        "Unique Dataset Identifier": "tsi-robust_nli-st_lm",
        "Dataset Name": "robust_nli-st_lm",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tyliupku/nli-debiasing-datasets",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8357,
            "Mean Inputs Length": 355.3412,
            "Mean Targets Length": 11.0438,
            "Max Inputs Length": 1095,
            "Max Targets Length": 14,
            "Min Inputs Length": 196,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/AbhilashaRavichander/NLI_StressTest"
            }
        ],
        "License Notes": "This subset is originally taken from https://github.com/AbhilashaRavichander/NLI_StressTest, derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli/ST_LM"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Language understanding",
                "Cognitive processes and reasoning",
                "Philosophy",
                "Education",
                "Language and communication",
                "General knowledge",
                "Logic",
                "Linguistics",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 237,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsi-robust_nli_is_sd": {
        "Unique Dataset Identifier": "tsi-robust_nli_is_sd",
        "Dataset Name": "robust_nli_is_sd",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/pietrolesci/robust_nli_is_sd",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli_is_sd",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 25500,
            "Mean Inputs Length": 168.6208,
            "Mean Targets Length": 12.9969,
            "Max Inputs Length": 218,
            "Max Targets Length": 15,
            "Min Inputs Length": 114,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://aclanthology.org/P19-1334/"
            }
        ],
        "License Notes": "Derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli_is_sd"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_is_sd",
            "HF Config": "pietrolesci--robust_nli_is_sd",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Textual entailment",
                "Communication",
                "Logic and reasoning",
                "Language and communication",
                "Semantics",
                "Logic",
                "Natural language processing",
                "Sentence structure",
                "Linguistics",
                "Language understanding"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 33,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsi-robust_nli_li_ts": {
        "Unique Dataset Identifier": "tsi-robust_nli_li_ts",
        "Dataset Name": "robust_nli_li_ts",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/pietrolesci/robust_nli_is_sd",
        "GitHub URL": "https://github.com/huggingface/datasets/issues/4211",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/robust_nli_li_ts",
        "Paper Title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03777",
        "Semantic Scholar Corpus ID": 222208690,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Natural Language Inference",
            "Paraphrase Detection",
            "Question Answering",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8357,
            "Mean Inputs Length": 273.656,
            "Mean Targets Length": 16.6742,
            "Max Inputs Length": 1050,
            "Max Targets Length": 18,
            "Min Inputs Length": 108,
            "Min Targets Length": 14,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Peng Cheng Laboratory",
            "Beijing University of Posts and Telecommunications",
            "University of Chicago"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://huggingface.co/datasets/pietrolesci/robust_nli_is_sd"
            }
        ],
        "License Notes": "Derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robust_nli_li_ts"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/robust_nli_li_ts",
            "HF Config": "pietrolesci--robust_nli_li_ts",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-08",
            "GitHub License": "",
            "Text Topics": [
                "Personal preferences",
                "Language and communication",
                "Geography",
                "Literature",
                "History",
                "Communication",
                "Education",
                "Linguistics",
                "Aviation"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 33,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [
            "snli",
            "mnli",
            "anli",
            "https://huggingface.co/datasets/metaeval/recast"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020AnES,\n author = {Tianyu Liu and Xin Zheng and Xiaoan Ding and Baobao Chang and Zhifang Sui},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference},\n volume = {abs/2010.03777},\n year = {2020}\n}\n"
    },
    "tsi-gen_debiased_nli-snli_seq_z": {
        "Unique Dataset Identifier": "tsi-gen_debiased_nli-snli_seq_z",
        "Dataset Name": "gen_debiased_nli-snli_seq_z",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "GitHub URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/gen_debiased_nli",
        "Paper Title": "Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets",
        "Papers with Code URL": "https://paperswithcode.com/dataset/gd-nli",
        "ArXiv URL": "https://arxiv.org/abs/2203.12942",
        "Semantic Scholar Corpus ID": 247628095,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 193.4862,
            "Mean Targets Length": 11.0301,
            "Max Inputs Length": 558,
            "Max Targets Length": 14,
            "Min Inputs Length": 115,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "University College London",
            "Microsoft Semantic Machines",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/jimmycode/gen-debiased-nli"
            }
        ],
        "License Notes": "Derived from SNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "gen_debiased_nli/snli_seq_z"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/gen_debiased_nli",
            "HF Config": "pietrolesci--gen_debiased_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-03-24",
            "S2 Date": "2022-03-24",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Daily routine",
                "Geography",
                "Entertainment",
                "Transportation",
                "Outdoor activities",
                "Culture",
                "Sports"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 177,
            "HF Likes (September 2023)": 0,
            "PwC Description": "This is a set of debiased Natural Language Inference (NLI) datasets produced by the paper  Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets. The datasets are constructed by augmenting SNLI or MNLI with data samples that are generated to mitigate the spurious correlations in the original datasets. Please visit this repository for more details.\n\nCitation:\n@inproceedings{gen-debiased-nli-2022,\n    title = \"Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets\",\n    author = \"Wu, Yuxiang  and\n      Gardner, Matt  and\n      Stenetorp, Pontus  and\n      Dasigi, Pradeep\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\",\n    month = may,\n    year = \"2022\",\n    publisher = \"Association for Computational Linguistics\",\n}",
            "S2 Citation Count (September 2023)": 31,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "MNLI"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wu2022GeneratingDT,\n author = {Yuxiang Wu and Matt Gardner and Pontus Stenetorp and Pradeep Dasigi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets},\n volume = {abs/2203.12942},\n year = {2022}\n}\n"
    },
    "tsi-gen_debiased_nli-snli_z_aug": {
        "Unique Dataset Identifier": "tsi-gen_debiased_nli-snli_z_aug",
        "Dataset Name": "gen_debiased_nli-snli_z_aug",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "GitHub URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/gen_debiased_nli",
        "Paper Title": "Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets",
        "Papers with Code URL": "https://paperswithcode.com/dataset/gd-nli",
        "ArXiv URL": "https://arxiv.org/abs/2203.12942",
        "Semantic Scholar Corpus ID": 247628095,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 195.8438,
            "Mean Targets Length": 11.0211,
            "Max Inputs Length": 650,
            "Max Targets Length": 14,
            "Min Inputs Length": 121,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "University College London",
            "Microsoft Semantic Machines",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/jimmycode/gen-debiased-nli"
            }
        ],
        "License Notes": "Derived from SNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "gen_debiased_nli/snli_z_aug"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/gen_debiased_nli",
            "HF Config": "pietrolesci--gen_debiased_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-03-24",
            "S2 Date": "2022-03-24",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Fashion and clothing",
                "Daily routine",
                "Visual perception",
                "Sports",
                "Culture",
                "Geography",
                "Performing arts",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 177,
            "HF Likes (September 2023)": 0,
            "PwC Description": "This is a set of debiased Natural Language Inference (NLI) datasets produced by the paper  Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets. The datasets are constructed by augmenting SNLI or MNLI with data samples that are generated to mitigate the spurious correlations in the original datasets. Please visit this repository for more details.\n\nCitation:\n@inproceedings{gen-debiased-nli-2022,\n    title = \"Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets\",\n    author = \"Wu, Yuxiang  and\n      Gardner, Matt  and\n      Stenetorp, Pontus  and\n      Dasigi, Pradeep\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\",\n    month = may,\n    year = \"2022\",\n    publisher = \"Association for Computational Linguistics\",\n}",
            "S2 Citation Count (September 2023)": 31,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "MNLI"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wu2022GeneratingDT,\n author = {Yuxiang Wu and Matt Gardner and Pontus Stenetorp and Pradeep Dasigi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets},\n volume = {abs/2203.12942},\n year = {2022}\n}\n"
    },
    "tsi-gen_debiased_nli-snli_par_z": {
        "Unique Dataset Identifier": "tsi-gen_debiased_nli-snli_par_z",
        "Dataset Name": "gen_debiased_nli-snli_par_z",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "GitHub URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/gen_debiased_nli",
        "Paper Title": "Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets",
        "Papers with Code URL": "https://paperswithcode.com/dataset/gd-nli",
        "ArXiv URL": "https://arxiv.org/abs/2203.12942",
        "Semantic Scholar Corpus ID": 247628095,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 193.6723,
            "Mean Targets Length": 11.0419,
            "Max Inputs Length": 510,
            "Max Targets Length": 14,
            "Min Inputs Length": 119,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "University College London",
            "Microsoft Semantic Machines",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/jimmycode/gen-debiased-nli"
            }
        ],
        "License Notes": "Derived from SNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "gen_debiased_nli/snli_par_z"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/gen_debiased_nli",
            "HF Config": "pietrolesci--gen_debiased_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-03-24",
            "S2 Date": "2022-03-24",
            "GitHub License": "",
            "Text Topics": [
                "Photography",
                "General knowledge",
                "Sports",
                "Politics",
                "Communication",
                "Daily routine",
                "Entertainment",
                "Culture",
                "Visual perception",
                "Social interactions"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 177,
            "HF Likes (September 2023)": 0,
            "PwC Description": "This is a set of debiased Natural Language Inference (NLI) datasets produced by the paper  Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets. The datasets are constructed by augmenting SNLI or MNLI with data samples that are generated to mitigate the spurious correlations in the original datasets. Please visit this repository for more details.\n\nCitation:\n@inproceedings{gen-debiased-nli-2022,\n    title = \"Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets\",\n    author = \"Wu, Yuxiang  and\n      Gardner, Matt  and\n      Stenetorp, Pontus  and\n      Dasigi, Pradeep\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\",\n    month = may,\n    year = \"2022\",\n    publisher = \"Association for Computational Linguistics\",\n}",
            "S2 Citation Count (September 2023)": 31,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "MNLI"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wu2022GeneratingDT,\n author = {Yuxiang Wu and Matt Gardner and Pontus Stenetorp and Pradeep Dasigi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets},\n volume = {abs/2203.12942},\n year = {2022}\n}\n"
    },
    "tsi-gen_debiased_nli-mnli_par_z": {
        "Unique Dataset Identifier": "tsi-gen_debiased_nli-mnli_par_z",
        "Dataset Name": "gen_debiased_nli-mnli_par_z",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/jimmycode/gen-debiased-nli",
        "GitHub URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/gen_debiased_nli",
        "Paper Title": "Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets",
        "Papers with Code URL": "https://paperswithcode.com/dataset/gd-nli",
        "ArXiv URL": "https://arxiv.org/abs/2203.12942",
        "Semantic Scholar Corpus ID": 247628095,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 265.3955,
            "Mean Targets Length": 10.9981,
            "Max Inputs Length": 1047,
            "Max Targets Length": 14,
            "Min Inputs Length": 104,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "University College London",
            "Microsoft Semantic Machines",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/jimmycode/gen-debiased-nli"
            }
        ],
        "License Notes": "Derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "gen_debiased_nli/mnli_par_z"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/gen_debiased_nli",
            "HF Config": "pietrolesci--gen_debiased_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-03-24",
            "S2 Date": "2022-03-24",
            "GitHub License": "",
            "Text Topics": [
                "Politics",
                "Travel",
                "Journalism",
                "Tourism",
                "Communication",
                "Geography",
                "International relations",
                "Architecture",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 177,
            "HF Likes (September 2023)": 0,
            "PwC Description": "This is a set of debiased Natural Language Inference (NLI) datasets produced by the paper  Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets. The datasets are constructed by augmenting SNLI or MNLI with data samples that are generated to mitigate the spurious correlations in the original datasets. Please visit this repository for more details.\n\nCitation:\n@inproceedings{gen-debiased-nli-2022,\n    title = \"Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets\",\n    author = \"Wu, Yuxiang  and\n      Gardner, Matt  and\n      Stenetorp, Pontus  and\n      Dasigi, Pradeep\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\",\n    month = may,\n    year = \"2022\",\n    publisher = \"Association for Computational Linguistics\",\n}",
            "S2 Citation Count (September 2023)": 31,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "MNLI"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wu2022GeneratingDT,\n author = {Yuxiang Wu and Matt Gardner and Pontus Stenetorp and Pradeep Dasigi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets},\n volume = {abs/2203.12942},\n year = {2022}\n}\n"
    },
    "tsi-gen_debiased_nli-mnli_z_aug": {
        "Unique Dataset Identifier": "tsi-gen_debiased_nli-mnli_z_aug",
        "Dataset Name": "gen_debiased_nli-mnli_z_aug",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/jimmycode/gen-debiased-nli",
        "GitHub URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/gen_debiased_nli",
        "Paper Title": "Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets",
        "Papers with Code URL": "https://paperswithcode.com/dataset/gd-nli",
        "ArXiv URL": "https://arxiv.org/abs/2203.12942",
        "Semantic Scholar Corpus ID": 247628095,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 265.4636,
            "Mean Targets Length": 11.0034,
            "Max Inputs Length": 1457,
            "Max Targets Length": 14,
            "Min Inputs Length": 105,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "University College London",
            "Microsoft Semantic Machines",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/jimmycode/gen-debiased-nli"
            }
        ],
        "License Notes": "Derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "gen_debiased_nli/mnli_z_aug"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/gen_debiased_nli",
            "HF Config": "pietrolesci--gen_debiased_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-03-24",
            "S2 Date": "2022-03-24",
            "GitHub License": "",
            "Text Topics": [
                "Language and communication",
                "Politics",
                "History",
                "General knowledge",
                "Religion",
                "Communication",
                "Geography",
                "Linguistics",
                "Journalism",
                "Travel"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 177,
            "HF Likes (September 2023)": 0,
            "PwC Description": "This is a set of debiased Natural Language Inference (NLI) datasets produced by the paper  Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets. The datasets are constructed by augmenting SNLI or MNLI with data samples that are generated to mitigate the spurious correlations in the original datasets. Please visit this repository for more details.\n\nCitation:\n@inproceedings{gen-debiased-nli-2022,\n    title = \"Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets\",\n    author = \"Wu, Yuxiang  and\n      Gardner, Matt  and\n      Stenetorp, Pontus  and\n      Dasigi, Pradeep\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\",\n    month = may,\n    year = \"2022\",\n    publisher = \"Association for Computational Linguistics\",\n}",
            "S2 Citation Count (September 2023)": 31,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "MNLI"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wu2022GeneratingDT,\n author = {Yuxiang Wu and Matt Gardner and Pontus Stenetorp and Pradeep Dasigi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets},\n volume = {abs/2203.12942},\n year = {2022}\n}\n"
    },
    "tsi-gen_debiased_nli-mnli_seq_z": {
        "Unique Dataset Identifier": "tsi-gen_debiased_nli-mnli_seq_z",
        "Dataset Name": "gen_debiased_nli-mnli_seq_z",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/jimmycode/gen-debiased-nli",
        "GitHub URL": "https://github.com/jimmycode/gen-debiased-nli#training-with-our-datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/gen_debiased_nli",
        "Paper Title": "Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets",
        "Papers with Code URL": "https://paperswithcode.com/dataset/gd-nli",
        "ArXiv URL": "https://arxiv.org/abs/2203.12942",
        "Semantic Scholar Corpus ID": 247628095,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 265.1557,
            "Mean Targets Length": 10.9734,
            "Max Inputs Length": 1044,
            "Max Targets Length": 14,
            "Min Inputs Length": 109,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "University College London",
            "Microsoft Semantic Machines",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "OANC",
                "License URL": "https://github.com/jimmycode/gen-debiased-nli"
            }
        ],
        "License Notes": "Derived from MNLI",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "gen_debiased_nli/mnli_seq_z"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/gen_debiased_nli",
            "HF Config": "pietrolesci--gen_debiased_nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-03-24",
            "S2 Date": "2022-03-24",
            "GitHub License": "",
            "Text Topics": [
                "Politics",
                "Geography",
                "Language understanding",
                "Religion",
                "Travel",
                "History",
                "Linguistics",
                "Language and communication",
                "Communication",
                "Technology"
            ],
            "Github Date": "",
            "HF Date": "2022-04-25",
            "HF Downloads (September 2023)": 177,
            "HF Likes (September 2023)": 0,
            "PwC Description": "This is a set of debiased Natural Language Inference (NLI) datasets produced by the paper  Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets. The datasets are constructed by augmenting SNLI or MNLI with data samples that are generated to mitigate the spurious correlations in the original datasets. Please visit this repository for more details.\n\nCitation:\n@inproceedings{gen-debiased-nli-2022,\n    title = \"Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets\",\n    author = \"Wu, Yuxiang  and\n      Gardner, Matt  and\n      Stenetorp, Pontus  and\n      Dasigi, Pradeep\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\",\n    month = may,\n    year = \"2022\",\n    publisher = \"Association for Computational Linguistics\",\n}",
            "S2 Citation Count (September 2023)": 31,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "MNLI"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wu2022GeneratingDT,\n author = {Yuxiang Wu and Matt Gardner and Pontus Stenetorp and Pradeep Dasigi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets},\n volume = {abs/2203.12942},\n year = {2022}\n}\n"
    },
    "tsi-add_one_rte": {
        "Unique Dataset Identifier": "tsi-add_one_rte",
        "Dataset Name": "add_one_rte",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/rabeehk/robust-nli/blob/c32ff958d4df68ac2fad9bf990f70d30eab9f297/data/scripts/add_one_rte.py",
        "GitHub URL": "https://github.com/rabeehk/robust-nli/blob/c32ff958d4df68ac2fad9bf990f70d30eab9f297/data/scripts/add_one_rte.py#L51-L52",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/add_one_rte",
        "Paper Title": "End-to-End Bias Mitigation by Modelling Biases in Corpora",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1909.06321",
        "Semantic Scholar Corpus ID": 215191351,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4481,
            "Mean Inputs Length": 206.8567,
            "Mean Targets Length": 12.0788,
            "Max Inputs Length": 827,
            "Max Targets Length": 13,
            "Min Inputs Length": 105,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "rte"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "EPFL",
            "Harvard University",
            "Massachusetts Institute of Technology",
            "Idiap Research Institute"
        ],
        "Licenses": [
            {
                "License": "Non Commercial",
                "License URL": "https://tac.nist.gov/data/forms/index.html"
            }
        ],
        "License Notes": "Non-commercial, research only",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "add_one_rte"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/add_one_rte",
            "HF Config": "pietrolesci--add_one_rte",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-09-13",
            "GitHub License": "",
            "Text Topics": [
                "Language and linguistics",
                "Language and semantics",
                "Language and communication",
                "Inference",
                "Language understanding",
                "Sports",
                "Logic",
                "Politics"
            ],
            "Github Date": "",
            "HF Date": "2022-04-22",
            "HF Downloads (September 2023)": 44,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 117,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Mahabadi2019EndtoEndBM,\n author = {Rabeeh Karimi Mahabadi and Yonatan Belinkov and J. Henderson},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8706-8716},\n title = {End-to-End Bias Mitigation by Modelling Biases in Corpora},\n year = {2019}\n}\n"
    },
    "tsi-imppres-presupposition_all_n_presupposition-presupposition": {
        "Unique Dataset Identifier": "tsi-imppres-presupposition_all_n_presupposition-presupposition",
        "Dataset Name": "imppres-presupposition_all_n_presupposition-presupposition",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1615,
            "Mean Inputs Length": 226.226,
            "Mean Targets Length": 11.6898,
            "Max Inputs Length": 356,
            "Max Targets Length": 15,
            "Min Inputs Length": 168,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_all_n_presupposition/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Language and communication",
                "Mathematics",
                "Logic and reasoning",
                "Linguistics",
                "Language understanding",
                "Education"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-presupposition_both_presupposition-presupposition": {
        "Unique Dataset Identifier": "tsi-imppres-presupposition_both_presupposition-presupposition",
        "Dataset Name": "imppres-presupposition_both_presupposition-presupposition",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1615,
            "Mean Inputs Length": 214.4644,
            "Mean Targets Length": 11.6898,
            "Max Inputs Length": 359,
            "Max Targets Length": 15,
            "Min Inputs Length": 165,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_both_presupposition/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Language and communication",
                "Mathematics",
                "Language understanding",
                "General knowledge",
                "Linguistics",
                "Communication",
                "Reasoning",
                "Logic and reasoning",
                "Education",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-presupposition_change_of_state-presupposition": {
        "Unique Dataset Identifier": "tsi-imppres-presupposition_change_of_state-presupposition",
        "Dataset Name": "imppres-presupposition_change_of_state-presupposition",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1615,
            "Mean Inputs Length": 152.9238,
            "Mean Targets Length": 11.6898,
            "Max Inputs Length": 189,
            "Max Targets Length": 15,
            "Min Inputs Length": 122,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_change_of_state/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Health",
                "General knowledge",
                "Relationships",
                "Daily routine",
                "Logic",
                "Language understanding",
                "Identity",
                "Employment",
                "Linguistics"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-presupposition_cleft_existence-presupposition": {
        "Unique Dataset Identifier": "tsi-imppres-presupposition_cleft_existence-presupposition",
        "Dataset Name": "imppres-presupposition_cleft_existence-presupposition",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1615,
            "Mean Inputs Length": 181.5152,
            "Mean Targets Length": 11.6898,
            "Max Inputs Length": 256,
            "Max Targets Length": 15,
            "Min Inputs Length": 141,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_cleft_existence/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Daily routine",
                "Logic",
                "Interpersonal relationships",
                "Communication",
                "Relationships",
                "Linguistics"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-presupposition_only_presupposition-presupposition": {
        "Unique Dataset Identifier": "tsi-imppres-presupposition_only_presupposition-presupposition",
        "Dataset Name": "imppres-presupposition_only_presupposition-presupposition",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1615,
            "Mean Inputs Length": 170.278,
            "Mean Targets Length": 11.6898,
            "Max Inputs Length": 253,
            "Max Targets Length": 15,
            "Min Inputs Length": 124,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_only_presupposition/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Daily routine",
                "Language and communication",
                "Relationships",
                "Logic",
                "Health",
                "Logic and reasoning",
                "Communication",
                "Language understanding"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-presupposition_possessed_definites_existence-presupposition": {
        "Unique Dataset Identifier": "tsi-imppres-presupposition_possessed_definites_existence-presupposition",
        "Dataset Name": "imppres-presupposition_possessed_definites_existence-presupposition",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1615,
            "Mean Inputs Length": 167.2483,
            "Mean Targets Length": 11.6898,
            "Max Inputs Length": 245,
            "Max Targets Length": 15,
            "Min Inputs Length": 137,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_possessed_definites_existence/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Personal preferences",
                "Daily routine",
                "Logic",
                "Relationships",
                "Language and communication",
                "Communication",
                "Social interactions"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-presupposition_possessed_definites_uniqueness-presupposition": {
        "Unique Dataset Identifier": "tsi-imppres-presupposition_possessed_definites_uniqueness-presupposition",
        "Dataset Name": "imppres-presupposition_possessed_definites_uniqueness-presupposition",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1615,
            "Mean Inputs Length": 216.9263,
            "Mean Targets Length": 11.6898,
            "Max Inputs Length": 289,
            "Max Targets Length": 15,
            "Min Inputs Length": 169,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_possessed_definites_uniqueness/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Interpersonal relationships",
                "Perception and interpretation",
                "Photography",
                "Logic and reasoning",
                "Logic",
                "Reasoning",
                "Language understanding"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-presupposition_question_presupposition-presupposition": {
        "Unique Dataset Identifier": "tsi-imppres-presupposition_question_presupposition-presupposition",
        "Dataset Name": "imppres-presupposition_question_presupposition-presupposition",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1615,
            "Mean Inputs Length": 191.9573,
            "Mean Targets Length": 11.6898,
            "Max Inputs Length": 315,
            "Max Targets Length": 15,
            "Min Inputs Length": 141,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_question_presupposition/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Memory and forgetfulness",
                "General knowledge",
                "Logic",
                "Problem-solving",
                "Interpersonal relationships",
                "Education",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-presupposition_cleft_uniqueness-presupposition": {
        "Unique Dataset Identifier": "tsi-imppres-presupposition_cleft_uniqueness-presupposition",
        "Dataset Name": "imppres-presupposition_cleft_uniqueness-presupposition",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1615,
            "Mean Inputs Length": 194.4254,
            "Mean Targets Length": 11.6898,
            "Max Inputs Length": 277,
            "Max Targets Length": 15,
            "Min Inputs Length": 151,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/presupposition_cleft_uniqueness/presupposition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Reasoning",
                "Language understanding",
                "Personal identity",
                "Linguistics",
                "Language and communication",
                "Logic and reasoning",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-implicature_connectives-prag": {
        "Unique Dataset Identifier": "tsi-imppres-implicature_connectives-prag",
        "Dataset Name": "imppres-implicature_connectives-prag",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1020,
            "Mean Inputs Length": 229.6029,
            "Mean Targets Length": 23.5088,
            "Max Inputs Length": 350,
            "Max Targets Length": 24,
            "Min Inputs Length": 183,
            "Min Targets Length": 21,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_connectives/prag"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Language and semantics",
                "Pragmatics",
                "Language understanding",
                "Education",
                "Social interactions",
                "Communication",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-implicature_gradable_adjective-prag": {
        "Unique Dataset Identifier": "tsi-imppres-implicature_gradable_adjective-prag",
        "Dataset Name": "imppres-implicature_gradable_adjective-prag",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1020,
            "Mean Inputs Length": 168.2,
            "Mean Targets Length": 23.5088,
            "Max Inputs Length": 198,
            "Max Targets Length": 24,
            "Min Inputs Length": 152,
            "Min Targets Length": 21,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_gradable_adjective/prag"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Personal characteristics and traits",
                "Comparative adjectives",
                "Evaluating individuals",
                "Descriptive language",
                "Body size and appearance",
                "Language and semantics",
                "Language and communication",
                "Food"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-implicature_numerals_2_3-prag": {
        "Unique Dataset Identifier": "tsi-imppres-implicature_numerals_2_3-prag",
        "Dataset Name": "imppres-implicature_numerals_2_3-prag",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1020,
            "Mean Inputs Length": 195.6314,
            "Mean Targets Length": 22.3147,
            "Max Inputs Length": 246,
            "Max Targets Length": 24,
            "Min Inputs Length": 154,
            "Min Targets Length": 18,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_numerals_2_3/prag"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Daily routine",
                "Communication",
                "Language and communication",
                "Logic",
                "Language understanding",
                "Linguistics",
                "Education",
                "Pragmatics",
                "Interpersonal relationships",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-implicature_gradable_verb-prag": {
        "Unique Dataset Identifier": "tsi-imppres-implicature_gradable_verb-prag",
        "Dataset Name": "imppres-implicature_gradable_verb-prag",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1020,
            "Mean Inputs Length": 191.9588,
            "Mean Targets Length": 23.5088,
            "Max Inputs Length": 227,
            "Max Targets Length": 24,
            "Min Inputs Length": 147,
            "Min Targets Length": 21,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_gradable_verb/prag"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Daily routine",
                "Pragmatics",
                "Communication",
                "Social interactions",
                "Geography",
                "Language and communication",
                "Language understanding",
                "Personal experiences",
                "Travel"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-implicature_numerals_10_100-prag": {
        "Unique Dataset Identifier": "tsi-imppres-implicature_numerals_10_100-prag",
        "Dataset Name": "imppres-implicature_numerals_10_100-prag",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1020,
            "Mean Inputs Length": 200.102,
            "Mean Targets Length": 22.3147,
            "Max Inputs Length": 252,
            "Max Targets Length": 24,
            "Min Inputs Length": 161,
            "Min Targets Length": 18,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_numerals_10_100/prag"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Communication",
                "Linguistics",
                "Language and communication",
                "Education",
                "Pragmatics",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-implicature_modals-prag": {
        "Unique Dataset Identifier": "tsi-imppres-implicature_modals-prag",
        "Dataset Name": "imppres-implicature_modals-prag",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1020,
            "Mean Inputs Length": 193.3382,
            "Mean Targets Length": 23.5088,
            "Max Inputs Length": 318,
            "Max Targets Length": 24,
            "Min Inputs Length": 158,
            "Min Targets Length": 21,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_modals/prag"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Language and communication",
                "Linguistics",
                "Problem-solving",
                "Pragmatics",
                "Education",
                "Communication",
                "Ethics",
                "Social interactions",
                "Language understanding",
                "Communication and understanding"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-implicature_quantifiers-prag": {
        "Unique Dataset Identifier": "tsi-imppres-implicature_quantifiers-prag",
        "Dataset Name": "imppres-implicature_quantifiers-prag",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1020,
            "Mean Inputs Length": 189.3667,
            "Mean Targets Length": 23.5088,
            "Max Inputs Length": 245,
            "Max Targets Length": 24,
            "Min Inputs Length": 151,
            "Min Targets Length": 21,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_quantifiers/prag"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Language understanding",
                "Logic and reasoning",
                "Education",
                "General knowledge",
                "Customer behavior",
                "Logic",
                "Linguistics",
                "Language and communication",
                "Pragmatics",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-implicature_connectives-log": {
        "Unique Dataset Identifier": "tsi-imppres-implicature_connectives-log",
        "Dataset Name": "imppres-implicature_connectives-log",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1020,
            "Mean Inputs Length": 223.6029,
            "Mean Targets Length": 19.5353,
            "Max Inputs Length": 344,
            "Max Targets Length": 22,
            "Min Inputs Length": 177,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_connectives/log"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Relationships",
                "Language understanding",
                "Language and communication",
                "Reasoning",
                "Language",
                "Logic",
                "Grammar"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-implicature_gradable_adjective-log": {
        "Unique Dataset Identifier": "tsi-imppres-implicature_gradable_adjective-log",
        "Dataset Name": "imppres-implicature_gradable_adjective-log",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1020,
            "Mean Inputs Length": 162.2,
            "Mean Targets Length": 19.5353,
            "Max Inputs Length": 192,
            "Max Targets Length": 22,
            "Min Inputs Length": 146,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_gradable_adjective/log"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Language and semantics",
                "Language and communication",
                "Food",
                "Personal attributes",
                "Language understanding",
                "Communication",
                "Intelligence",
                "Semantics",
                "Logic",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-implicature_gradable_verb-log": {
        "Unique Dataset Identifier": "tsi-imppres-implicature_gradable_verb-log",
        "Dataset Name": "imppres-implicature_gradable_verb-log",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1020,
            "Mean Inputs Length": 185.9588,
            "Mean Targets Length": 19.5353,
            "Max Inputs Length": 221,
            "Max Targets Length": 22,
            "Min Inputs Length": 141,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_gradable_verb/log"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "Logic",
                "Reasoning",
                "Communication",
                "Linguistics",
                "Daily routine",
                "Language and communication",
                "Language"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-implicature_quantifiers-log": {
        "Unique Dataset Identifier": "tsi-imppres-implicature_quantifiers-log",
        "Dataset Name": "imppres-implicature_quantifiers-log",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1020,
            "Mean Inputs Length": 183.3667,
            "Mean Targets Length": 19.5353,
            "Max Inputs Length": 239,
            "Max Targets Length": 22,
            "Min Inputs Length": 145,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_quantifiers/log"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Reasoning",
                "Language",
                "Social interactions",
                "Communication",
                "Logic",
                "Language understanding",
                "Language and communication",
                "Linguistics"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-implicature_numerals_2_3-log": {
        "Unique Dataset Identifier": "tsi-imppres-implicature_numerals_2_3-log",
        "Dataset Name": "imppres-implicature_numerals_2_3-log",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1020,
            "Mean Inputs Length": 189.6314,
            "Mean Targets Length": 19.5353,
            "Max Inputs Length": 240,
            "Max Targets Length": 22,
            "Min Inputs Length": 148,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_numerals_2_3/log"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Language understanding",
                "Communication",
                "General knowledge",
                "Logic",
                "Mathematics",
                "Daily routine",
                "Education",
                "Reasoning"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-implicature_modals-log": {
        "Unique Dataset Identifier": "tsi-imppres-implicature_modals-log",
        "Dataset Name": "imppres-implicature_modals-log",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1020,
            "Mean Inputs Length": 187.3382,
            "Mean Targets Length": 19.5353,
            "Max Inputs Length": 312,
            "Max Targets Length": 22,
            "Min Inputs Length": 152,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_modals/log"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "Clothing",
                "Language",
                "Communication",
                "Relationships",
                "Logic",
                "Language and communication",
                "Ethics",
                "Linguistics",
                "Language understanding",
                "Education"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-imppres-implicature_numerals_10_100-log": {
        "Unique Dataset Identifier": "tsi-imppres-implicature_numerals_10_100-log",
        "Dataset Name": "imppres-implicature_numerals_10_100-log",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/Imppres",
        "GitHub URL": "https://github.com/facebookresearch/Imppres",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1020,
            "Mean Inputs Length": 194.102,
            "Mean Targets Length": 19.5353,
            "Max Inputs Length": 246,
            "Max Targets Length": 22,
            "Min Inputs Length": 155,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/Imppres#license"
            }
        ],
        "License Notes": "References 2 other databases used to help generate the data: https://github.com/facebookresearch/Imppres#the-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "imppres/implicature_numerals_10_100/log"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Education",
                "Medical profession",
                "Relationships",
                "Mathematics",
                "Reasoning",
                "Logic",
                "Language understanding"
            ],
            "Github Date": "",
            "HF Date": "2023-01-05",
            "HF Downloads (September 2023)": 752,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": 15,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "tsi-glue_diagnostics-diagnostics": {
        "Unique Dataset Identifier": "tsi-glue_diagnostics-diagnostics",
        "Dataset Name": "glue_diagnostics-diagnostics",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://gluebenchmark.com/diagnostics",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/glue_diagnostics",
        "Paper Title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
        "Papers with Code URL": "https://paperswithcode.com/dataset/glue",
        "ArXiv URL": "https://arxiv.org/abs/1804.07461",
        "Semantic Scholar Corpus ID": 5034059,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 938,
            "Mean Inputs Length": 288.6962,
            "Mean Targets Length": 10.6002,
            "Max Inputs Length": 675,
            "Max Targets Length": 14,
            "Min Inputs Length": 125,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "videos",
            "glosses",
            "forum posts",
            "twitter",
            "student answers",
            "wikipedia.org",
            "image descriptions"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University",
            "Paul G. Allen School of Computer Science & Engineering",
            "DeepMind"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "glue_diagnostics/diagnostics"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/glue_diagnostics",
            "HF Config": "pietrolesci--glue_diagnostics",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Various",
            "PwC License URL": "https://gluebenchmark.com/faq",
            "PwC Date": "2019-01-01",
            "S2 Date": "2018-04-20",
            "GitHub License": "",
            "Text Topics": [
                "Natural language processing",
                "Technology",
                "Language and communication",
                "Biology",
                "Linguistics",
                "History",
                "International relations"
            ],
            "Github Date": "",
            "HF Date": "2022-04-21",
            "HF Downloads (September 2023)": 52,
            "HF Likes (September 2023)": 0,
            "PwC Description": "General Language Understanding Evaluation (GLUE) benchmark is a collection of nine natural language understanding tasks, including single-sentence tasks CoLA and SST-2, similarity and paraphrasing tasks MRPC, STS-B and QQP, and natural language inference tasks MNLI, QNLI, RTE and WNLI.",
            "S2 Citation Count (September 2023)": 4366,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Wang2018GLUEAM,\n author = {Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},\n booktitle = {BlackboxNLP@EMNLP},\n pages = {353-355},\n title = {GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n year = {2018}\n}\n"
    },
    "tsi-hlgd": {
        "Unique Dataset Identifier": "tsi-hlgd",
        "Dataset Name": "hlgd",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/tingofurro/headline_grouping",
        "GitHub URL": "https://github.com/tingofurro/headline_grouping",
        "Hugging Face URL": "https://huggingface.co/datasets/hlgd",
        "Paper Title": "News Headline Grouping as a Challenging NLU Task",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hlgd",
        "ArXiv URL": "https://arxiv.org/abs/2105.05391",
        "Semantic Scholar Corpus ID": 232371994,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Paraphrase Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 15492,
            "Mean Inputs Length": 211.8487,
            "Mean Targets Length": 11.7017,
            "Max Inputs Length": 329,
            "Max Targets Length": 16,
            "Min Inputs Length": 149,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "cnn.com",
            "nytmes",
            "france24"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "UC Berkeley"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/tingofurro/headline_grouping/blob/main/LEGAL.md"
            }
        ],
        "License Notes": "Dataset is made of news headlines which fall under fair use according to this article: https://www.americanbar.org/groups/gpsolo/publications/gp_solo/2011/september/fair_use_news_reviews/",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "hlgd"
        ],
        "Inferred Metadata": {
            "HF Dataset": "hlgd",
            "HF Config": "default",
            "HF Config License": "Apache License 2.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "https://github.com/tingofurro/headline_grouping/blob/main/LICENSE",
            "PwC Date": "2021-05-12",
            "S2 Date": "2021-05-12",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Current events",
                "Government actions",
                "Social issues",
                "International relations",
                "News and current events",
                "News reporting",
                "Politics",
                "Natural disasters"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 999,
            "HF Likes (September 2023)": 2,
            "PwC Description": "The Headline Grouping dataset is a binary classification dataset on pairs of news headline.\nFor each pair of headline, the binary label indicates whether the two headlines are part of the same group (and describe the same underlying event), or whether they are in distinct groups.\nThe dataset contains a total of 20k annotated headline pairs, further split in a train, validation and test portions.",
            "S2 Citation Count (September 2023)": 12,
            "GitHub Stars": 11,
            "GitHub Topics": [
                "headline",
                "headline-generation",
                "headline-grouping",
                "headlines",
                "naacl2021",
                "news"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Laban2021NewsHG,\n author = {Philippe Laban and Lucas Bandarkar and Marti A. Hearst},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {News Headline Grouping as a Challenging NLU Task},\n volume = {abs/2105.05391},\n year = {2021}\n}\n"
    },
    "tsi-medical_questions_pairs": {
        "Unique Dataset Identifier": "tsi-medical_questions_pairs",
        "Dataset Name": "medical_questions_pairs",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/curai/medical-question-pair-dataset",
        "GitHub URL": "https://github.com/curai/medical-question-pair-dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/medical_questions_pairs",
        "Paper Title": "Effective Transfer Learning for Identifying Similar Questions: Matching User Questions to COVID-19 FAQs",
        "Papers with Code URL": "https://paperswithcode.com/dataset/medical-question-pairs",
        "ArXiv URL": "https://arxiv.org/abs/2008.13546",
        "Semantic Scholar Corpus ID": 221191709,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "BioMedical Question Answering",
            "Fact Checking"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2590,
            "Mean Inputs Length": 279.471,
            "Mean Targets Length": 5.5012,
            "Max Inputs Length": 670,
            "Max Targets Length": 6,
            "Min Inputs Length": 126,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "healthtap.com"
        ],
        "Model Generated": [],
        "Creators": [
            "EightSleep",
            "Curai",
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Hand written and labelled by Doctors at Curai: https://github.com/curai/medical-question-pair-dataset#medical-question-pairs-mqp-dataset",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "medical_questions_pairs"
        ],
        "Inferred Metadata": {
            "HF Dataset": "medical_questions_pairs",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-08-04",
            "S2 Date": "2020-07-06",
            "GitHub License": "",
            "Text Topics": [
                "Medical procedures",
                "Health",
                "Medical conditions",
                "Pregnancy",
                "Injury",
                "Medical advice",
                "Sexual health",
                "Medical symptoms",
                "Pain management",
                "Dermatology"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 35210,
            "HF Likes (September 2023)": 27,
            "PwC Description": "Medical Question Pairs (MQP) Dataset\nThis repository contains a dataset of 3048 similar and dissimilar medical question pairs hand-generated and labeled by Curai's doctors. The dataset is described in detail in our paper.\n\nMethodology\nWe present our doctors with a list of 1524 patient-asked questions randomly sampled from the publicly available crawl of HealthTap. Each question results in one similar and one different pair through the following instructions provided to the labelers:\n\n\nRewrite the original question in a different way while maintaining the same intent. Restructure the syntax as much as possible and change medical details that would not impact your response.\n e.g. \"I'm a 22-y-o female\" could become \"My 26 year old daughter\"\nCome up with a related but dissimilar question for which the answer to the original question would be WRONG OR IRRELEVANT. Use similar key words.\n\nThe first instruction generates a positive question pair (similar) and the second generates a negative question pair (different). With the above instructions, we intentionally frame the task such that positive question pairs can look very different by superficial metrics, and negative question pairs can conversely look very similar. This ensures that the task is not trivial.\n\nDataset format\nThe dataset is formatted as dr_id, question_1, question_2, label. We used 11 different doctors for this task so dr_id ranges from 1 to 11. The label is 1 if the question pair is similar and 0 otherwise.\n\nDataset statistics\nThe final dataset contains 4567 unique questions. The minimum, maximum, median and average number of tokens in these questions are 4, 81, 20 and 22.675 respectively showing there is reasonable variance in the length of the questions. The shortest question is Are fibroadenomas malignant?\n\nAn off-the-shelf medical entity recognizer finds around 1000 unique medical entities in the questions. Some of the top entity mentions were: physician, pregnancy, pain, lasting weeks, menstruation, emotional state, cancer, visual function, headache, bleeding, fever, sexual intercourse",
            "S2 Citation Count (September 2023)": 41,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{McCreery2020EffectiveTL,\n author = {Clara H. McCreery and Namit Katariya and A. Kannan and Manish Chablani and X. Amatriain},\n booktitle = {Knowledge Discovery and Data Mining},\n journal = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining},\n title = {Effective Transfer Learning for Identifying Similar Questions: Matching User Questions to COVID-19 FAQs},\n year = {2020}\n}\n"
    },
    "tsi-conll2003-pos_tags": {
        "Unique Dataset Identifier": "tsi-conll2003-pos_tags",
        "Dataset Name": "conll2003-pos_tags",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://www.aclweb.org/anthology/W03-0419/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/conll2003",
        "Paper Title": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/conll-2003",
        "ArXiv URL": "https://arxiv.org/abs/cs/0306050",
        "Semantic Scholar Corpus ID": 2470716,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Part-of-Speech Tagging",
            "Linguistic Analysis",
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 14041,
            "Mean Inputs Length": 202.797,
            "Mean Targets Length": 123.893,
            "Max Inputs Length": 659,
            "Max Targets Length": 839,
            "Min Inputs Length": 113,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reuters.com",
            "frankfurter rundshau newspaper"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Antwerp"
        ],
        "Licenses": [
            {
                "License": "Academic Research Purposes Only",
                "License URL": "https://huggingface.co/datasets/conll2003"
            },
            {
                "License": "Request Form",
                "License URL": "https://huggingface.co/datasets/conll2003"
            }
        ],
        "License Notes": "Huggingface has paper excerpts which say that you need to contact the corpus to get the data for research purposes: https://huggingface.co/datasets/conll2003#licensing-information",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "conll2003/pos_tags"
        ],
        "Inferred Metadata": {
            "HF Dataset": "conll2003",
            "HF Config": "conll2003",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2003-06-12",
            "S2 Date": "2003-05-31",
            "GitHub License": "",
            "Text Topics": [
                "Data analysis",
                "Sports",
                "Identity",
                "Daily routine",
                "Language and grammar",
                "Language",
                "General knowledge",
                "Geography",
                "Travel"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 79858,
            "HF Likes (September 2023)": 63,
            "PwC Description": "CoNLL-2003 is a named entity recognition dataset released as a part of CoNLL-2003 shared task: language-independent named entity recognition.\nThe data consists of eight files covering two languages: English and German.\nFor each of the languages there is a training file, a development file, a test file and a large file with unannotated data.\n\nThe English data was taken from the Reuters Corpus. This corpus consists of Reuters news stories between August 1996 and August 1997.\nFor the training and development set, ten days worth of data were taken from the files representing the end of August 1996.\nFor the test set, the texts were from December 1996. The preprocessed raw data covers the month of September 1996.\n\nThe text for the German data was taken from the ECI Multilingual Text Corpus. This corpus consists of texts in many languages. The portion of data that\nwas used for this task, was extracted from the German newspaper Frankfurter Rundshau. All three of the training, development and test sets were taken\nfrom articles written in one week at the end of August 1992.\nThe raw data were taken from the months of September to December 1992.\n\n| English      data | Articles | Sentences | Tokens  | LOC  | MISC | ORG  | PER  |\n|-------------------|----------|-----------|---------|------|------|------|------|\n| Training     set  | 946      | 14,987    | 203,621 | 7140 | 3438 | 6321 | 6600 |\n| Development  set  | 216      | 3,466     | 51,362  | 1837 | 922  | 1341 | 1842 |\n| Test         set  | 231      | 3,684     | 46,435  | 1668 | 702  | 1661 | 1617 |\n\nNumber of articles, sentences, tokens and entities (locations, miscellaneous, organizations, and persons) in English data files.\n\n| German       data | Articles | Sentences | Tokens  | LOC  | MISC | ORG  | PER  |\n|-------------------|----------|-----------|---------|------|------|------|------|\n| Training     set  | 553      | 12,705    | 206,931 | 4363 | 2288 | 2427 | 2773 |\n| Development  set  | 201      | 3,068     | 51,444  | 1181 | 1010 | 1241 | 1401 |\n| Test         set  | 155      | 3,160     | 51,943  | 1035 | 670  | 773  | 1195 |\n\nNumber of articles, sentences, tokens and entities (locations, miscellaneous, organizations, and persons) in German data files.",
            "S2 Citation Count (September 2023)": 3667,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sang2003IntroductionTT,\n author = {E. T. K. Sang and F. D. Meulder},\n booktitle = {Conference on Computational Natural Language Learning},\n pages = {142-147},\n title = {Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition},\n year = {2003}\n}\n"
    },
    "tsi-conll2003-chunk_tags": {
        "Unique Dataset Identifier": "tsi-conll2003-chunk_tags",
        "Dataset Name": "conll2003-chunk_tags",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://www.aclweb.org/anthology/W03-0419/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/conll2003",
        "Paper Title": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/conll-2003",
        "ArXiv URL": "https://arxiv.org/abs/cs/0306050",
        "Semantic Scholar Corpus ID": 2470716,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Part-of-Speech Tagging",
            "Question Answering",
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 14041,
            "Mean Inputs Length": 226.6458,
            "Mean Targets Length": 144.3316,
            "Max Inputs Length": 660,
            "Max Targets Length": 1039,
            "Min Inputs Length": 156,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reuters.com",
            "frankfurter rundshau newspaper"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Antwerp"
        ],
        "Licenses": [
            {
                "License": "Academic Research Purposes Only",
                "License URL": "https://huggingface.co/datasets/conll2003"
            },
            {
                "License": "Request Form",
                "License URL": "https://huggingface.co/datasets/conll2003"
            }
        ],
        "License Notes": "Huggingface has paper excerps which say that you need to contact the corpus to get the data for research purposes: https://huggingface.co/datasets/conll2003#licensing-information",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "conll2003/chunk_tags"
        ],
        "Inferred Metadata": {
            "HF Dataset": "conll2003",
            "HF Config": "conll2003",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2003-06-12",
            "S2 Date": "2003-05-31",
            "GitHub License": "",
            "Text Topics": [
                "Sports",
                "Geography",
                "Language processing",
                "Soccer",
                "Travel",
                "International relations",
                "Finance",
                "Health",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 79858,
            "HF Likes (September 2023)": 63,
            "PwC Description": "CoNLL-2003 is a named entity recognition dataset released as a part of CoNLL-2003 shared task: language-independent named entity recognition.\nThe data consists of eight files covering two languages: English and German.\nFor each of the languages there is a training file, a development file, a test file and a large file with unannotated data.\n\nThe English data was taken from the Reuters Corpus. This corpus consists of Reuters news stories between August 1996 and August 1997.\nFor the training and development set, ten days worth of data were taken from the files representing the end of August 1996.\nFor the test set, the texts were from December 1996. The preprocessed raw data covers the month of September 1996.\n\nThe text for the German data was taken from the ECI Multilingual Text Corpus. This corpus consists of texts in many languages. The portion of data that\nwas used for this task, was extracted from the German newspaper Frankfurter Rundshau. All three of the training, development and test sets were taken\nfrom articles written in one week at the end of August 1992.\nThe raw data were taken from the months of September to December 1992.\n\n| English      data | Articles | Sentences | Tokens  | LOC  | MISC | ORG  | PER  |\n|-------------------|----------|-----------|---------|------|------|------|------|\n| Training     set  | 946      | 14,987    | 203,621 | 7140 | 3438 | 6321 | 6600 |\n| Development  set  | 216      | 3,466     | 51,362  | 1837 | 922  | 1341 | 1842 |\n| Test         set  | 231      | 3,684     | 46,435  | 1668 | 702  | 1661 | 1617 |\n\nNumber of articles, sentences, tokens and entities (locations, miscellaneous, organizations, and persons) in English data files.\n\n| German       data | Articles | Sentences | Tokens  | LOC  | MISC | ORG  | PER  |\n|-------------------|----------|-----------|---------|------|------|------|------|\n| Training     set  | 553      | 12,705    | 206,931 | 4363 | 2288 | 2427 | 2773 |\n| Development  set  | 201      | 3,068     | 51,444  | 1181 | 1010 | 1241 | 1401 |\n| Test         set  | 155      | 3,160     | 51,943  | 1035 | 670  | 773  | 1195 |\n\nNumber of articles, sentences, tokens and entities (locations, miscellaneous, organizations, and persons) in German data files.",
            "S2 Citation Count (September 2023)": 3667,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sang2003IntroductionTT,\n author = {E. T. K. Sang and F. D. Meulder},\n booktitle = {Conference on Computational Natural Language Learning},\n pages = {142-147},\n title = {Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition},\n year = {2003}\n}\n"
    },
    "tsi-conll2003-ner_tags": {
        "Unique Dataset Identifier": "tsi-conll2003-ner_tags",
        "Dataset Name": "conll2003-ner_tags",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://www.aclweb.org/anthology/W03-0419/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/conll2003",
        "Paper Title": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/conll-2003",
        "ArXiv URL": "https://arxiv.org/abs/cs/0306050",
        "Semantic Scholar Corpus ID": 2470716,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 14041,
            "Mean Inputs Length": 215.8907,
            "Mean Targets Length": 115.9197,
            "Max Inputs Length": 651,
            "Max Targets Length": 742,
            "Min Inputs Length": 140,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reuters.com",
            "frankfurter rundshau newspaper"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Antwerp"
        ],
        "Licenses": [
            {
                "License": "Academic Research Purposes Only",
                "License URL": "https://huggingface.co/datasets/conll2003"
            },
            {
                "License": "Request Form",
                "License URL": "https://huggingface.co/datasets/conll2003"
            }
        ],
        "License Notes": "Huggingface has paper excerps which say that you need to contact the corpus to get the data for research purposes: https://huggingface.co/datasets/conll2003#licensing-information",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "conll2003/ner_tags"
        ],
        "Inferred Metadata": {
            "HF Dataset": "conll2003",
            "HF Config": "conll2003",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2003-06-12",
            "S2 Date": "2003-05-31",
            "GitHub License": "",
            "Text Topics": [
                "International relations",
                "Named Entity Recognition (NER)",
                "Finance",
                "Geography",
                "General knowledge",
                "History",
                "Identity"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 79858,
            "HF Likes (September 2023)": 63,
            "PwC Description": "CoNLL-2003 is a named entity recognition dataset released as a part of CoNLL-2003 shared task: language-independent named entity recognition.\nThe data consists of eight files covering two languages: English and German.\nFor each of the languages there is a training file, a development file, a test file and a large file with unannotated data.\n\nThe English data was taken from the Reuters Corpus. This corpus consists of Reuters news stories between August 1996 and August 1997.\nFor the training and development set, ten days worth of data were taken from the files representing the end of August 1996.\nFor the test set, the texts were from December 1996. The preprocessed raw data covers the month of September 1996.\n\nThe text for the German data was taken from the ECI Multilingual Text Corpus. This corpus consists of texts in many languages. The portion of data that\nwas used for this task, was extracted from the German newspaper Frankfurter Rundshau. All three of the training, development and test sets were taken\nfrom articles written in one week at the end of August 1992.\nThe raw data were taken from the months of September to December 1992.\n\n| English      data | Articles | Sentences | Tokens  | LOC  | MISC | ORG  | PER  |\n|-------------------|----------|-----------|---------|------|------|------|------|\n| Training     set  | 946      | 14,987    | 203,621 | 7140 | 3438 | 6321 | 6600 |\n| Development  set  | 216      | 3,466     | 51,362  | 1837 | 922  | 1341 | 1842 |\n| Test         set  | 231      | 3,684     | 46,435  | 1668 | 702  | 1661 | 1617 |\n\nNumber of articles, sentences, tokens and entities (locations, miscellaneous, organizations, and persons) in English data files.\n\n| German       data | Articles | Sentences | Tokens  | LOC  | MISC | ORG  | PER  |\n|-------------------|----------|-----------|---------|------|------|------|------|\n| Training     set  | 553      | 12,705    | 206,931 | 4363 | 2288 | 2427 | 2773 |\n| Development  set  | 201      | 3,068     | 51,444  | 1181 | 1010 | 1241 | 1401 |\n| Test         set  | 155      | 3,160     | 51,943  | 1035 | 670  | 773  | 1195 |\n\nNumber of articles, sentences, tokens and entities (locations, miscellaneous, organizations, and persons) in German data files.",
            "S2 Citation Count (September 2023)": 3667,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sang2003IntroductionTT,\n author = {E. T. K. Sang and F. D. Meulder},\n booktitle = {Conference on Computational Natural Language Learning},\n pages = {142-147},\n title = {Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition},\n year = {2003}\n}\n"
    },
    "tsi-hh_rlhf": {
        "Unique Dataset Identifier": "tsi-hh_rlhf",
        "Dataset Name": "hh_rlhf",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/anthropics/hh-rlhf",
        "GitHub URL": "https://github.com/anthropics/hh-rlhf",
        "Hugging Face URL": "https://huggingface.co/datasets/Anthropic/hh-rlhf",
        "Paper Title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs//2204.05862",
        "Semantic Scholar Corpus ID": 248118878,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 1963.3657,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 18940,
            "Max Targets Length": 2,
            "Min Inputs Length": 133,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "Anthropic AI"
        ],
        "Licenses": [
            {
                "License": "MIT License",
                "License URL": "https://github.com/anthropics/hh-rlhf"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "hh-rlhf"
        ],
        "Inferred Metadata": {
            "HF Dataset": "Anthropic/hh-rlhf",
            "HF Config": "Anthropic--hh-rlhf",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-04-12",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Health",
                "Food",
                "Travel",
                "Ethics and morality",
                "Cooking",
                "General knowledge",
                "Cultural differences",
                "Psychology"
            ],
            "Github Date": "",
            "HF Date": "2022-12-08",
            "HF Downloads (September 2023)": 103462,
            "HF Likes (September 2023)": 632,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 270,
            "GitHub Stars": 1123,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Bai2022TrainingAH,\n author = {Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and T. Henighan and Nicholas Joseph and Saurav Kadavath and John Kernion and Tom Conerly and S. El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and S. Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom B. Brown and Jack Clark and Sam McCandlish and C. Olah and Benjamin Mann and Jared Kaplan},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback},\n volume = {abs/2204.05862},\n year = {2022}\n}\n"
    },
    "tsi-model_written_evals": {
        "Unique Dataset Identifier": "tsi-model_written_evals",
        "Dataset Name": "model_written_evals",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/Anthropic/model-written-evals",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/Anthropic/model-written-evals",
        "Paper Title": "Discovering Language Model Behaviors with Model-Written Evaluations",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2212.09251",
        "Semantic Scholar Corpus ID": 254854519,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2764,
            "Mean Inputs Length": 201.4175,
            "Mean Targets Length": 4.0,
            "Max Inputs Length": 2533,
            "Max Targets Length": 4,
            "Min Inputs Length": 14,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "anthropic"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "Anthropic AI",
            "Surge AI",
            "Machine Intelligence Research Institute"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://huggingface.co/datasets/Anthropic/model-written-evals"
            }
        ],
        "License Notes": "Anthropic organization uploaded and set the license in Hugging Face themselves, so likely reliable",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "model-written-evals"
        ],
        "Inferred Metadata": {
            "HF Dataset": "Anthropic/model-written-evals",
            "HF Config": "Anthropic--model-written-evals",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-12-19",
            "GitHub License": "",
            "Text Topics": [
                "Machine learning",
                "Machine Learning",
                "Technology",
                "Artificial intelligence",
                "Sports",
                "Neural networks",
                "Natural language processing",
                "Optimization algorithms",
                "Artificial Intelligence",
                "Data analysis"
            ],
            "Github Date": "",
            "HF Date": "2022-12-21",
            "HF Downloads (September 2023)": 85,
            "HF Likes (September 2023)": 27,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 61,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Perez2022DiscoveringLM,\n author = {Ethan Perez and Sam Ringer and Kamil Lukoit and Karina Nguyen and Edwin Chen and Scott Heiner and Craig Pettit and Catherine Olsson and Sandipan Kundu and Saurav Kadavath and Andy Jones and Anna Chen and Benjamin Mann and Brian Israel and Bryan Seethor and C. McKinnon and C. Olah and Daisong Yan and D. Amodei and Dario Amodei and Dawn Drain and Dustin Li and Eli Tran-Johnson and G. Khundadze and John Kernion and J. Landis and Jamie Kerr and J. Mueller and Jeeyoon Hyun and J. Landau and Kamal Ndousse and L. Goldberg and Liane Lovitt and Martin Lucas and Michael Sellitto and Miranda Zhang and Neerav Kingsland and Nelson Elhage and Nicholas Joseph and Noem'i Mercado and Nova DasSarma and Oliver Rausch and Robin Larson and Sam McCandlish and Scott Johnston and S. Kravec and S. E. Showk and Tamera Lanham and Timothy Telleen-Lawton and Tom B. Brown and T. Henighan and Tristan Hume and Yuntao Bai and Zac Hatfield-Dodds and Jack Clark and Sam Bowman and Amanda Askell and Roger C. Grosse and Danny Hernandez and Deep Ganguli and Evan Hubinger and Nicholas Schiefer and Jared Kaplan},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Discovering Language Model Behaviors with Model-Written Evaluations},\n volume = {abs/2212.09251},\n year = {2022}\n}\n"
    },
    "tsi-truthful_qa-multiple_choice": {
        "Unique Dataset Identifier": "tsi-truthful_qa-multiple_choice",
        "Dataset Name": "truthful_qa-multiple_choice",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sylinrl/TruthfulQA",
        "GitHub URL": "https://github.com/sylinrl/TruthfulQA",
        "Hugging Face URL": "https://huggingface.co/datasets/truthful_qa",
        "Paper Title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods",
        "Papers with Code URL": "https://paperswithcode.com/dataset/truthfulqa",
        "ArXiv URL": "https://arxiv.org/abs/2109.07958",
        "Semantic Scholar Corpus ID": 237532606,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 694,
            "Mean Inputs Length": 229.0562,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 423,
            "Max Targets Length": 2,
            "Min Inputs Length": 120,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "human"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Oxford",
            "OpenAI"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Utilizes GPT-3 with human written questions to filter out questions into datasets: https://huggingface.co/datasets/truthful_qa#initial-data-collection-and-normalization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "truthful_qa/multiple_choice"
        ],
        "Inferred Metadata": {
            "HF Dataset": "truthful_qa",
            "HF Config": "generation",
            "HF Config License": "Apache License 2.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2021-09-08",
            "S2 Date": "2021-09-08",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "History",
                "General knowledge",
                "Travel",
                "Health",
                "Geography",
                "Logic",
                "Literature",
                "Biology"
            ],
            "Github Date": "",
            "HF Date": "2022-06-08",
            "HF Downloads (September 2023)": 316913,
            "HF Likes (September 2023)": 48,
            "PwC Description": "TruthfulQA is a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. The authors crafted questions that some humans would answer falsely due to a false belief or misconception.",
            "S2 Citation Count (September 2023)": 223,
            "GitHub Stars": 291,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Lin2021TruthfulQAMH,\n author = {Stephanie C. Lin and Jacob Hilton and Owain Evans},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {3214-3252},\n title = {TruthfulQA: Measuring How Models Mimic Human Falsehoods},\n year = {2021}\n}\n"
    },
    "tsi-fig_qa": {
        "Unique Dataset Identifier": "tsi-fig_qa",
        "Dataset Name": "fig_qa",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/nightingal3/Fig-QA",
        "GitHub URL": "https://github.com/nightingal3/Fig-QA",
        "Hugging Face URL": "https://huggingface.co/datasets/nightingal3/fig-qa",
        "Paper Title": "Testing the Ability of Language Models to Interpret Figurative Language",
        "Papers with Code URL": "https://paperswithcode.com/dataset/fig-qa",
        "ArXiv URL": "https://arxiv.org/abs/2204.12632",
        "Semantic Scholar Corpus ID": 248406097,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9674,
            "Mean Inputs Length": 169.4287,
            "Mean Targets Length": 2.018,
            "Max Inputs Length": 434,
            "Max Targets Length": 26,
            "Min Inputs Length": 35,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "fig-qa"
        ],
        "Inferred Metadata": {
            "HF Dataset": "nightingal3/fig-qa",
            "HF Config": "nightingal3--fig-qa",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "MIT License",
            "PwC License URL": "https://github.com/nightingal3/Fig-QA/blob/master/LICENSE",
            "PwC Date": "2022-04-26",
            "S2 Date": "2022-04-26",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Sensory perception",
                "Sports",
                "Animal behavior",
                "Comparisons",
                "Emotions",
                "Food and beverages",
                "Descriptive language",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-06-16",
            "HF Downloads (September 2023)": 100,
            "HF Likes (September 2023)": 2,
            "PwC Description": "Fig-QA consists of 10256 examples of human-written creative metaphors that are paired as a Winograd schema. It can be used to evaluate the commonsense reasoning of models. The metaphors themselves can also be used as training data for other tasks, such as metaphor detection or generation.",
            "S2 Citation Count (September 2023)": 21,
            "GitHub Stars": 13,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2022TestingTA,\n author = {Emmy Liu and Chenxuan Cui and Kenneth Zheng and Graham Neubig},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Testing the Ability of Language Models to Interpret Figurative Language},\n volume = {abs/2204.12632},\n year = {2022}\n}\n"
    },
    "tsi-social_i_qa": {
        "Unique Dataset Identifier": "tsi-social_i_qa",
        "Dataset Name": "social_i_qa",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://allenai.org/data/socialiqa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/social_i_qa",
        "Paper Title": "SocialIQA: Commonsense Reasoning about Social Interactions",
        "Papers with Code URL": "https://paperswithcode.com/dataset/social-iqa",
        "ArXiv URL": "https://arxiv.org/abs/1904.09728",
        "Semantic Scholar Corpus ID": 128296356,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 165.82,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 471,
            "Max Targets Length": 2,
            "Min Inputs Length": 108,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced (amt)"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "Paul G. Allen School of Computer Science & Engineering"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://allenai.org/data/socialiqa"
            }
        ],
        "License Notes": "Home page states that the data was crowdsourced: http://maartensap.com/social-iqa/",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "social_i_qa"
        ],
        "Inferred Metadata": {
            "HF Dataset": "social_i_qa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2019-04-22",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Social interactions",
                "Communication",
                "Personality traits",
                "Interpersonal relationships",
                "Decision-making",
                "Personal preferences",
                "Emotions and feelings",
                "Daily routine",
                "Communication skills",
                "Emotions"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 36880,
            "HF Likes (September 2023)": 4,
            "PwC Description": "Social Interaction QA (SIQA) is a question-answering benchmark for testing social commonsense intelligence. Contrary to many prior benchmarks that focus on physical or taxonomic knowledge, Social IQa focuses on reasoning about peoples actions and their social implications. For example, given an action like \"Jesse saw a concert\" and a question like \"Why did Jesse do this?\", humans can easily infer that Jesse wanted \"to see their favorite performer\" or \"to enjoy the music\", and not \"to see what's happening inside\" or \"to see if it works\". The actions in Social IQa span a wide variety of social situations, and answer candidates contain both human-curated answers and adversarially-filtered machine-generated candidates. Social IQa contains over 37,000 QA pairs for evaluating models abilities to reason about the social implications of everyday events and situations.",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": ""
    },
    "tsi-balanced_copa": {
        "Unique Dataset Identifier": "tsi-balanced_copa",
        "Dataset Name": "balanced_copa",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://balanced-copa.github.io/",
        "GitHub URL": "https://balanced-copa.github.io/",
        "Hugging Face URL": "https://huggingface.co/datasets/pkavumba/balanced-copa",
        "Paper Title": "When Choosing Plausible Alternatives, Clever Hans can be Clever",
        "Papers with Code URL": "https://paperswithcode.com/dataset/copa",
        "ArXiv URL": "https://arxiv.org/abs/1911.00225",
        "Semantic Scholar Corpus ID": 207780212,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1000,
            "Mean Inputs Length": 159.306,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 254,
            "Max Targets Length": 2,
            "Min Inputs Length": 111,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "human"
        ],
        "Model Generated": [],
        "Creators": [
            "Tohoku University",
            "RIKEN Center for Advanced Intelligence Project (AIP)"
        ],
        "Licenses": [
            {
                "License": "BSD 2-Clause License",
                "License URL": "https://people.ict.usc.edu/~gordon/copa.html"
            }
        ],
        "License Notes": "From what I can tell this is a remix of the original COPA dataset than was edited by people so I would assume it falls under the same license",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "balanced-copa"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pkavumba/balanced-copa",
            "HF Config": "pkavumba--balanced-copa",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "BSD 2-Clause License",
            "PwC License URL": "https://people.ict.usc.edu/~gordon/copa.html",
            "PwC Date": "2011-01-01",
            "S2 Date": "2019-11-01",
            "GitHub License": "",
            "Text Topics": [
                "Animal behavior",
                "Conflict resolution",
                "Health",
                "Personal experiences",
                "Weather",
                "Sports",
                "Food and eating habits",
                "Decision-making",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2022-10-03",
            "HF Downloads (September 2023)": 198,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The Choice Of Plausible Alternatives (COPA) evaluation provides researchers with a tool for assessing progress in open-domain commonsense causal reasoning. COPA consists of 1000 questions, split equally into development and test sets of 500 questions each. Each question is composed of a premise and two alternatives, where the task is to select the alternative that more plausibly has a causal relation with the premise. The correct alternative is randomized so that the expected performance of randomly guessing is 50%.",
            "S2 Citation Count (September 2023)": 29,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "COPA dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Kavumba2019WhenCP,\n author = {Pride Kavumba and Naoya Inoue and Benjamin Heinzerling and Keshav Singh and Paul Reisert and Kentaro Inui},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {When Choosing Plausible Alternatives, Clever Hans can be Clever},\n volume = {abs/1911.00225},\n year = {2019}\n}\n"
    },
    "tsi-e_care": {
        "Unique Dataset Identifier": "tsi-e_care",
        "Dataset Name": "e_care",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/waste-wood/e-care",
        "GitHub URL": "https://github.com/waste-wood/e-care",
        "Hugging Face URL": "https://huggingface.co/datasets/12ml/e-CARE",
        "Paper Title": "e-CARE: a New Dataset for Exploring Explainable Causal Reasoning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2205.05849",
        "Semantic Scholar Corpus ID": 248722161,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 14928,
            "Mean Inputs Length": 193.4137,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 456,
            "Max Targets Length": 2,
            "Min Inputs Length": 116,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "undisclosed web",
            "arc corpus"
        ],
        "Model Generated": [],
        "Creators": [
            "Harbin Institute of Technology"
        ],
        "Licenses": [
            {
                "License": "BSD 2-Clause License",
                "License URL": "https://huggingface.co/datasets/12ml/e-CARE#notes"
            }
        ],
        "License Notes": "Derived from COPA",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "e-CARE"
        ],
        "Inferred Metadata": {
            "HF Dataset": "12ml/e-CARE",
            "HF Config": "12ml--e-CARE",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-05-12",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Education",
                "Nutrition",
                "Botany",
                "Health",
                "History",
                "Biology",
                "Ecology",
                "Gardening",
                "Medical conditions",
                "Science"
            ],
            "Github Date": "",
            "HF Date": "2022-12-21",
            "HF Downloads (September 2023)": 30,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 16,
            "GitHub Stars": 45,
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "GenericsKB"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Du2022eCAREAN,\n author = {Li Du and Xiao Ding and Kai Xiong and Ting Liu and Bing Qin},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {e-CARE: a New Dataset for Exploring Explainable Causal Reasoning},\n volume = {abs/2205.05849},\n year = {2022}\n}\n"
    },
    "tsi-insincere_questions": {
        "Unique Dataset Identifier": "tsi-insincere_questions",
        "Dataset Name": "insincere_questions",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://www.kaggle.com/c/quora-insincere-questions-classification",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/SetFit/insincere-questions",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "BioMedical Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 165.6395,
            "Mean Targets Length": 15.2431,
            "Max Inputs Length": 348,
            "Max Targets Length": 19,
            "Min Inputs Length": 107,
            "Min Targets Length": 15,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "quora"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "insincere-questions"
        ],
        "Inferred Metadata": {
            "HF Dataset": "SetFit/insincere-questions",
            "HF Config": "SetFit--insincere-questions",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Education",
                "History",
                "Religion",
                "Geography",
                "Travel",
                "Philosophy",
                "Technology"
            ],
            "Github Date": "",
            "HF Date": "2022-01-19",
            "HF Downloads (September 2023)": 474,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-turingbench": {
        "Unique Dataset Identifier": "tsi-turingbench",
        "Dataset Name": "turingbench",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/TuringBench/TuringBench",
        "GitHub URL": "https://github.com/TuringBench/TuringBench",
        "Hugging Face URL": "https://huggingface.co/datasets/turingbench/TuringBench",
        "Paper Title": "TURINGBENCH: A Benchmark Environment for Turing Test in the Age of Neural Text Generation ",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2109.13296",
        "Semantic Scholar Corpus ID": 237589233,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 1356.8557,
            "Mean Targets Length": 9.7543,
            "Max Inputs Length": 3558,
            "Max Targets Length": 13,
            "Min Inputs Length": 153,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [
            "pplm_distil",
            "OpenAI GPT-3",
            "OpenAI GPT-1",
            "transformer_xl",
            "xlm",
            "Grover",
            "CTRL",
            "OpenAI GPT-2",
            "XLNet",
            "wmt"
        ],
        "Creators": [
            "The Pennsylvania State University",
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/TuringBench/TuringBench/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "TuringBench"
        ],
        "Inferred Metadata": {
            "HF Dataset": "turingbench/TuringBench",
            "HF Config": "AA",
            "HF Config License": "Apache License 2.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-09-27",
            "GitHub License": "",
            "Text Topics": [
                "Sports",
                "Finance",
                "Mutual Funds",
                "Mutual funds",
                "International relations",
                "Politics",
                "News and current events",
                "Finance and Investment"
            ],
            "Github Date": "",
            "HF Date": "2021-05-04",
            "HF Downloads (September 2023)": 521,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 29,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Uchendu2021TURINGBENCHAB,\n author = {Adaku Uchendu and Zeyu Ma and Thai Le and Rui Zhang and Dongwon Lee},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {2001-2016},\n title = {TURINGBENCH: A Benchmark Environment for Turing Test in the Age of Neural Text Generation},\n year = {2021}\n}\n"
    },
    "tsi-vitaminc-tals__vitaminc": {
        "Unique Dataset Identifier": "tsi-vitaminc-tals__vitaminc",
        "Dataset Name": "vitaminc-tals__vitaminc",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/TalSchuster/VitaminC",
        "GitHub URL": "https://github.com/TalSchuster/VitaminC",
        "Hugging Face URL": "https://huggingface.co/datasets/tals/vitaminc",
        "Paper Title": "Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence",
        "Papers with Code URL": "https://paperswithcode.com/dataset/vitaminc",
        "ArXiv URL": "https://arxiv.org/abs/2103.08541",
        "Semantic Scholar Corpus ID": 232233599,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Natural Language Inference",
            "Fact Verification",
            "Named Entity Recognition",
            "Question Answering",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 316.0072,
            "Mean Targets Length": 9.6265,
            "Max Inputs Length": 2809,
            "Max Targets Length": 16,
            "Min Inputs Length": 128,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Massachusetts Institute of Technology"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Github states the dataset is deribed from wikipedia pages: https://github.com/TalSchuster/VitaminC#vitaminc",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "vitaminc/tals--vitaminc"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tals/vitaminc",
            "HF Config": "tals--vitaminc",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "https://github.com/TalSchuster/VitaminC/edit/main/DATA_LICENSE",
            "PwC Date": "2021-03-15",
            "S2 Date": "2021-03-15",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Entertainment",
                "Historical events",
                "Biography",
                "Music",
                "Health",
                "COVID-19 statistics",
                "Film industry",
                "Geography",
                "Sports",
                "Entertainment industry"
            ],
            "Github Date": "",
            "HF Date": "2022-06-21",
            "HF Downloads (September 2023)": 284,
            "HF Likes (September 2023)": 2,
            "PwC Description": "The VitaminC dataset contains more than 450,000 claim-evidence pairs for fact verification and factual consistent generation. Based on over 100,000 revisions to popular Wikipedia pages, and additional \"synthetic\" revisions.",
            "S2 Citation Count (September 2023)": 95,
            "GitHub Stars": 58,
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "FEVER"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Schuster2021GetYV,\n author = {Tal Schuster and Adam Fisch and R. Barzilay},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {624-643},\n title = {Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence},\n year = {2021}\n}\n"
    },
    "tsi-rumoureval_2019-rumoureval2019": {
        "Unique Dataset Identifier": "tsi-rumoureval_2019-rumoureval2019",
        "Dataset Name": "rumoureval_2019-rumoureval2019",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/leondz",
        "GitHub URL": "https://github.com/leondz",
        "Hugging Face URL": "https://huggingface.co/datasets/strombergnlp/rumoureval_2019",
        "Paper Title": "SemEval-2019 Task 7: RumourEval, Determining Rumour Veracity and Support for Rumours",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1809.06683",
        "Semantic Scholar Corpus ID": 52298363,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4877,
            "Mean Inputs Length": 320.9008,
            "Mean Targets Length": 7.6213,
            "Max Inputs Length": 4120,
            "Max Targets Length": 8,
            "Min Inputs Length": 139,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter",
            "reddit",
            "snopes.com"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Sheffield",
            "IT University of Copenhagen",
            "University of Warwick"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://competitions.codalab.org/competitions/19938#learn_the_details-terms_and_conditions"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "rumoureval_2019/RumourEval2019"
        ],
        "Inferred Metadata": {
            "HF Dataset": "strombergnlp/rumoureval_2019",
            "HF Config": "RumourEval2019",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-09-18",
            "GitHub License": "",
            "Text Topics": [
                "Politics",
                "Social justice and police brutality",
                "Social media and online communication",
                "Current events/news",
                "Law enforcement",
                "Terrorism",
                "Social media",
                "Current events"
            ],
            "Github Date": "",
            "HF Date": "2022-05-12",
            "HF Downloads (September 2023)": 112,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 130,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Gorrell2018SemEval2019T7,\n author = {G. Gorrell and Kalina Bontcheva and Leon Derczynski and E. Kochkina and Maria Liakata and A. Zubiaga},\n booktitle = {International Workshop on Semantic Evaluation},\n journal = {ArXiv},\n title = {SemEval-2019 Task 7: RumourEval, Determining Rumour Veracity and Support for Rumours},\n volume = {abs/1809.06683},\n year = {2018}\n}\n"
    },
    "tsi-tweet_eval-irony": {
        "Unique Dataset Identifier": "tsi-tweet_eval-irony",
        "Dataset Name": "tweet_eval-irony",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Sentiment Analysis",
            "Text Classification",
            "Irony Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2862,
            "Mean Inputs Length": 154.8906,
            "Mean Targets Length": 7.9804,
            "Max Inputs Length": 1075,
            "Max Targets Length": 10,
            "Min Inputs Length": 81,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/irony"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Health",
                "Language and communication",
                "Humor",
                "Daily routine",
                "Emotions",
                "Social media and online communication",
                "Humor and irony",
                "Social media"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsi-tweet_eval-stance_abortion": {
        "Unique Dataset Identifier": "tsi-tweet_eval-stance_abortion",
        "Dataset Name": "tweet_eval-stance_abortion",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 587,
            "Mean Inputs Length": 188.0256,
            "Mean Targets Length": 6.816,
            "Max Inputs Length": 222,
            "Max Targets Length": 8,
            "Min Inputs Length": 106,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/stance_abortion"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Ethics and morality",
                "Women's rights",
                "Reproductive rights",
                "Social issues",
                "Political discourse",
                "Pro-life movement",
                "Religion"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsi-tweet_eval-hate": {
        "Unique Dataset Identifier": "tsi-tweet_eval-hate",
        "Dataset Name": "tweet_eval-hate",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Toxicity Detection",
            "Bias Detection",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9000,
            "Mean Inputs Length": 197.8352,
            "Mean Targets Length": 7.3187,
            "Max Inputs Length": 378,
            "Max Targets Length": 9,
            "Min Inputs Length": 74,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/hate"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "International relations",
                "Current events",
                "Politics",
                "Immigration",
                "Social justice",
                "Gender equality",
                "Immigration policy",
                "Social media etiquette",
                "Social media"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsi-tweet_eval-stance_atheism": {
        "Unique Dataset Identifier": "tsi-tweet_eval-stance_atheism",
        "Dataset Name": "tweet_eval-stance_atheism",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Question Answering",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 461,
            "Mean Inputs Length": 189.8178,
            "Mean Targets Length": 6.9566,
            "Max Inputs Length": 223,
            "Max Targets Length": 8,
            "Min Inputs Length": 117,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/stance_atheism"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Belief",
                "Prayer",
                "Religion",
                "Spirituality",
                "Social media",
                "Social issues",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsi-tweet_eval-stance_climate": {
        "Unique Dataset Identifier": "tsi-tweet_eval-stance_climate",
        "Dataset Name": "tweet_eval-stance_climate",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Question Answering",
            "Text Classification",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 355,
            "Mean Inputs Length": 184.3775,
            "Mean Targets Length": 5.6479,
            "Max Inputs Length": 217,
            "Max Targets Length": 8,
            "Min Inputs Length": 116,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/stance_climate"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Environmental conservation",
                "Weather",
                "Social media",
                "Environmental issues",
                "Climate change",
                "Environmental impact",
                "Current events",
                "Politics"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsi-tweet_eval-emoji": {
        "Unique Dataset Identifier": "tsi-tweet_eval-emoji",
        "Dataset Name": "tweet_eval-emoji",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 146.1374,
            "Mean Targets Length": 2.021,
            "Max Inputs Length": 217,
            "Max Targets Length": 3,
            "Min Inputs Length": 83,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/emoji"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Social media and hashtags",
                "Geography",
                "Communication",
                "Social media",
                "Photography",
                "Social media and online communication",
                "Location",
                "Entertainment",
                "Travel",
                "Food and dining experiences"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsi-tweet_eval-offensive": {
        "Unique Dataset Identifier": "tsi-tweet_eval-offensive",
        "Dataset Name": "tweet_eval-offensive",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Creativity",
            "Natural Language Inference",
            "Summarization",
            "Toxicity Detection",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11916,
            "Mean Inputs Length": 209.7481,
            "Mean Targets Length": 12.6771,
            "Max Inputs Length": 665,
            "Max Targets Length": 14,
            "Min Inputs Length": 92,
            "Min Targets Length": 10,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/offensive"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Online communication",
                "Social issues",
                "Public opinion",
                "Social media",
                "Politics",
                "Political discourse",
                "Social media etiquette"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsi-tweet_eval-sentiment": {
        "Unique Dataset Identifier": "tsi-tweet_eval-sentiment",
        "Dataset Name": "tweet_eval-sentiment",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 196.998,
            "Mean Targets Length": 8.5472,
            "Max Inputs Length": 290,
            "Max Targets Length": 9,
            "Min Inputs Length": 107,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/sentiment"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Religion",
                "Pop culture",
                "Entertainment",
                "Music",
                "Communication",
                "Current events",
                "Daily routine",
                "Social media",
                "Sports",
                "Travel"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsi-tweet_eval-emotion": {
        "Unique Dataset Identifier": "tsi-tweet_eval-emotion",
        "Dataset Name": "tweet_eval-emotion",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3257,
            "Mean Inputs Length": 185.272,
            "Mean Targets Length": 6.3611,
            "Max Inputs Length": 254,
            "Max Targets Length": 9,
            "Min Inputs Length": 100,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/emotion"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Personal experiences",
                "Relationships",
                "Humor",
                "Emotions",
                "Music",
                "Customer service",
                "Social issues"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsi-tweet_eval-stance_feminist": {
        "Unique Dataset Identifier": "tsi-tweet_eval-stance_feminist",
        "Dataset Name": "tweet_eval-stance_feminist",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Sentiment Analysis",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 597,
            "Mean Inputs Length": 189.1055,
            "Mean Targets Length": 6.799,
            "Max Inputs Length": 222,
            "Max Targets Length": 8,
            "Min Inputs Length": 117,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/stance_feminist"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Online activism",
                "Feminism",
                "Social media",
                "Feminism and gender equality",
                "Social media discourse",
                "Online harassment",
                "Social justice",
                "Social activism"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsi-tweet_eval-stance_hillary": {
        "Unique Dataset Identifier": "tsi-tweet_eval-stance_hillary",
        "Dataset Name": "tweet_eval-stance_hillary",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/cardiffnlp/tweeteval",
        "GitHub URL": "https://github.com/cardiffnlp/tweeteval",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_eval",
        "Paper Title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweeteval",
        "ArXiv URL": "https://arxiv.org/abs/2010.12421",
        "Semantic Scholar Corpus ID": 225062026,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Question Answering",
            "Text Classification",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 620,
            "Mean Inputs Length": 183.2516,
            "Mean Targets Length": 6.8839,
            "Max Inputs Length": 220,
            "Max Targets Length": 8,
            "Min Inputs Length": 115,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Snap Inc.",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            },
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Contains links to all the sub data sets: https://github.com/cardiffnlp/tweeteval#tweeteval-the-benchmark",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweet_eval/stance_hillary"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_eval",
            "HF Config": "emoji",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Text Topics": [
                "Social media",
                "Current events",
                "Social issues",
                "Online communication",
                "Political discourse",
                "Social media etiquette",
                "Politics",
                "Social media activism",
                "Language and communication",
                "Gender equality"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 41646,
            "HF Likes (September 2023)": 78,
            "PwC Description": "TweetEval introduces an evaluation framework consisting of seven heterogeneous Twitter-specific classification tasks.",
            "S2 Citation Count (September 2023)": 353,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Barbieri2020TweetEvalUB,\n author = {Francesco Barbieri and Jos Camacho-Collados and Leonardo Neves and Luis Espinosa-Anke},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},\n volume = {abs/2010.12421},\n year = {2020}\n}\n"
    },
    "tsi-discovery-discovery": {
        "Unique Dataset Identifier": "tsi-discovery-discovery",
        "Dataset Name": "discovery-discovery",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/Discovery",
        "GitHub URL": "https://github.com/sileod/Discovery",
        "Hugging Face URL": "https://huggingface.co/datasets/discovery",
        "Paper Title": "Mining Discourse Markers for Unsupervised Sentence Representation Learning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/discovery",
        "ArXiv URL": "https://arxiv.org/abs/1903.11850",
        "Semantic Scholar Corpus ID": 85543290,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 299.4865,
            "Mean Targets Length": 10.5752,
            "Max Inputs Length": 594,
            "Max Targets Length": 18,
            "Min Inputs Length": 107,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "inf.uni-hamburg.de/en/inst/ab/lt/resources/data/depcc.html"
        ],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Comes from: https://www.inf.uni-hamburg.de/en/inst/ab/lt/resources/data/depcc.html",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "discovery/discovery"
        ],
        "Inferred Metadata": {
            "HF Dataset": "discovery",
            "HF Config": "discovery",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "",
            "PwC Date": "2019-03-28",
            "S2 Date": "2019-03-28",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Politics",
                "Technology",
                "Ethics and morality",
                "Daily routine",
                "Decision-making",
                "Communication",
                "Economics",
                "Engineering",
                "Sports",
                "Computer hardware"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1559,
            "HF Likes (September 2023)": 5,
            "PwC Description": "The Discovery datasets consists of adjacent sentence pairs (s1,s2) with a discourse marker (y) that occurred at the beginning of s2. They were extracted from the depcc web corpus.\n\nMarkers prediction can be used in order to train a sentence encoders. Discourse markers can be considered as noisy labels for various semantic tasks, such as entailment (y=therefore), subjectivity analysis (y=personally) or sentiment analysis (y=sadly), similarity (y=similarly), typicality, (y=curiously) ...\n\nThe specificity of this dataset is the diversity of the markers, since previously used data used only ~10 imbalanced classes. The author of the dataset provide:\n\n\na list of the 174 discourse markers\na Base version of the dataset with 1.74 million pairs (10k examples per marker)\na Big version with 3.4 million pairs\na Hard version with 1.74 million pairs where the connective couldn't be predicted with a fastText linear model",
            "S2 Citation Count (September 2023)": 52,
            "GitHub Stars": 59,
            "GitHub Topics": [
                "dataset",
                "deep-learning",
                "discourse-analysis",
                "discourse-connectives",
                "discourse-markers",
                "discourse-parsing",
                "infersent",
                "large-dataset",
                "natural-language-inference",
                "natural-language-processing",
                "natural-language-understanding",
                "pdtb",
                "pretrained-model",
                "sentence-embeddings",
                "unsupervised-learning"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Sileo2019MiningDM,\n author = {Damien Sileo and T. V. D. Cruys and Camille Pradel and Philippe Muller},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {3477-3486},\n title = {Mining Discourse Markers for Unsupervised Sentence Representation Learning},\n year = {2019}\n}\n"
    },
    "tsi-pragmeval-verifiability": {
        "Unique Dataset Identifier": "tsi-pragmeval-verifiability",
        "Dataset Name": "pragmeval-verifiability",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Dialogue Generation",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5712,
            "Mean Inputs Length": 194.7314,
            "Mean Targets Length": 13.6338,
            "Max Inputs Length": 675,
            "Max Targets Length": 17,
            "Min Inputs Length": 109,
            "Min Targets Length": 13,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/verifiability"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Epistemology",
                "Allergies",
                "Customer service",
                "Travel",
                "Decision-making",
                "Finance"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsi-pragmeval-mrda": {
        "Unique Dataset Identifier": "tsi-pragmeval-mrda",
        "Dataset Name": "pragmeval-mrda",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 14484,
            "Mean Inputs Length": 181.1927,
            "Mean Targets Length": 16.026,
            "Max Inputs Length": 579,
            "Max Targets Length": 38,
            "Min Inputs Length": 105,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/mrda"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Decision-making",
                "Problem-solving",
                "Language understanding",
                "Conversation analysis",
                "Communication skills",
                "Data analysis",
                "Technology"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsi-pragmeval-switchboard": {
        "Unique Dataset Identifier": "tsi-pragmeval-switchboard",
        "Dataset Name": "pragmeval-switchboard",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 18930,
            "Mean Inputs Length": 174.3973,
            "Mean Targets Length": 17.7304,
            "Max Inputs Length": 704,
            "Max Targets Length": 29,
            "Min Inputs Length": 109,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/switchboard"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Conversation analysis",
                "Social interactions",
                "Linguistics",
                "Language and communication",
                "Personal finance",
                "Language understanding",
                "Daily routine",
                "Language"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsi-pragmeval-emergent": {
        "Unique Dataset Identifier": "tsi-pragmeval-emergent",
        "Dataset Name": "pragmeval-emergent",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Natural Language Inference",
            "Named Entity Recognition",
            "Question Answering",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2076,
            "Mean Inputs Length": 213.8907,
            "Mean Targets Length": 6.8256,
            "Max Inputs Length": 607,
            "Max Targets Length": 10,
            "Min Inputs Length": 127,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/emergent"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "International relations",
                "News reporting",
                "Apple products",
                "Current events",
                "Entertainment industry",
                "Technology",
                "Terrorism"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsi-pragmeval-gum": {
        "Unique Dataset Identifier": "tsi-pragmeval-gum",
        "Dataset Name": "pragmeval-gum",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1700,
            "Mean Inputs Length": 244.9335,
            "Mean Targets Length": 10.7871,
            "Max Inputs Length": 622,
            "Max Targets Length": 13,
            "Min Inputs Length": 119,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/gum"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Education",
                "History",
                "Geography",
                "Culinary arts",
                "Cultural differences",
                "Communication",
                "Cooking",
                "Travel",
                "Gardening"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsi-pragmeval-sarcasm": {
        "Unique Dataset Identifier": "tsi-pragmeval-sarcasm",
        "Dataset Name": "pragmeval-sarcasm",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Irony Detection",
            "Textual Entailment",
            "Logical Reasoning",
            "Dialogue Generation",
            "Question Answering",
            "Linguistic Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3754,
            "Mean Inputs Length": 630.8506,
            "Mean Targets Length": 6.5072,
            "Max Inputs Length": 9876,
            "Max Targets Length": 8,
            "Min Inputs Length": 155,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/sarcasm"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Gun control",
                "Philosophy",
                "Religion",
                "Language and communication",
                "Logic",
                "Science",
                "Ethics and morality",
                "History"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsi-pragmeval-stac": {
        "Unique Dataset Identifier": "tsi-pragmeval-stac",
        "Dataset Name": "pragmeval-stac",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11230,
            "Mean Inputs Length": 150.228,
            "Mean Targets Length": 13.3317,
            "Max Inputs Length": 267,
            "Max Targets Length": 23,
            "Min Inputs Length": 103,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/stac"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "General conversation",
                "Communication",
                "Agriculture",
                "Social interaction",
                "Bartering",
                "Technology",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsi-pragmeval-pdtb": {
        "Unique Dataset Identifier": "tsi-pragmeval-pdtb",
        "Dataset Name": "pragmeval-pdtb",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/pragmeval",
        "GitHub URL": "https://github.com/sileod",
        "Hugging Face URL": "https://huggingface.co/datasets/pragmeval",
        "Paper Title": " A Pragmatics-Centered Evaluation Framework for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1907.08672",
        "Semantic Scholar Corpus ID": 247939207,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12907,
            "Mean Inputs Length": 322.0896,
            "Mean Targets Length": 10.0425,
            "Max Inputs Length": 2733,
            "Max Targets Length": 21,
            "Min Inputs Length": 113,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Synapse Dveloppement",
            "KU Leuven",
            "University of Toulouse"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Datasets used in this dataset: https://github.com/sileod/pragmeval#contents",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "pragmeval/pdtb"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pragmeval",
            "HF Config": "verifiability",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Business operations",
                "Financial markets",
                "Communication",
                "Earnings",
                "Technology",
                "Business and finance",
                "Business"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5552,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2019APE,\n author = {Damien Sileo and Philippe Muller and T. V. D. Cruys and Camille Pradel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2382-2394},\n title = {A Pragmatics-Centered Evaluation Framework for Natural Language Understanding},\n year = {2019}\n}\n"
    },
    "tsi-silicone-dyda_e": {
        "Unique Dataset Identifier": "tsi-silicone-dyda_e",
        "Dataset Name": "silicone-dyda_e",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://yanran.li/dailydialog.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 161.0183,
            "Mean Targets Length": 10.7365,
            "Max Inputs Length": 926,
            "Max Targets Length": 11,
            "Min Inputs Length": 100,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "http://yanran.li/dailydialog.html, https://huggingface.co/datasets/silicone#licensing-information"
            },
            {
                "License": "CC BY-SA 4.0",
                "License URL": "http://yanran.li/dailydialog.html, https://huggingface.co/datasets/silicone#licensing-information"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "silicone/dyda_e"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Personal preferences",
                "Communication skills",
                "Education",
                "Travel",
                "Daily routine",
                "Relationships",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsi-silicone-oasis": {
        "Unique Dataset Identifier": "tsi-silicone-oasis",
        "Dataset Name": "silicone-oasis",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/silicone",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12076,
            "Mean Inputs Length": 145.0096,
            "Mean Targets Length": 7.0513,
            "Max Inputs Length": 2111,
            "Max Targets Length": 21,
            "Min Inputs Length": 90,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/silicone#licensing-information"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "silicone/oasis"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Customer service",
                "Social interaction",
                "Communication skills",
                "Daily routine",
                "Social interactions",
                "Telecommunications",
                "Communication",
                "Technology"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsi-silicone-meld_s": {
        "Unique Dataset Identifier": "tsi-silicone-meld_s",
        "Dataset Name": "silicone-meld_s",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://affective-meld.github.io/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9989,
            "Mean Inputs Length": 133.5298,
            "Mean Targets Length": 8.5285,
            "Max Inputs Length": 439,
            "Max Targets Length": 9,
            "Min Inputs Length": 91,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/silicone#licensing-information"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "silicone/meld_s"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "Relationships",
                "Linguistics",
                "Daily routine",
                "Social interaction",
                "Social interactions",
                "Language understanding",
                "Emotions",
                "Interpersonal relationships",
                "Language",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsi-silicone-meld_e": {
        "Unique Dataset Identifier": "tsi-silicone-meld_e",
        "Dataset Name": "silicone-meld_e",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://affective-meld.github.io/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9989,
            "Mean Inputs Length": 138.1026,
            "Mean Targets Length": 7.1201,
            "Max Inputs Length": 445,
            "Max Targets Length": 9,
            "Min Inputs Length": 93,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/silicone#licensing-information"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "silicone/meld_e"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "Social interactions",
                "Language",
                "Communication",
                "Daily routine",
                "Personal relationships",
                "Travel",
                "Entertainment"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsi-silicone-maptask": {
        "Unique Dataset Identifier": "tsi-silicone-maptask",
        "Dataset Name": "silicone-maptask",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://groups.inf.ed.ac.uk/maptask/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 20905,
            "Mean Inputs Length": 127.1032,
            "Mean Targets Length": 8.6303,
            "Max Inputs Length": 609,
            "Max Targets Length": 12,
            "Min Inputs Length": 95,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://groups.inf.ed.ac.uk/maptask/maptasknxt.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "silicone/maptask"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Daily routine",
                "Conversation etiquette",
                "Language understanding",
                "Language",
                "Language and communication",
                "Linguistics",
                "Communication",
                "Travel",
                "Outdoor activities"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsi-silicone-dyda_da": {
        "Unique Dataset Identifier": "tsi-silicone-dyda_da",
        "Dataset Name": "silicone-dyda_da",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://yanran.li/dailydialog.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 164.1378,
            "Mean Targets Length": 8.4215,
            "Max Inputs Length": 929,
            "Max Targets Length": 11,
            "Min Inputs Length": 105,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "http://yanran.li/dailydialog.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "silicone/dyda_da"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "Time management",
                "Personal experiences",
                "General knowledge",
                "Communication",
                "Travel",
                "Customer service",
                "Language",
                "Social plans"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsi-silicone-sem": {
        "Unique Dataset Identifier": "tsi-silicone-sem",
        "Dataset Name": "silicone-sem",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://ieeexplore.ieee.org/document/5959155",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Question Answering",
            "Dialogue Generation",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4264,
            "Mean Inputs Length": 150.7765,
            "Mean Targets Length": 8.4627,
            "Max Inputs Length": 1311,
            "Max Targets Length": 9,
            "Min Inputs Length": 92,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/silicone#licensing-information"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "silicone/sem"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "Personal relationships",
                "Language understanding",
                "Communication",
                "Travel",
                "Language",
                "Emotions",
                "Time management",
                "Social interaction",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsi-silicone-iemocap": {
        "Unique Dataset Identifier": "tsi-silicone-iemocap",
        "Dataset Name": "silicone-iemocap",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://sail.usc.edu/iemocap/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/silicone",
        "Paper Title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog",
        "Papers with Code URL": "https://paperswithcode.com/dataset/silicone-benchmark",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 221856689,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7213,
            "Mean Inputs Length": 141.6796,
            "Mean Targets Length": 4.0,
            "Max Inputs Length": 637,
            "Max Targets Length": 4,
            "Min Inputs Length": 84,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "http://sail.usc.edu/iemocap/Data_Release_Form_IEMOCAP.pdf, https://docs.google.com/forms/d/e/1FAIpQLScBecgI2K5bFTrXi_-05IYSSwOcqL5mX7dh57xcJV1m_NoznA/viewform?usp=sf_link"
            },
            {
                "License": "Request Form",
                "License URL": "http://sail.usc.edu/iemocap/Data_Release_Form_IEMOCAP.pdf, https://docs.google.com/forms/d/e/1FAIpQLScBecgI2K5bFTrXi_-05IYSSwOcqL5mX7dh57xcJV1m_NoznA/viewform?usp=sf_link"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "silicone/iemocap"
        ],
        "Inferred Metadata": {
            "HF Dataset": "silicone",
            "HF Config": "dyda_da",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "https://huggingface.co/datasets/silicone",
            "PwC Date": "2020-09-23",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Text Topics": [
                "Travel",
                "Language",
                "Relationships",
                "Linguistics",
                "Social interaction",
                "Emotions",
                "General knowledge"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3526,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems specifically designed for spoken language. All datasets are in the English language and covers a  large variety of domains (e.g daily life, scripted scenarios, joint task completion, phone call conversations, and televsion dialogue). Some datasets additionally include emotion and/or sentiment labels.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2020HierarchicalPF,\n author = {E. Chapuis and Pierre Colombo and Matteo Manica and Matthieu Labeau and C. Clavel},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Hierarchical Pre-training for Sequence Labelling in Spoken Dialog},\n volume = {abs/2009.11152},\n year = {2020}\n}\n"
    },
    "tsi-lex_glue-scotus": {
        "Unique Dataset Identifier": "tsi-lex_glue-scotus",
        "Dataset Name": "lex_glue-scotus",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/coastalcph/lex-glue",
        "GitHub URL": "https://github.com/coastalcph/lex-glue",
        "Hugging Face URL": "https://huggingface.co/datasets/lex_glue",
        "Paper Title": "LexGLUE: A Benchmark Dataset for Legal Language Understanding in English",
        "Papers with Code URL": "https://paperswithcode.com/dataset/lexglue",
        "ArXiv URL": "https://arxiv.org/abs/2110.00976",
        "Semantic Scholar Corpus ID": 238259595,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5000,
            "Mean Inputs Length": 35796.1442,
            "Mean Targets Length": 2.0934,
            "Max Inputs Length": 562845,
            "Max Targets Length": 3,
            "Min Inputs Length": 185,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "University of Copenhagen",
            "Universitat Hamburg",
            "Athens University of Economics and Business",
            "University of Sheffield",
            "Illinois Tech  Chicago Kent College of Law",
            "Bucerius Law School",
            "CodeX",
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "http://scdb.wustl.edu/documentation.php?var=cite"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lex_glue/scotus"
        ],
        "Inferred Metadata": {
            "HF Dataset": "lex_glue",
            "HF Config": "ecthr_a",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2021-10-03",
            "S2 Date": "2021-10-03",
            "GitHub License": "",
            "Text Topics": [
                "United States Supreme Court",
                "Legal case analysis",
                "Court decisions",
                "Legal citations",
                "Legal citation",
                "United States Supreme Court cases",
                "Court proceedings"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 53914,
            "HF Likes (September 2023)": 27,
            "PwC Description": "Legal General Language Understanding Evaluation (LexGLUE) benchmark is a collection of datasets for evaluating model performance across a diverse set of legal NLU tasks in a standardized way.",
            "S2 Citation Count (September 2023)": 84,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Chalkidis2021LexGLUEAB,\n author = {Ilias Chalkidis and Abhik Jana and D. Hartung and M. Bommarito and Ion Androutsopoulos and D. Katz and Nikolaos Aletras},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {4310-4330},\n title = {LexGLUE: A Benchmark Dataset for Legal Language Understanding in English},\n year = {2021}\n}\n"
    },
    "tsi-lex_glue-ledgar": {
        "Unique Dataset Identifier": "tsi-lex_glue-ledgar",
        "Dataset Name": "lex_glue-ledgar",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://metatext.io/datasets/ledgar",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/lex_glue",
        "Paper Title": "LexGLUE: A Benchmark Dataset for Legal Language Understanding in English",
        "Papers with Code URL": "https://paperswithcode.com/dataset/lexglue",
        "ArXiv URL": "https://arxiv.org/abs/2110.00976",
        "Semantic Scholar Corpus ID": 238259595,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 822.011,
            "Mean Targets Length": 12.5611,
            "Max Inputs Length": 7371,
            "Max Targets Length": 29,
            "Min Inputs Length": 130,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "University of Copenhagen",
            "Universitat Hamburg",
            "Athens University of Economics and Business",
            "University of Sheffield",
            "Illinois Tech  Chicago Kent College of Law",
            "Bucerius Law School",
            "CodeX",
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://metatext.io/datasets/ledgar"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lex_glue/ledgar"
        ],
        "Inferred Metadata": {
            "HF Dataset": "lex_glue",
            "HF Config": "ecthr_a",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2021-10-03",
            "S2 Date": "2021-10-03",
            "GitHub License": "",
            "Text Topics": [
                "Legal terminology",
                "Legal contracts",
                "Business transactions",
                "Corporate governance",
                "Business operations",
                "Contract law",
                "Legal agreements",
                "Contractual agreements"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 53914,
            "HF Likes (September 2023)": 27,
            "PwC Description": "Legal General Language Understanding Evaluation (LexGLUE) benchmark is a collection of datasets for evaluating model performance across a diverse set of legal NLU tasks in a standardized way.",
            "S2 Citation Count (September 2023)": 84,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Chalkidis2021LexGLUEAB,\n author = {Ilias Chalkidis and Abhik Jana and D. Hartung and M. Bommarito and Ion Androutsopoulos and D. Katz and Nikolaos Aletras},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {4310-4330},\n title = {LexGLUE: A Benchmark Dataset for Legal Language Understanding in English},\n year = {2021}\n}\n"
    },
    "tsi-lex_glue-case_hold": {
        "Unique Dataset Identifier": "tsi-lex_glue-case_hold",
        "Dataset Name": "lex_glue-case_hold",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/reglab/casehold",
        "GitHub URL": "https://github.com/reglab/casehold",
        "Hugging Face URL": "https://huggingface.co/datasets/lex_glue",
        "Paper Title": "LexGLUE: A Benchmark Dataset for Legal Language Understanding in English",
        "Papers with Code URL": "https://paperswithcode.com/dataset/lexglue",
        "ArXiv URL": "https://arxiv.org/abs/2110.00976",
        "Semantic Scholar Corpus ID": 238259595,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 1551.8095,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 4290,
            "Max Targets Length": 2,
            "Min Inputs Length": 457,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "University of Copenhagen",
            "Universitat Hamburg",
            "Athens University of Economics and Business",
            "University of Sheffield",
            "Illinois Tech  Chicago Kent College of Law",
            "Bucerius Law School",
            "CodeX",
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/reglab/casehold"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lex_glue/case_hold"
        ],
        "Inferred Metadata": {
            "HF Dataset": "lex_glue",
            "HF Config": "ecthr_a",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2021-10-03",
            "S2 Date": "2021-10-03",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Legal cases and precedents",
                "Legal terminology and concepts",
                "Legal principles and concepts",
                "Legal proceedings",
                "Immigration law",
                "Law",
                "Legal procedures and rules",
                "Employment law"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 53914,
            "HF Likes (September 2023)": 27,
            "PwC Description": "Legal General Language Understanding Evaluation (LexGLUE) benchmark is a collection of datasets for evaluating model performance across a diverse set of legal NLU tasks in a standardized way.",
            "S2 Citation Count (September 2023)": 84,
            "GitHub Stars": 58,
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Chalkidis2021LexGLUEAB,\n author = {Ilias Chalkidis and Abhik Jana and D. Hartung and M. Bommarito and Ion Androutsopoulos and D. Katz and Nikolaos Aletras},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {4310-4330},\n title = {LexGLUE: A Benchmark Dataset for Legal Language Understanding in English},\n year = {2021}\n}\n"
    },
    "tsi-language_identification": {
        "Unique Dataset Identifier": "tsi-language_identification",
        "Dataset Name": "language_identification",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/papluca/language-identification",
        "GitHub URL": "https://github.com/LucaPapariello",
        "Hugging Face URL": "https://huggingface.co/datasets/papluca/language-identification",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 189.7904,
            "Mean Targets Length": 3.0,
            "Max Inputs Length": 2501,
            "Max Targets Length": 3,
            "Min Inputs Length": 81,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://docs.opendata.aws/amazon-reviews-ml/license.txt, https://dl.fbaipublicfiles.com/glue/data/STS-B.zip, https://github.com/facebookresearch/XNLI/blob/main/LICENSE"
            },
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://docs.opendata.aws/amazon-reviews-ml/license.txt, https://dl.fbaipublicfiles.com/glue/data/STS-B.zip, https://github.com/facebookresearch/XNLI/blob/main/LICENSE"
            },
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://docs.opendata.aws/amazon-reviews-ml/license.txt, https://dl.fbaipublicfiles.com/glue/data/STS-B.zip, https://github.com/facebookresearch/XNLI/blob/main/LICENSE"
            }
        ],
        "License Notes": "Derived from Amazon reviews, XNLI, and STS-B",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "language-identification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "papluca/language-identification",
            "HF Config": "papluca--language-identification",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Language and communication",
                "Cultural diversity",
                "Language identification",
                "Multilingualism",
                "Cultural exchange",
                "Product review",
                "Cultural understanding"
            ],
            "Github Date": "",
            "HF Date": "2021-11-24",
            "HF Downloads (September 2023)": 499,
            "HF Likes (September 2023)": 13,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-rotten_tomatoes": {
        "Unique Dataset Identifier": "tsi-rotten_tomatoes",
        "Dataset Name": "rotten_tomatoes",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://www.cs.cornell.edu/people/pabo/movie-review-data/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/rotten_tomatoes",
        "Paper Title": "Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mr",
        "ArXiv URL": "https://arxiv.org/abs/cs/0506075",
        "Semantic Scholar Corpus ID": 3264224,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8530,
            "Mean Inputs Length": 182.9716,
            "Mean Targets Length": 4.0,
            "Max Inputs Length": 336,
            "Max Targets Length": 4,
            "Min Inputs Length": 73,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "rottentomatoes.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Cornell University",
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "rotten_tomatoes"
        ],
        "Inferred Metadata": {
            "HF Dataset": "rotten_tomatoes",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2004-01-01",
            "S2 Date": "2005-06-17",
            "GitHub License": "",
            "Text Topics": [
                "Film criticism",
                "Emotions",
                "Entertainment",
                "Acting",
                "Literature",
                "Film critique",
                "Comedy",
                "Film and entertainment",
                "Aesthetics",
                "Film analysis"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 58503,
            "HF Likes (September 2023)": 26,
            "PwC Description": "MR Movie Reviews is a dataset for use in sentiment-analysis experiments. Available are collections of movie-review documents labeled with respect to their overall sentiment polarity (positive or negative) or subjective rating (e.g., \"two and a half stars\") and sentences labeled with respect to their subjectivity status (subjective or objective) or polarity.",
            "S2 Citation Count (September 2023)": 2631,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Pang2005SeeingSE,\n author = {B. Pang and Lillian Lee},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {115-124},\n title = {Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales},\n year = {2005}\n}\n"
    },
    "tsi-hate_speech18": {
        "Unique Dataset Identifier": "tsi-hate_speech18",
        "Dataset Name": "hate_speech18",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Vicomtech/hate-speech-dataset",
        "GitHub URL": "https://github.com/Vicomtech/hate-speech-dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/hate_speech18",
        "Paper Title": "Hate Speech Dataset from a White Supremacy Forum",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hate-speech",
        "ArXiv URL": "https://arxiv.org/abs/1809.04444",
        "Semantic Scholar Corpus ID": 52194540,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9302,
            "Mean Inputs Length": 186.8964,
            "Mean Targets Length": 6.8241,
            "Max Inputs Length": 1679,
            "Max Targets Length": 9,
            "Min Inputs Length": 98,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "stormfront.org"
        ],
        "Model Generated": [],
        "Creators": [
            "HSLT Group at Vicomtech"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 3.0",
                "License URL": "https://github.com/Vicomtech/hate-speech-dataset/blob/master/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "hate_speech18"
        ],
        "Inferred Metadata": {
            "HF Dataset": "hate_speech18",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/3.0/es/",
            "PwC Date": "",
            "S2 Date": "2018-09-12",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "Social issues",
                "History",
                "Education",
                "Religion",
                "Communication",
                "Identity",
                "Personal preferences",
                "General knowledge",
                "Culture"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 40578,
            "HF Likes (September 2023)": 13,
            "PwC Description": "Dataset of hate speech annotated on Internet forum posts in English at sentence-level. The source forum in Stormfront, a large online community of white nacionalists. A total of 10,568 sentence have been been extracted from Stormfront and classified as conveying hate speech or not.",
            "S2 Citation Count (September 2023)": 270,
            "GitHub Stars": 133,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Gibert2018HateSD,\n author = {Ona de Gibert and Naiara Prez and Aitor Garca-Pablos and Montse Cuadros},\n booktitle = {Workshop on Abusive Language Online},\n journal = {ArXiv},\n title = {Hate Speech Dataset from a White Supremacy Forum},\n volume = {abs/1809.04444},\n year = {2018}\n}\n"
    },
    "tsi-sms_spam": {
        "Unique Dataset Identifier": "tsi-sms_spam",
        "Dataset Name": "sms_spam",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sms_spam",
        "Paper Title": "Contributions to the Study of SMS Spam Filtering: New Collection and Results",
        "Papers with Code URL": "https://paperswithcode.com/dataset/sms-spam-collection-data-set",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 13871930,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Question Answering",
            "Dialogue Generation",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4737,
            "Mean Inputs Length": 150.4036,
            "Mean Targets Length": 4.1341,
            "Max Inputs Length": 699,
            "Max Targets Length": 5,
            "Min Inputs Length": 72,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grumbletext"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "http://archive.ics.uci.edu/dataset/228/sms+spam+collection"
            }
        ],
        "License Notes": "There are more sources listed on the document, but this was the main one that I saw",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "sms_spam"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sms_spam",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2011-09-19",
            "GitHub License": "",
            "Text Topics": [
                "Daily routine",
                "Time management",
                "Linguistics",
                "Travel",
                "Communication",
                "Social plans",
                "General knowledge",
                "Relationships",
                "Personal relationships",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1974,
            "HF Likes (September 2023)": 11,
            "PwC Description": "This corpus has been collected from free or free for research sources at the Internet:\n\n\nA collection of 425 SMS spam messages was manually extracted from the Grumbletext Web site. This is a UK forum in which cell phone users make public claims about SMS spam messages, most of them without reporting the very spam message received. The identification of the text of spam messages in the claims is a very hard and time-consuming task, and it involved carefully scanning hundreds of web pages.\nA subset of 3,375 SMS randomly chosen ham messages of the NUS SMS Corpus (NSC), which is a dataset of about 10,000 legitimate messages collected for research at the Department of Computer Science at the National University of Singapore. The messages largely originate from Singaporeans and mostly from students attending the University. These messages were collected from volunteers who were made aware that their contributions were going to be made publicly available.\nA list of 450 SMS ham messages collected from Caroline Tag's PhD Thesis.\nthe SMS Spam Corpus v.0.1 Big. It has 1,002 SMS ham messages and 322 spam messages.",
            "S2 Citation Count (September 2023)": 386,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Almeida2011ContributionsTT,\n author = {Tiago A. Almeida and J. M. G. Hidalgo and A. Yamakami},\n booktitle = {ACM Symposium on Document Engineering},\n pages = {259-262},\n title = {Contributions to the study of SMS spam filtering: new collection and results},\n year = {2011}\n}\n"
    },
    "tsi-humicroedit-subtask_2": {
        "Unique Dataset Identifier": "tsi-humicroedit-subtask_2",
        "Dataset Name": "humicroedit-subtask_2",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://www.cs.rochester.edu/u/nhossain/humicroedit.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/humicroedit",
        "Paper Title": "President Vows to Cut  Hair: Dataset and Analysis of Creative Text Editing for Humorous Headlines",
        "Papers with Code URL": "https://paperswithcode.com/dataset/humicroedit",
        "ArXiv URL": "https://arxiv.org/abs/2002.02031",
        "Semantic Scholar Corpus ID": 173990506,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Textual Entailment",
            "Sentence Completion",
            "Named Entity Recognition",
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9381,
            "Mean Inputs Length": 256.5349,
            "Mean Targets Length": 9.574,
            "Max Inputs Length": 408,
            "Max Targets Length": 10,
            "Min Inputs Length": 155,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "headlines"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "humicroedit/subtask-2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "humicroedit",
            "HF Config": "subtask-1",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-01",
            "GitHub License": "",
            "Text Topics": [
                "News and current events",
                "Communication",
                "Current events",
                "Geography",
                "International relations",
                "Natural disasters",
                "Religion",
                "Politics",
                "Media coverage",
                "Healthcare"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1954,
            "HF Likes (September 2023)": 1,
            "PwC Description": "Humicroedit is a humorous headline dataset. The data consists of regular English news headlines paired with versions of the same headlines that contain simple replacement edits designed to make them funny. The authors carefully curated crowdsourced editors to create funny headlines and judges to score a to a total of 15,095 edited headlines, with five judges per headline.",
            "S2 Citation Count (September 2023)": 73,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hossain2019PresidentVT,\n author = {Nabil Hossain and John Krumm and Michael Gamon},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {President Vows to Cut  Hair: Dataset and Analysis of Creative Text Editing for Humorous Headlines},\n volume = {abs/1906.00274},\n year = {2019}\n}\n"
    },
    "tsi-snips_built_in_intents": {
        "Unique Dataset Identifier": "tsi-snips_built_in_intents",
        "Dataset Name": "snips_built_in_intents",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sonos/nlu-benchmark/tree/master/2016-12-built-in-intents",
        "GitHub URL": "https://github.com/sonos/nlu-benchmark/tree/master/2016-12-built-in-intents",
        "Hugging Face URL": "https://huggingface.co/datasets/snips_built_in_intents",
        "Paper Title": "Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces",
        "Papers with Code URL": "https://paperswithcode.com/dataset/snips",
        "ArXiv URL": "https://arxiv.org/abs/1805.10190",
        "Semantic Scholar Corpus ID": 44061213,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 278,
            "Mean Inputs Length": 171.4353,
            "Mean Targets Length": 14.3201,
            "Max Inputs Length": 221,
            "Max Targets Length": 22,
            "Min Inputs Length": 127,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "original"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Snips"
        ],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://huggingface.co/datasets/snips_built_in_intents#source-data"
            }
        ],
        "License Notes": "Unclear how the data was made/collected even in the article: https://huggingface.co/datasets/snips_built_in_intents#source-data. Paper may provide more insight",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "snips_built_in_intents"
        ],
        "Inferred Metadata": {
            "HF Dataset": "snips_built_in_intents",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC0 1.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-05-25",
            "GitHub License": "CC0 1.0",
            "Text Topics": [
                "Weather",
                "Restaurant reservations",
                "Daily routine",
                "Location-based services",
                "Navigation",
                "Communication",
                "Transportation",
                "Travel"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1496,
            "HF Likes (September 2023)": 4,
            "PwC Description": "The SNIPS Natural Language Understanding benchmark is a dataset of over 16,000 crowdsourced queries distributed among 7 user intents of various complexity:\n\n\nSearchCreativeWork (e.g. Find me the I, Robot television show),\nGetWeather (e.g. Is it windy in Boston, MA right now?),\nBookRestaurant (e.g. I want to book a highly rated restaurant in Paris tomorrow night),\nPlayMusic (e.g. Play the last track from Beyonc off Spotify),\nAddToPlaylist (e.g. Add Diamonds to my roadtrip playlist),\nRateBook (e.g. Give 6 stars to Of Mice and Men),\nSearchScreeningEvent (e.g. Check the showtimes for Wonder Woman in Paris).\nThe training set contains of 13,084 utterances, the validation set and the test set contain 700 utterances each, with 100 queries per intent.",
            "S2 Citation Count (September 2023)": 604,
            "GitHub Stars": 484,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Coucke2018SnipsVP,\n author = {A. Coucke and Alaa Saade and Adrien Ball and Thodore Bluche and A. Caulier and David Leroy and Clment Doumouro and Thibault Gisselbrecht and F. Caltagirone and Thibaut Lavril and Mal Primet and J. Dureau},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces},\n volume = {abs/1805.10190},\n year = {2018}\n}\n"
    },
    "tsi-hate_speech_offensive": {
        "Unique Dataset Identifier": "tsi-hate_speech_offensive",
        "Dataset Name": "hate_speech_offensive",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/t-davidson/hate-speech-and-offensive-language",
        "GitHub URL": "https://github.com/Vicomtech/hate-speech-dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/hate_speech_offensive",
        "Paper Title": "Hate Speech Dataset from a White Supremacy Forum",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hate-speech",
        "ArXiv URL": "https://arxiv.org/abs/1809.04444",
        "Semantic Scholar Corpus ID": 52194540,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 21065,
            "Mean Inputs Length": 188.4413,
            "Mean Targets Length": 16.7617,
            "Max Inputs Length": 857,
            "Max Targets Length": 19,
            "Min Inputs Length": 108,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "stormfront.org"
        ],
        "Model Generated": [],
        "Creators": [
            "HSLT Group at Vicomtech"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "States it is a curated list of tweets: https://huggingface.co/datasets/hate_speech_offensive#dataset-summary",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "hate_speech_offensive"
        ],
        "Inferred Metadata": {
            "HF Dataset": "hate_speech18",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/3.0/es/",
            "PwC Date": "",
            "S2 Date": "2018-09-12",
            "GitHub License": "",
            "Text Topics": [
                "Language and Communication",
                "Social interactions",
                "Offensive language and hate speech",
                "Social media",
                "Language and communication",
                "Social media and online interactions",
                "Social media etiquette"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 6310,
            "HF Likes (September 2023)": 5,
            "PwC Description": "Dataset of hate speech annotated on Internet forum posts in English at sentence-level. The source forum in Stormfront, a large online community of white nacionalists. A total of 10,568 sentence have been been extracted from Stormfront and classified as conveying hate speech or not.",
            "S2 Citation Count (September 2023)": 270,
            "GitHub Stars": 133,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Gibert2018HateSD,\n author = {Ona de Gibert and Naiara Prez and Aitor Garca-Pablos and Montse Cuadros},\n booktitle = {Workshop on Abusive Language Online},\n journal = {ArXiv},\n title = {Hate Speech Dataset from a White Supremacy Forum},\n volume = {abs/1809.04444},\n year = {2018}\n}\n"
    },
    "tsi-hyperpartisan_news": {
        "Unique Dataset Identifier": "tsi-hyperpartisan_news",
        "Dataset Name": "hyperpartisan_news",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/hyperpartisan_news_detection",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/hyperpartisan_news_detection",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Fact Verification",
            "Text Generation",
            "Fact Checking",
            "Question Answering",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 516,
            "Mean Inputs Length": 3307.9942,
            "Mean Targets Length": 5.6376,
            "Max Inputs Length": 24517,
            "Max Targets Length": 6,
            "Min Inputs Length": 163,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": null
            }
        ],
        "License Notes": "https://huggingface.co/datasets/hyperpartisan_news_detection#licensing-information",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "hyperpartisan_news"
        ],
        "Inferred Metadata": {
            "HF Dataset": "zapsdcn/hyperpartisan_news",
            "HF Config": "zapsdcn--hyperpartisan_news",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Current events",
                "International relations",
                "Social activism",
                "Journalism",
                "Public opinion",
                "Social media",
                "Politics",
                "Social issues"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2585,
            "HF Likes (September 2023)": 8,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-sciie": {
        "Unique Dataset Identifier": "tsi-sciie",
        "Dataset Name": "sciie",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://nlp.cs.washington.edu/sciIE/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/zapsdcn/sciie",
        "Paper Title": "Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction",
        "Papers with Code URL": "https://paperswithcode.com/dataset/scierc",
        "ArXiv URL": "https://arxiv.org/abs/1808.09602",
        "Semantic Scholar Corpus ID": 52118895,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3219,
            "Mean Inputs Length": 300.5387,
            "Mean Targets Length": 9.9472,
            "Max Inputs Length": 689,
            "Max Targets Length": 13,
            "Min Inputs Length": 161,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semantic scholar articles"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "sciie"
        ],
        "Inferred Metadata": {
            "HF Dataset": "zapsdcn/sciie",
            "HF Config": "zapsdcn--sciie",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-08-29",
            "GitHub License": "",
            "Text Topics": [
                "Computer vision",
                "Natural language processing",
                "Image processing",
                "Linguistics",
                "Machine Learning",
                "Computer Science",
                "Artificial Intelligence",
                "Artificial intelligence"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 354,
            "HF Likes (September 2023)": 0,
            "PwC Description": "SciERC dataset is a collection of 500 scientific abstract annotated with scientific entities, their relations, and coreference clusters. The abstracts are taken from 12 AI conference/workshop proceedings in four AI communities, from the Semantic Scholar Corpus. SciERC extends previous datasets in scientific articles SemEval 2017 Task 10 and SemEval 2018 Task 7 by extending entity types, relation types, relation coverage, and adding cross-sentence relations using coreference links.",
            "S2 Citation Count (September 2023)": 449,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Luan2018MultiTaskIO,\n author = {Yi Luan and Luheng He and Mari Ostendorf and Hannaneh Hajishirzi},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {3219-3232},\n title = {Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction},\n year = {2018}\n}\n"
    },
    "tsi-citation_intent": {
        "Unique Dataset Identifier": "tsi-citation_intent",
        "Dataset Name": "citation_intent",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/zapsdcn/citation_intent",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/zapsdcn/citation_intent",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1688,
            "Mean Inputs Length": 330.4147,
            "Mean Targets Length": 10.8839,
            "Max Inputs Length": 1198,
            "Max Targets Length": 18,
            "Min Inputs Length": 124,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "citation_intent"
        ],
        "Inferred Metadata": {
            "HF Dataset": "zapsdcn/citation_intent",
            "HF Config": "zapsdcn--citation_intent",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Natural language processing",
                "Linguistics",
                "Computational Linguistics",
                "Machine Learning",
                "Machine learning",
                "Computational linguistics",
                "Information retrieval",
                "Machine Translation"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 318,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-scicite": {
        "Unique Dataset Identifier": "tsi-scicite",
        "Dataset Name": "scicite",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/allenai/scicite",
        "GitHub URL": "https://github.com/allenai/scicite",
        "Hugging Face URL": "https://huggingface.co/datasets/scicite",
        "Paper Title": "Structural Scaffolds for Citation Intent Classification in Scientific Publications",
        "Papers with Code URL": "https://paperswithcode.com/dataset/scicite",
        "ArXiv URL": "https://arxiv.org/abs/1904.01608",
        "Semantic Scholar Corpus ID": 102483154,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Summarization"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8194,
            "Mean Inputs Length": 309.3763,
            "Mean Targets Length": 9.3627,
            "Max Inputs Length": 3416,
            "Max Targets Length": 11,
            "Min Inputs Length": 165,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semantic scholar articles"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "scicite"
        ],
        "Inferred Metadata": {
            "HF Dataset": "scicite",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2019-01-01",
            "S2 Date": "2019-04-01",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Molecular biology",
                "Medicine",
                "Biology",
                "Data analysis",
                "Cell biology",
                "Medical research",
                "Neuroscience",
                "Research methodology"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 690,
            "HF Likes (September 2023)": 3,
            "PwC Description": "SciCite is a dataset of citation intents that addresses multiple scientific domains and is more than five times larger than ACL-ARC.",
            "S2 Citation Count (September 2023)": 160,
            "GitHub Stars": 106,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Cohan2019StructuralSF,\n author = {Arman Cohan and Waleed Ammar and Madeleine van Zuylen and Field Cady},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Structural Scaffolds for Citation Intent Classification in Scientific Publications},\n volume = {abs/1904.01608},\n year = {2019}\n}\n"
    },
    "tsi-lexical_relation_classification-root09": {
        "Unique Dataset Identifier": "tsi-lexical_relation_classification-root09",
        "Dataset Name": "lexical_relation_classification-root09",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/asahi417/relbert",
        "GitHub URL": "https://github.com/asahi417/relbert",
        "Hugging Face URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification",
        "Paper Title": "SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2110.15705",
        "Semantic Scholar Corpus ID": 196172347,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Dialogue Generation",
            "Linguistic Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8933,
            "Mean Inputs Length": 92.1892,
            "Mean Targets Length": 6.5014,
            "Max Inputs Length": 106,
            "Max Targets Length": 7,
            "Min Inputs Length": 84,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semeval 2012 task 2",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification#license"
            }
        ],
        "License Notes": "License from huggingface but looks legit. The datasets the data is from is listed at the top so we can also go through the licensing on those if need be to confirm",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lexical_relation_classification/ROOT09"
        ],
        "Inferred Metadata": {
            "HF Dataset": "relbert/lexical_relation_classification",
            "HF Config": "BLESS",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-01",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Language",
                "Linguistics",
                "Food",
                "Vocabulary",
                "Word association",
                "Animals",
                "Weapons",
                "Biology",
                "Randomness",
                "Clothing"
            ],
            "Github Date": "",
            "HF Date": "2022-07-20",
            "HF Downloads (September 2023)": 140,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": 39,
            "GitHub Topics": [
                "bert",
                "nlp",
                "relation-extraction"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wang2019SphereREDL,\n author = {Chengyu Wang and Xiaofeng He and Aoying Zhou},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1727-1737},\n title = {SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings},\n year = {2019}\n}\n"
    },
    "tsi-lexical_relation_classification-cogalexv": {
        "Unique Dataset Identifier": "tsi-lexical_relation_classification-cogalexv",
        "Dataset Name": "lexical_relation_classification-cogalexv",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/asahi417/relbert",
        "GitHub URL": "https://github.com/asahi417/relbert",
        "Hugging Face URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification",
        "Paper Title": "SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2110.15705",
        "Semantic Scholar Corpus ID": 196172347,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3054,
            "Mean Inputs Length": 98.2043,
            "Mean Targets Length": 6.5691,
            "Max Inputs Length": 111,
            "Max Targets Length": 8,
            "Min Inputs Length": 90,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semeval 2012 task 2",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification#license"
            }
        ],
        "License Notes": "License from huggingface but looks legit. The datasets the data is from is listed at the top so we can also go through the licensing on those if need be to confirm",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lexical_relation_classification/CogALexV"
        ],
        "Inferred Metadata": {
            "HF Dataset": "relbert/lexical_relation_classification",
            "HF Config": "BLESS",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-01",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Word association",
                "General knowledge",
                "Communication",
                "Language and Linguistics",
                "Semantics",
                "Vocabulary",
                "Language and semantics"
            ],
            "Github Date": "",
            "HF Date": "2022-07-20",
            "HF Downloads (September 2023)": 140,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": 39,
            "GitHub Topics": [
                "bert",
                "nlp",
                "relation-extraction"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wang2019SphereREDL,\n author = {Chengyu Wang and Xiaofeng He and Aoying Zhou},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1727-1737},\n title = {SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings},\n year = {2019}\n}\n"
    },
    "tsi-lexical_relation_classification-k&h+n": {
        "Unique Dataset Identifier": "tsi-lexical_relation_classification-k&h+n",
        "Dataset Name": "lexical_relation_classification-k&h+n",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/asahi417/relbert",
        "GitHub URL": "https://github.com/asahi417/relbert",
        "Hugging Face URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification",
        "Paper Title": "SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2110.15705",
        "Semantic Scholar Corpus ID": 196172347,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 98.9668,
            "Mean Targets Length": 5.4558,
            "Max Inputs Length": 115,
            "Max Targets Length": 6,
            "Min Inputs Length": 90,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semeval 2012 task 2",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification#license"
            }
        ],
        "License Notes": "License from huggingface but looks legit. The datasets the data is from is listed at the top so we can also go through the licensing on those if need be to confirm",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lexical_relation_classification/K&H+N"
        ],
        "Inferred Metadata": {
            "HF Dataset": "relbert/lexical_relation_classification",
            "HF Config": "BLESS",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-01",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Zoology",
                "Biology",
                "Language and semantics",
                "Taxonomy",
                "Vocabulary",
                "Linguistics",
                "Animal classification",
                "Categorization and classification",
                "Botanical knowledge"
            ],
            "Github Date": "",
            "HF Date": "2022-07-20",
            "HF Downloads (September 2023)": 140,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": 39,
            "GitHub Topics": [
                "bert",
                "nlp",
                "relation-extraction"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wang2019SphereREDL,\n author = {Chengyu Wang and Xiaofeng He and Aoying Zhou},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1727-1737},\n title = {SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings},\n year = {2019}\n}\n"
    },
    "tsi-lexical_relation_classification-bless": {
        "Unique Dataset Identifier": "tsi-lexical_relation_classification-bless",
        "Dataset Name": "lexical_relation_classification-bless",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/asahi417/relbert",
        "GitHub URL": "https://github.com/asahi417/relbert",
        "Hugging Face URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification",
        "Paper Title": "SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2110.15705",
        "Semantic Scholar Corpus ID": 196172347,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 18582,
            "Mean Inputs Length": 99.9939,
            "Mean Targets Length": 6.3486,
            "Max Inputs Length": 134,
            "Max Targets Length": 7,
            "Min Inputs Length": 92,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semeval 2012 task 2",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification#license"
            }
        ],
        "License Notes": "License from huggingface but looks legit. The datasets the data is from is listed at the top so we can also go through the licensing on those if need be to confirm",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lexical_relation_classification/BLESS"
        ],
        "Inferred Metadata": {
            "HF Dataset": "relbert/lexical_relation_classification",
            "HF Config": "BLESS",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-01",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Linguistics",
                "Language and Linguistics",
                "Animal classification",
                "Food",
                "Randomness",
                "Transportation",
                "Cooking",
                "Animals",
                "Music"
            ],
            "Github Date": "",
            "HF Date": "2022-07-20",
            "HF Downloads (September 2023)": 140,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": 39,
            "GitHub Topics": [
                "bert",
                "nlp",
                "relation-extraction"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wang2019SphereREDL,\n author = {Chengyu Wang and Xiaofeng He and Aoying Zhou},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1727-1737},\n title = {SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings},\n year = {2019}\n}\n"
    },
    "tsi-lexical_relation_classification-evalution": {
        "Unique Dataset Identifier": "tsi-lexical_relation_classification-evalution",
        "Dataset Name": "lexical_relation_classification-evalution",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/asahi417/relbert",
        "GitHub URL": "https://github.com/asahi417/relbert",
        "Hugging Face URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification",
        "Paper Title": "SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2110.15705",
        "Semantic Scholar Corpus ID": 196172347,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5160,
            "Mean Inputs Length": 103.7312,
            "Mean Targets Length": 7.3167,
            "Max Inputs Length": 123,
            "Max Targets Length": 12,
            "Min Inputs Length": 93,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semeval 2012 task 2",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://huggingface.co/datasets/relbert/lexical_relation_classification#license"
            }
        ],
        "License Notes": "License from huggingface but looks legit. The datasets the data is from is listed at the top so we can also go through the licensing on those if need be to confirm",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lexical_relation_classification/EVALution"
        ],
        "Inferred Metadata": {
            "HF Dataset": "relbert/lexical_relation_classification",
            "HF Config": "BLESS",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-07-01",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Biology",
                "Word Relationships",
                "Language",
                "General knowledge",
                "Language and semantics",
                "Linguistics",
                "Language and Linguistics"
            ],
            "Github Date": "",
            "HF Date": "2022-07-20",
            "HF Downloads (September 2023)": 140,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": 39,
            "GitHub Topics": [
                "bert",
                "nlp",
                "relation-extraction"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wang2019SphereREDL,\n author = {Chengyu Wang and Xiaofeng He and Aoying Zhou},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1727-1737},\n title = {SphereRE: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings},\n year = {2019}\n}\n"
    },
    "tsi-crowdflower-political_media_bias": {
        "Unique Dataset Identifier": "tsi-crowdflower-political_media_bias",
        "Dataset Name": "crowdflower-political_media_bias",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Sentiment Analysis",
            "Dialogue Generation",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4249,
            "Mean Inputs Length": 278.7727,
            "Mean Targets Length": 8.2641,
            "Max Inputs Length": 14746,
            "Max Targets Length": 9,
            "Min Inputs Length": 79,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/political-media-bias"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Healthcare",
                "Current events",
                "Economics",
                "Political discourse",
                "Education",
                "Healthcare policy",
                "Politics"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsi-crowdflower-tweet_global_warming": {
        "Unique Dataset Identifier": "tsi-crowdflower-tweet_global_warming",
        "Dataset Name": "crowdflower-tweet_global_warming",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Fact Verification",
            "Summarization",
            "Question Answering",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3589,
            "Mean Inputs Length": 179.9766,
            "Mean Targets Length": 3.7403,
            "Max Inputs Length": 229,
            "Max Targets Length": 4,
            "Min Inputs Length": 89,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/tweet_global_warming"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Environmental issues",
                "Climate change",
                "Politics",
                "Environmental impact",
                "Environmental science",
                "Global warming",
                "Social media"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsi-crowdflower-text_emotion": {
        "Unique Dataset Identifier": "tsi-crowdflower-text_emotion",
        "Dataset Name": "crowdflower-text_emotion",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 168.6418,
            "Mean Targets Length": 7.3085,
            "Max Inputs Length": 245,
            "Max Targets Length": 11,
            "Min Inputs Length": 93,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/text_emotion"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Music",
                "Personal experiences",
                "Emotional well-being",
                "Communication",
                "Relationships",
                "Online communication",
                "Daily routine",
                "Entertainment",
                "Social media",
                "Emotions"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsi-crowdflower-political_media_message": {
        "Unique Dataset Identifier": "tsi-crowdflower-political_media_message",
        "Dataset Name": "crowdflower-political_media_message",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4249,
            "Mean Inputs Length": 303.4064,
            "Mean Targets Length": 8.5493,
            "Max Inputs Length": 14773,
            "Max Targets Length": 13,
            "Min Inputs Length": 101,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/political-media-message"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Current events",
                "History",
                "Communication",
                "Politics",
                "Legislative process",
                "Government and politics",
                "Government",
                "International relations"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsi-crowdflower-political_media_audience": {
        "Unique Dataset Identifier": "tsi-crowdflower-political_media_audience",
        "Dataset Name": "crowdflower-political_media_audience",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Sentiment Analysis",
            "Text Classification",
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4249,
            "Mean Inputs Length": 283.7727,
            "Mean Targets Length": 9.8284,
            "Max Inputs Length": 14751,
            "Max Targets Length": 13,
            "Min Inputs Length": 84,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/political-media-audience"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Government",
                "History",
                "Healthcare",
                "Immigration policy",
                "Politics",
                "Public policy",
                "Current events",
                "Education"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsi-crowdflower-economic_news": {
        "Unique Dataset Identifier": "tsi-crowdflower-economic_news",
        "Dataset Name": "crowdflower-economic_news",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Information Extraction",
            "Summarization",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6465,
            "Mean Inputs Length": 1484.7111,
            "Mean Targets Length": 3.1856,
            "Max Inputs Length": 5094,
            "Max Targets Length": 9,
            "Min Inputs Length": 192,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/economic-news"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Economics",
                "Finance",
                "Monetary policy",
                "Stock market",
                "Government policies",
                "Stock market analysis",
                "Economic indicators",
                "Financial markets",
                "Financial news"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsi-crowdflower-corporate_messaging": {
        "Unique Dataset Identifier": "tsi-crowdflower-corporate_messaging",
        "Dataset Name": "crowdflower-corporate_messaging",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2650,
            "Mean Inputs Length": 224.1838,
            "Mean Targets Length": 10.58,
            "Max Inputs Length": 262,
            "Max Targets Length": 12,
            "Min Inputs Length": 125,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/corporate-messaging"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Product recall",
                "Food safety",
                "Banking industry",
                "Health and wellness",
                "Social media",
                "Health",
                "Finance",
                "Healthcare",
                "Corporate social responsibility",
                "Social media communication"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsi-crowdflower-airline_sentiment": {
        "Unique Dataset Identifier": "tsi-crowdflower-airline_sentiment",
        "Dataset Name": "crowdflower-airline_sentiment",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12444,
            "Mean Inputs Length": 193.3928,
            "Mean Targets Length": 8.7875,
            "Max Inputs Length": 319,
            "Max Targets Length": 9,
            "Min Inputs Length": 92,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/airline-sentiment"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Social media communication",
                "Customer service experience",
                "Travel",
                "Customer service",
                "Complaints",
                "Communication",
                "Social media"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsi-crowdflower-sentiment_nuclear_power": {
        "Unique Dataset Identifier": "tsi-crowdflower-sentiment_nuclear_power",
        "Dataset Name": "crowdflower-sentiment_nuclear_power",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/crowdflower",
        "Paper Title": "Designing a scalable crowdsourcing platform",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 38954687,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 161,
            "Mean Inputs Length": 275.7019,
            "Mean Targets Length": 40.6957,
            "Max Inputs Length": 318,
            "Max Targets Length": 45,
            "Min Inputs Length": 203,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdflower.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Not even sure if this the right source since huggingface had no info",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "crowdflower/sentiment_nuclear_power"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/crowdflower",
            "HF Config": "sentiment_nuclear_power",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-20",
            "GitHub License": "",
            "Text Topics": [
                "Current events",
                "Technology",
                "Nuclear energy",
                "Energy sources",
                "Environmental impact",
                "Social media",
                "Energy"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 349,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 42,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Pelt2012DesigningAS,\n author = {C. V. Pelt and A. Sorokin},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},\n title = {Designing a scalable crowdsourcing platform},\n year = {2012}\n}\n"
    },
    "tsi-ethics-commonsense": {
        "Unique Dataset Identifier": "tsi-ethics-commonsense",
        "Dataset Name": "ethics-commonsense",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/hendrycks/ethics",
        "GitHub URL": "https://github.com/hendrycks/ethics",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/ethics",
        "Paper Title": "ALIGNING AI WITH SHARED HUMAN VALUES",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ethics-1",
        "ArXiv URL": "https://arxiv.org/abs/2008.02275",
        "Semantic Scholar Corpus ID": 220968818,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Dialogue Generation",
            "Dialog Generation",
            "Question Answering",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13910,
            "Mean Inputs Length": 1103.9738,
            "Mean Targets Length": 11.9136,
            "Max Inputs Length": 12253,
            "Max Targets Length": 13,
            "Min Inputs Length": 95,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Berkeley",
            "Columbia University",
            "University of Chicago",
            "Microsoft"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ethics/commonsense"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/ethics",
            "HF Config": "commonsense",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-08-05",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Ethics and morality",
                "Family dynamics",
                "Ethics",
                "Family dynamics and relationships",
                "Personal boundaries",
                "Relationships",
                "Communication and conflict resolution",
                "Social etiquette",
                "Communication",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 447,
            "HF Likes (September 2023)": 4,
            "PwC Description": "A new benchmark that spans concepts in justice, well-being, duties, virtues, and commonsense morality.",
            "S2 Citation Count (September 2023)": 147,
            "GitHub Stars": 150,
            "GitHub Topics": [
                "ai-safety",
                "ethical-ai",
                "gpt-3",
                "machine-ethics",
                "ml-safety"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hendrycks2020AligningAW,\n author = {Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and J. Li and D. Song and J. Steinhardt},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Aligning AI With Shared Human Values},\n volume = {abs/2008.02275},\n year = {2020}\n}\n"
    },
    "tsi-ethics-deontology": {
        "Unique Dataset Identifier": "tsi-ethics-deontology",
        "Dataset Name": "ethics-deontology",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/hendrycks/ethics",
        "GitHub URL": "https://github.com/hendrycks/ethics",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/ethics",
        "Paper Title": "ALIGNING AI WITH SHARED HUMAN VALUES",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ethics-1",
        "ArXiv URL": "https://arxiv.org/abs/2008.02275",
        "Semantic Scholar Corpus ID": 220968818,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Dialogue Generation",
            "Text Classification",
            "Dialog Generation"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 18164,
            "Mean Inputs Length": 131.2896,
            "Mean Targets Length": 12.078,
            "Max Inputs Length": 216,
            "Max Targets Length": 13,
            "Min Inputs Length": 114,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Berkeley",
            "Columbia University",
            "University of Chicago",
            "Microsoft"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ethics/deontology"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/ethics",
            "HF Config": "commonsense",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-08-05",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Education",
                "Daily routine",
                "Home maintenance",
                "Travel",
                "Household chores",
                "Cooking",
                "Communication",
                "Social etiquette",
                "Customer service",
                "Time management"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 447,
            "HF Likes (September 2023)": 4,
            "PwC Description": "A new benchmark that spans concepts in justice, well-being, duties, virtues, and commonsense morality.",
            "S2 Citation Count (September 2023)": 147,
            "GitHub Stars": 150,
            "GitHub Topics": [
                "ai-safety",
                "ethical-ai",
                "gpt-3",
                "machine-ethics",
                "ml-safety"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hendrycks2020AligningAW,\n author = {Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and J. Li and D. Song and J. Steinhardt},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Aligning AI With Shared Human Values},\n volume = {abs/2008.02275},\n year = {2020}\n}\n"
    },
    "tsi-ethics-justice": {
        "Unique Dataset Identifier": "tsi-ethics-justice",
        "Dataset Name": "ethics-justice",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/hendrycks/ethics",
        "GitHub URL": "https://github.com/hendrycks/ethics",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/ethics",
        "Paper Title": "ALIGNING AI WITH SHARED HUMAN VALUES",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ethics-1",
        "ArXiv URL": "https://arxiv.org/abs/2008.02275",
        "Semantic Scholar Corpus ID": 220968818,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Sentiment Analysis",
            "Text Classification",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 21791,
            "Mean Inputs Length": 188.1053,
            "Mean Targets Length": 12.0858,
            "Max Inputs Length": 499,
            "Max Targets Length": 13,
            "Min Inputs Length": 134,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Berkeley",
            "Columbia University",
            "University of Chicago",
            "Microsoft"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ethics/justice"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/ethics",
            "HF Config": "commonsense",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-08-05",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Health",
                "Family dynamics",
                "Education",
                "Daily routine",
                "Communication",
                "Social interactions",
                "Ethics and morality"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 447,
            "HF Likes (September 2023)": 4,
            "PwC Description": "A new benchmark that spans concepts in justice, well-being, duties, virtues, and commonsense morality.",
            "S2 Citation Count (September 2023)": 147,
            "GitHub Stars": 150,
            "GitHub Topics": [
                "ai-safety",
                "ethical-ai",
                "gpt-3",
                "machine-ethics",
                "ml-safety"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hendrycks2020AligningAW,\n author = {Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and J. Li and D. Song and J. Steinhardt},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Aligning AI With Shared Human Values},\n volume = {abs/2008.02275},\n year = {2020}\n}\n"
    },
    "tsi-ethics-virtue": {
        "Unique Dataset Identifier": "tsi-ethics-virtue",
        "Dataset Name": "ethics-virtue",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/hendrycks/ethics",
        "GitHub URL": "https://github.com/hendrycks/ethics",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/ethics",
        "Paper Title": "ALIGNING AI WITH SHARED HUMAN VALUES",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ethics-1",
        "ArXiv URL": "https://arxiv.org/abs/2008.02275",
        "Semantic Scholar Corpus ID": 220968818,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Natural Language Inference",
            "Fact Verification",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 28245,
            "Mean Inputs Length": 161.0769,
            "Mean Targets Length": 11.171,
            "Max Inputs Length": 260,
            "Max Targets Length": 13,
            "Min Inputs Length": 128,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Berkeley",
            "Columbia University",
            "University of Chicago",
            "Microsoft"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ethics/virtue"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/ethics",
            "HF Config": "commonsense",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-08-05",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Communication",
                "Ethics and morality",
                "Relationships",
                "Health",
                "Daily routine",
                "Study habits",
                "Emotional intelligence",
                "Ethics"
            ],
            "Github Date": "",
            "HF Date": "2021-12-08",
            "HF Downloads (September 2023)": 447,
            "HF Likes (September 2023)": 4,
            "PwC Description": "A new benchmark that spans concepts in justice, well-being, duties, virtues, and commonsense morality.",
            "S2 Citation Count (September 2023)": 147,
            "GitHub Stars": 150,
            "GitHub Topics": [
                "ai-safety",
                "ethical-ai",
                "gpt-3",
                "machine-ethics",
                "ml-safety"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hendrycks2020AligningAW,\n author = {Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and J. Li and D. Song and J. Steinhardt},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Aligning AI With Shared Human Values},\n volume = {abs/2008.02275},\n year = {2020}\n}\n"
    },
    "tsi-tweets_hate_speech_detection": {
        "Unique Dataset Identifier": "tsi-tweets_hate_speech_detection",
        "Dataset Name": "tweets_hate_speech_detection",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sharmaroshan/Twitter-Sentiment-Analysis",
        "GitHub URL": "https://github.com/sharmaroshan/Twitter-Sentiment-Analysis",
        "Hugging Face URL": "https://huggingface.co/datasets/tweets_hate_speech_detection",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 27167,
            "Mean Inputs Length": 171.2463,
            "Mean Targets Length": 14.789,
            "Max Inputs Length": 361,
            "Max Targets Length": 15,
            "Min Inputs Length": 98,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Github readme is an article on the dataset which doesn't seem to have an actual paper",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tweets_hate_speech_detection"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweets_hate_speech_detection",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "GNU General Public License v3.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "Social media",
                "Event planning",
                "Emotions",
                "Social media etiquette",
                "Travel",
                "Education",
                "Daily routine",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 927,
            "HF Likes (September 2023)": 12,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 162,
            "GitHub Topics": [
                "bag-of-words",
                "classification",
                "count-vectorizer",
                "cross-validation",
                "data-analysis",
                "data-visualization",
                "datacleaning",
                "eda",
                "evaluation-metrics",
                "hashtags",
                "machine-learning",
                "nlp",
                "sentiment-analysis",
                "wordcloud"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-wnut_17-wnut_17": {
        "Unique Dataset Identifier": "tsi-wnut_17-wnut_17",
        "Dataset Name": "wnut_17-wnut_17",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://noisy-text.github.io/2017/emerging-rare-entities.html",
        "GitHub URL": "http://noisy-text.github.io/2017/emerging-rare-entities.html",
        "Hugging Face URL": "https://huggingface.co/datasets/wnut_17",
        "Paper Title": "Results of the WNUT2017 Shared Task on Novel and Emerging Entity Recognition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wnut-2017-emerging-and-rare-entity",
        "ArXiv URL": "https://aclanthology.org/W17-4418/",
        "Semantic Scholar Corpus ID": 26988506,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Text Generation",
            "Named Entity Recognition",
            "Question Answering",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3394,
            "Mean Inputs Length": 296.6214,
            "Mean Targets Length": 142.7811,
            "Max Inputs Length": 375,
            "Max Targets Length": 326,
            "Min Inputs Length": 207,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter",
            "reddit",
            "youtube",
            "stackexchange.com"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Sheffield",
            "Honda Research Institute",
            "VU University Amsterdam",
            "Accenture"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "wnut_17/wnut_17"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wnut_17",
            "HF Config": "wnut_17",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "",
            "PwC Date": "2017-09-01",
            "S2 Date": "2017-09-01",
            "GitHub License": "",
            "Text Topics": [
                "Social media",
                "Language and communication",
                "Entertainment",
                "Music",
                "Communication",
                "Online communication",
                "Time and date"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3989,
            "HF Likes (September 2023)": 8,
            "PwC Description": "This shared task focuses on identifying unusual, previously-unseen entities in the context of emerging discussions. Named entities form the basis of many modern approaches to other tasks (like event clustering and summarisation), but recall on them is a real problem in noisy text - even among annotators. This drop tends to be due to novel entities and surface forms. Take for example the tweet so.. kktny in 30 mins? - even human experts find entity kktny hard to detect and resolve. This task will evaluate the ability to detect and classify novel, emerging, singleton named entities in noisy text.\n\nThe goal of this task is to provide a definition of emerging and of rare entities, and based on that, also datasets for detecting these entities.",
            "S2 Citation Count (September 2023)": 273,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Derczynski2017ResultsOT,\n author = {Leon Derczynski and Eric Nichols and M. Erp and Nut Limsopatham},\n booktitle = {NUT@EMNLP},\n pages = {140-147},\n title = {Results of the WNUT2017 Shared Task on Novel and Emerging Entity Recognition},\n year = {2017}\n}\n"
    },
    "tsi-ncbi_disease-ncbi_disease": {
        "Unique Dataset Identifier": "tsi-ncbi_disease-ncbi_disease",
        "Dataset Name": "ncbi_disease-ncbi_disease",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3951655/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ncbi_disease",
        "Paper Title": "NCBI disease corpus: A resource for disease name recognition and concept normalization",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ncbi-disease-1",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 234064,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "BioMedical Question Answering",
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5433,
            "Mean Inputs Length": 232.2301,
            "Mean Targets Length": 207.9168,
            "Max Inputs Length": 721,
            "Max Targets Length": 996,
            "Min Inputs Length": 90,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "pubmed"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ncbi_disease/ncbi_disease"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ncbi_disease",
            "HF Config": "ncbi_disease",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2014-01-01",
            "S2 Date": "2014-02-01",
            "GitHub License": "",
            "Text Topics": [
                "Medical research",
                "Biology",
                "Health",
                "Cell biology",
                "Medical conditions",
                "Biochemistry",
                "Genetics",
                "Molecular biology"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2731,
            "HF Likes (September 2023)": 18,
            "PwC Description": "The NCBI Disease corpus consists of 793 PubMed abstracts, which are separated into training (593), development (100) and test (100) subsets. The NCBI Disease corpus is annotated with disease mentions, using concept identifiers from either MeSH or OMIM.",
            "S2 Citation Count (September 2023)": 614,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Dogan2014NCBIDC,\n author = {R. Dogan and Robert Leaman and Zhiyong Lu},\n booktitle = {Journal of Biomedical Informatics},\n journal = {Journal of biomedical informatics},\n pages = {\n          1-10\n        },\n title = {NCBI disease corpus: A resource for disease name recognition and concept normalization},\n volume = {47},\n year = {2014}\n}\n"
    },
    "tsi-acronym_identification": {
        "Unique Dataset Identifier": "tsi-acronym_identification",
        "Dataset Name": "acronym_identification",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/amirveyseh/AAAI-21-SDU-shared-task-1-AI",
        "GitHub URL": "https://github.com/amirveyseh/AAAI-21-SDU-shared-task-1-AI",
        "Hugging Face URL": "https://huggingface.co/datasets/acronym_identification",
        "Paper Title": "What Does This Acronym Mean? Introducing a New Dataset for Acronym Identification and Disambiguation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/acronym-identification",
        "ArXiv URL": "https://arxiv.org/abs/2010.14678",
        "Semantic Scholar Corpus ID": 225094666,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Natural Language Inference",
            "Text Generation",
            "Named Entity Recognition",
            "Question Answering",
            "Part-of-Speech Tagging"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 14006,
            "Mean Inputs Length": 287.4482,
            "Mean Targets Length": 271.0061,
            "Max Inputs Length": 1083,
            "Max Targets Length": 1377,
            "Min Inputs Length": 115,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "arxiv.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Oregon",
            "Adobe Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "https://github.com/amirveyseh/AAAI-21-SDU-shared-task-1-AI#licenses"
            }
        ],
        "License Notes": "States data is taken from scientific paper on arxiv: https://sites.google.com/view/sdu-aaai21/shared-task",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "acronym_identification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "acronym_identification",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-28",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Computer Science",
                "Artificial Intelligence",
                "Data analysis",
                "Linguistics",
                "Machine learning",
                "Mathematics",
                "Natural language processing",
                "Technology",
                "Machine Learning",
                "Natural Language Processing"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5034,
            "HF Likes (September 2023)": 17,
            "PwC Description": "Is an acronym disambiguation (AD) dataset for scientific domain with 62,441 samples which is significantly larger than the previous scientific AD dataset.",
            "S2 Citation Count (September 2023)": 47,
            "GitHub Stars": 27,
            "GitHub Topics": [
                "acronym-identification"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Veyseh2020WhatDT,\n author = {Amir Pouran Ben Veyseh and Franck Dernoncourt and Quan Hung Tran and Thien Huu Nguyen},\n booktitle = {International Conference on Computational Linguistics},\n pages = {3285-3301},\n title = {What Does This Acronym Mean? Introducing a New Dataset for Acronym Identification and Disambiguation},\n year = {2020}\n}\n"
    },
    "tsi-jnlpba-jnlpba": {
        "Unique Dataset Identifier": "tsi-jnlpba-jnlpba",
        "Dataset Name": "jnlpba-jnlpba",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "http://www.geniaproject.org/shared-tasks/bionlp-jnlpba-shared-task-2004",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/jnlpba",
        "Paper Title": "Introduction to the Bio-Entity Recognition Task at JNLPBA",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/W04-1213/",
        "Semantic Scholar Corpus ID": 7985741,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 18546,
            "Mean Inputs Length": 336.7806,
            "Mean Targets Length": 260.9158,
            "Max Inputs Length": 1087,
            "Max Targets Length": 1695,
            "Min Inputs Length": 177,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "pubmed articles"
        ],
        "Model Generated": [],
        "Creators": [
            "Center for Research on Engineering Software Technologies",
            "University of Tokyo",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "jnlpba/jnlpba"
        ],
        "Inferred Metadata": {
            "HF Dataset": "jnlpba",
            "HF Config": "jnlpba",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2004-08-28",
            "GitHub License": "",
            "Text Topics": [
                "Molecular biology",
                "Biochemistry",
                "Transcription factors",
                "Cell biology",
                "Biology",
                "Gene expression",
                "Genetics"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 723,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 649,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "Genia dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Collier2004IntroductionTT,\n author = {Nigel Collier and Jin-Dong Kim},\n booktitle = {NLPBA/BioNLP},\n pages = {70-75},\n title = {Introduction to the Bio-entity Recognition Task at JNLPBA},\n year = {2004}\n}\n"
    },
    "tsi-ontonotes_english-speedofmagic__ontonotes_english": {
        "Unique Dataset Identifier": "tsi-ontonotes_english-speedofmagic__ontonotes_english",
        "Dataset Name": "ontonotes_english-speedofmagic__ontonotes_english",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://www.aclweb.org/anthology/W03-0419/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/SpeedOfMagic/ontonotes_english",
        "Paper Title": "Towards Robust Linguistic Analysis using OntoNotes",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/W13-3516/",
        "Semantic Scholar Corpus ID": 14515377,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Sentiment Analysis",
            "Text Classification",
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 250.4136,
            "Mean Targets Length": 145.4048,
            "Max Inputs Length": 1562,
            "Max Targets Length": 1849,
            "Min Inputs Length": 155,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "newswire",
            "broadcast conversation",
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "Boston Childrens Hospital",
            "Harvard University",
            "University of Trento",
            "Qatar Computing Research Institute",
            "Qatar Computing Research Institute",
            "Brandeis University",
            "National University of Singapore",
            "University of Stuttgart"
        ],
        "Licenses": [
            {
                "License": "No License",
                "License URL": "https://huggingface.co/datasets/SpeedOfMagic/ontonotes_english#dataset-summary"
            }
        ],
        "License Notes": "On huggingface, the author says the data comes from a private repository which in turn comes from a public repository. They were told that there should be no license on the data",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ontonotes_english/SpeedOfMagic--ontonotes_english"
        ],
        "Inferred Metadata": {
            "HF Dataset": "SpeedOfMagic/ontonotes_english",
            "HF Config": "SpeedOfMagic--ontonotes_english",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2013-08-01",
            "GitHub License": "",
            "Text Topics": [
                "General conversation",
                "Communication",
                "Geography",
                "International relations",
                "Politics",
                "General knowledge",
                "Language and communication",
                "Small talk"
            ],
            "Github Date": "",
            "HF Date": "2022-06-28",
            "HF Downloads (September 2023)": 115,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 365,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "OntoNotes corpus"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Pradhan2013TowardsRL,\n author = {Sameer Pradhan and Alessandro Moschitti and Nianwen Xue and H. Ng and Anders Bjrkelund and Olga Uryupina and Yuchen Zhang and Z. Zhong},\n booktitle = {Conference on Computational Natural Language Learning},\n pages = {143-152},\n title = {Towards Robust Linguistic Analysis using OntoNotes},\n year = {2013}\n}\n"
    },
    "tsi-blog_authorship_corpus-gender": {
        "Unique Dataset Identifier": "tsi-blog_authorship_corpus-gender",
        "Dataset Name": "blog_authorship_corpus-gender",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://lingcog.blogspot.com/p/datasets.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/blog_authorship_corpus",
        "Paper Title": "Effects of Age and Gender on Blogging",
        "Papers with Code URL": "https://paperswithcode.com/dataset/blog-authorship-corpus",
        "ArXiv URL": "https://arxiv.org/abs/2306.02488",
        "Semantic Scholar Corpus ID": 2075411,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Text Generation",
            "Named Entity Recognition",
            "Summarization",
            "Dialogue Generation",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 1103.808,
            "Mean Targets Length": 5.9792,
            "Max Inputs Length": 122151,
            "Max Targets Length": 7,
            "Min Inputs Length": 74,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "blogger.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Pennsylvania State University",
            "Wright State University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://u.cs.biu.ac.il/~koppel/BlogCorpus.htm"
            }
        ],
        "License Notes": "Academic Research Purposes Only",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "blog_authorship_corpus/gender"
        ],
        "Inferred Metadata": {
            "HF Dataset": "blog_authorship_corpus",
            "HF Config": "blog_authorship_corpus",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Music",
                "Gender stereotypes and assumptions",
                "Health",
                "Gender stereotypes",
                "Daily routine",
                "Personal experiences",
                "Technology"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 917,
            "HF Likes (September 2023)": 4,
            "PwC Description": "The Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or approximately 35 posts and 7250 words per person.",
            "S2 Citation Count (September 2023)": 765,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Schler2006EffectsOA,\n author = {Jonathan Schler and Moshe Koppel and S. Argamon and J. Pennebaker},\n booktitle = {AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs},\n pages = {199-205},\n title = {Effects of Age and Gender on Blogging},\n year = {2006}\n}\n"
    },
    "tsi-blog_authorship_corpus-horoscope": {
        "Unique Dataset Identifier": "tsi-blog_authorship_corpus-horoscope",
        "Dataset Name": "blog_authorship_corpus-horoscope",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://lingcog.blogspot.com/p/datasets.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/blog_authorship_corpus",
        "Paper Title": "Effects of Age and Gender on Blogging",
        "Papers with Code URL": "https://paperswithcode.com/dataset/blog-authorship-corpus",
        "ArXiv URL": "https://arxiv.org/abs/2306.02488",
        "Semantic Scholar Corpus ID": 2075411,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 1127.3781,
            "Mean Targets Length": 7.2629,
            "Max Inputs Length": 122174,
            "Max Targets Length": 12,
            "Min Inputs Length": 92,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "blogger.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Pennsylvania State University",
            "Wright State University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://u.cs.biu.ac.il/~koppel/BlogCorpus.htm"
            }
        ],
        "License Notes": "Non-commercial research only",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "blog_authorship_corpus/horoscope"
        ],
        "Inferred Metadata": {
            "HF Dataset": "blog_authorship_corpus",
            "HF Config": "blog_authorship_corpus",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Personality traits",
                "Daily routine",
                "Astrology",
                "Personal experiences",
                "Travel",
                "Zodiac signs"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 917,
            "HF Likes (September 2023)": 4,
            "PwC Description": "The Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or approximately 35 posts and 7250 words per person.",
            "S2 Citation Count (September 2023)": 765,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Schler2006EffectsOA,\n author = {Jonathan Schler and Moshe Koppel and S. Argamon and J. Pennebaker},\n booktitle = {AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs},\n pages = {199-205},\n title = {Effects of Age and Gender on Blogging},\n year = {2006}\n}\n"
    },
    "tsi-blog_authorship_corpus-job": {
        "Unique Dataset Identifier": "tsi-blog_authorship_corpus-job",
        "Dataset Name": "blog_authorship_corpus-job",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://lingcog.blogspot.com/p/datasets.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/blog_authorship_corpus",
        "Paper Title": "Effects of Age and Gender on Blogging",
        "Papers with Code URL": "https://paperswithcode.com/dataset/blog-authorship-corpus",
        "ArXiv URL": "https://arxiv.org/abs/2306.02488",
        "Semantic Scholar Corpus ID": 2075411,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 1142.322,
            "Mean Targets Length": 8.8688,
            "Max Inputs Length": 122192,
            "Max Targets Length": 24,
            "Min Inputs Length": 100,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "blogger.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Pennsylvania State University",
            "Wright State University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://u.cs.biu.ac.il/~koppel/BlogCorpus.htm"
            }
        ],
        "License Notes": "Non-commercial research only",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "blog_authorship_corpus/job"
        ],
        "Inferred Metadata": {
            "HF Dataset": "blog_authorship_corpus",
            "HF Config": "blog_authorship_corpus",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Film and entertainment",
                "Personal experiences",
                "Education",
                "Music",
                "Technology",
                "Daily routine",
                "Communication",
                "Travel",
                "Entertainment"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 917,
            "HF Likes (September 2023)": 4,
            "PwC Description": "The Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or approximately 35 posts and 7250 words per person.",
            "S2 Citation Count (September 2023)": 765,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Schler2006EffectsOA,\n author = {Jonathan Schler and Moshe Koppel and S. Argamon and J. Pennebaker},\n booktitle = {AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs},\n pages = {199-205},\n title = {Effects of Age and Gender on Blogging},\n year = {2006}\n}\n"
    },
    "tsi-open_question_type": {
        "Unique Dataset Identifier": "tsi-open_question_type",
        "Dataset Name": "open_question_type",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://shuyangcao.github.io/projects/ontology_open_ended_question/",
        "GitHub URL": "https://shuyangcao.github.io/projects/ontology_open_ended_question/",
        "Hugging Face URL": "https://huggingface.co/datasets/launch/open_question_type",
        "Paper Title": "Controllable Open-ended Question Generation with A New Question Type Ontology",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2107.00152",
        "Semantic Scholar Corpus ID": 235678938,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3716,
            "Mean Inputs Length": 171.3388,
            "Mean Targets Length": 9.4419,
            "Max Inputs Length": 306,
            "Max Targets Length": 13,
            "Min Inputs Length": 116,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reddit",
            "yahoo"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Michigan"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "open_question_type"
        ],
        "Inferred Metadata": {
            "HF Dataset": "launch/open_question_type",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-07-01",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Psychology",
                "User interface design",
                "Religion",
                "Technology",
                "Health",
                "Music",
                "Personal experiences"
            ],
            "Github Date": "",
            "HF Date": "2022-06-28",
            "HF Downloads (September 2023)": 99,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 24,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Cao2021ControllableOQ,\n author = {Shuyang Cao and Lu Wang},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Controllable Open-ended Question Generation with A New Question Type Ontology},\n volume = {abs/2107.00152},\n year = {2021}\n}\n"
    },
    "tsi-commonsense_qa": {
        "Unique Dataset Identifier": "tsi-commonsense_qa",
        "Dataset Name": "commonsense_qa",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://www.tau-nlp.org/commonsenseqa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/commonsense_qa",
        "Paper Title": "CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/commonsenseqa",
        "ArXiv URL": "https://arxiv.org/abs/1811.00937",
        "Semantic Scholar Corpus ID": 53296520,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9741,
            "Mean Inputs Length": 193.9589,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 494,
            "Max Targets Length": 2,
            "Min Inputs Length": 128,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conceptnet",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Tel Aviv University",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "commonsense_qa"
        ],
        "Inferred Metadata": {
            "HF Dataset": "commonsense_qa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2019-01-01",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "Food",
                "Home appliances",
                "Music",
                "Education",
                "Animal behavior",
                "Entertainment"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 11299,
            "HF Likes (September 2023)": 20,
            "PwC Description": "The CommonsenseQA is a dataset for commonsense question answering task. The dataset consists of 12,247 questions with 5 choices each.\nThe dataset was generated by Amazon Mechanical Turk workers in the following process (an example is provided in parentheses):\n\n\na crowd worker observes a source concept from ConceptNet (River) and three target concepts (Waterfall, Bridge, Valley) that are all related by the same ConceptNet relation (AtLocation),\nthe worker authors three questions, one per target concept, such that only that particular target concept is the answer, while the other two distractor concepts are not, (Where on a river can you hold a cup upright to catch water on a sunny day?, Where can I stand on a river to see water falling without getting wet?, Im crossing the river, my feet are wet but my body is dry, where am I?)\nfor each question, another worker chooses one additional distractor from Concept Net (pebble, stream, bank), and the author another distractor (mountain, bottom, island) manually.",
            "S2 Citation Count (September 2023)": 685,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Talmor2019CommonsenseQAAQ,\n author = {Alon Talmor and Jonathan Herzig and Nicholas Lourie and Jonathan Berant},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n volume = {abs/1811.00937},\n year = {2019}\n}\n"
    },
    "tsi-mc_taco": {
        "Unique Dataset Identifier": "tsi-mc_taco",
        "Dataset Name": "mc_taco",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://cogcomp.seas.upenn.edu/page/resource_view/125",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/mc_taco",
        "Paper Title": "Going on a vacation takes longer than Going for a walk: A Study of Temporal Commonsense Understanding",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mc-taco",
        "ArXiv URL": "https://arxiv.org/abs/1909.03065",
        "Semantic Scholar Corpus ID": 202541184,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3783,
            "Mean Inputs Length": 230.4174,
            "Mean Targets Length": 3.3249,
            "Max Inputs Length": 396,
            "Max Targets Length": 4,
            "Min Inputs Length": 147,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "cnn.com",
            "wsj",
            "nytmes",
            "wikipedia.org",
            "project gutenberg",
            "9/11 reports",
            "textbooks",
            "mctest",
            "anc corpus",
            "masc dataset"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Pennsylvania",
            "AI2",
            "University of Illinois Urbana-Champaign"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mc_taco"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mc_taco",
            "HF Config": "plain_text",
            "HF Config License": "Unspecified",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2019-09-06",
            "S2 Date": "2019-09-06",
            "GitHub License": "",
            "Text Topics": [
                "Literature",
                "Time",
                "Geography",
                "Time measurement",
                "Education",
                "Health",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1739,
            "HF Likes (September 2023)": 0,
            "PwC Description": "MC-TACO is a dataset of 13k question-answer pairs that require temporal commonsense comprehension. The dataset contains five temporal properties, (1) duration (how long an event takes), (2) temporal ordering (typical order of events), (3) typical time (when an event occurs), (4) frequency (how often an event occurs), and (5) stationarity (whether a state is maintained for a very long time or indefinitely).",
            "S2 Citation Count (September 2023)": 129,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "MultiRC"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zhou2019GoingOA,\n author = {Ben Zhou and Daniel Khashabi and Qiang Ning and D. Roth},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Going on a vacation takes longer than Going for a walk: A Study of Temporal Commonsense Understanding},\n volume = {abs/1909.03065},\n year = {2019}\n}\n"
    },
    "tsi-discosense": {
        "Unique Dataset Identifier": "tsi-discosense",
        "Dataset Name": "discosense",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/prajjwal1/discosense",
        "GitHub URL": "https://github.com/prajjwal1/discosense",
        "Hugging Face URL": "https://huggingface.co/datasets/prajjwal1/discosense",
        "Paper Title": "DISCOSENSE: Commonsense Reasoning with Discourse Connectives",
        "Papers with Code URL": "https://paperswithcode.com/dataset/discosense",
        "ArXiv URL": "https://arxiv.org/abs/2210.12478",
        "Semantic Scholar Corpus ID": 253098557,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9299,
            "Mean Inputs Length": 569.7275,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 1243,
            "Max Targets Length": 2,
            "Min Inputs Length": 201,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "undisclosed web",
            "commoncrawl.org"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "University of Texas at Dallas"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "discosense"
        ],
        "Inferred Metadata": {
            "HF Dataset": "prajjwal1/discosense",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-10-22",
            "S2 Date": "2022-10-22",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "User interface design",
                "Philosophy",
                "Religion",
                "Biology",
                "History",
                "Politics",
                "Research methodology",
                "Ethics and morality"
            ],
            "Github Date": "",
            "HF Date": "2022-10-14",
            "HF Downloads (September 2023)": 17,
            "HF Likes (September 2023)": 0,
            "PwC Description": "DiscoSense is a benchmark sourced from datasets that contain two sentences connected through a discourse connective. Specifically, it is sourced from two peer reviewed academic datasets, DISCOVERY and DISCOFUSE for commonsense reasoning via understanding a wide variety of discourse connectives.",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "Discovery dataset",
            "Discofuse dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Bhargava2022DiscoSenseCR,\n author = {Prajjwal Bhargava and Vincent Ng},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {10295-10310},\n title = {DiscoSense: Commonsense Reasoning with Discourse Connectives},\n year = {2022}\n}\n"
    },
    "tsi-effectivefeedbackstudentwriting": {
        "Unique Dataset Identifier": "tsi-effectivefeedbackstudentwriting",
        "Dataset Name": "effectivefeedbackstudentwriting",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/YaHi/EffectiveFeedbackStudentWriting",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/YaHi/EffectiveFeedbackStudentWriting",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Creativity",
            "Summarization",
            "Question Answering",
            "Explanation Generation",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 344.5295,
            "Mean Targets Length": 9.7824,
            "Max Inputs Length": 4193,
            "Max Targets Length": 12,
            "Min Inputs Length": 98,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "EffectiveFeedbackStudentWriting"
        ],
        "Inferred Metadata": {
            "HF Dataset": "YaHi/EffectiveFeedbackStudentWriting",
            "HF Config": "YaHi--EffectiveFeedbackStudentWriting",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Technology",
                "Education",
                "Science",
                "Astronomy",
                "Communication skills",
                "Electoral systems",
                "Communication",
                "Politics"
            ],
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-phrase_similarity": {
        "Unique Dataset Identifier": "tsi-phrase_similarity",
        "Dataset Name": "phrase_similarity",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://phrase-in-context.github.io/",
        "GitHub URL": "https://phrase-in-context.github.io/",
        "Hugging Face URL": "https://huggingface.co/datasets/PiC/phrase_similarity",
        "Paper Title": "PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic Search",
        "Papers with Code URL": "https://paperswithcode.com/dataset/phrase-in-context",
        "ArXiv URL": "https://arxiv.org/abs/2207.09068",
        "Semantic Scholar Corpus ID": 250462558,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7004,
            "Mean Inputs Length": 353.9355,
            "Mean Targets Length": 9.0,
            "Max Inputs Length": 574,
            "Max Targets Length": 9,
            "Min Inputs Length": 186,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Auburn University",
            "Adobe Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://phrase-in-context.github.io/"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "phrase_similarity"
        ],
        "Inferred Metadata": {
            "HF Dataset": "PiC/phrase_similarity",
            "HF Config": "PS-hard",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "CC BY-NC 4.0",
            "PwC License Name": "CC BY-NC 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-nc/4.0/",
            "PwC Date": "2022-06-10",
            "S2 Date": "2022-07-19",
            "GitHub License": "",
            "Text Topics": [
                "Business and entrepreneurship",
                "Communication",
                "Cultural traditions and customs",
                "History",
                "Mathematics",
                "Geography",
                "Technology"
            ],
            "Github Date": "",
            "HF Date": "2022-06-14",
            "HF Downloads (September 2023)": 394,
            "HF Likes (September 2023)": 6,
            "PwC Description": "Phrase in Context is a curated benchmark for phrase understanding and semantic search, consisting of three tasks of increasing difficulty: Phrase Similarity (PS), Phrase Retrieval (PR) and Phrase Sense Disambiguation (PSD). The datasets are annotated by 13 linguistic experts on Upwork and verified by two groups: ~1000 AMT crowdworkers and another set of 5 linguistic experts. PiC benchmark is distributed under CC-BY-NC 4.0.",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Pham2022PiCAP,\n author = {Thang M. Pham and Seunghyun Yoon and Trung Bui and Anh M Nguyen},\n booktitle = {Conference of the European Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic Search},\n volume = {abs/2207.09068},\n year = {2022}\n}\n"
    },
    "tsi-scientific_exaggeration_detection": {
        "Unique Dataset Identifier": "tsi-scientific_exaggeration_detection",
        "Dataset Name": "scientific_exaggeration_detection",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/copenlu/scientific-exaggeration-detection",
        "GitHub URL": "https://github.com/copenlu/scientific-exaggeration-detection",
        "Hugging Face URL": "https://huggingface.co/datasets/copenlu/scientific-exaggeration-detection",
        "Paper Title": "Semi-Supervised Exaggeration Detection of Health Science Press Releases",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2108.13493",
        "Semantic Scholar Corpus ID": 237363790,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Textual Entailment",
            "Question Answering",
            "Paraphrase Generation"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 100,
            "Mean Inputs Length": 430.45,
            "Mean Targets Length": 7.39,
            "Max Inputs Length": 740,
            "Max Targets Length": 12,
            "Min Inputs Length": 216,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "press releases",
            "sciencedaily"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Copenhagen"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "scientific-exaggeration-detection"
        ],
        "Inferred Metadata": {
            "HF Dataset": "copenlu/scientific-exaggeration-detection",
            "HF Config": "copenlu--scientific-exaggeration-detection",
            "HF Config License": "",
            "HF Yaml License": "GNU General Public License v3.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-08-30",
            "GitHub License": "",
            "Text Topics": [
                "Biology",
                "Science",
                "Scientific research",
                "Health",
                "Research methods",
                "Neuroscience",
                "Genetics",
                "Medicine/Health",
                "Psychology"
            ],
            "Github Date": "",
            "HF Date": "2022-08-17",
            "HF Downloads (September 2023)": 101,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 8,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "Sumner et al 2014",
            "Bratton et al 2019"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Wright2021SemiSupervisedED,\n author = {Dustin Wright and Isabelle Augenstein},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {10824-10836},\n title = {Semi-Supervised Exaggeration Detection of Health Science Press Releases},\n year = {2021}\n}\n"
    },
    "tsi-fever_evidence_related-mwong__fever_related": {
        "Unique Dataset Identifier": "tsi-fever_evidence_related-mwong__fever_related",
        "Dataset Name": "fever_evidence_related-mwong__fever_related",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/mwong/fever-evidence-related",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/mwong/fever-evidence-related",
        "Paper Title": "FEVER: a large-scale dataset for Fact Extraction and VERification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/fever",
        "ArXiv URL": "https://arxiv.org/abs/1803.05355",
        "Semantic Scholar Corpus ID": 4711425,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Creativity",
            "Fact Verification",
            "Named Entity Recognition",
            "Question Answering",
            "Entity Linking"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 1539.0363,
            "Mean Targets Length": 10.8272,
            "Max Inputs Length": 19885,
            "Max Targets Length": 12,
            "Min Inputs Length": 115,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Sheffield",
            "Amazon"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://fever.ai/download/feverous/license.html"
            }
        ],
        "License Notes": "States that it is data extracted from the fever database: https://fever.ai/. However, it doesn't clearly state which fever dataset the data is from",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "fever-evidence-related/mwong--fever-related"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mwong/fever-evidence-related",
            "HF Config": "mwong--fever-related",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "Custom",
            "PwC License URL": "https://s3-eu-west-1.amazonaws.com/fever.public/license.html",
            "PwC Date": "2018-03-14",
            "S2 Date": "2018-03-14",
            "GitHub License": "",
            "Text Topics": [
                "General knowledge",
                "Literature",
                "Geography",
                "Sports",
                "Biography",
                "Film industry",
                "Culture",
                "Music",
                "History",
                "Entertainment"
            ],
            "Github Date": "",
            "HF Date": "2022-04-12",
            "HF Downloads (September 2023)": 273,
            "HF Likes (September 2023)": 1,
            "PwC Description": "FEVER is a publicly available dataset for fact extraction and verification against textual sources.\n\nIt consists of 185,445 claims manually verified against the introductory sections of Wikipedia pages and classified as SUPPORTED, REFUTED or NOTENOUGHINFO. For the first two classes, systems and annotators need to also return the combination of sentences forming the necessary evidence supporting or refuting the claim.\n\nThe claims were generated by human annotators extracting claims from Wikipedia and mutating them in a variety of ways, some of which were meaning-altering. The verification of each claim was conducted in a separate annotation process by annotators who were aware of the page but not the sentence from which original claim was\nextracted and thus in 31.75% of the claims more than one sentence was considered appropriate evidence. Claims require composition of evidence from multiple sentences in 16.82% of cases. Furthermore, in 12.15% of the claims, this evidence was taken from multiple pages.",
            "S2 Citation Count (September 2023)": 934,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Thorne2018FEVERAL,\n author = {James Thorne and Andreas Vlachos and Christos Christodoulopoulos and Arpit Mittal},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {FEVER: a Large-scale Dataset for Fact Extraction and VERification},\n volume = {abs/1803.05355},\n year = {2018}\n}\n"
    },
    "tsi-numer_sense": {
        "Unique Dataset Identifier": "tsi-numer_sense",
        "Dataset Name": "numer_sense",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://inklab.usc.edu/NumerSense/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/numer_sense",
        "Paper Title": "Birds Have Four Legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-trained Language Models",
        "Papers with Code URL": "https://paperswithcode.com/dataset/numersense",
        "ArXiv URL": "https://arxiv.org/abs/2005.00683",
        "Semantic Scholar Corpus ID": 218486812,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8877,
            "Mean Inputs Length": 153.375,
            "Mean Targets Length": 4.7949,
            "Max Inputs Length": 192,
            "Max Targets Length": 6,
            "Min Inputs Length": 105,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "github.com/commonsense/omcs",
            "conceptnet"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "numer_sense"
        ],
        "Inferred Metadata": {
            "HF Dataset": "numer_sense",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-02",
            "GitHub License": "",
            "Text Topics": [
                "Medical conditions",
                "Health",
                "Entomology",
                "General knowledge",
                "Zoology",
                "Animal anatomy",
                "Biology",
                "Nutrition",
                "Animal behavior"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1373,
            "HF Likes (September 2023)": 1,
            "PwC Description": "Contains 13.6k masked-word-prediction probes, 10.5k for fine-tuning and 3.1k for testing.",
            "S2 Citation Count (September 2023)": 107,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lin2020BirdsHF,\n author = {Bill Yuchen Lin and Seyeon Lee and Rahul Khanna and Xiang Ren},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {6862-6868},\n title = {Birds Have Four Legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-trained Language Models},\n year = {2020}\n}\n"
    },
    "tsi-dynasent-dynabench.dynasent.r1.all-r1": {
        "Unique Dataset Identifier": "tsi-dynasent-dynabench.dynasent.r1.all-r1",
        "Dataset Name": "dynasent-dynabench.dynasent.r1.all-r1",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://dynabench.org/tasks/3",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/dynabench/dynasent",
        "Paper Title": "DynaSent: A Dynamic Benchmark for Sentiment Analysis",
        "Papers with Code URL": "https://paperswithcode.com/dataset/dynasent",
        "ArXiv URL": "https://arxiv.org/abs/2012.15349",
        "Semantic Scholar Corpus ID": 229923903,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 159.4123,
            "Mean Targets Length": 8.4411,
            "Max Inputs Length": 1569,
            "Max Targets Length": 9,
            "Min Inputs Length": 95,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://huggingface.co/datasets/dynabench/dynasent#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "dynasent/dynabench.dynasent.r1.all/r1"
        ],
        "Inferred Metadata": {
            "HF Dataset": "dynabench/dynasent",
            "HF Config": "dynabench.dynasent.r1.all",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-12-30",
            "GitHub License": "",
            "Text Topics": [
                "Daily routine",
                "Personal experiences",
                "Automotive maintenance",
                "Communication",
                "Food and dining",
                "Time management",
                "Culinary experiences"
            ],
            "Github Date": "",
            "HF Date": "2021-04-29",
            "HF Downloads (September 2023)": 3998,
            "HF Likes (September 2023)": 3,
            "PwC Description": "DynaSent is an English-language benchmark task for ternary (positive/negative/neutral) sentiment analysis. DynaSent combines naturally occurring sentences with sentences created using the open-source Dynabench Platform, which facilities human-and-model-in-the-loop dataset creation. DynaSent has a total of 121,634 sentences, each validated by five crowdworkers.",
            "S2 Citation Count (September 2023)": 49,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Potts2020DynaSentAD,\n author = {Christopher Potts and Zhengxuan Wu and Atticus Geiger and Douwe Kiela},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {DynaSent: A Dynamic Benchmark for Sentiment Analysis},\n volume = {abs/2012.15349},\n year = {2020}\n}\n"
    },
    "tsi-dynasent-dynabench.dynasent.r2.all-r2": {
        "Unique Dataset Identifier": "tsi-dynasent-dynabench.dynasent.r2.all-r2",
        "Dataset Name": "dynasent-dynabench.dynasent.r2.all-r2",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://dynabench.org/tasks/3",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/dynabench/dynasent",
        "Paper Title": "DynaSent: A Dynamic Benchmark for Sentiment Analysis",
        "Papers with Code URL": "https://paperswithcode.com/dataset/dynasent",
        "ArXiv URL": "https://arxiv.org/abs/2012.15349",
        "Semantic Scholar Corpus ID": 229923903,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13065,
            "Mean Inputs Length": 155.1597,
            "Mean Targets Length": 8.8126,
            "Max Inputs Length": 372,
            "Max Targets Length": 9,
            "Min Inputs Length": 95,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://huggingface.co/datasets/dynabench/dynasent#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "dynasent/dynabench.dynasent.r2.all/r2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "dynabench/dynasent",
            "HF Config": "dynabench.dynasent.r1.all",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-12-30",
            "GitHub License": "",
            "Text Topics": [
                "Customer satisfaction",
                "Personal preferences",
                "Culinary experiences",
                "Emotions",
                "Communication",
                "Personal experiences",
                "Customer service",
                "Travel",
                "Food",
                "Social interactions"
            ],
            "Github Date": "",
            "HF Date": "2021-04-29",
            "HF Downloads (September 2023)": 3998,
            "HF Likes (September 2023)": 3,
            "PwC Description": "DynaSent is an English-language benchmark task for ternary (positive/negative/neutral) sentiment analysis. DynaSent combines naturally occurring sentences with sentences created using the open-source Dynabench Platform, which facilities human-and-model-in-the-loop dataset creation. DynaSent has a total of 121,634 sentences, each validated by five crowdworkers.",
            "S2 Citation Count (September 2023)": 49,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Potts2020DynaSentAD,\n author = {Christopher Potts and Zhengxuan Wu and Atticus Geiger and Douwe Kiela},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {DynaSent: A Dynamic Benchmark for Sentiment Analysis},\n volume = {abs/2012.15349},\n year = {2020}\n}\n"
    },
    "tsi-sem_eval_2010_task_8": {
        "Unique Dataset Identifier": "tsi-sem_eval_2010_task_8",
        "Dataset Name": "sem_eval_2010_task_8",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://semeval2.fbk.eu/semeval2.php?location=tasks&taskid=11",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sem_eval_2010_task_8",
        "Paper Title": "SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations between Pairs of Nominals",
        "Papers with Code URL": "https://paperswithcode.com/dataset/semeval-2010-task-8",
        "ArXiv URL": "https://arxiv.org/abs/1911.10422",
        "Semantic Scholar Corpus ID": 436023,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8000,
            "Mean Inputs Length": 274.5431,
            "Mean Targets Length": 20.1301,
            "Max Inputs Length": 665,
            "Max Targets Length": 26,
            "Min Inputs Length": 184,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Lisbon",
            "University of Melbourne",
            "University of Alicante",
            "National University of Singapore",
            "University of Cambridge",
            "University of Stuttgart",
            "Yahoo! Inc.",
            "Fondazione Bruno Kessler",
            "University of Ottawa",
            "Polish Academy of Sciences"
        ],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://semeval2.fbk.eu/semeval2.php?location=tasks&taskid=11"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "sem_eval_2010_task_8"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sem_eval_2010_task_8",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/3.0/",
            "PwC Date": "2019-11-23",
            "S2 Date": "2009-06-04",
            "GitHub License": "",
            "Text Topics": [
                "Engineering",
                "Travel",
                "Physics",
                "Technology",
                "Mechanics",
                "Health",
                "Geography",
                "Politics",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2110,
            "HF Likes (September 2023)": 4,
            "PwC Description": "The dataset for the SemEval-2010 Task 8 is a dataset for multi-way classification of mutually exclusive semantic relations between pairs of nominals.",
            "S2 Citation Count (September 2023)": 664,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hendrickx2009SemEval2010T8,\n author = {Iris Hendrickx and Su Nam Kim and Zornitsa Kozareva and Preslav Nakov and Diarmuid  Saghdha and Sebastian Pad and M. Pennacchiotti and Lorenza Romano and Stan Szpakowicz},\n booktitle = {SEW@NAACL-HLT},\n pages = {94-99},\n title = {SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations Between Pairs of Nominals},\n year = {2009}\n}\n"
    },
    "tsi-medmcqa": {
        "Unique Dataset Identifier": "tsi-medmcqa",
        "Dataset Name": "medmcqa",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://medmcqa.github.io",
        "GitHub URL": "https://medmcqa.github.io",
        "Hugging Face URL": "https://huggingface.co/datasets/medmcqa",
        "Paper Title": "MedMCQA : A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2203.14371",
        "Semantic Scholar Corpus ID": 247763070,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 237.5686,
            "Mean Targets Length": 2.0003,
            "Max Inputs Length": 1414,
            "Max Targets Length": 7,
            "Min Inputs Length": 73,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "aiims pg exams",
            "neet pg exams"
        ],
        "Model Generated": [],
        "Creators": [
            "Saama AI Research Chennai"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "medmcqa"
        ],
        "Inferred Metadata": {
            "HF Dataset": "medmcqa",
            "HF Config": "default",
            "HF Config License": "Apache License 2.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-03-27",
            "GitHub License": "",
            "Text Topics": [
                "Biology",
                "Medicine",
                "Medical terminology",
                "Biochemistry",
                "Medical conditions and diseases",
                "Anatomy",
                "Dentistry"
            ],
            "Github Date": "",
            "HF Date": "2022-05-06",
            "HF Downloads (September 2023)": 3233,
            "HF Likes (September 2023)": 38,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 39,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Pal2022MedMCQAA,\n author = {Ankit Pal and Logesh Kumar Umapathi and Malaikannan Sankarasubbu},\n booktitle = {ACM Conference on Health, Inference, and Learning},\n pages = {248-260},\n title = {MedMCQA : A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering},\n year = {2022}\n}\n"
    },
    "tsi-logiqa": {
        "Unique Dataset Identifier": "tsi-logiqa",
        "Dataset Name": "logiqa",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/lgw863/LogiQA-dataset",
        "GitHub URL": "https://github.com/lgw863/LogiQA-dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/lucasmccabe/logiqa",
        "Paper Title": "LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/medmcqa",
        "ArXiv URL": "https://arxiv.org/abs/2007.08124",
        "Semantic Scholar Corpus ID": 220483148,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7376,
            "Mean Inputs Length": 928.7779,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 2401,
            "Max Targets Length": 2,
            "Min Inputs Length": 194,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "national civil servants examination of china"
        ],
        "Model Generated": [],
        "Creators": [
            "Fudan University",
            "Westlake University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "logiqa"
        ],
        "Inferred Metadata": {
            "HF Dataset": "lucasmccabe/logiqa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-03-27",
            "S2 Date": "2020-07-01",
            "GitHub License": "",
            "Text Topics": [
                "Finance",
                "Education",
                "Biology",
                "Mental health",
                "Psychology",
                "Geography",
                "Legal concepts and terminology",
                "Logic",
                "Economics"
            ],
            "Github Date": "",
            "HF Date": "2023-01-12",
            "HF Downloads (September 2023)": 222,
            "HF Likes (September 2023)": 1,
            "PwC Description": "MedMCQA is a large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions.\n\nMedMCQA has more than 194k high-quality AIIMS & NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity.",
            "S2 Citation Count (September 2023)": 90,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020LogiQAAC,\n author = {Jian Liu and Leyang Cui and Hanmeng Liu and Dandan Huang and Yile Wang and Yue Zhang},\n booktitle = {International Joint Conference on Artificial Intelligence},\n journal = {ArXiv},\n title = {LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning},\n volume = {abs/2007.08124},\n year = {2020}\n}\n"
    },
    "tsi-cycic_classification": {
        "Unique Dataset Identifier": "tsi-cycic_classification",
        "Dataset Name": "cycic_classification",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/cycic_classification",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/cycic_classification",
        "Paper Title": "Do Fine-tuned Commonsense Language Models Really Generalize?",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2011.09159",
        "Semantic Scholar Corpus ID": 227012557,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4156,
            "Mean Inputs Length": 239.0513,
            "Mean Targets Length": 5.5883,
            "Max Inputs Length": 386,
            "Max Targets Length": 6,
            "Min Inputs Length": 122,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "cyc.com"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "cycic_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/cycic_classification",
            "HF Config": "metaeval--cycic_classification",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-18",
            "GitHub License": "",
            "Text Topics": [
                "Personal preferences",
                "Fire safety",
                "Gift giving",
                "Logic",
                "Gift-giving",
                "Perception and observation",
                "Animals"
            ],
            "Github Date": "",
            "HF Date": "2023-01-18",
            "HF Downloads (September 2023)": 36,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 7,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Kejriwal2020DoFC,\n author = {M. Kejriwal and Ke Shen},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Do Fine-tuned Commonsense Language Models Really Generalize?},\n volume = {abs/2011.09159},\n year = {2020}\n}\n"
    },
    "tsi-cycic_multiplechoice": {
        "Unique Dataset Identifier": "tsi-cycic_multiplechoice",
        "Dataset Name": "cycic_multiplechoice",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/cycic_multiplechoice",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/cycic_multiplechoice",
        "Paper Title": "Do Fine-tuned Commonsense Language Models Really Generalize?",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2011.09159",
        "Semantic Scholar Corpus ID": 227012557,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6521,
            "Mean Inputs Length": 262.8847,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 570,
            "Max Targets Length": 2,
            "Min Inputs Length": 124,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "cyc.com"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "cycic_multiplechoice"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/cycic_multiplechoice",
            "HF Config": "metaeval--cycic_multiplechoice",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-18",
            "GitHub License": "",
            "Text Topics": [
                "Interpersonal relationships",
                "Communication",
                "Logic and reasoning",
                "Problem-solving",
                "Emotions",
                "Time management",
                "Non-verbal communication",
                "Emotions and feelings",
                "General knowledge",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2023-01-18",
            "HF Downloads (September 2023)": 72,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 7,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Kejriwal2020DoFC,\n author = {M. Kejriwal and Ke Shen},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Do Fine-tuned Commonsense Language Models Really Generalize?},\n volume = {abs/2011.09159},\n year = {2020}\n}\n"
    },
    "tsi-commonsense_qa_2.0": {
        "Unique Dataset Identifier": "tsi-commonsense_qa_2.0",
        "Dataset Name": "commonsense_qa_2.0",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/commonsense_qa_2.0",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/commonsense_qa_2.0",
        "Paper Title": "CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/commonsenseqa",
        "ArXiv URL": "https://arxiv.org/abs/2201.05320",
        "Semantic Scholar Corpus ID": 53296520,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9264,
            "Mean Inputs Length": 127.0689,
            "Mean Targets Length": 3.5,
            "Max Inputs Length": 351,
            "Max Targets Length": 4,
            "Min Inputs Length": 81,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Tel Aviv University",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "commonsense_qa_2.0"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/commonsense_qa_2.0",
            "HF Config": "metaeval--commonsense_qa_2.0",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2019-01-01",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Music",
                "Science",
                "History",
                "Biology",
                "Geography",
                "General knowledge",
                "Astronomy",
                "Philosophy"
            ],
            "Github Date": "",
            "HF Date": "2023-01-24",
            "HF Downloads (September 2023)": 40,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The CommonsenseQA is a dataset for commonsense question answering task. The dataset consists of 12,247 questions with 5 choices each.\nThe dataset was generated by Amazon Mechanical Turk workers in the following process (an example is provided in parentheses):\n\n\na crowd worker observes a source concept from ConceptNet (River) and three target concepts (Waterfall, Bridge, Valley) that are all related by the same ConceptNet relation (AtLocation),\nthe worker authors three questions, one per target concept, such that only that particular target concept is the answer, while the other two distractor concepts are not, (Where on a river can you hold a cup upright to catch water on a sunny day?, Where can I stand on a river to see water falling without getting wet?, Im crossing the river, my feet are wet but my body is dry, where am I?)\nfor each question, another worker chooses one additional distractor from Concept Net (pebble, stream, bank), and the author another distractor (mountain, bottom, island) manually.",
            "S2 Citation Count (September 2023)": 685,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Talmor2019CommonsenseQAAQ,\n author = {Alon Talmor and Jonathan Herzig and Nicholas Lourie and Jonathan Berant},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n volume = {abs/1811.00937},\n year = {2019}\n}\n"
    },
    "tsi-lingnli": {
        "Unique Dataset Identifier": "tsi-lingnli",
        "Dataset Name": "lingnli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Alicia-Parrish/ling_in_loop/",
        "GitHub URL": "https://github.com/Alicia-Parrish/ling_in_loop/",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/lingnli",
        "Paper Title": "Does Putting a Linguist in the Loop Improve NLU Data Collection?",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2104.07179",
        "Semantic Scholar Corpus ID": 233240777,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 267.4663,
            "Mean Targets Length": 11.0007,
            "Max Inputs Length": 818,
            "Max Targets Length": 14,
            "Min Inputs Length": 114,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced (amt)"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University",
            "Indian Institute of Technology",
            "Columbia University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lingnli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/lingnli",
            "HF Config": "metaeval--lingnli",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-04-15",
            "GitHub License": "",
            "Text Topics": [
                "Communication",
                "Business and entrepreneurship",
                "Technology",
                "Economics",
                "Politics",
                "Journalism",
                "Literature",
                "Current events",
                "Entertainment industry",
                "History"
            ],
            "Github Date": "",
            "HF Date": "2023-01-11",
            "HF Downloads (September 2023)": 35,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 21,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Parrish2021DoesPA,\n author = {Alicia Parrish and William Huang and Omar Agha and Soo-hwan Lee and Nikita Nangia and Alex Warstadt and Karmanya Aggarwal and Emily Allaway and Tal Linzen and Samuel R. Bowman},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Does Putting a Linguist in the Loop Improve NLU Data Collection?},\n volume = {abs/2104.07179},\n year = {2021}\n}\n"
    },
    "tsi-monotonicity_entailment": {
        "Unique Dataset Identifier": "tsi-monotonicity_entailment",
        "Dataset Name": "monotonicity_entailment",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/monotonicity-entailment",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/monotonicity-entailment",
        "Paper Title": "Can Neural Networks Understand Monotonicity Reasoning?",
        "Papers with Code URL": "https://paperswithcode.com/dataset/med",
        "ArXiv URL": "https://arxiv.org/abs/1906.06448",
        "Semantic Scholar Corpus ID": 189927911,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4574,
            "Mean Inputs Length": 158.2022,
            "Mean Targets Length": 9.5177,
            "Max Inputs Length": 531,
            "Max Targets Length": 11,
            "Min Inputs Length": 104,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "parallel meaning bank",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "RIKEN",
            "Ochanomizu University",
            "Tohoku University",
            "University of Groningen"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "monotonicity-entailment"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/monotonicity-entailment",
            "HF Config": "metaeval--monotonicity-entailment",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-15",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Daily routine",
                "Language and communication",
                "General knowledge",
                "Education",
                "Language understanding",
                "Food preferences",
                "Language",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2023-01-24",
            "HF Downloads (September 2023)": 26,
            "HF Likes (September 2023)": 0,
            "PwC Description": "MED is a new evaluation dataset that covers a wide range of monotonicity reasoning that was created by crowdsourcing and collected from linguistics publications. The dataset was constructed by collecting naturally-occurring examples by crowdsourcing and well-designed ones from linguistics publications.\nIt consists of 5,382 examples.",
            "S2 Citation Count (September 2023)": 59,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Yanaka2019CanNN,\n author = {Hitomi Yanaka and K. Mineshima and D. Bekki and Kentaro Inui and S. Sekine and Lasha Abzianidze and Johan Bos},\n booktitle = {BlackboxNLP@ACL},\n pages = {31-40},\n title = {Can Neural Networks Understand Monotonicity Reasoning?},\n year = {2019}\n}\n"
    },
    "tsi-arct": {
        "Unique Dataset Identifier": "tsi-arct",
        "Dataset Name": "arct",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/UKPLab/argument-reasoning-comprehension-task",
        "GitHub URL": "https://github.com/UKPLab/argument-reasoning-comprehension-task",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/arct",
        "Paper Title": "The Argument Reasoning Comprehension Task: Identification and Reconstruction of Implicit Warrants",
        "Papers with Code URL": "https://paperswithcode.com/dataset/arct",
        "ArXiv URL": "https://arxiv.org/abs/1708.01425",
        "Semantic Scholar Corpus ID": 3555187,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1210,
            "Mean Inputs Length": 297.0926,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 568,
            "Max Targets Length": 2,
            "Min Inputs Length": 153,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "nytmes"
        ],
        "Model Generated": [],
        "Creators": [
            "Technische Universitat Darmstadt",
            "Bauhaus-Universitat Weimar"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "arct"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/arct",
            "HF Config": "metaeval--arct",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "CC0 1.0",
            "PwC License URL": "",
            "PwC Date": "2018-06-20",
            "S2 Date": "2017-08-04",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Vaccination and public health",
                "International relations",
                "Language learning",
                "Sports",
                "International relations and diplomacy",
                "Transportation and urban planning",
                "Politics",
                "Education policy",
                "Parenting styles and their impact on child development",
                "Education"
            ],
            "Github Date": "",
            "HF Date": "2023-01-26",
            "HF Downloads (September 2023)": 17,
            "HF Likes (September 2023)": 0,
            "PwC Description": "Freely licensed dataset with warrants for 2k authentic arguments from news comments. On this basis, we present a new challenging task, the argument reasoning comprehension task. Given an argument with a claim and a premise, the goal is to choose the correct implicit warrant from two options. Both warrants are plausible and lexically close, but lead to contradicting claims.",
            "S2 Citation Count (September 2023)": 116,
            "GitHub Stars": 70,
            "GitHub Topics": [
                "argumentation",
                "nlp-machine-learning"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Habernal2017TheAR,\n author = {Ivan Habernal and Henning Wachsmuth and Iryna Gurevych and Benno Stein},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {The Argument Reasoning Comprehension Task: Identification and Reconstruction of Implicit Warrants},\n volume = {abs/1708.01425},\n year = {2017}\n}\n"
    },
    "tsi-scinli": {
        "Unique Dataset Identifier": "tsi-scinli",
        "Dataset Name": "scinli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/msadat3/SciNLI",
        "GitHub URL": "https://github.com/msadat3/SciNLI",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/scinli",
        "Paper Title": "SciNLI: A Corpus for Natural Language Inference on Scientific Text",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2203.06728",
        "Semantic Scholar Corpus ID": 247447069,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 389.8884,
            "Mean Targets Length": 10.2431,
            "Max Inputs Length": 1188,
            "Max Targets Length": 12,
            "Min Inputs Length": 165,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "aclanthology.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Illinois"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/msadat3/SciNLI#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "scinli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/scinli",
            "HF Config": "metaeval--scinli",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-03-13",
            "GitHub License": "",
            "Text Topics": [
                "Natural Language Processing (NLP)",
                "Computational linguistics",
                "Information retrieval",
                "Natural Language Processing",
                "Artificial intelligence",
                "Translation",
                "Natural language processing"
            ],
            "Github Date": "",
            "HF Date": "2023-01-26",
            "HF Downloads (September 2023)": 82,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 12,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sadat2022SciNLIAC,\n author = {Mobashir Sadat and Cornelia Caragea},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {SciNLI: A Corpus for Natural Language Inference on Scientific Text},\n volume = {abs/2203.06728},\n year = {2022}\n}\n"
    },
    "tsi-naturallogic": {
        "Unique Dataset Identifier": "tsi-naturallogic",
        "Dataset Name": "naturallogic",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/feng-yufei/Neural-Natural-Logic",
        "GitHub URL": "https://github.com/feng-yufei/Neural-Natural-Logic",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/naturallogic",
        "Paper Title": "Exploring End-to-End Differentiable Natural Logic Modeling",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2011.04044",
        "Semantic Scholar Corpus ID": 226282443,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5436,
            "Mean Inputs Length": 192.1795,
            "Mean Targets Length": 9.117,
            "Max Inputs Length": 345,
            "Max Targets Length": 14,
            "Min Inputs Length": 133,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "parallel meaning bank"
        ],
        "Model Generated": [],
        "Creators": [
            "Queens University",
            "iFLYTEK Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "naturallogic"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/naturallogic",
            "HF Config": "metaeval--naturallogic",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-08",
            "GitHub License": "",
            "Text Topics": [
                "Daily routine",
                "Food preferences",
                "Linguistics",
                "Family relationships",
                "Logic and reasoning",
                "Logic",
                "General knowledge",
                "Natural language processing",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2023-01-26",
            "HF Downloads (September 2023)": 31,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 9,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "MED Dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Feng2020ExploringED,\n author = {Yufei Feng and Zi'ou Zheng and QUAN LIU and M. Greenspan and Xiaodan Zhu},\n booktitle = {International Conference on Computational Linguistics},\n pages = {1172-1185},\n title = {Exploring End-to-End Differentiable Natural Logic Modeling},\n year = {2020}\n}\n"
    },
    "tsi-onestop_qa": {
        "Unique Dataset Identifier": "tsi-onestop_qa",
        "Dataset Name": "onestop_qa",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/berzak/onestop-qa",
        "GitHub URL": "https://github.com/berzak/onestop-qa",
        "Hugging Face URL": "https://huggingface.co/datasets/onestop_qa",
        "Paper Title": "STARC: Structured Annotations for Reading Comprehension",
        "Papers with Code URL": "https://paperswithcode.com/dataset/onestopqa",
        "ArXiv URL": "https://arxiv.org/abs/2004.14797",
        "Semantic Scholar Corpus ID": 216869963,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1239,
            "Mean Inputs Length": 948.4044,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 1414,
            "Max Targets Length": 2,
            "Min Inputs Length": 475,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "onestopenglish corpus"
        ],
        "Model Generated": [],
        "Creators": [
            "Massachusetts Institute of Technology"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/berzak/onestop-qa/blob/master/LICENSE.md"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "onestop_qa"
        ],
        "Inferred Metadata": {
            "HF Dataset": "onestop_qa",
            "HF Config": "default",
            "HF Config License": "CC BY-SA 4.0",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-30",
            "GitHub License": "CC BY-SA 4.0",
            "Text Topics": [
                "Astronomy",
                "History",
                "International relations",
                "Transportation",
                "Geography",
                "Transportation trends",
                "Chemistry",
                "Criminal justice system",
                "Travel"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 561,
            "HF Likes (September 2023)": 3,
            "PwC Description": "OneStopQA provides an alternative test set for reading comprehension which alleviates these shortcomings and has a substantially higher human ceiling performance.",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": 23,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Berzak2020STARCSA,\n author = {Yevgeni Berzak and J. Malmaud and R. Levy},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {5726-5735},\n title = {STARC: Structured Annotations for Reading Comprehension},\n year = {2020}\n}\n"
    },
    "tsi-moral_stories-full": {
        "Unique Dataset Identifier": "tsi-moral_stories-full",
        "Dataset Name": "moral_stories-full",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/demelin/moral_stories",
        "GitHub URL": "https://github.com/demelin/moral_stories",
        "Hugging Face URL": "https://huggingface.co/datasets/demelin/moral_stories",
        "Paper Title": "Moral Stories: Situated Reasoning about Norms, Intents, Actions, and their Consequences",
        "Papers with Code URL": "https://paperswithcode.com/dataset/moral-stories",
        "ArXiv URL": "https://arxiv.org/abs/2012.15738",
        "Semantic Scholar Corpus ID": 229923749,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10200,
            "Mean Inputs Length": 360.4266,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 644,
            "Max Targets Length": 2,
            "Min Inputs Length": 191,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Edinburgh",
            "AI2",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "moral_stories/full"
        ],
        "Inferred Metadata": {
            "HF Dataset": "demelin/moral_stories",
            "HF Config": "full",
            "HF Config License": "MIT License",
            "HF Yaml License": "MIT License",
            "PwC License Name": "MIT License",
            "PwC License URL": "",
            "PwC Date": "2021-11-07",
            "S2 Date": "2020-12-31",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Sports",
                "Conflict resolution",
                "Communication and conflict resolution",
                "Decision-making",
                "Personal hygiene",
                "Daily routine",
                "Communication skills",
                "Communication",
                "Time management"
            ],
            "Github Date": "",
            "HF Date": "2022-07-14",
            "HF Downloads (September 2023)": 320,
            "HF Likes (September 2023)": 10,
            "PwC Description": "Moral Stories is a crowd-sourced dataset of structured narratives that describe normative and norm-divergent actions taken by individuals to accomplish certain intentions in concrete situations, and their respective consequences.",
            "S2 Citation Count (September 2023)": 64,
            "GitHub Stars": 45,
            "GitHub Topics": [
                "commonsense-reasoning",
                "dataset",
                "natural-language-generation",
                "natural-language-processing",
                "natural-language-understanding",
                "nlg",
                "nlu",
                "social-reasoning"
            ]
        },
        "Derived from Datasets": [
            "SOCIAL-CHEM-101 dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Emelin2020MoralSS,\n author = {Denis Emelin and Ronan Le Bras and Jena D. Hwang and Maxwell Forbes and Yejin Choi},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Moral Stories: Situated Reasoning about Norms, Intents, Actions, and their Consequences},\n volume = {abs/2012.15738},\n year = {2020}\n}\n"
    },
    "tsi-prost": {
        "Unique Dataset Identifier": "tsi-prost",
        "Dataset Name": "prost",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/nala-cub/prost",
        "GitHub URL": "https://github.com/nala-cub/prost",
        "Hugging Face URL": "https://huggingface.co/datasets/corypaik/prost",
        "Paper Title": "PROST: Physical Reasoning about Objects through Space and Time",
        "Papers with Code URL": "https://paperswithcode.com/dataset/prost",
        "ArXiv URL": "https://arxiv.org/abs/2106.03634",
        "Semantic Scholar Corpus ID": 235358436,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 15925,
            "Mean Inputs Length": 175.8504,
            "Mean Targets Length": 6.0995,
            "Max Inputs Length": 385,
            "Max Targets Length": 10,
            "Min Inputs Length": 90,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Colorado Boulder"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/nala-cub/prost#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "prost"
        ],
        "Inferred Metadata": {
            "HF Dataset": "corypaik/prost",
            "HF Config": "default",
            "HF Config License": "Apache License 2.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "https://github.com/nala-cub/prost/blob/main/LICENSE",
            "PwC Date": "2021-06-07",
            "S2 Date": "2021-06-07",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Objects and their properties",
                "Probability",
                "Materials and their properties",
                "General knowledge",
                "Sports and recreation",
                "Physics",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2021-05-30",
            "HF Downloads (September 2023)": 1074,
            "HF Likes (September 2023)": 1,
            "PwC Description": "The PROST (Physical Reasoning about Objects Through Space and Time) dataset contains 18,736 multiple-choice questions made from 14 manually curated templates, covering 10 physical reasoning concepts. All questions are designed to probe both causal and masked language models in a zero-shot setting.",
            "S2 Citation Count (September 2023)": 22,
            "GitHub Stars": 5,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Aroca-Ouellette2021PROSTPR,\n author = {Stephane T Aroca-Ouellette and Cory Paik and A. Roncone and Katharina Kann},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {PROST: Physical Reasoning about Objects through Space and Time},\n volume = {abs/2106.03634},\n year = {2021}\n}\n"
    },
    "tsi-dynahate": {
        "Unique Dataset Identifier": "tsi-dynahate",
        "Dataset Name": "dynahate",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://arxiv.org/abs/2012.15761",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/aps/dynahate",
        "Paper Title": "Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2012.15761",
        "Semantic Scholar Corpus ID": 229923220,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 208.0747,
            "Mean Targets Length": 6.3805,
            "Max Inputs Length": 2448,
            "Max Targets Length": 8,
            "Min Inputs Length": 78,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Alan Turing Institute",
            "University of Sheffield",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "dynahate"
        ],
        "Inferred Metadata": {
            "HF Dataset": "aps/dynahate",
            "HF Config": "0.2.3",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-01-01",
            "GitHub License": "",
            "Text Topics": [
                "Identity",
                "Social issues",
                "Stereotypes",
                "Cultural sensitivity",
                "Social interactions",
                "Communication",
                "Language and communication",
                "Stereotypes and prejudice",
                "Ethics and morality"
            ],
            "Github Date": "",
            "HF Date": "2022-04-29",
            "HF Downloads (September 2023)": 62,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 97,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Vidgen2021LearningFT,\n author = {Bertie Vidgen and Tristan Thrush and Zeerak Talat and Douwe Kiela},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection},\n volume = {abs/2012.15761},\n year = {2021}\n}\n"
    },
    "tsi-syntactic_augmentation_nli": {
        "Unique Dataset Identifier": "tsi-syntactic_augmentation_nli",
        "Dataset Name": "syntactic_augmentation_nli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/syntactic-augmentation-nli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/syntactic-augmentation-nli",
        "Paper Title": "Syntactic Data Augmentation Increases Robustness to Inference Heuristics",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2004.11999",
        "Semantic Scholar Corpus ID": 216553149,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10327,
            "Mean Inputs Length": 232.3545,
            "Mean Targets Length": 9.221,
            "Max Inputs Length": 933,
            "Max Targets Length": 14,
            "Min Inputs Length": 113,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "Johns Hopkins University",
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/Aatlantise/syntactic-augmentation-nli#license"
            }
        ],
        "License Notes": "License appears to be for the repository, not the data",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "syntactic-augmentation-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/syntactic-augmentation-nli",
            "HF Config": "metaeval--syntactic-augmentation-nli",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-24",
            "GitHub License": "",
            "Text Topics": [
                "Language and communication",
                "Communication",
                "Language and semantics",
                "Language and linguistics",
                "Communication and understanding",
                "Language understanding",
                "History"
            ],
            "Github Date": "",
            "HF Date": "2023-01-30",
            "HF Downloads (September 2023)": 34,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 119,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "MNLI"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Min2020SyntacticDA,\n author = {Junghyun Min and R. Thomas McCoy and Dipanjan Das and Emily Pitler and Tal Linzen},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {2339-2352},\n title = {Syntactic Data Augmentation Increases Robustness to Inference Heuristics},\n year = {2020}\n}\n"
    },
    "tsi-autotnli": {
        "Unique Dataset Identifier": "tsi-autotnli",
        "Dataset Name": "autotnli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Dibyakanti/AutoTNLI-code",
        "GitHub URL": "https://github.com/Dibyakanti/AutoTNLI-code",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/autotnli",
        "Paper Title": "Realistic Data Augmentation Framework for Enhancing Tabular Reasoning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2210.12795",
        "Semantic Scholar Corpus ID": 253097739,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 1044.5018,
            "Mean Targets Length": 9.4896,
            "Max Inputs Length": 2383,
            "Max Targets Length": 11,
            "Min Inputs Length": 131,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "crowdsourced"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Indian Institute of Technology",
            "University of Utah",
            "Bloomberg"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "autotnli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/autotnli",
            "HF Config": "metaeval--autotnli",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-10-23",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Entertainment industry",
                "Sports",
                "General knowledge",
                "History",
                "Family relationships",
                "Biography",
                "Music",
                "Geography"
            ],
            "Github Date": "",
            "HF Date": "2023-02-07",
            "HF Downloads (September 2023)": 39,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": 4,
            "GitHub Topics": [
                "autotnli",
                "emnlp2022",
                "inference",
                "infotabs",
                "nli",
                "nlp",
                "nlp-datasets",
                "nlp-machine-learning",
                "roberta",
                "semi-structured-data",
                "tables",
                "transformer",
                "wikipedia"
            ]
        },
        "Derived from Datasets": [
            "InfoTabs dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Kumar2022RealisticDA,\n author = {D. K. Santhosh Kumar and Vivek Gupta and Soumya Sharma and Shuo Zhang},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Realistic Data Augmentation Framework for Enhancing Tabular Reasoning},\n volume = {abs/2210.12795},\n year = {2022}\n}\n"
    },
    "tsi-condaqa": {
        "Unique Dataset Identifier": "tsi-condaqa",
        "Dataset Name": "condaqa",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/AbhilashaRavichander/CondaQA",
        "GitHub URL": "https://github.com/AbhilashaRavichander/CondaQA",
        "Hugging Face URL": "https://huggingface.co/datasets/lasha-nlp/CONDAQA",
        "Paper Title": "CONDAQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2211.00295",
        "Semantic Scholar Corpus ID": 253244137,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5724,
            "Mean Inputs Length": 915.0919,
            "Mean Targets Length": 4.3384,
            "Max Inputs Length": 1662,
            "Max Targets Length": 11,
            "Min Inputs Length": 225,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University",
            "Microsoft Semantic Machines",
            "University of Utah"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/AbhilashaRavichander/CondaQA/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "CONDAQA"
        ],
        "Inferred Metadata": {
            "HF Dataset": "lasha-nlp/CONDAQA",
            "HF Config": "lasha-nlp--CONDAQA",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-11-01",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Geography",
                "History",
                "Biology",
                "Mining industry",
                "Politics",
                "Sports",
                "Climate",
                "Gemstones"
            ],
            "Github Date": "",
            "HF Date": "2022-11-08",
            "HF Downloads (September 2023)": 69,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 8,
            "GitHub Stars": 9,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Ravichander2022CONDAQAAC,\n author = {Abhilasha Ravichander and Matt Gardner and Ana Marasovi},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {CONDAQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation},\n volume = {abs/2211.00295},\n year = {2022}\n}\n"
    },
    "tsi-webgpt_comparisons": {
        "Unique Dataset Identifier": "tsi-webgpt_comparisons",
        "Dataset Name": "webgpt_comparisons",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://openaipublic.blob.core.windows.net/webgpt-answer-viewer/comparisons.jsonl",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/openai/webgpt_comparisons",
        "Paper Title": "WebGPT: Browser-assisted question-answering with human feedback",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2112.09332",
        "Semantic Scholar Corpus ID": 245329531,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 16641,
            "Mean Inputs Length": 1746.8908,
            "Mean Targets Length": 1.9884,
            "Max Inputs Length": 6380,
            "Max Targets Length": 2,
            "Min Inputs Length": 11,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "crowdsourced",
            "reddit"
        ],
        "Model Generated": [
            "OpenAI GPT-3"
        ],
        "Creators": [
            "OpenAI"
        ],
        "Licenses": [
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2112.09332"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "webgpt_comparisons"
        ],
        "Inferred Metadata": {
            "HF Dataset": "openai/webgpt_comparisons",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-12-17",
            "GitHub License": "",
            "Text Topics": [
                "Animal behavior",
                "Mathematics",
                "Philosophy",
                "Personal finance",
                "Technology",
                "Science",
                "Consumer behavior",
                "Health",
                "Biology"
            ],
            "Github Date": "",
            "HF Date": "2022-12-18",
            "HF Downloads (September 2023)": 13602,
            "HF Likes (September 2023)": 168,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 324,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "TriviaQA"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Nakano2021WebGPTBQ,\n author = {Reiichiro Nakano and Jacob Hilton and S. Balaji and Jeff Wu and Ouyang Long and Christina Kim and Christopher Hesse and Shantanu Jain and V. Kosaraju and W. Saunders and Xu Jiang and Karl Cobbe and Tyna Eloundou and Gretchen Krueger and Kevin Button and Matthew Knight and B. Chess and John Schulman},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {WebGPT: Browser-assisted question-answering with human feedback},\n volume = {abs/2112.09332},\n year = {2021}\n}\n"
    },
    "tsi-synthetic_instruct_gptj_pairwise": {
        "Unique Dataset Identifier": "tsi-synthetic_instruct_gptj_pairwise",
        "Dataset Name": "synthetic_instruct_gptj_pairwise",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/Dahoas/synthetic-instruct-gptj-pairwise",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/Dahoas/synthetic-instruct-gptj-pairwise",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 28171,
            "Mean Inputs Length": 1000.8894,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 5491,
            "Max Targets Length": 2,
            "Min Inputs Length": 110,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [
            "Instruct-GPT-J"
        ],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "synthetic-instruct-gptj-pairwise"
        ],
        "Inferred Metadata": {
            "HF Dataset": "Dahoas/synthetic-instruct-gptj-pairwise",
            "HF Config": "Dahoas--synthetic-instruct-gptj-pairwise",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Education",
                "Personal finance",
                "Personal development",
                "Geography",
                "Budgeting",
                "Travel",
                "Fitness"
            ],
            "Github Date": "",
            "HF Date": "2022-12-19",
            "HF Downloads (September 2023)": 1797,
            "HF Likes (September 2023)": 41,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-scruples": {
        "Unique Dataset Identifier": "tsi-scruples",
        "Dataset Name": "scruples",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/scruples",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/scruples",
        "Paper Title": "",
        "Papers with Code URL": "https://paperswithcode.com/dataset/scruples",
        "ArXiv URL": "https://arxiv.org/abs/2008.09094",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Sentiment Analysis",
            "Dialogue Generation"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 27766,
            "Mean Inputs Length": 1836.1062,
            "Mean Targets Length": 6.0,
            "Max Inputs Length": 10906,
            "Max Targets Length": 6,
            "Min Inputs Length": 72,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "Paul G. Allen School of Computer Science & Engineering"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://github.com/allenai/scruples#disclaimer"
            }
        ],
        "License Notes": "For research only",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "scruples"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/scruples",
            "HF Config": "metaeval--scruples",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Social interactions",
                "Relationships",
                "Friendship",
                "Personal experiences",
                "Friendship and relationships",
                "Daily routine",
                "Travel"
            ],
            "Github Date": "",
            "HF Date": "2023-02-03",
            "HF Downloads (September 2023)": 50,
            "HF Likes (September 2023)": 1,
            "PwC Description": "Dataset with 625,000 ethical judgments over 32,000 real-life anecdotes. Each anecdote recounts a complex ethical situation, often posing moral dilemmas, paired with a distribution of judgments contributed by the community members.",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": ""
    },
    "tsi-wouldyourather": {
        "Unique Dataset Identifier": "tsi-wouldyourather",
        "Dataset Name": "wouldyourather",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/wouldyourather",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/wouldyourather",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2313,
            "Mean Inputs Length": 152.872,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 397,
            "Max Targets Length": 2,
            "Min Inputs Length": 100,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://www.kaggle.com/datasets/charlieray668/would-you-rather"
            }
        ],
        "License Notes": "Look in metadata --> provenance/license to find sources and license info",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "wouldyourather"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/wouldyourather",
            "HF Config": "metaeval--wouldyourather",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Ethics and morality",
                "Preferences",
                "Pop culture",
                "Personal preferences and choices",
                "Decision-making",
                "Social norms and taboos",
                "Food preferences",
                "Existentialism",
                "Personal preferences",
                "Preferences and choices"
            ],
            "Github Date": "",
            "HF Date": "2023-02-03",
            "HF Downloads (September 2023)": 17,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-attempto_nli": {
        "Unique Dataset Identifier": "tsi-attempto_nli",
        "Dataset Name": "attempto_nli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/sileod/attempto-nli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sileod/attempto-nli",
        "Paper Title": "First-Order Reasoning for Attempto Controlled English",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/0807.4623",
        "Semantic Scholar Corpus ID": 357102,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 24723,
            "Mean Inputs Length": 281.7099,
            "Mean Targets Length": 13.7602,
            "Max Inputs Length": 648,
            "Max Targets Length": 19,
            "Min Inputs Length": 133,
            "Min Targets Length": 13,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Zurich"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "attempto-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sileod/attempto-nli",
            "HF Config": "sileod--attempto-nli",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2010-09-13",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Language and semantics",
                "Language and communication",
                "Logic and reasoning",
                "Language understanding",
                "Relationships",
                "Linguistics",
                "Language and linguistics",
                "Language"
            ],
            "Github Date": "",
            "HF Date": "2023-02-03",
            "HF Downloads (September 2023)": 34,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 27,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Fuchs2010FirstOrderRF,\n author = {Norbert E. Fuchs},\n booktitle = {Controlled Natural Language},\n pages = {73-94},\n title = {First-Order Reasoning for Attempto Controlled English},\n year = {2010}\n}\n"
    },
    "tsi-defeasible_nli-snli": {
        "Unique Dataset Identifier": "tsi-defeasible_nli-snli",
        "Dataset Name": "defeasible_nli-snli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/defeasible-nli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/defeasible-nli",
        "Paper Title": "Thinking Like a Skeptic: Defeasible Inference in Natural Language",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/2020.findings-emnlp.418/",
        "Semantic Scholar Corpus ID": 226283602,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Natural Language Inference",
            "Textual Entailment",
            "Question Answering",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 232.8244,
            "Mean Targets Length": 11.0092,
            "Max Inputs Length": 602,
            "Max Targets Length": 13,
            "Min Inputs Length": 135,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "University of Maryland"
        ],
        "Licenses": [
            {
                "License": "MIT License",
                "License URL": "https://github.com/rudinger/defeasible-nli/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "defeasible-nli/snli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/defeasible-nli",
            "HF Config": "atomic",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-01",
            "GitHub License": "",
            "Text Topics": [
                "Visual perception",
                "Travel",
                "Outdoor activities",
                "Daily routine",
                "Gender roles",
                "Sports",
                "Culture"
            ],
            "Github Date": "",
            "HF Date": "2023-02-02",
            "HF Downloads (September 2023)": 121,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 51,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "social chemestry",
            "ATOMIC"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Rudinger2020ThinkingLA,\n author = {Rachel Rudinger and Vered Shwartz and Jena D. Hwang and Chandra Bhagavatula and Maxwell Forbes and Ronan Le Bras and Noah A. Smith and Yejin Choi},\n booktitle = {Findings},\n pages = {4661-4675},\n title = {Thinking Like a Skeptic: Defeasible Inference in Natural Language},\n year = {2020}\n}\n"
    },
    "tsi-defeasible_nli-atomic": {
        "Unique Dataset Identifier": "tsi-defeasible_nli-atomic",
        "Dataset Name": "defeasible_nli-atomic",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/defeasible-nli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/defeasible-nli",
        "Paper Title": "Thinking Like a Skeptic: Defeasible Inference in Natural Language",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/2020.findings-emnlp.418/",
        "Semantic Scholar Corpus ID": 226283602,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Natural Language Inference",
            "Textual Entailment",
            "Sentence Completion",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 182.4321,
            "Mean Targets Length": 11.0223,
            "Max Inputs Length": 326,
            "Max Targets Length": 13,
            "Min Inputs Length": 129,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "University of Maryland"
        ],
        "Licenses": [
            {
                "License": "MIT License",
                "License URL": "https://github.com/rudinger/defeasible-nli/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "defeasible-nli/atomic"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/defeasible-nli",
            "HF Config": "atomic",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-01",
            "GitHub License": "",
            "Text Topics": [
                "Personal preferences",
                "Personal finance",
                "Interpersonal relationships",
                "Relationships",
                "Personal development",
                "Communication",
                "Health",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2023-02-02",
            "HF Downloads (September 2023)": 121,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 51,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI",
            "social chemestry",
            "ATOMIC"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Rudinger2020ThinkingLA,\n author = {Rachel Rudinger and Vered Shwartz and Jena D. Hwang and Chandra Bhagavatula and Maxwell Forbes and Ronan Le Bras and Noah A. Smith and Yejin Choi},\n booktitle = {Findings},\n pages = {4661-4675},\n title = {Thinking Like a Skeptic: Defeasible Inference in Natural Language},\n year = {2020}\n}\n"
    },
    "tsi-help_nli": {
        "Unique Dataset Identifier": "tsi-help_nli",
        "Dataset Name": "help_nli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/verypluming/HELP",
        "GitHub URL": "https://github.com/verypluming/HELP",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/help-nli",
        "Paper Title": "HELP: A Dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/help",
        "ArXiv URL": "https://arxiv.org/abs/1904.12166",
        "Semantic Scholar Corpus ID": 139105363,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 176.652,
            "Mean Targets Length": 9.4959,
            "Max Inputs Length": 882,
            "Max Targets Length": 11,
            "Min Inputs Length": 105,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "parallel meaning bank"
        ],
        "Model Generated": [],
        "Creators": [
            "RIKEN",
            "Ochanomizu University",
            "Tohoku University",
            "University of Groningen"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/verypluming/HELP/blob/master/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "help-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/help-nli",
            "HF Config": "metaeval--help-nli",
            "HF Config License": "",
            "HF Yaml License": "CC0 1.0",
            "PwC License Name": "Custom",
            "PwC License URL": "https://github.com/verypluming/HELP",
            "PwC Date": "",
            "S2 Date": "2019-04-27",
            "GitHub License": "CC BY-SA 4.0",
            "Text Topics": [
                "Language understanding",
                "General knowledge",
                "Language and communication",
                "Communication",
                "Linguistics",
                "Food",
                "Education",
                "Geography",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2023-02-04",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The HELP dataset is an automatically created natural language inference (NLI) dataset that embodies the combination of lexical and logical inferences focusing on monotonicity (i.e., phrase replacement-based reasoning). The HELP (Ver.1.0) has 36K inference pairs consisting of upward monotone, downward monotone, non-monotone, conjunction, and disjunction.",
            "S2 Citation Count (September 2023)": 46,
            "GitHub Stars": 13,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Yanaka2019HELPAD,\n author = {Hitomi Yanaka and K. Mineshima and D. Bekki and Kentaro Inui and S. Sekine and Lasha Abzianidze and Johan Bos},\n booktitle = {International Workshop on Semantic Evaluation},\n journal = {ArXiv},\n title = {HELP: A Dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning},\n volume = {abs/1904.12166},\n year = {2019}\n}\n"
    },
    "tsi-nli_veridicality_transitivity": {
        "Unique Dataset Identifier": "tsi-nli_veridicality_transitivity",
        "Dataset Name": "nli_veridicality_transitivity",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/nli-veridicality-transitivity",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/nli-veridicality-transitivity",
        "Paper Title": "Adversarial NLI: A New Benchmark for Natural Language Understanding",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2101.10713",
        "Semantic Scholar Corpus ID": 207756753,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 191.7483,
            "Mean Targets Length": 9.5037,
            "Max Inputs Length": 381,
            "Max Targets Length": 11,
            "Min Inputs Length": 109,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flickr",
            "crowdsourced",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "UNC Chapel Hill",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "nli-veridicality-transitivity"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/nli-veridicality-transitivity",
            "HF Config": "metaeval--nli-veridicality-transitivity",
            "HF Config License": "",
            "HF Yaml License": "CC0 1.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-10-31",
            "GitHub License": "",
            "Text Topics": [
                "Communication and language",
                "Perception",
                "Communication",
                "Animal behavior",
                "Animals",
                "Sports",
                "Language and communication",
                "Perception and observation",
                "Linguistics"
            ],
            "Github Date": "",
            "HF Date": "2023-02-04",
            "HF Downloads (September 2023)": 33,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 601,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SICK dataset",
            "MegaVeridicality2",
            "Verb veridicality dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Nie2019AdversarialNA,\n author = {Yixin Nie and Adina Williams and Emily Dinan and Mohit Bansal and J. Weston and Douwe Kiela},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Adversarial NLI: A New Benchmark for Natural Language Understanding},\n volume = {abs/1910.14599},\n year = {2019}\n}\n"
    },
    "tsi-natural_language_satisfiability": {
        "Unique Dataset Identifier": "tsi-natural_language_satisfiability",
        "Dataset Name": "natural_language_satisfiability",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/natural-language-satisfiability",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/natural-language-satisfiability",
        "Paper Title": "Can Transformers Reason in Fragments of Natural Language?",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2211.05417",
        "Semantic Scholar Corpus ID": 253446947,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Logical Reasoning",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6800,
            "Mean Inputs Length": 759.9257,
            "Mean Targets Length": 12.0294,
            "Max Inputs Length": 1095,
            "Max Targets Length": 13,
            "Min Inputs Length": 472,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "ASUS Intelligent Cloud Services (AICS)",
            "University of Manchester",
            "Instytut Informatyki Uniwersytet Opolski"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "natural-language-satisfiability"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/natural-language-satisfiability",
            "HF Config": "metaeval--natural-language-satisfiability",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-11-10",
            "GitHub License": "",
            "Text Topics": [
                "Reasoning",
                "Categorical statements",
                "Philosophy",
                "Logic",
                "Categorization",
                "Language",
                "Language and grammar",
                "General knowledge",
                "Language understanding"
            ],
            "Github Date": "",
            "HF Date": "2023-02-04",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Schlegel2022CanTR,\n author = {Viktor Schlegel and Kamen V. Pavlov and Ian Pratt-Hartmann},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {11184-11199},\n title = {Can Transformers Reason in Fragments of Natural Language?},\n year = {2022}\n}\n"
    },
    "tsi-lonli": {
        "Unique Dataset Identifier": "tsi-lonli",
        "Dataset Name": "lonli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/microsoft/LoNLI",
        "GitHub URL": "https://github.com/microsoft/LoNLI",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/lonli",
        "Paper Title": "Trusting RoBERTa over BERT: Insights from CheckListing the Natural Language Inference Task",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2107.07229",
        "Semantic Scholar Corpus ID": 235899209,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 177.8242,
            "Mean Targets Length": 12.0778,
            "Max Inputs Length": 301,
            "Max Targets Length": 14,
            "Min Inputs Length": 119,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "Samsung",
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "Trademarks listed at the bottom of github (idk if we need this though): https://github.com/microsoft/LoNLI#trademarks",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lonli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/lonli",
            "HF Config": "metaeval--lonli",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-07-15",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Logic",
                "General knowledge",
                "Time management",
                "Daily routine",
                "Communication",
                "Education",
                "Language understanding",
                "Cultural diversity"
            ],
            "Github Date": "",
            "HF Date": "2023-02-04",
            "HF Downloads (September 2023)": 33,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": 6,
            "GitHub Topics": [
                "checklist",
                "logic",
                "nli",
                "nlp",
                "reasoning"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Tarunesh2021TrustingRO,\n author = {Ishan Tarunesh and Somak Aditya and M. Choudhury},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Trusting RoBERTa over BERT: Insights from CheckListing the Natural Language Inference Task},\n volume = {abs/2107.07229},\n year = {2021}\n}\n"
    },
    "tsi-dadc_limit_nli": {
        "Unique Dataset Identifier": "tsi-dadc_limit_nli",
        "Dataset Name": "dadc_limit_nli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/facebookresearch/dadc-limit",
        "GitHub URL": "https://github.com/facebookresearch/dadc-limit",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/dadc-limit-nli",
        "Paper Title": "Analyzing Dynamic Adversarial Training Data in the Limit",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2110.08514",
        "Semantic Scholar Corpus ID": 239016790,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 651,
            "Mean Inputs Length": 817.4378,
            "Mean Targets Length": 12.5806,
            "Max Inputs Length": 1195,
            "Max Targets Length": 14,
            "Min Inputs Length": 434,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "project gutenberg",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Berkeley",
            "Facebook AI Research",
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "dadc-limit-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/dadc-limit-nli",
            "HF Config": "metaeval--dadc-limit-nli",
            "HF Config License": "",
            "HF Yaml License": "CC0 1.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-10-16",
            "GitHub License": "",
            "Text Topics": [
                "Biography",
                "Ethics",
                "Cage design",
                "Physics",
                "Animal behavior",
                "History",
                "Geography",
                "Science"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 4,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 16,
            "GitHub Stars": 4,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Wallace2021AnalyzingDA,\n author = {Eric Wallace and Adina Williams and Robin Jia and Douwe Kiela},\n booktitle = {Findings},\n pages = {202-217},\n title = {Analyzing Dynamic Adversarial Training Data in the Limit},\n year = {2021}\n}\n"
    },
    "tsi-flute": {
        "Unique Dataset Identifier": "tsi-flute",
        "Dataset Name": "flute",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://figlang2022sharedtask.github.io/",
        "GitHub URL": "https://figlang2022sharedtask.github.io/",
        "Hugging Face URL": "https://huggingface.co/datasets/ColumbiaNLP/FLUTE",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Natural Language Inference",
            "Textual Entailment",
            "Paraphrase Generation",
            "Paraphrase Detection",
            "Sentiment Analysis",
            "Linguistic Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6403,
            "Mean Inputs Length": 232.1819,
            "Mean Targets Length": 12.7411,
            "Max Inputs Length": 534,
            "Max Targets Length": 14,
            "Min Inputs Length": 104,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "FLUTE"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ColumbiaNLP/FLUTE",
            "HF Config": "ColumbiaNLP--FLUTE",
            "HF Config License": "",
            "HF Yaml License": "Academic Free License v3.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Philosophy",
                "Daily routine",
                "Communication",
                "Emotions",
                "Language and communication",
                "Ethics",
                "Personal experiences"
            ],
            "Github Date": "",
            "HF Date": "2022-07-05",
            "HF Downloads (September 2023)": 168,
            "HF Likes (September 2023)": 4,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-summarize_from_feedback-comparisons": {
        "Unique Dataset Identifier": "tsi-summarize_from_feedback-comparisons",
        "Dataset Name": "summarize_from_feedback-comparisons",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://openaipublic.blob.core.windows.net/summarize-from-feedback/dataset",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/openai/summarize_from_feedback",
        "Paper Title": "Learning to summarize from human feedback",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2009.01325",
        "Semantic Scholar Corpus ID": 221665105,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 1618.371,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 2987,
            "Max Targets Length": 2,
            "Min Inputs Length": 340,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "OpenAI"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "summarize_from_feedback/comparisons"
        ],
        "Inferred Metadata": {
            "HF Dataset": "openai/summarize_from_feedback",
            "HF Config": "comparisons",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-09-02",
            "GitHub License": "",
            "Text Topics": [
                "Relationships and dating",
                "Dating and relationships",
                "Communication",
                "Communication in relationships",
                "Relationships",
                "Emotional well-being",
                "Personal experiences",
                "Relationships and communication"
            ],
            "Github Date": "",
            "HF Date": "2022-12-28",
            "HF Downloads (September 2023)": 2591,
            "HF Likes (September 2023)": 108,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 478,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Stiennon2020LearningTS,\n author = {Nisan Stiennon and Long Ouyang and Jeff Wu and Daniel M. Ziegler and Ryan J. Lowe and Chelsea Voss and Alec Radford and Dario Amodei and Paul Christiano},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Learning to summarize from human feedback},\n volume = {abs/2009.01325},\n year = {2020}\n}\n"
    },
    "tsi-folio": {
        "Unique Dataset Identifier": "tsi-folio",
        "Dataset Name": "folio",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Yale-LILY/FOLIO",
        "GitHub URL": "https://github.com/Yale-LILY/FOLIO",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/folio",
        "Paper Title": "FOLIO: Natural Language Reasoning with First-Order Logic",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2209.00840",
        "Semantic Scholar Corpus ID": 252070866,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Logical Reasoning",
            "Fact Verification",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1004,
            "Mean Inputs Length": 455.7281,
            "Mean Targets Length": 6.2709,
            "Max Inputs Length": 1368,
            "Max Targets Length": 8,
            "Min Inputs Length": 143,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "original"
        ],
        "Model Generated": [],
        "Creators": [
            "Yale University",
            "University of Illinois",
            "Iowa City West High School",
            "University of Washington",
            "The University of Hong Kong",
            "Penn State University",
            "Meta",
            "Salesforce Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/Yale-LILY/FOLIO/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "folio"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/folio",
            "HF Config": "metaeval--folio",
            "HF Config License": "",
            "HF Yaml License": "CC0 1.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-09-02",
            "GitHub License": "CC BY-SA 4.0",
            "Text Topics": [
                "Music",
                "Reasoning",
                "Categorization",
                "Science",
                "Education",
                "Logic",
                "Sports"
            ],
            "Github Date": "",
            "HF Date": "2023-02-21",
            "HF Downloads (September 2023)": 14,
            "HF Likes (September 2023)": 4,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 22,
            "GitHub Stars": 70,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Han2022FOLIONL,\n author = {Simeng Han and Hailey Schoelkopf and Yilun Zhao and Zhenting Qi and Martin Riddell and Luke Benson and Lucy Sun and E. Zubova and Yujie Qiao and Matthew Burtell and David Peng and Jonathan Fan and Yixin Liu and Brian Wong and Malcolm Sailor and Ansong Ni and Linyong Nan and Jungo Kasai and Tao Yu and Rui Zhang and Shafiq R. Joty and Alexander R. Fabbri and Wojciech Kryscinski and Xi Victoria Lin and Caiming Xiong and Dragomir R. Radev},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {FOLIO: Natural Language Reasoning with First-Order Logic},\n volume = {abs/2209.00840},\n year = {2022}\n}\n"
    },
    "tsi-tomi_nli": {
        "Unique Dataset Identifier": "tsi-tomi_nli",
        "Dataset Name": "tomi_nli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/tomi-nli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/tomi-nli",
        "Paper Title": "tasksource: Structured Dataset Preprocessing Annotations for Frictionless Extreme Multi-Task Learning and Evaluation",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 255942186,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5994,
            "Mean Inputs Length": 376.2289,
            "Mean Targets Length": 13.0,
            "Max Inputs Length": 533,
            "Max Targets Length": 15,
            "Min Inputs Length": 262,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tomi-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/tomi-nli",
            "HF Config": "metaeval--tomi-nli",
            "HF Config License": "",
            "HF Yaml License": "GNU General Public License v3.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Object location",
                "Object manipulation",
                "General knowledge",
                "Language and communication",
                "Relationships",
                "Location",
                "Object placement"
            ],
            "Github Date": "",
            "HF Date": "2023-02-05",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 4,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sileo2023tasksourceSD,\n author = {Damien Sileo},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {tasksource: Structured Dataset Preprocessing Annotations for Frictionless Extreme Multi-Task Learning and Evaluation},\n volume = {abs/2301.05948},\n year = {2023}\n}\n"
    },
    "tsi-avicenna": {
        "Unique Dataset Identifier": "tsi-avicenna",
        "Dataset Name": "avicenna",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/avicenna",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/avicenna",
        "Paper Title": "Avicenna: a challenge dataset for natural language generation toward commonsense syllogistic reasoning",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 247115366,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Text Classification",
            "Paraphrase Generation"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4800,
            "Mean Inputs Length": 226.1158,
            "Mean Targets Length": 3.5056,
            "Max Inputs Length": 518,
            "Max Targets Length": 4,
            "Min Inputs Length": 106,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "avicenna"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/avicenna",
            "HF Config": "metaeval--avicenna",
            "HF Config License": "",
            "HF Yaml License": "CC0 1.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-01-02",
            "GitHub License": "",
            "Text Topics": [
                "Business management",
                "Psychology",
                "Health and wellness",
                "Economics",
                "Health",
                "Biology",
                "Agriculture",
                "Science",
                "Geography"
            ],
            "Github Date": "",
            "HF Date": "2023-02-23",
            "HF Downloads (September 2023)": 28,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 3,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Aghahadi2022AvicennaAC,\n author = {Zeinab Aghahadi and A. Talebpour},\n booktitle = {J. Appl. Non Class. Logics},\n journal = {Journal of Applied Non-Classical Logics},\n pages = {55 - 71},\n title = {Avicenna: a challenge dataset for natural language generation toward commonsense syllogistic reasoning},\n volume = {32},\n year = {2022}\n}\n"
    },
    "tsi-shp": {
        "Unique Dataset Identifier": "tsi-shp",
        "Dataset Name": "shp",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/stanfordnlp/SHP",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/stanfordnlp/SHP",
        "Paper Title": "Understanding Dataset Difficulty with V-Usable Information",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2110.08420",
        "Semantic Scholar Corpus ID": 250340652,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 1897.2423,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 42478,
            "Max Targets Length": 2,
            "Min Inputs Length": 108,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University",
            "AI2",
            "Paul G. Allen School of Computer Science & Engineering",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://huggingface.co/datasets/stanfordnlp/SHP#license"
            }
        ],
        "License Notes": "Reddit terms of use",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "SHP"
        ],
        "Inferred Metadata": {
            "HF Dataset": "stanfordnlp/SHP",
            "HF Config": "stanfordnlp--SHP",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-10-16",
            "GitHub License": "",
            "Text Topics": [
                "Engineering",
                "Cooking",
                "Baking",
                "Recipe ideas",
                "Education",
                "Exam preparation",
                "Cooking/baking",
                "Film analysis",
                "Science fiction"
            ],
            "Github Date": "",
            "HF Date": "2023-02-18",
            "HF Downloads (September 2023)": 2515,
            "HF Likes (September 2023)": 220,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 27,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Ethayarajh2021UnderstandingDD,\n author = {Kawin Ethayarajh and Yejin Choi and Swabha Swayamdipta},\n booktitle = {International Conference on Machine Learning},\n pages = {5988-6008},\n title = {Understanding Dataset Difficulty with V-Usable Information},\n year = {2021}\n}\n"
    },
    "tsi-medqa_usmle_4_options_hf": {
        "Unique Dataset Identifier": "tsi-medqa_usmle_4_options_hf",
        "Dataset Name": "medqa_usmle_4_options_hf",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/GBaker/MedQA-USMLE-4-options-hf",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/GBaker/MedQA-USMLE-4-options-hf",
        "Paper Title": "What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams",
        "Papers with Code URL": "https://paperswithcode.com/dataset/medqa-usmle",
        "ArXiv URL": "https://arxiv.org/abs/2009.13081v1",
        "Semantic Scholar Corpus ID": 221970190,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10178,
            "Mean Inputs Length": 918.4655,
            "Mean Targets Length": 2.0009,
            "Max Inputs Length": 4108,
            "Max Targets Length": 11,
            "Min Inputs Length": 234,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "step1.medbullets.com",
            "amboss.com/us/usmle",
            "lecturio.com/usmle-step-1"
        ],
        "Model Generated": [],
        "Creators": [
            "Massachusetts Institute of Technology",
            "Tongji Medical College"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "MedQA-USMLE-4-options-hf"
        ],
        "Inferred Metadata": {
            "HF Dataset": "GBaker/MedQA-USMLE-4-options-hf",
            "HF Config": "GBaker--MedQA-USMLE-4-options-hf",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-09-28",
            "S2 Date": "2020-09-28",
            "GitHub License": "",
            "Text Topics": [
                "Women's health",
                "Neurological disorders",
                "Pediatrics",
                "Dermatology",
                "Medical symptoms and diagnosis",
                "Health",
                "Medical conditions and symptoms",
                "Medical diagnosis"
            ],
            "Github Date": "",
            "HF Date": "2023-01-24",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 3,
            "PwC Description": "Multiple choice question answering based on the United States Medical License Exams (USMLE). The dataset is collected from the professional medical board exams. It covers three languages: English, simplified Chinese, and traditional Chinese, and contains 12,723, 34,251, and 14,123 questions for the three languages, respectively.",
            "S2 Citation Count (September 2023)": 84,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jin2020WhatDD,\n author = {Di Jin and Eileen Pan and Nassim Oufattole and W. Weng and Hanyi Fang and Peter Szolovits},\n booktitle = {Applied Sciences},\n journal = {ArXiv},\n title = {What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams},\n volume = {abs/2009.13081},\n year = {2020}\n}\n"
    },
    "tsi-wikimedqa-medwiki": {
        "Unique Dataset Identifier": "tsi-wikimedqa-medwiki",
        "Dataset Name": "wikimedqa-medwiki",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://sileod.s3.eu-west-3.amazonaws.com/wikimedqa/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sileod/wikimedqa",
        "Paper Title": "Generating multiple-choice questions for medical question answering with distractors and cue-masking",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2303.07069",
        "Semantic Scholar Corpus ID": 257496837,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 1674.2463,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 11883,
            "Max Targets Length": 2,
            "Min Inputs Length": 180,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "wikidoc encyclopedia",
            "wikem encyclopedia"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Lille",
            "KU Leuven"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "wikimedqa/medwiki"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sileod/wikimedqa",
            "HF Config": "medwiki",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-03-13",
            "GitHub License": "",
            "Text Topics": [
                "Medical procedures",
                "Genetics",
                "Health",
                "Dermatology",
                "Biology",
                "Pharmacology",
                "Biochemistry",
                "Medical conditions and symptoms",
                "Medical conditions"
            ],
            "Github Date": "",
            "HF Date": "2022-07-14",
            "HF Downloads (September 2023)": 121,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 0,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Sileo2023GeneratingMQ,\n author = {Damien Sileo and Kanimozhi Uma and M. Moens},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Generating multiple-choice questions for medical question answering with distractors and cue-masking},\n volume = {abs/2303.07069},\n year = {2023}\n}\n"
    },
    "tsi-cicero": {
        "Unique Dataset Identifier": "tsi-cicero",
        "Dataset Name": "cicero",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/declare-lab/CICERO",
        "GitHub URL": "https://github.com/declare-lab/CICERO",
        "Hugging Face URL": "https://huggingface.co/datasets/declare-lab/cicero",
        "Paper Title": "CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues",
        "Papers with Code URL": "https://paperswithcode.com/dataset/cicero",
        "ArXiv URL": "https://arxiv.org/abs/2203.13926",
        "Semantic Scholar Corpus ID": 247762111,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 820.2821,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 2129,
            "Max Targets Length": 2,
            "Min Inputs Length": 335,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web",
            "web exams",
            "web exams",
            "web exams",
            "web exams"
        ],
        "Model Generated": [],
        "Creators": [
            "Singapore University of Technology and Design",
            "University of Michigan"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "cicero"
        ],
        "Inferred Metadata": {
            "HF Dataset": "declare-lab/cicero",
            "HF Config": "declare-lab--cicero",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "MIT License",
            "PwC License URL": "",
            "PwC Date": "2022-03-25",
            "S2 Date": "2022-03-25",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Travel",
                "Education",
                "Health",
                "Communication",
                "Communication and conversation",
                "Daily routine",
                "Family and relationships",
                "Time management"
            ],
            "Github Date": "",
            "HF Date": "2022-05-31",
            "HF Downloads (September 2023)": 14,
            "HF Likes (September 2023)": 1,
            "PwC Description": "CICERO contains 53,000 inferences for five commonsense dimensions -- cause, subsequent event, prerequisite, motivation, and emotional reaction -- collected from 5600 dialogues. It involves two challenging generative and multi-choice alternative selection tasks for the state-of-the-art NLP models to solve. Download the dataset using this link.",
            "S2 Citation Count (September 2023)": 16,
            "GitHub Stars": 60,
            "GitHub Topics": [
                "commonsense-reasoning",
                "dialogue-systems",
                "roberta-model",
                "seq2seq",
                "transformers"
            ]
        },
        "Derived from Datasets": [
            "DailyDialog dataset",
            "MuTual dataset",
            "DREAM dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Ghosal2022CICEROAD,\n author = {Deepanway Ghosal and Siqi Shen and Navonil Majumder and Rada Mihalcea and Soujanya Poria},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {5010-5028},\n title = {CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues},\n year = {2022}\n}\n"
    },
    "tsi-mutual": {
        "Unique Dataset Identifier": "tsi-mutual",
        "Dataset Name": "mutual",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/mutual",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/mutual",
        "Paper Title": "MuTual: A Dataset for Multi-Turn Dialogue Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mutual",
        "ArXiv URL": "https://arxiv.org/abs/2004.04494",
        "Semantic Scholar Corpus ID": 215548215,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6024,
            "Mean Inputs Length": 769.5355,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 2232,
            "Max Targets Length": 2,
            "Min Inputs Length": 240,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "Zhejiang University",
            "Microsoft Research",
            "Westlake University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mutual"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/mutual",
            "HF Config": "metaeval--mutual",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-09",
            "GitHub License": "",
            "Text Topics": [
                "Language learning",
                "Daily routine",
                "Customer service",
                "Personal preferences",
                "Communication",
                "Travel",
                "Time management",
                "Weather"
            ],
            "Github Date": "",
            "HF Date": "2023-02-28",
            "HF Downloads (September 2023)": 46,
            "HF Likes (September 2023)": 0,
            "PwC Description": "MuTual is a retrieval-based dataset for multi-turn dialogue reasoning, which is modified from Chinese high school English listening comprehension test data. It tests dialogue reasoning via next utterance prediction.",
            "S2 Citation Count (September 2023)": 101,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Cui2020MuTualAD,\n author = {Leyang Cui and Yu Wu and Shujie Liu and Yue Zhang and Ming Zhou},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {MuTual: A Dataset for Multi-Turn Dialogue Reasoning},\n volume = {abs/2004.04494},\n year = {2020}\n}\n"
    },
    "tsi-neqa": {
        "Unique Dataset Identifier": "tsi-neqa",
        "Dataset Name": "neqa",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/inverse-scaling/NeQA",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/inverse-scaling/NeQA",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 255,
            "Mean Inputs Length": 272.5176,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 475,
            "Max Targets Length": 2,
            "Min Inputs Length": 209,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://github.com/inverse-scaling/prize/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "NeQA"
        ],
        "Inferred Metadata": {
            "HF Dataset": "inverse-scaling/NeQA",
            "HF Config": "inverse-scaling--NeQA",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Astronomy",
                "Common sense",
                "Multiple choice questions",
                "General knowledge",
                "Geography",
                "Animal behavior",
                "Weather",
                "Decision-making",
                "Biology"
            ],
            "Github Date": "",
            "HF Date": "2022-10-06",
            "HF Downloads (September 2023)": 96,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-quote_repetition": {
        "Unique Dataset Identifier": "tsi-quote_repetition",
        "Dataset Name": "quote_repetition",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/inverse-scaling/quote-repetition",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/inverse-scaling/quote-repetition",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 255,
            "Mean Inputs Length": 442.651,
            "Mean Targets Length": 2.5529,
            "Max Inputs Length": 995,
            "Max Targets Length": 15,
            "Min Inputs Length": 245,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://github.com/inverse-scaling/prize/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "quote-repetition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "inverse-scaling/quote-repetition",
            "HF Config": "inverse-scaling--quote-repetition",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Decision-making and choices",
                "Philosophy and existentialism",
                "Literature and quotes",
                "General knowledge and trivia",
                "Literature",
                "Literature and poetry",
                "Philosophy",
                "General knowledge",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2022-10-06",
            "HF Downloads (September 2023)": 84,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-redefine_math": {
        "Unique Dataset Identifier": "tsi-redefine_math",
        "Dataset Name": "redefine_math",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/inverse-scaling/redefine-math",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/inverse-scaling/redefine-math",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 765,
            "Mean Inputs Length": 146.4732,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 175,
            "Max Targets Length": 2,
            "Min Inputs Length": 61,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://github.com/inverse-scaling/prize/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "redefine-math"
        ],
        "Inferred Metadata": {
            "HF Dataset": "inverse-scaling/redefine-math",
            "HF Config": "inverse-scaling--redefine-math",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Mathematics",
                "Arithmetic",
                "General knowledge",
                "Number theory",
                "Pi",
                "Math",
                "Number systems"
            ],
            "Github Date": "",
            "HF Date": "2022-10-08",
            "HF Downloads (September 2023)": 121,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-puzzte": {
        "Unique Dataset Identifier": "tsi-puzzte",
        "Dataset Name": "puzzte",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/puzzte",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/puzzte",
        "Paper Title": "A Puzzle-Based Dataset for Natural Language Inference",
        "Papers with Code URL": "https://paperswithcode.com/dataset/puzzte",
        "ArXiv URL": "https://arxiv.org/abs/2112.05742",
        "Semantic Scholar Corpus ID": 245117929,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 21469,
            "Mean Inputs Length": 420.9808,
            "Mean Targets Length": 22.8305,
            "Max Inputs Length": 1658,
            "Max Targets Length": 31,
            "Min Inputs Length": 216,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Technical University of Cluj-Napoca"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "puzzte"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/puzzte",
            "HF Config": "metaeval--puzzte",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/4.0/",
            "PwC Date": "2021-12-10",
            "S2 Date": "2021-12-10",
            "GitHub License": "",
            "Text Topics": [
                "Comparative height",
                "General knowledge",
                "Height comparison",
                "Puzzle",
                "Puzzle-solving",
                "Philosophy",
                "Relationships",
                "Reasoning"
            ],
            "Github Date": "",
            "HF Date": "2023-03-08",
            "HF Downloads (September 2023)": 30,
            "HF Likes (September 2023)": 1,
            "PwC Description": "Puzzles dataset: comparison, knight&knaves, and zebra puzzles.",
            "S2 Citation Count (September 2023)": 3,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Szomiu2021APD,\n author = {Roxana Szomiu and Adrian Groza},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A Puzzle-Based Dataset for Natural Language Inference},\n volume = {abs/2112.05742},\n year = {2021}\n}\n"
    },
    "tsi-implicatures": {
        "Unique Dataset Identifier": "tsi-implicatures",
        "Dataset Name": "implicatures",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/implicatures",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/implicatures",
        "Paper Title": "Conversational implicatures in English dialogue: Annotated dataset",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1911.10704",
        "Semantic Scholar Corpus ID": 208267578,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 850,
            "Mean Inputs Length": 176.9529,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 455,
            "Max Targets Length": 2,
            "Min Inputs Length": 98,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "toefl",
            "imsdb.com",
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "International Institute of Information Technology"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "implicatures"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/implicatures",
            "HF Config": "metaeval--implicatures",
            "HF Config License": "",
            "HF Yaml License": "GNU General Public License v3.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-11-25",
            "GitHub License": "",
            "Text Topics": [
                "Daily routine",
                "Relationships",
                "Time management",
                "Travel",
                "Communication",
                "General knowledge",
                "Decision-making",
                "Personal preferences",
                "Family relationships",
                "Health"
            ],
            "Github Date": "",
            "HF Date": "2023-02-27",
            "HF Downloads (September 2023)": 15,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 11,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{George2019ConversationalII,\n author = {Elizabeth Jasmi George and R. Mamidi},\n booktitle = {Procedia Computer Science},\n journal = {ArXiv},\n title = {Conversational implicatures in English dialogue: Annotated dataset},\n volume = {abs/1911.10704},\n year = {2019}\n}\n"
    },
    "tsi-race_c": {
        "Unique Dataset Identifier": "tsi-race_c",
        "Dataset Name": "race_c",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/mrcdata/race-c",
        "GitHub URL": "https://github.com/mrcdata/race-c",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/race-c",
        "Paper Title": "A New Multi-choice Reading Comprehension Dataset for Curriculum Learning",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 204854503,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12702,
            "Mean Inputs Length": 2713.3622,
            "Mean Targets Length": 2.0777,
            "Max Inputs Length": 7017,
            "Max Targets Length": 38,
            "Min Inputs Length": 402,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Non Commercial",
                "License URL": "https://github.com/mrcdata/race-c/blob/master/license.txt"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "race-c"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/race-c",
            "HF Config": "metaeval--race-c",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-10-15",
            "GitHub License": "",
            "Text Topics": [
                "Marine biology",
                "Reading comprehension",
                "Vocabulary",
                "History",
                "Technology",
                "Biology",
                "Language comprehension",
                "Communication",
                "Geography",
                "Evolution"
            ],
            "Github Date": "",
            "HF Date": "2023-04-06",
            "HF Downloads (September 2023)": 224,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 24,
            "GitHub Stars": 1,
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Liang2019ANM,\n author = {Yinlong Liang and Jianheng Li and Jian Yin},\n booktitle = {Asian Conference on Machine Learning},\n pages = {742-757},\n title = {A New Multi-choice Reading Comprehension Dataset for Curriculum Learning},\n year = {2019}\n}\n"
    },
    "tsi-spartqa_yn": {
        "Unique Dataset Identifier": "tsi-spartqa_yn",
        "Dataset Name": "spartqa_yn",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/spartqa-yn",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/spartqa-yn",
        "Paper Title": "SPARTQA: A Textual Question Answering Benchmark for Spatial Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/spartqa-1",
        "ArXiv URL": "https://arxiv.org/abs/2104.05832",
        "Semantic Scholar Corpus ID": 233219660,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 23968,
            "Mean Inputs Length": 741.0074,
            "Mean Targets Length": 3.5338,
            "Max Inputs Length": 1769,
            "Max Targets Length": 4,
            "Min Inputs Length": 394,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Michigan State University",
            "Amazon"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "spartqa-yn"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/spartqa-mchoice",
            "HF Config": "metaeval--spartqa-mchoice",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2021-06-01",
            "S2 Date": "2021-04-12",
            "GitHub License": "",
            "Text Topics": [
                "Visual perception",
                "Object identification",
                "Logic",
                "Object description",
                "Puzzle solving",
                "Spatial reasoning",
                "Problem-solving",
                "Spatial relationships"
            ],
            "Github Date": "",
            "HF Date": "2023-03-13",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 1,
            "PwC Description": "We take advantage of the ground truth of NLVR images, design CFGs to generate stories, and use spatial reasoning rules to ask and answer spatial reasoning questions. This automatically generated data is called SpaRTQA.   https://aclanthology.org/2021.naacl-main.364/",
            "S2 Citation Count (September 2023)": 21,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "NLVR dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Mirzaee2021SPARTQAAT,\n author = {Roshanak Mirzaee and Hossein Rajaby Faghihi and Qiang Ning and Parisa Kordjmashidi},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {SPARTQA: A Textual Question Answering Benchmark for Spatial Reasoning},\n volume = {abs/2104.05832},\n year = {2021}\n}\n"
    },
    "tsi-spartqa_mchoice": {
        "Unique Dataset Identifier": "tsi-spartqa_mchoice",
        "Dataset Name": "spartqa_mchoice",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/spartqa-mchoice",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/spartqa-mchoice",
        "Paper Title": "SPARTQA: A Textual Question Answering Benchmark for Spatial Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/spartqa-1",
        "ArXiv URL": "https://arxiv.org/abs/2104.05832",
        "Semantic Scholar Corpus ID": 233219660,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 22749,
            "Mean Inputs Length": 852.6961,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 1860,
            "Max Targets Length": 2,
            "Min Inputs Length": 442,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Michigan State University",
            "Amazon"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "spartqa-mchoice"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/spartqa-mchoice",
            "HF Config": "metaeval--spartqa-mchoice",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2021-06-01",
            "S2 Date": "2021-04-12",
            "GitHub License": "",
            "Text Topics": [
                "Problem-solving",
                "Spatial reasoning",
                "Problem-solving skills",
                "Puzzle solving",
                "Geometry",
                "Logic",
                "Visual perception"
            ],
            "Github Date": "",
            "HF Date": "2023-03-13",
            "HF Downloads (September 2023)": 48,
            "HF Likes (September 2023)": 1,
            "PwC Description": "We take advantage of the ground truth of NLVR images, design CFGs to generate stories, and use spatial reasoning rules to ask and answer spatial reasoning questions. This automatically generated data is called SpaRTQA.   https://aclanthology.org/2021.naacl-main.364/",
            "S2 Citation Count (September 2023)": 21,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "NLVR dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Mirzaee2021SPARTQAAT,\n author = {Roshanak Mirzaee and Hossein Rajaby Faghihi and Qiang Ning and Parisa Kordjmashidi},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {SPARTQA: A Textual Question Answering Benchmark for Spatial Reasoning},\n volume = {abs/2104.05832},\n year = {2021}\n}\n"
    },
    "tsi-temporal_nli": {
        "Unique Dataset Identifier": "tsi-temporal_nli",
        "Dataset Name": "temporal_nli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/temporal-nli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/temporal-nli",
        "Paper Title": "Probing Language Models for Understanding of Temporal Expressions",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2110.01113",
        "Semantic Scholar Corpus ID": 238259493,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 187.7118,
            "Mean Targets Length": 11.4021,
            "Max Inputs Length": 258,
            "Max Targets Length": 14,
            "Min Inputs Length": 133,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "temporal-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/temporal-nli",
            "HF Config": "metaeval--temporal-nli",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-10-03",
            "GitHub License": "",
            "Text Topics": [
                "Time management",
                "Time measurement",
                "Business and economics",
                "Coding",
                "Daily routine",
                "Event planning",
                "Time and duration",
                "Politics",
                "Time and scheduling"
            ],
            "Github Date": "",
            "HF Date": "2023-03-13",
            "HF Downloads (September 2023)": 29,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 7,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Thukral2021ProbingLM,\n author = {Shivin Thukral and Kunal Kukreja and Christian Kavouras},\n booktitle = {BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},\n pages = {396-406},\n title = {Probing Language Models for Understanding of Temporal Expressions},\n year = {2021}\n}\n"
    },
    "tsi-riddle_sense": {
        "Unique Dataset Identifier": "tsi-riddle_sense",
        "Dataset Name": "riddle_sense",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://inklab.usc.edu/RiddleSense/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/riddle_sense",
        "Paper Title": "RiddleSense: Reasoning about Riddle Questions Featuring Linguistic Creativity and Commonsense Knowledge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/riddle-sense",
        "ArXiv URL": "https://arxiv.org/abs/2101.00376",
        "Semantic Scholar Corpus ID": 235731975,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3510,
            "Mean Inputs Length": 222.7142,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 699,
            "Max Targets Length": 2,
            "Min Inputs Length": 129,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "brainzilla.com",
            "riddlewot.com"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Request Form",
                "License URL": "https://forms.gle/iWdsgN44TeoXW19e6"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "riddle_sense"
        ],
        "Inferred Metadata": {
            "HF Dataset": "riddle_sense",
            "HF Config": "default",
            "HF Config License": "Custom",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2021-01-02",
            "S2 Date": "2021-01-02",
            "GitHub License": "",
            "Text Topics": [
                "Riddles",
                "Trivia",
                "Logic",
                "Humor",
                "Problem-solving",
                "Language and communication",
                "Language and linguistics",
                "Riddles and puzzles"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1083,
            "HF Likes (September 2023)": 10,
            "PwC Description": "Question: I have five fingers but I am not alive. What am I? Answer: a glove.\n\nAnswering such a riddle-style question is a challenging cognitive process, in that it requires complex commonsense reasoning abilities, an understanding of figurative language, and counterfactual reasoning skills, which are all important abilities for advanced natural language understanding (NLU). However, there is currently no dedicated datasets aiming to test these abilities. Herein, we present RiddleSense, a new multiple-choice question answering task, which comes with the first large dataset (5.7k examples) for answering riddle-style commonsense questions. We systematically evaluate a wide range of models over the challenge, and point out that there is a large gap between the best-supervised model and human performance  suggesting intriguing future research in the direction of higher-order commonsense reasoning and linguistic creativity towards building advanced NLU systems.",
            "S2 Citation Count (September 2023)": 21,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lin2021RiddleSenseRA,\n author = {Bill Yuchen Lin and Ziyi Wu and Yichi Yang and Dong-Ho Lee and Xiang Ren},\n booktitle = {Findings},\n pages = {1504-1515},\n title = {RiddleSense: Reasoning about Riddle Questions Featuring Linguistic Creativity and Commonsense Knowledge},\n year = {2021}\n}\n"
    },
    "tsi-clcd_english": {
        "Unique Dataset Identifier": "tsi-clcd_english",
        "Dataset Name": "clcd_english",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/clcd-english",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/clcd-english",
        "Paper Title": "A logical-based corpus for cross-lingual evaluation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1905.05704",
        "Semantic Scholar Corpus ID": 208101144,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Text Classification",
            "Named Entity Recognition",
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10000,
            "Mean Inputs Length": 249.1422,
            "Mean Targets Length": 15.9884,
            "Max Inputs Length": 555,
            "Max Targets Length": 18,
            "Min Inputs Length": 141,
            "Min Targets Length": 14,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Sao Paulo"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "clcd-english"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/clcd-english",
            "HF Config": "metaeval--clcd-english",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-05-10",
            "GitHub License": "",
            "Text Topics": [
                "Relationships",
                "Travel",
                "General knowledge",
                "Mathematics",
                "Cultural experiences",
                "Geography",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2023-03-21",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 17,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Salvatore2019ALC,\n author = {Felipe Salvatore and M. Finger and R. Hirata},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {22-30},\n title = {A logical-based corpus for cross-lingual evaluation},\n year = {2019}\n}\n"
    },
    "tsi-twentyquestions": {
        "Unique Dataset Identifier": "tsi-twentyquestions",
        "Dataset Name": "twentyquestions",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/huggingface/datasets/blob/main/CONTRIBUTING.md#how-to-contribute-to-the-dataset-cards",
        "GitHub URL": "https://github.com/huggingface/datasets/blob/main/CONTRIBUTING.md#how-to-contribute-to-the-dataset-cards",
        "Hugging Face URL": "https://huggingface.co/datasets/maximedb/twentyquestions",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Text Classification",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 96.471,
            "Mean Targets Length": 5.4842,
            "Max Inputs Length": 186,
            "Max Targets Length": 6,
            "Min Inputs Length": 76,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "twentyquestions"
        ],
        "Inferred Metadata": {
            "HF Dataset": "maximedb/twentyquestions",
            "HF Config": "maximedb--twentyquestions",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Classification",
                "Communication",
                "Categorization",
                "Shopping",
                "Language understanding",
                "Animal classification",
                "General knowledge",
                "Trivia",
                "Biology"
            ],
            "Github Date": "",
            "HF Date": "2022-12-18",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-reclor": {
        "Unique Dataset Identifier": "tsi-reclor",
        "Dataset Name": "reclor",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/reclor",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/reclor",
        "Paper Title": "ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/reclor",
        "ArXiv URL": "https://arxiv.org/abs/2002.04326",
        "Semantic Scholar Corpus ID": 209485573,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4638,
            "Mean Inputs Length": 1056.9198,
            "Mean Targets Length": 2.0041,
            "Max Inputs Length": 2118,
            "Max Targets Length": 11,
            "Min Inputs Length": 419,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "gmat",
            "lsat"
        ],
        "Model Generated": [],
        "Creators": [
            "National University of Singapore"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "reclor"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/reclor",
            "HF Config": "metaeval--reclor",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-02-11",
            "S2 Date": "2020-02-11",
            "GitHub License": "",
            "Text Topics": [
                "Environmental conservation",
                "Education",
                "Animal behavior",
                "Psychology",
                "Archaeology",
                "Biology",
                "Language and communication",
                "Health",
                "Economics",
                "Workplace safety"
            ],
            "Github Date": "",
            "HF Date": "2023-03-23",
            "HF Downloads (September 2023)": 128,
            "HF Likes (September 2023)": 2,
            "PwC Description": "Logical reasoning is an important ability to examine, analyze, and critically evaluate arguments as they occur in ordinary language as the definition from Law School Admission Council. ReClor is a dataset extracted from logical reasoning questions of standardized graduate admission examinations.",
            "S2 Citation Count (September 2023)": 111,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Yu2020ReClorAR,\n author = {Weihao Yu and Zihang Jiang and Yanfei Dong and Jiashi Feng},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning},\n volume = {abs/2002.04326},\n year = {2020}\n}\n"
    },
    "tsi-counterfactually_augmented_imdb": {
        "Unique Dataset Identifier": "tsi-counterfactually_augmented_imdb",
        "Dataset Name": "counterfactually_augmented_imdb",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/counterfactually-augmented-imdb",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/counterfactually-augmented-imdb",
        "Paper Title": "Learning the Difference that Makes a Difference with Counterfactually-Augmented Data",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1909.12435",
        "Semantic Scholar Corpus ID": 203591519,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Question Answering",
            "Summarization",
            "Fact Checking"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1707,
            "Mean Inputs Length": 989.4564,
            "Mean Targets Length": 9.0,
            "Max Inputs Length": 2130,
            "Max Targets Length": 9,
            "Min Inputs Length": 158,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "imdb.com",
            "flickr"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "counterfactually-augmented-imdb"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/counterfactually-augmented-snli",
            "HF Config": "metaeval--counterfactually-augmented-snli",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-09-26",
            "GitHub License": "",
            "Text Topics": [
                "Movie reviews",
                "Entertainment",
                "Film analysis",
                "Film criticism",
                "Personal preferences",
                "Film appreciation",
                "Personal preferences in movies",
                "Acting performance",
                "Entertainment industry",
                "Film critique"
            ],
            "Github Date": "",
            "HF Date": "2023-03-08",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 401,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "imdb",
            "snli"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Kaushik2019LearningTD,\n author = {Divyansh Kaushik and E. Hovy and Zachary Chase Lipton},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Learning the Difference that Makes a Difference with Counterfactually-Augmented Data},\n volume = {abs/1909.12434},\n year = {2019}\n}\n"
    },
    "tsi-counterfactually_augmented_snli": {
        "Unique Dataset Identifier": "tsi-counterfactually_augmented_snli",
        "Dataset Name": "counterfactually_augmented_snli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/counterfactually-augmented-snli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/counterfactually-augmented-snli",
        "Paper Title": "Learning the Difference that Makes a Difference with Counterfactually-Augmented Data",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1909.12435",
        "Semantic Scholar Corpus ID": 203591519,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6664,
            "Mean Inputs Length": 200.0273,
            "Mean Targets Length": 11.0036,
            "Max Inputs Length": 443,
            "Max Targets Length": 14,
            "Min Inputs Length": 111,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "imdb.com",
            "flickr"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "counterfactually-augmented-snli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/counterfactually-augmented-snli",
            "HF Config": "metaeval--counterfactually-augmented-snli",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-09-26",
            "GitHub License": "",
            "Text Topics": [
                "Outdoor activities",
                "Natural language processing",
                "Sports",
                "Daily routine",
                "Language understanding",
                "Textual entailment",
                "Visual perception",
                "Music",
                "Culture"
            ],
            "Github Date": "",
            "HF Date": "2023-03-08",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 401,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "imdb",
            "snli"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Kaushik2019LearningTD,\n author = {Divyansh Kaushik and E. Hovy and Zachary Chase Lipton},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Learning the Difference that Makes a Difference with Counterfactually-Augmented Data},\n volume = {abs/1909.12434},\n year = {2019}\n}\n"
    },
    "tsi-cnli": {
        "Unique Dataset Identifier": "tsi-cnli",
        "Dataset Name": "cnli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/cnli",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/cnli",
        "Paper Title": "Counterfactually-Augmented SNLI Training Data Does Not Yield Better Generalization Than Unaugmented Data",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.04762",
        "Semantic Scholar Corpus ID": 222291772,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7080,
            "Mean Inputs Length": 199.9623,
            "Mean Targets Length": 11.0131,
            "Max Inputs Length": 443,
            "Max Targets Length": 14,
            "Min Inputs Length": 111,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "cnli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/cnli",
            "HF Config": "metaeval--cnli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-09",
            "GitHub License": "",
            "Text Topics": [
                "Gender roles",
                "Animals",
                "Language understanding",
                "Visual perception",
                "Fashion",
                "Daily routine",
                "Sports"
            ],
            "Github Date": "",
            "HF Date": "2023-04-07",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 27,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "SNLI"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Huang2020CounterfactuallyAugmentedST,\n author = {William Huang and Haokun Liu and Samuel R. Bowman},\n booktitle = {First Workshop on Insights from Negative Results in NLP},\n pages = {82-87},\n title = {Counterfactually-Augmented SNLI Training Data Does Not Yield Better Generalization Than Unaugmented Data},\n year = {2020}\n}\n"
    },
    "tsi-boolq_natural_perturbations": {
        "Unique Dataset Identifier": "tsi-boolq_natural_perturbations",
        "Dataset Name": "boolq_natural_perturbations",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/boolq-natural-perturbations",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/boolq-natural-perturbations",
        "Paper Title": "Natural Perturbation for Robust Question Answering",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2004.04849",
        "Semantic Scholar Corpus ID": 215737246,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Fact Verification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9727,
            "Mean Inputs Length": 119.0406,
            "Mean Targets Length": 5.4106,
            "Max Inputs Length": 178,
            "Max Targets Length": 6,
            "Min Inputs Length": 92,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "boolq-natural-perturbations"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/boolq-natural-perturbations",
            "HF Config": "metaeval--boolq-natural-perturbations",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-09",
            "GitHub License": "",
            "Text Topics": [
                "Politics",
                "Geography",
                "Government",
                "Sports",
                "Television shows",
                "Entertainment",
                "Pop culture"
            ],
            "Github Date": "",
            "HF Date": "2023-04-07",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 3,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Khashabi2020NaturalPF,\n author = {Daniel Khashabi and Tushar Khot and Ashish Sabharwal},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Natural Perturbation for Robust Question Answering},\n volume = {abs/2004.04849},\n year = {2020}\n}\n"
    },
    "tsi-equate": {
        "Unique Dataset Identifier": "tsi-equate",
        "Dataset Name": "equate",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/equate",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/equate",
        "Paper Title": "EQUATE: A Benchmark Evaluation Framework for Quantitative Reasoning in Natural Language Inference",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1901.03735",
        "Semantic Scholar Corpus ID": 58004756,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1649,
            "Mean Inputs Length": 248.3948,
            "Mean Targets Length": 10.738,
            "Max Inputs Length": 533,
            "Max Targets Length": 14,
            "Min Inputs Length": 118,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "rte",
            "cnn.com",
            "reddit",
            "gmat",
            "gre exams",
            "arithmetic word problems"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "equate"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/equate",
            "HF Config": "metaeval--equate",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-01-11",
            "GitHub License": "",
            "Text Topics": [
                "Math",
                "Arithmetic",
                "Economics",
                "Current events",
                "Quantities",
                "Logic",
                "Sports",
                "News reporting"
            ],
            "Github Date": "",
            "HF Date": "2023-01-30",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 61,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "RTE-Quant",
            "NewNLI",
            "RedditNLI",
            "StressTest",
            "AwpNLI"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Ravichander2019EQUATEAB,\n author = {Abhilasha Ravichander and Aakanksha Naik and C. Ros and E. Hovy},\n booktitle = {Conference on Computational Natural Language Learning},\n pages = {349-361},\n title = {EQUATE: A Benchmark Evaluation Framework for Quantitative Reasoning in Natural Language Inference},\n year = {2019}\n}\n"
    },
    "tsi-scienceqa_text_only": {
        "Unique Dataset Identifier": "tsi-scienceqa_text_only",
        "Dataset Name": "scienceqa_text_only",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/ScienceQA_text_only",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/ScienceQA_text_only",
        "Paper Title": "ScienceQA: a novel resource for question answering on scholarly articles",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 250729995,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6508,
            "Mean Inputs Length": 215.6275,
            "Mean Targets Length": 2.3642,
            "Max Inputs Length": 1034,
            "Max Targets Length": 10,
            "Min Inputs Length": 29,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ScienceQA_text_only"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/ScienceQA_text_only",
            "HF Config": "metaeval--ScienceQA_text_only",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-07-20",
            "GitHub License": "",
            "Text Topics": [
                "Vocabulary",
                "Genetics",
                "Biology",
                "Chemistry",
                "Grammar",
                "Dictionary usage",
                "Physics",
                "Communication",
                "Physical changes",
                "Language and linguistics"
            ],
            "Github Date": "",
            "HF Date": "2023-04-11",
            "HF Downloads (September 2023)": 275,
            "HF Likes (September 2023)": 16,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 3,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Saikh2022ScienceQAAN,\n author = {Tanik Saikh and Tirthankar Ghosal and Amish Mittal and Asif Ekbal and P. Bhattacharyya},\n booktitle = {International Journal on Digital Libraries},\n journal = {International Journal on Digital Libraries},\n pages = {289 - 301},\n title = {ScienceQA: a novel resource for question answering on scholarly articles},\n volume = {23},\n year = {2022}\n}\n"
    },
    "tsi-ekar_english": {
        "Unique Dataset Identifier": "tsi-ekar_english",
        "Dataset Name": "ekar_english",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://ekar-leaderboard.github.io",
        "GitHub URL": "https://ekar-leaderboard.github.io",
        "Hugging Face URL": "https://huggingface.co/datasets/Jiangjie/ekar_english",
        "Paper Title": "E-KAR: A Benchmark for Rationalizing Natural Language Analogical Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/e-kar",
        "ArXiv URL": "https://arxiv.org/abs/2203.08480",
        "Semantic Scholar Corpus ID": 247475874,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 868,
            "Mean Inputs Length": 194.3283,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 373,
            "Max Targets Length": 2,
            "Min Inputs Length": 130,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "civil service exams of china"
        ],
        "Model Generated": [],
        "Creators": [
            "Shanghai Key Laboratory of Data Science",
            "Fudan University",
            "ByteDance AI Lab",
            "Brain Technologies",
            "South China University of Technology",
            "UC Santa Barbara",
            "Fudan-Aishu Cognitive Intelligence Joint Research Center"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "https://ekar-leaderboard.github.io/"
            }
        ],
        "License Notes": "Found at the bottom of the website so unsure if the license is for the data, models, and/or website",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ekar_english"
        ],
        "Inferred Metadata": {
            "HF Dataset": "Jiangjie/ekar_english",
            "HF Config": "Jiangjie--ekar_english",
            "HF Config License": "",
            "HF Yaml License": "Academic Free License v3.0",
            "PwC License Name": "CC BY-NC-SA 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-nc-sa/4.0/",
            "PwC Date": "2022-03-16",
            "S2 Date": "2022-03-16",
            "GitHub License": "",
            "Text Topics": [
                "Language and vocabulary",
                "Vocabulary",
                "Critical thinking and reasoning",
                "Education",
                "Language and linguistics",
                "Analogies",
                "Geography",
                "Vocabulary and word associations",
                "General knowledge",
                "Technology"
            ],
            "Github Date": "",
            "HF Date": "2022-03-27",
            "HF Downloads (September 2023)": 81,
            "HF Likes (September 2023)": 3,
            "PwC Description": "The ability to recognize analogies is fundamental to human cognition. Existing benchmarks to test word analogy do not reveal the underneath process of analogical reasoning of neural models.\n\nHolding the belief that models capable of reasoning should be right for the right reasons, we propose a first-of-its-kind Explainable Knowledge-intensive Analogical Reasoning benchmark (E-KAR). Our benchmark consists of 1,655 (in Chinese) and 1,251 (in English) problems sourced from the Civil Service Exams, which require intensive background knowledge to solve. More importantly, we design a free-text explanation scheme to explain whether an analogy should be drawn, and manually annotate them for each and every question and candidate answer.",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chen2022EKARAB,\n author = {Jiangjie Chen and Rui Xu and Ziquan Fu and Wei Shi and Zhongqiao Li and Xinbo Zhang and Changzhi Sun and Lei Li and Yanghua Xiao and Hao Zhou},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {E-KAR: A Benchmark for Rationalizing Natural Language Analogical Reasoning},\n volume = {abs/2203.08480},\n year = {2022}\n}\n"
    },
    "tsi-implicit_hate_stg1": {
        "Unique Dataset Identifier": "tsi-implicit_hate_stg1",
        "Dataset Name": "implicit_hate_stg1",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/SALT-NLP/implicit-hate",
        "GitHub URL": "https://github.com/SALT-NLP/implicit-hate",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/implicit-hate-stg1",
        "Paper Title": "Latent Hatred: A Benchmark for Understanding Implicit Hate Speech",
        "Papers with Code URL": "https://paperswithcode.com/dataset/implicit-hate",
        "ArXiv URL": "https://arxiv.org/abs/2109.05322",
        "Semantic Scholar Corpus ID": 237490428,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 18258,
            "Mean Inputs Length": 190.4956,
            "Mean Targets Length": 10.8962,
            "Max Inputs Length": 902,
            "Max Targets Length": 14,
            "Min Inputs Length": 105,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "UC San Diego",
            "Georgia Institute of Technology"
        ],
        "Licenses": [
            {
                "License": "Request Form",
                "License URL": "https://forms.gle/QxCpEbVp91Z35hWFA"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "implicit-hate-stg1"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/implicit-hate-stg1",
            "HF Config": "metaeval--implicit-hate-stg1",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2021-09-11",
            "S2 Date": "2021-09-11",
            "GitHub License": "MIT License",
            "Text Topics": [
                "History",
                "Political discourse",
                "Discrimination",
                "Racism",
                "Politics",
                "Hate speech",
                "Hate speech and discrimination"
            ],
            "Github Date": "",
            "HF Date": "2023-04-17",
            "HF Downloads (September 2023)": 94,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The Implicit Hate corpus is a dataset for hate speech detection with fine-grained labels for each message and its implication. This dataset contains 22,056 tweets from the most prominent extremist groups in the United States; 6,346 of these tweets contain implicit hate speech.",
            "S2 Citation Count (September 2023)": 84,
            "GitHub Stars": 26,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Elsherief2021LatentHA,\n author = {Mai Elsherief and Caleb Ziems and D. Muchlinski and Vaishnavi Anupindi and Jordyn Seybolt and M. Choudhury and Diyi Yang},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {345-363},\n title = {Latent Hatred: A Benchmark for Understanding Implicit Hate Speech},\n year = {2021}\n}\n"
    },
    "tsi-logiqa_2.0_nli": {
        "Unique Dataset Identifier": "tsi-logiqa_2.0_nli",
        "Dataset Name": "logiqa_2.0_nli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/csitfun/LogiQA2.0",
        "GitHub URL": "https://github.com/lgw863/LogiQA-dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/logiqa-2.0-nli",
        "Paper Title": "LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/medmcqa",
        "ArXiv URL": "https://arxiv.org/abs/2007.08124",
        "Semantic Scholar Corpus ID": 220483148,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6867,
            "Mean Inputs Length": 668.5081,
            "Mean Targets Length": 12.8063,
            "Max Inputs Length": 1651,
            "Max Targets Length": 15,
            "Min Inputs Length": 187,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "national civil servants examination of china"
        ],
        "Model Generated": [],
        "Creators": [
            "Fudan University",
            "Westlake University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "https://github.com/csitfun/LogiQA2.0#logiqa20"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "logiqa-2.0-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "lucasmccabe/logiqa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2022-03-27",
            "S2 Date": "2020-07-01",
            "GitHub License": "",
            "Text Topics": [
                "History",
                "Politics",
                "Psychology",
                "Logic",
                "Science",
                "Philosophy",
                "Environmental issues"
            ],
            "Github Date": "",
            "HF Date": "2023-04-24",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "MedMCQA is a large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions.\n\nMedMCQA has more than 194k high-quality AIIMS & NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity.",
            "S2 Citation Count (September 2023)": 90,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020LogiQAAC,\n author = {Jian Liu and Leyang Cui and Hanmeng Liu and Dandan Huang and Yile Wang and Yue Zhang},\n booktitle = {International Joint Conference on Artificial Intelligence},\n journal = {ArXiv},\n title = {LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning},\n volume = {abs/2007.08124},\n year = {2020}\n}\n"
    },
    "tsi-pararule_plus": {
        "Unique Dataset Identifier": "tsi-pararule_plus",
        "Dataset Name": "pararule_plus",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Strong-AI-Lab/Multi-Step-Deductive-Reasoning-Over-Natural-Language",
        "GitHub URL": "https://github.com/Strong-AI-Lab/Multi-Step-Deductive-Reasoning-Over-Natural-Language",
        "Hugging Face URL": "https://huggingface.co/datasets/qbao775/PARARULE-Plus",
        "Paper Title": "Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2207.14000",
        "Semantic Scholar Corpus ID": 251135345,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Textual Entailment/Inference/Reasoning",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 935.34,
            "Mean Targets Length": 5.5003,
            "Max Inputs Length": 1439,
            "Max Targets Length": 6,
            "Min Inputs Length": 511,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "The University of Auckland"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "PARARULE-Plus"
        ],
        "Inferred Metadata": {
            "HF Dataset": "qbao775/PARARULE-Plus",
            "HF Config": "qbao775--PARARULE-Plus",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-07-28",
            "GitHub License": "",
            "Text Topics": [
                "Animal characteristics",
                "Animal behavior",
                "Animal characteristics and behavior",
                "General knowledge",
                "Descriptive language",
                "Language understanding",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2023-04-16",
            "HF Downloads (September 2023)": 52,
            "HF Likes (September 2023)": 4,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 4,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Bao2022MultiStepDR,\n author = {Qiming Bao and A. Peng and Tim Hartill and N. Tan and Zhenyun Deng and M. Witbrock and Jiamou Liu},\n booktitle = {International Workshop on Neural-Symbolic Learning and Reasoning},\n journal = {ArXiv},\n title = {Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation},\n volume = {abs/2207.14000},\n year = {2022}\n}\n"
    },
    "tsi-mindgames": {
        "Unique Dataset Identifier": "tsi-mindgames",
        "Dataset Name": "mindgames",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/llm-theory-of-mind",
        "GitHub URL": "https://github.com/sileod/llm-theory-of-mind",
        "Hugging Face URL": "https://huggingface.co/datasets/sileod/mindgames",
        "Paper Title": "MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mindgames",
        "ArXiv URL": "https://arxiv.org/abs/2305.03353",
        "Semantic Scholar Corpus ID": 258547259,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11174,
            "Mean Inputs Length": 425.1873,
            "Mean Targets Length": 13.0068,
            "Max Inputs Length": 865,
            "Max Targets Length": 15,
            "Min Inputs Length": 227,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Lille"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/sileod/llm-theory-of-mind"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mindgames"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sileod/mindgames",
            "HF Config": "all",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "",
            "PwC Date": "2023-05-05",
            "S2 Date": "2023-05-05",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Logic",
                "Social dynamics",
                "Epistemology",
                "Communication",
                "Knowledge",
                "Public announcements",
                "Philosophy"
            ],
            "Github Date": "",
            "HF Date": "2023-05-03",
            "HF Downloads (September 2023)": 64,
            "HF Likes (September 2023)": 4,
            "PwC Description": "We generate epistemic reasoning problems using modal logic to target theory of mind (tom) in natural language processing models.",
            "S2 Citation Count (September 2023)": 5,
            "GitHub Stars": 6,
            "GitHub Topics": [
                "chatgpt",
                "dataset",
                "english",
                "entailment",
                "epistemic-logic",
                "epistemic-reasoning",
                "gpt-4",
                "language-model",
                "llm",
                "modal-logic",
                "natural-language",
                "natural-language-inference",
                "natural-language-processing",
                "nli",
                "nlp",
                "pal",
                "public-announcement-logic",
                "social-reasoning",
                "theory-of-mind",
                "tom"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sileo2023MindGamesTT,\n author = {Damien Sileo and Antoine Lernould},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic},\n volume = {abs/2305.03353},\n year = {2023}\n}\n"
    },
    "tsi-universal_dependencies-en_partut-deprel": {
        "Unique Dataset Identifier": "tsi-universal_dependencies-en_partut-deprel",
        "Dataset Name": "universal_dependencies-en_partut-deprel",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://universaldependencies.org/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/universal_dependencies",
        "Paper Title": "Universal Dependencies v1: A Multilingual Treebank Collection",
        "Papers with Code URL": "https://paperswithcode.com/dataset/universal-dependencies",
        "ArXiv URL": "https://aclanthology.org/L16-1262/",
        "Semantic Scholar Corpus ID": 17954486,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Dependency Parsing",
            "Named Entity Recognition",
            "Question Answering",
            "Part-of-Speech Tagging",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1781,
            "Mean Inputs Length": 307.251,
            "Mean Targets Length": 262.6575,
            "Max Inputs Length": 1378,
            "Max Targets Length": 2232,
            "Min Inputs Length": 154,
            "Min Targets Length": 20,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Uppsala University",
            "The Ohio State University",
            "University of Turku",
            "Bar-Ilan University",
            "Charles University",
            "Stanford University",
            "Google",
            "University of Cambridge",
            "The Open University of Israel"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://universaldependencies.org/introduction.html"
            }
        ],
        "License Notes": "URL contains link to history page with many more publications",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "universal_dependencies/en_partut/deprel"
        ],
        "Inferred Metadata": {
            "HF Dataset": "universal_dependencies",
            "HF Config": "af_afribooms",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Various",
            "PwC License URL": "https://lindat.mff.cuni.cz/repository/xmlui/page/licence-UD-2.1",
            "PwC Date": "2016-01-01",
            "S2 Date": "2016-05-01",
            "GitHub License": "",
            "Text Topics": [
                "Language and Linguistics",
                "Language processing",
                "Language and grammar",
                "Syntax and grammar",
                "Language analysis",
                "Politics",
                "Literature"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3002,
            "HF Likes (September 2023)": 12,
            "PwC Description": "The Universal Dependencies (UD) project seeks to develop cross-linguistically consistent treebank annotation of morphology and syntax for multiple languages. The first version of the dataset was released in 2015 and consisted of 10 treebanks over 10 languages. Version 2.7 released in 2020 consists of 183 treebanks over 104 languages. The annotation consists of UPOS (universal part-of-speech tags), XPOS (language-specific part-of-speech tags), Feats (universal morphological features), Lemmas, dependency heads and universal dependency labels.",
            "S2 Citation Count (September 2023)": 1233,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Nivre2016UniversalDV,\n author = {Joakim Nivre and M. Marneffe and Filip Ginter and Yoav Goldberg and Jan Hajic and Christopher D. Manning and Ryan T. McDonald and Slav Petrov and Sampo Pyysalo and Natalia Silveira and Reut Tsarfaty and Daniel Zeman},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {1659-1666},\n title = {Universal Dependencies v1: A Multilingual Treebank Collection},\n year = {2016}\n}\n"
    },
    "tsi-universal_dependencies-en_lines-deprel": {
        "Unique Dataset Identifier": "tsi-universal_dependencies-en_lines-deprel",
        "Dataset Name": "universal_dependencies-en_lines-deprel",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://universaldependencies.org/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/universal_dependencies",
        "Paper Title": "Universal Dependencies v1: A Multilingual Treebank Collection",
        "Papers with Code URL": "https://paperswithcode.com/dataset/universal-dependencies",
        "ArXiv URL": "https://aclanthology.org/L16-1262/",
        "Semantic Scholar Corpus ID": 17954486,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Part-of-Speech Tagging",
            "Text Classification",
            "Dependency Parsing"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3176,
            "Mean Inputs Length": 253.1612,
            "Mean Targets Length": 187.427,
            "Max Inputs Length": 751,
            "Max Targets Length": 1034,
            "Min Inputs Length": 151,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Uppsala University",
            "The Ohio State University",
            "University of Turku",
            "Bar-Ilan University",
            "Charles University",
            "Stanford University",
            "Google",
            "University of Cambridge",
            "The Open University of Israel"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://universaldependencies.org/introduction.html"
            }
        ],
        "License Notes": "URL contains link to history page with many more publications",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "universal_dependencies/en_lines/deprel"
        ],
        "Inferred Metadata": {
            "HF Dataset": "universal_dependencies",
            "HF Config": "af_afribooms",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Various",
            "PwC License URL": "https://lindat.mff.cuni.cz/repository/xmlui/page/licence-UD-2.1",
            "PwC Date": "2016-01-01",
            "S2 Date": "2016-05-01",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Grammar",
                "Language analysis",
                "Communication",
                "Daily routine",
                "Language",
                "Personal experiences",
                "Syntax"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3002,
            "HF Likes (September 2023)": 12,
            "PwC Description": "The Universal Dependencies (UD) project seeks to develop cross-linguistically consistent treebank annotation of morphology and syntax for multiple languages. The first version of the dataset was released in 2015 and consisted of 10 treebanks over 10 languages. Version 2.7 released in 2020 consists of 183 treebanks over 104 languages. The annotation consists of UPOS (universal part-of-speech tags), XPOS (language-specific part-of-speech tags), Feats (universal morphological features), Lemmas, dependency heads and universal dependency labels.",
            "S2 Citation Count (September 2023)": 1233,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Nivre2016UniversalDV,\n author = {Joakim Nivre and M. Marneffe and Filip Ginter and Yoav Goldberg and Jan Hajic and Christopher D. Manning and Ryan T. McDonald and Slav Petrov and Sampo Pyysalo and Natalia Silveira and Reut Tsarfaty and Daniel Zeman},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {1659-1666},\n title = {Universal Dependencies v1: A Multilingual Treebank Collection},\n year = {2016}\n}\n"
    },
    "tsi-universal_dependencies-en_gum-deprel": {
        "Unique Dataset Identifier": "tsi-universal_dependencies-en_gum-deprel",
        "Dataset Name": "universal_dependencies-en_gum-deprel",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://universaldependencies.org/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/universal_dependencies",
        "Paper Title": "Universal Dependencies v1: A Multilingual Treebank Collection",
        "Papers with Code URL": "https://paperswithcode.com/dataset/universal-dependencies",
        "ArXiv URL": "https://aclanthology.org/L16-1262/",
        "Semantic Scholar Corpus ID": 17954486,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Dependency Parsing",
            "Named Entity Recognition",
            "Dialog Generation",
            "Question Answering",
            "Part-of-Speech Tagging"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4287,
            "Mean Inputs Length": 267.6114,
            "Mean Targets Length": 204.0252,
            "Max Inputs Length": 776,
            "Max Targets Length": 1102,
            "Min Inputs Length": 149,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Uppsala University",
            "The Ohio State University",
            "University of Turku",
            "Bar-Ilan University",
            "Charles University",
            "Stanford University",
            "Google",
            "University of Cambridge",
            "The Open University of Israel"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://universaldependencies.org/introduction.html"
            }
        ],
        "License Notes": "URL contains link to history page with many more publications",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "universal_dependencies/en_gum/deprel"
        ],
        "Inferred Metadata": {
            "HF Dataset": "universal_dependencies",
            "HF Config": "af_afribooms",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Various",
            "PwC License URL": "https://lindat.mff.cuni.cz/repository/xmlui/page/licence-UD-2.1",
            "PwC Date": "2016-01-01",
            "S2 Date": "2016-05-01",
            "GitHub License": "",
            "Text Topics": [
                "Linguistics",
                "Daily routine",
                "Geography",
                "Language and linguistics",
                "Language and grammar",
                "Language",
                "Communication",
                "Grammar",
                "Travel",
                "Language analysis"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3002,
            "HF Likes (September 2023)": 12,
            "PwC Description": "The Universal Dependencies (UD) project seeks to develop cross-linguistically consistent treebank annotation of morphology and syntax for multiple languages. The first version of the dataset was released in 2015 and consisted of 10 treebanks over 10 languages. Version 2.7 released in 2020 consists of 183 treebanks over 104 languages. The annotation consists of UPOS (universal part-of-speech tags), XPOS (language-specific part-of-speech tags), Feats (universal morphological features), Lemmas, dependency heads and universal dependency labels.",
            "S2 Citation Count (September 2023)": 1233,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Nivre2016UniversalDV,\n author = {Joakim Nivre and M. Marneffe and Filip Ginter and Yoav Goldberg and Jan Hajic and Christopher D. Manning and Ryan T. McDonald and Slav Petrov and Sampo Pyysalo and Natalia Silveira and Reut Tsarfaty and Daniel Zeman},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {1659-1666},\n title = {Universal Dependencies v1: A Multilingual Treebank Collection},\n year = {2016}\n}\n"
    },
    "tsi-universal_dependencies-en_ewt-deprel": {
        "Unique Dataset Identifier": "tsi-universal_dependencies-en_ewt-deprel",
        "Dataset Name": "universal_dependencies-en_ewt-deprel",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://universaldependencies.org/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/universal_dependencies",
        "Paper Title": "Universal Dependencies v1: A Multilingual Treebank Collection",
        "Papers with Code URL": "https://paperswithcode.com/dataset/universal-dependencies",
        "ArXiv URL": "https://aclanthology.org/L16-1262/",
        "Semantic Scholar Corpus ID": 17954486,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Part-of-Speech Tagging",
            "Sentence Completion",
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12543,
            "Mean Inputs Length": 249.8736,
            "Mean Targets Length": 174.1187,
            "Max Inputs Length": 1125,
            "Max Targets Length": 1691,
            "Min Inputs Length": 148,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Uppsala University",
            "The Ohio State University",
            "University of Turku",
            "Bar-Ilan University",
            "Charles University",
            "Stanford University",
            "Google",
            "University of Cambridge",
            "The Open University of Israel"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://universaldependencies.org/introduction.html"
            }
        ],
        "License Notes": "URL contains link to history page with many more publications",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "universal_dependencies/en_ewt/deprel"
        ],
        "Inferred Metadata": {
            "HF Dataset": "universal_dependencies",
            "HF Config": "af_afribooms",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Various",
            "PwC License URL": "https://lindat.mff.cuni.cz/repository/xmlui/page/licence-UD-2.1",
            "PwC Date": "2016-01-01",
            "S2 Date": "2016-05-01",
            "GitHub License": "",
            "Text Topics": [
                "Language and Linguistics",
                "Language and linguistics",
                "Language",
                "Communication",
                "Linguistics",
                "Syntax",
                "Grammar",
                "Language analysis",
                "Language and grammar",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3002,
            "HF Likes (September 2023)": 12,
            "PwC Description": "The Universal Dependencies (UD) project seeks to develop cross-linguistically consistent treebank annotation of morphology and syntax for multiple languages. The first version of the dataset was released in 2015 and consisted of 10 treebanks over 10 languages. Version 2.7 released in 2020 consists of 183 treebanks over 104 languages. The annotation consists of UPOS (universal part-of-speech tags), XPOS (language-specific part-of-speech tags), Feats (universal morphological features), Lemmas, dependency heads and universal dependency labels.",
            "S2 Citation Count (September 2023)": 1233,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Nivre2016UniversalDV,\n author = {Joakim Nivre and M. Marneffe and Filip Ginter and Yoav Goldberg and Jan Hajic and Christopher D. Manning and Ryan T. McDonald and Slav Petrov and Sampo Pyysalo and Natalia Silveira and Reut Tsarfaty and Daniel Zeman},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {1659-1666},\n title = {Universal Dependencies v1: A Multilingual Treebank Collection},\n year = {2016}\n}\n"
    },
    "tsi-ambient": {
        "Unique Dataset Identifier": "tsi-ambient",
        "Dataset Name": "ambient",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/ambient",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/ambient",
        "Paper Title": "We're Afraid Language Models Aren't Modeling Ambiguity",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.14399",
        "Semantic Scholar Corpus ID": 258352700,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Textual Entailment",
            "Text Classification",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 50,
            "Mean Inputs Length": 177.88,
            "Mean Targets Length": 5.86,
            "Max Inputs Length": 293,
            "Max Targets Length": 6,
            "Min Inputs Length": 97,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "textbooks",
            "templates",
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Paul G. Allen School of Computer Science & Engineering",
            "University of Washington",
            "AI2",
            "University of Southern California",
            "Saarland University",
            "New York University",
            "Massachusetts Institute of Technology"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ambient"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/ambient",
            "HF Config": "metaeval--ambient",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-27",
            "GitHub License": "",
            "Text Topics": [
                "Daily life",
                "Problem-solving",
                "Family dynamics",
                "Communication",
                "Decision-making",
                "Logic",
                "Finance",
                "Psychology"
            ],
            "Github Date": "",
            "HF Date": "2023-05-04",
            "HF Downloads (September 2023)": 31,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "distNLI",
            "ImpPres",
            "GLUE",
            "MNLI",
            "WaNLI"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Liu2023WereAL,\n author = {Alisa Liu and Zhaofeng Wu and Julian Michael and Alane Suhr and Peter West and Alexander Koller and Swabha Swayamdipta and Noah A. Smith and Yejin Choi},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {We're Afraid Language Models Aren't Modeling Ambiguity},\n volume = {abs/2304.14399},\n year = {2023}\n}\n"
    },
    "tsi-path_naturalness_prediction": {
        "Unique Dataset Identifier": "tsi-path_naturalness_prediction",
        "Dataset Name": "path_naturalness_prediction",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/huggingface/datasets/blob/main/CONTRIBUTING.md#how-to-contribute-to-the-dataset-cards",
        "GitHub URL": "https://github.com/huggingface/datasets/blob/main/CONTRIBUTING.md#how-to-contribute-to-the-dataset-cards",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/path-naturalness-prediction",
        "Paper Title": "Predicting ConceptNet Path Quality Using Crowdsourced Assessments of Naturalness",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1902.07831",
        "Semantic Scholar Corpus ID": 67788038,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 222.4317,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 399,
            "Max Targets Length": 2,
            "Min Inputs Length": 104,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conceptnet",
            "opencyc",
            "wordnet",
            "verbosity",
            "dbpedia",
            "wiktionary.org"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "Massachusetts Institute of Technology",
            "Cardiff University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "path-naturalness-prediction"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/path-naturalness-prediction",
            "HF Config": "metaeval--path-naturalness-prediction",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-02-21",
            "GitHub License": "",
            "Text Topics": [
                "Synonyms and antonyms",
                "Language",
                "General knowledge",
                "Critical thinking and reasoning",
                "Logic",
                "Language and semantics",
                "Synonyms and word relationships",
                "Language and linguistics",
                "Word associations",
                "Logic and reasoning"
            ],
            "Github Date": "",
            "HF Date": "2023-04-14",
            "HF Downloads (September 2023)": 15,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 5,
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zhou2019PredictingCP,\n author = {Yilun Zhou and Steven Schockaert and J. Shah},\n booktitle = {The Web Conference},\n journal = {The World Wide Web Conference},\n title = {Predicting ConceptNet Path Quality Using Crowdsourced Assessments of Naturalness},\n year = {2019}\n}\n"
    },
    "tsi-cloth": {
        "Unique Dataset Identifier": "tsi-cloth",
        "Dataset Name": "cloth",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://www.cs.cmu.edu/~glai1/data/cloth/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/AndyChiang/cloth",
        "Paper Title": "Large-scale Cloze Test Dataset Created by Teachers",
        "Papers with Code URL": "https://paperswithcode.com/dataset/cloth",
        "ArXiv URL": "https://arxiv.org/abs/1711.03225",
        "Semantic Scholar Corpus ID": 52112703,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 229.525,
            "Mean Targets Length": 2.0009,
            "Max Inputs Length": 1438,
            "Max Targets Length": 6,
            "Min Inputs Length": 107,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "www.21cnjy.com",
            "5utk.ks5u.com",
            "zujuan.xkw.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "cloth"
        ],
        "Inferred Metadata": {
            "HF Dataset": "AndyChiang/cloth",
            "HF Config": "AndyChiang--cloth",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2018-01-01",
            "S2 Date": "2017-11-09",
            "GitHub License": "",
            "Text Topics": [
                "Communication and understanding",
                "Travel",
                "Education",
                "Social interactions",
                "Communication",
                "Social interaction",
                "Decision-making",
                "Language learning",
                "Geography"
            ],
            "Github Date": "",
            "HF Date": "2022-10-14",
            "HF Downloads (September 2023)": 57,
            "HF Likes (September 2023)": 2,
            "PwC Description": "The Cloze Test by Teachers (CLOTH) benchmark is a collection of nearly 100,000 4-way multiple-choice cloze-style questions from middle- and high school-level English language exams, where the answer fills a blank in a given text. Each question is labeled with a type of deep reasoning it involves, where the four possible types are grammar, short-term reasoning, matching/paraphrasing, and long-term reasoning, i.e., reasoning over multiple sentences",
            "S2 Citation Count (September 2023)": 52,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Xie2017LargescaleCT,\n author = {Qizhe Xie and Guokun Lai and Zihang Dai and E. Hovy},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {2344-2356},\n title = {Large-scale Cloze Test Dataset Created by Teachers},\n year = {2017}\n}\n"
    },
    "tsi-dgen": {
        "Unique Dataset Identifier": "tsi-dgen",
        "Dataset Name": "dgen",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/DRSY/DGen",
        "GitHub URL": "https://github.com/DRSY/DGen",
        "Hugging Face URL": "https://huggingface.co/datasets/AndyChiang/dgen",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2004.09853",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2321,
            "Mean Inputs Length": 174.5782,
            "Mean Targets Length": 2.0095,
            "Max Inputs Length": 713,
            "Max Targets Length": 13,
            "Min Inputs Length": 62,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "sciq",
            "mcql",
            "ai2 science questions",
            "trivia websites"
        ],
        "Model Generated": [],
        "Creators": [
            "Tong University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "dgen"
        ],
        "Inferred Metadata": {
            "HF Dataset": "AndyChiang/dgen",
            "HF Config": "AndyChiang--dgen",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Cognitive processes",
                "Chemistry",
                "Psychology",
                "Ecology",
                "Neuroscience",
                "Heat transfer",
                "Anatomy"
            ],
            "Github Date": "",
            "HF Date": "2022-10-14",
            "HF Downloads (September 2023)": 49,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": ""
    },
    "tsi-oasst1_pairwise_rlhf_reward": {
        "Unique Dataset Identifier": "tsi-oasst1_pairwise_rlhf_reward",
        "Dataset Name": "oasst1_pairwise_rlhf_reward",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/tasksource/oasst1_pairwise_rlhf_reward",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/oasst1_pairwise_rlhf_reward",
        "Paper Title": "OpenAssistant Conversations -- Democratizing Large Language Model Alignment",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.07327",
        "Semantic Scholar Corpus ID": 258179434,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 17966,
            "Mean Inputs Length": 2065.5547,
            "Mean Targets Length": 2.0148,
            "Max Inputs Length": 21731,
            "Max Targets Length": 81,
            "Min Inputs Length": 86,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "oasst1_pairwise_rlhf_reward"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/oasst1_pairwise_rlhf_reward",
            "HF Config": "tasksource--oasst1_pairwise_rlhf_reward",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-14",
            "GitHub License": "",
            "Text Topics": [
                "Mathematics",
                "Language learning",
                "Python programming",
                "Travel",
                "Literature",
                "Technology",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2023-05-09",
            "HF Downloads (September 2023)": 43267,
            "HF Likes (September 2023)": 17,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 57,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Kopf2023OpenAssistantC,\n author = {Andreas Kopf and Yannic Kilcher and Dimitri von Rutte and Sotiris Anagnostidis and Zhi Rui Tam and K. Stevens and Abdullah Barhoum and Nguyen Minh Duc and Oliver Stanley and Rich'ard Nagyfi and ES Shahul and Sameer Suri and David Glushkov and Arnav Dantuluri and Andrew Maguire and Christoph Schuhmann and Huu Nguyen and A. Mattick},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {OpenAssistant Conversations - Democratizing Large Language Model Alignment},\n volume = {abs/2304.07327},\n year = {2023}\n}\n"
    },
    "tsi-i2d2": {
        "Unique Dataset Identifier": "tsi-i2d2",
        "Dataset Name": "i2d2",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/tasksource/I2D2",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/I2D2",
        "Paper Title": "I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2212.09246",
        "Semantic Scholar Corpus ID": 254854264,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 14989,
            "Mean Inputs Length": 129.3249,
            "Mean Targets Length": 5.4411,
            "Max Inputs Length": 255,
            "Max Targets Length": 6,
            "Min Inputs Length": 87,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "OpenAI GPT-2"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "AI2",
            "University of Southern California",
            "Tohoku University",
            "Northwestern University",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "I2D2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/I2D2",
            "HF Config": "tasksource--I2D2",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-12-19",
            "GitHub License": "",
            "Text Topics": [
                "Animal behavior",
                "Education",
                "Shopping",
                "Food",
                "Travel",
                "Animals",
                "Biology",
                "General knowledge",
                "Communication",
                "Furniture"
            ],
            "Github Date": "",
            "HF Date": "2023-05-12",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Bhagavatula2022I2D2IK,\n author = {Chandra Bhagavatula and Jena D. Hwang and Doug Downey and Ronan Le Bras and Ximing Lu and Keisuke Sakaguchi and Swabha Swayamdipta and Peter West and Yejin Choi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {9614-9630},\n title = {I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation},\n year = {2022}\n}\n"
    },
    "tsi-args_me": {
        "Unique Dataset Identifier": "tsi-args_me",
        "Dataset Name": "args_me",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://zenodo.org/record/4139439",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/webis/args_me",
        "Paper Title": "Data Acquisition for Argument Search: The args.me Corpus",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 202559512,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Sentiment Analysis",
            "Logical Reasoning",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 1779.4572,
            "Mean Targets Length": 4.0,
            "Max Inputs Length": 50260,
            "Max Targets Length": 4,
            "Min Inputs Length": 71,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "debatewise.org",
            "idebate.org",
            "debatepedia.org",
            "debate.org"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://zenodo.org/record/4139439"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "args_me"
        ],
        "Inferred Metadata": {
            "HF Dataset": "webis/args_me",
            "HF Config": "corpus",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-09-23",
            "GitHub License": "",
            "Text Topics": [
                "Economics",
                "Gun control",
                "Communication",
                "Philosophy",
                "Debate",
                "Religion",
                "Education",
                "Debate and argumentation",
                "Argumentation",
                "Politics"
            ],
            "Github Date": "",
            "HF Date": "2021-07-13",
            "HF Downloads (September 2023)": 101,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 70,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Ajjour2019DataAF,\n author = {Yamen Ajjour and Henning Wachsmuth and Johannes Kiesel and Martin Potthast and Matthias Hagen and Benno Stein},\n booktitle = {Deutsche Jahrestagung fr Knstliche Intelligenz},\n pages = {48-59},\n title = {Data Acquisition for Argument Search: The args.me Corpus},\n year = {2019}\n}\n"
    },
    "tsi-touche23_valueeval": {
        "Unique Dataset Identifier": "tsi-touche23_valueeval",
        "Dataset Name": "touche23_valueeval",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://webis.de/data/touche23-valueeval.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/webis/Touche23-ValueEval",
        "Paper Title": "The Touch23-ValueEval Dataset for Identifying Human Values behind Arguments",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2301.13771",
        "Semantic Scholar Corpus ID": 256416203,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Creativity",
            "Natural Language Inference",
            "Question Answering",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5393,
            "Mean Inputs Length": 246.5398,
            "Mean Targets Length": 10.1495,
            "Max Inputs Length": 921,
            "Max Targets Length": 12,
            "Min Inputs Length": 130,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "conference on the future of europe",
            "groupdiscussionideas.com",
            "nahj al-balagha",
            "zhihu",
            "nytmes"
        ],
        "Model Generated": [],
        "Creators": [
            "Bauhaus-Universitat Weimar",
            "Leibniz University Hannover",
            "Universitt Leipzig",
            "Technische Universitt Mnchen",
            "CENIA",
            "Shahid Beheshti University",
            "Sharif University of Technology",
            "UC Berkeley",
            "Heinrich Heine-Universitt Dsseldorf"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://zenodo.org/record/7879430"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "Touche23-ValueEval"
        ],
        "Inferred Metadata": {
            "HF Dataset": "webis/Touche23-ValueEval",
            "HF Config": "main",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-01-31",
            "GitHub License": "",
            "Text Topics": [
                "Health",
                "Ethics",
                "International relations",
                "Education",
                "Economic policy",
                "Environmental conservation",
                "Religion",
                "Ethics and morality",
                "Social issues",
                "Economics"
            ],
            "Github Date": "",
            "HF Date": "2023-04-17",
            "HF Downloads (September 2023)": 114,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 23,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Mirzakhmedova2023TheTD,\n author = {Nailia Mirzakhmedova and Johannes Kiesel and Milad Alshomary and Maximilian Heinrich and Nicolas Handke and Xiaoni Cai and Barriere Valentin and D. Dastgheib and Omid Ghahroodi and Mohammad Ali Sadraei and Ehsaneddin Asgari and Lea Kawaletz and Henning Wachsmuth and Benno Stein},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {The Touch23-ValueEval Dataset for Identifying Human Values behind Arguments},\n volume = {abs/2301.13771},\n year = {2023}\n}\n"
    },
    "tsi-starcon": {
        "Unique Dataset Identifier": "tsi-starcon",
        "Dataset Name": "starcon",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/dwslab/StArCon",
        "GitHub URL": "https://github.com/dwslab/StArCon",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/starcon",
        "Paper Title": "Unsupervised Stance Detection for Arguments from Consequences",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/2020.emnlp-main.4/",
        "Semantic Scholar Corpus ID": 226262286,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Sentiment Analysis",
            "Text Classification",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1276,
            "Mean Inputs Length": 147.4734,
            "Mean Targets Length": 4.0,
            "Max Inputs Length": 309,
            "Max Targets Length": 4,
            "Min Inputs Length": 103,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "debatepedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Mannheim"
        ],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://github.com/dwslab/StArCon/tree/master/data"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "starcon"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/starcon",
            "HF Config": "tasksource--starcon",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-01",
            "GitHub License": "",
            "Text Topics": [
                "Environmental sustainability",
                "Politics",
                "Religion",
                "Ethics and morality",
                "Climate change",
                "International relations",
                "Environmental impact",
                "Economics",
                "Education"
            ],
            "Github Date": "",
            "HF Date": "2023-05-14",
            "HF Downloads (September 2023)": 56,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 17,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Kobbe2020UnsupervisedSD,\n author = {J. Kobbe and Ioana Hulpus and H. Stuckenschmidt},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {50-60},\n title = {Unsupervised Stance Detection for Arguments from Consequences},\n year = {2020}\n}\n"
    },
    "tsi-banking77": {
        "Unique Dataset Identifier": "tsi-banking77",
        "Dataset Name": "banking77",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/PolyAI-LDN/task-specific-datasets",
        "GitHub URL": "https://github.com/PolyAI-LDN/task-specific-datasets",
        "Hugging Face URL": "https://huggingface.co/datasets/PolyAI/banking77",
        "Paper Title": "Efficient Intent Detection with Dual Sentence Encoders",
        "Papers with Code URL": "https://paperswithcode.com/dataset/banking77",
        "ArXiv URL": "https://arxiv.org/abs/2005.08866",
        "Semantic Scholar Corpus ID": 212645349,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10003,
            "Mean Inputs Length": 212.8163,
            "Mean Targets Length": 22.1232,
            "Max Inputs Length": 581,
            "Max Targets Length": 49,
            "Min Inputs Length": 141,
            "Min Targets Length": 10,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "customer service queries"
        ],
        "Model Generated": [],
        "Creators": [
            "PolyAI Limited"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://github.com/PolyAI-LDN/task-specific-datasets#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "banking77"
        ],
        "Inferred Metadata": {
            "HF Dataset": "PolyAI/banking77",
            "HF Config": "default",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://github.com/PolyAI-LDN/task-specific-datasets/blob/master/LICENSE",
            "PwC Date": "2020-03-10",
            "S2 Date": "2020-03-10",
            "GitHub License": "CC BY 4.0",
            "Text Topics": [
                "Customer service",
                "Banking",
                "Personal finance",
                "Financial transactions",
                "Banking and finance",
                "Currency exchange",
                "Customer support",
                "Finance",
                "Payment methods",
                "Payment processing"
            ],
            "Github Date": "",
            "HF Date": "2022-04-27",
            "HF Downloads (September 2023)": 3164,
            "HF Likes (September 2023)": 13,
            "PwC Description": "Dataset composed of online banking queries annotated with their corresponding intents.\n\nBANKING77 dataset provides a very fine-grained set of intents in a banking domain. It comprises 13,083 customer service queries labeled with 77 intents. It focuses on fine-grained single-domain intent detection.",
            "S2 Citation Count (September 2023)": 211,
            "GitHub Stars": 131,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Casanueva2020EfficientID,\n author = {I. Casanueva and Tadas Temvcinas and D. Gerz and Matthew Henderson and Ivan Vulic},\n booktitle = {NLP4CONVAI},\n journal = {ArXiv},\n title = {Efficient Intent Detection with Dual Sentence Encoders},\n volume = {abs/2003.04807},\n year = {2020}\n}\n"
    },
    "tsi-ruletaker": {
        "Unique Dataset Identifier": "tsi-ruletaker",
        "Dataset Name": "ruletaker",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/allenai/ruletaker",
        "GitHub URL": "https://github.com/allenai/ruletaker",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/ruletaker",
        "Paper Title": "Transformers as Soft Reasoners over Language",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2002.05867",
        "Semantic Scholar Corpus ID": 211126663,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 575.232,
            "Mean Targets Length": 13.0047,
            "Max Inputs Length": 1315,
            "Max Targets Length": 15,
            "Min Inputs Length": 132,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://allenai.org/data/ruletaker"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ruletaker"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/ruletaker",
            "HF Config": "tasksource--ruletaker",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-02-14",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Logic",
                "Language and communication",
                "Inference",
                "Language and semantics",
                "Linguistics",
                "Language understanding",
                "Animal behavior",
                "General knowledge",
                "Inference and reasoning",
                "Reasoning"
            ],
            "Github Date": "",
            "HF Date": "2023-05-23",
            "HF Downloads (September 2023)": 44,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 202,
            "GitHub Stars": 32,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Clark2020TransformersAS,\n author = {Peter Clark and Oyvind Tafjord and Kyle Richardson},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {3882-3890},\n title = {Transformers as Soft Reasoners over Language},\n year = {2020}\n}\n"
    },
    "tsi-lsat_qa-all": {
        "Unique Dataset Identifier": "tsi-lsat_qa-all",
        "Dataset Name": "lsat_qa-all",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/lighteval/lsat_qa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/lighteval/lsat_qa",
        "Paper Title": "From LSAT: The Progress and Challenges of Complex Reasoning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2108.00648",
        "Semantic Scholar Corpus ID": 236772032,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1630,
            "Mean Inputs Length": 876.6178,
            "Mean Targets Length": 2.3626,
            "Max Inputs Length": 1564,
            "Max Targets Length": 15,
            "Min Inputs Length": 399,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "lsac.org/lsat"
        ],
        "Model Generated": [],
        "Creators": [
            "Fudan University",
            "Shandong University",
            "Sun Yat-Sen University",
            "Sinovation Ventures",
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "lsat_qa/all"
        ],
        "Inferred Metadata": {
            "HF Dataset": "lighteval/lsat_qa",
            "HF Config": "all",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-08-02",
            "GitHub License": "",
            "Text Topics": [
                "Puzzle-solving",
                "Decision-making",
                "Math",
                "Education",
                "Daily routine",
                "Teamwork",
                "Coding",
                "Problem-solving"
            ],
            "Github Date": "",
            "HF Date": "2023-05-10",
            "HF Downloads (September 2023)": 65,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 8,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wang2021FromLT,\n author = {Siyuan Wang and Zhongkun Liu and Wanjun Zhong and Ming Zhou and Zhongyu Wei and Zhumin Chen and Nan Duan},\n booktitle = {IEEE/ACM Transactions on Audio Speech and Language Processing},\n journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},\n pages = {2201-2216},\n title = {From LSAT: The Progress and Challenges of Complex Reasoning},\n volume = {30},\n year = {2021}\n}\n"
    },
    "tsi-control_nli": {
        "Unique Dataset Identifier": "tsi-control_nli",
        "Dataset Name": "control_nli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/csitfun/ConTRoL-dataset",
        "GitHub URL": "https://github.com/csitfun/ConTRoL-dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/ConTRoL-nli",
        "Paper Title": "Natural Language Inference in Context - Investigating Contextual Reasoning over Long Texts",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2011.04864",
        "Semantic Scholar Corpus ID": 226289632,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6719,
            "Mean Inputs Length": 2882.2465,
            "Mean Targets Length": 11.1549,
            "Max Inputs Length": 9545,
            "Max Targets Length": 14,
            "Min Inputs Length": 133,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "pirt tests",
            "mcat tests",
            "ucat tests"
        ],
        "Model Generated": [],
        "Creators": [
            "Zhejiang University",
            "Fudan University",
            "Westlake University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "https://github.com/csitfun/ConTRoL-dataset#control-dataset"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "ConTRoL-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/ConTRoL-nli",
            "HF Config": "tasksource--ConTRoL-nli",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-10",
            "GitHub License": "",
            "Text Topics": [
                "Philosophy",
                "History",
                "Demographics",
                "Categorization",
                "Psychology",
                "Logic",
                "Education",
                "Economics",
                "General knowledge",
                "Geography"
            ],
            "Github Date": "",
            "HF Date": "2023-05-24",
            "HF Downloads (September 2023)": 34,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 25,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Liu2020NaturalLI,\n author = {Hanmeng Liu and Leyang Cui and Jian Liu and Yue Zhang},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {13388-13396},\n title = {Natural Language Inference in Context - Investigating Contextual Reasoning over Long Texts},\n year = {2020}\n}\n"
    },
    "tsi-tracie": {
        "Unique Dataset Identifier": "tsi-tracie",
        "Dataset Name": "tracie",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/allenai/aristo-leaderboard/tree/master/tracie/data",
        "GitHub URL": "https://github.com/allenai/aristo-leaderboard/tree/master/tracie/data",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/tracie",
        "Paper Title": "Temporal Reasoning on Implicit Events from Distant Supervision",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.12753",
        "Semantic Scholar Corpus ID": 225066771,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1174,
            "Mean Inputs Length": 391.5954,
            "Mean Targets Length": 13.0,
            "Max Inputs Length": 530,
            "Max Targets Length": 15,
            "Min Inputs Length": 251,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "University of Pennsylvania",
            "Amazon"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "tracie"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/tracie",
            "HF Config": "tasksource--tracie",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-24",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Outdoor activities",
                "Disappointment",
                "Daily routine",
                "Consumer rights",
                "Parental custody",
                "Sports",
                "Legal proceedings",
                "Decision-making"
            ],
            "Github Date": "",
            "HF Date": "2023-05-25",
            "HF Downloads (September 2023)": 31,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 46,
            "GitHub Stars": 35,
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "ROCStories dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zhou2020TemporalRO,\n author = {Ben Zhou and Kyle Richardson and Qiang Ning and Tushar Khot and Ashish Sabharwal and D. Roth},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Temporal Reasoning on Implicit Events from Distant Supervision},\n volume = {abs/2010.12753},\n year = {2020}\n}\n"
    },
    "tsi-sherliic": {
        "Unique Dataset Identifier": "tsi-sherliic",
        "Dataset Name": "sherliic",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/mnschmit/SherLIiC",
        "GitHub URL": "https://github.com/mnschmit/SherLIiC",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/sherliic",
        "Paper Title": "SherLIiC: A Typed Event-Focused Lexical Inference Benchmark for Evaluating Natural Language Inference",
        "Papers with Code URL": "https://paperswithcode.com/dataset/sherliic",
        "ArXiv URL": "https://arxiv.org/abs/1906.01393",
        "Semantic Scholar Corpus ID": 174797858,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 996,
            "Mean Inputs Length": 165.5191,
            "Mean Targets Length": 13.6707,
            "Max Inputs Length": 284,
            "Max Targets Length": 15,
            "Min Inputs Length": 121,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "freebase",
            "crowdsourced",
            "undisclosed web"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "LMU Munich"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "sherliic"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/sherliic",
            "HF Config": "tasksource--sherliic",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/4.0/",
            "PwC Date": "2019-06-04",
            "S2 Date": "2019-06-04",
            "GitHub License": "",
            "Text Topics": [
                "Competition",
                "General knowledge",
                "Geography",
                "Technology",
                "Politics",
                "Sports",
                "Current events"
            ],
            "Github Date": "",
            "HF Date": "2023-05-25",
            "HF Downloads (September 2023)": 49,
            "HF Likes (September 2023)": 0,
            "PwC Description": "SherLIiC is a testbed for lexical inference in context (LIiC), consisting of 3985 manually annotated inference rule candidates (InfCands), accompanied by (i) ~960k unlabeled InfCands, and (ii) ~190k typed textual relations between Freebase entities extracted from the large entity-linked corpus ClueWeb09. Each InfCand consists of one of these relations, expressed as a lemmatized dependency path, and two argument placeholders, each linked to one or more Freebase types.",
            "S2 Citation Count (September 2023)": 14,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "ClueWeb09"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Schmitt2019SherLIiCAT,\n author = {Martin Schmitt and Hinrich Schtze},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {902-914},\n title = {SherLIiC: A Typed Event-Focused Lexical Inference Benchmark for Evaluating Natural Language Inference},\n year = {2019}\n}\n"
    },
    "tsi-sen_making-1": {
        "Unique Dataset Identifier": "tsi-sen_making-1",
        "Dataset Name": "sen_making-1",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/wangcunxiang/Sen-Making-and-Explanation",
        "GitHub URL": "https://github.com/wangcunxiang/Sen-Making-and-Explanation",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/sen-making",
        "Paper Title": "Does it Make Sense? And Why? A Pilot Study for Sense Making and Explanation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1906.00363",
        "Semantic Scholar Corpus ID": 173990423,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1717,
            "Mean Inputs Length": 173.8288,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 275,
            "Max Targets Length": 2,
            "Min Inputs Length": 115,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "original"
        ],
        "Model Generated": [],
        "Creators": [
            "Westlake University",
            "Singapore University of Technology and Design",
            "Xidian University",
            "Zhejiang University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "sen-making/1"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/sen-making",
            "HF Config": "tasksource--sen-making",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-02",
            "GitHub License": "",
            "Text Topics": [
                "Daily routine",
                "Health",
                "Perception",
                "Nature",
                "Communication",
                "Animals",
                "Weather"
            ],
            "Github Date": "",
            "HF Date": "2023-05-25",
            "HF Downloads (September 2023)": 39,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 91,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Wang2019DoesIM,\n author = {Cunxiang Wang and Shuailong Liang and Yue Zhang and Xiaonan Li and Tian Gao},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Does it Make Sense? And Why? A Pilot Study for Sense Making and Explanation},\n volume = {abs/1906.00363},\n year = {2019}\n}\n"
    },
    "tsi-sen_making-2": {
        "Unique Dataset Identifier": "tsi-sen_making-2",
        "Dataset Name": "sen_making-2",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/wangcunxiang/Sen-Making-and-Explanation",
        "GitHub URL": "https://github.com/wangcunxiang/Sen-Making-and-Explanation",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/sen-making",
        "Paper Title": "Does it Make Sense? And Why? A Pilot Study for Sense Making and Explanation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1906.00363",
        "Semantic Scholar Corpus ID": 173990423,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1717,
            "Mean Inputs Length": 271.0775,
            "Mean Targets Length": 2.0,
            "Max Inputs Length": 439,
            "Max Targets Length": 2,
            "Min Inputs Length": 178,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "original"
        ],
        "Model Generated": [],
        "Creators": [
            "Westlake University",
            "Singapore University of Technology and Design",
            "Xidian University",
            "Zhejiang University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "sen-making/2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/sen-making",
            "HF Config": "tasksource--sen-making",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-02",
            "GitHub License": "",
            "Text Topics": [
                "Plausibility",
                "Daily routine",
                "Science",
                "Geography",
                "Logic",
                "Travel",
                "Health",
                "Sports",
                "Physics"
            ],
            "Github Date": "",
            "HF Date": "2023-05-25",
            "HF Downloads (September 2023)": 39,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 91,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Wang2019DoesIM,\n author = {Cunxiang Wang and Shuailong Liang and Yue Zhang and Xiaonan Li and Tian Gao},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Does it Make Sense? And Why? A Pilot Study for Sense Making and Explanation},\n volume = {abs/1906.00363},\n year = {2019}\n}\n"
    },
    "tsi-winowhy": {
        "Unique Dataset Identifier": "tsi-winowhy",
        "Dataset Name": "winowhy",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/HKUST-KnowComp/WinoWhy",
        "GitHub URL": "https://github.com/HKUST-KnowComp/WinoWhy",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/winowhy",
        "Paper Title": "WinoWhy: A Deep Diagnosis of Essential Commonsense Knowledge for Answering Winograd Schema Challenge",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2005.05763",
        "Semantic Scholar Corpus ID": 218595822,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Coreference Resolution",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2435,
            "Mean Inputs Length": 491.5261,
            "Mean Targets Length": 5.5556,
            "Max Inputs Length": 1052,
            "Max Targets Length": 6,
            "Min Inputs Length": 314,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "winograd schema challenge dataset",
            "conceptnet",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong University of Science and Technology"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "winowhy"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/winowhy",
            "HF Config": "tasksource--winowhy",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-12",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Communication",
                "Linguistics",
                "Inference",
                "Contextual understanding",
                "Reading comprehension",
                "Language comprehension",
                "Language and communication",
                "Interpersonal relationships",
                "Pronoun reference",
                "Communication and understanding"
            ],
            "Github Date": "",
            "HF Date": "2023-05-25",
            "HF Downloads (September 2023)": 46,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 35,
            "GitHub Stars": 16,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zhang2020WinoWhyAD,\n author = {Hongming Zhang and Xinran Zhao and Yangqiu Song},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {5736-5745},\n title = {WinoWhy: A Deep Diagnosis of Essential Commonsense Knowledge for Answering Winograd Schema Challenge},\n year = {2020}\n}\n"
    },
    "tsi-mbib_base-cognitive_bias": {
        "Unique Dataset Identifier": "tsi-mbib_base-cognitive_bias",
        "Dataset Name": "mbib_base-cognitive_bias",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Text Classification",
            "Fact Checking"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6028,
            "Mean Inputs Length": 197.8198,
            "Mean Targets Length": 17.002,
            "Max Inputs Length": 460,
            "Max Targets Length": 19,
            "Min Inputs Length": 106,
            "Min Targets Length": 15,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/cognitive-bias"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "Communication",
                "Taxation",
                "Statistics",
                "Economics",
                "Government policies",
                "Politics",
                "Cognitive biases",
                "Education",
                "Finance"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsi-mbib_base-fake_news": {
        "Unique Dataset Identifier": "tsi-mbib_base-fake_news",
        "Dataset Name": "mbib_base-fake_news",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Fact Verification",
            "Fact Checking",
            "Question Answering",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7260,
            "Mean Inputs Length": 185.3972,
            "Mean Targets Length": 12.0116,
            "Max Inputs Length": 450,
            "Max Targets Length": 14,
            "Min Inputs Length": 95,
            "Min Targets Length": 10,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/fake-news"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "Education",
                "Current events",
                "Healthcare",
                "International relations",
                "Terrorism",
                "News categorization",
                "Fact-checking"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsi-mbib_base-gender_bias": {
        "Unique Dataset Identifier": "tsi-mbib_base-gender_bias",
        "Dataset Name": "mbib_base-gender_bias",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Dialogue Generation",
            "Toxicity Detection",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 15249,
            "Mean Inputs Length": 175.1921,
            "Mean Targets Length": 13.9975,
            "Max Inputs Length": 290,
            "Max Targets Length": 16,
            "Min Inputs Length": 88,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/gender-bias"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "Stereotypes",
                "Communication",
                "Gender bias",
                "Relationships",
                "Language and communication",
                "Discrimination",
                "Gender stereotypes",
                "Social media",
                "Social issues"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsi-mbib_base-hate_speech": {
        "Unique Dataset Identifier": "tsi-mbib_base-hate_speech",
        "Dataset Name": "mbib_base-hate_speech",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Question Answering",
            "Text Classification",
            "Bias Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 364.2015,
            "Mean Targets Length": 13.9976,
            "Max Inputs Length": 1083,
            "Max Targets Length": 16,
            "Min Inputs Length": 92,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/hate-speech"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "Discrimination and prejudice",
                "Hate speech",
                "Social issues",
                "Communication",
                "Language and communication",
                "Political discourse",
                "Politics",
                "Social interactions",
                "Freedom of speech"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsi-mbib_base-linguistic_bias": {
        "Unique Dataset Identifier": "tsi-mbib_base-linguistic_bias",
        "Dataset Name": "mbib_base-linguistic_bias",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Fact Verification",
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 376.2266,
            "Mean Targets Length": 17.9904,
            "Max Inputs Length": 6640,
            "Max Targets Length": 20,
            "Min Inputs Length": 112,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/linguistic-bias"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "International relations",
                "History",
                "Linguistics",
                "Music",
                "Politics",
                "Sports",
                "Religion",
                "Geography"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsi-mbib_base-political_bias": {
        "Unique Dataset Identifier": "tsi-mbib_base-political_bias",
        "Dataset Name": "mbib_base-political_bias",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Question Answering",
            "Summarization",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 15048,
            "Mean Inputs Length": 316.4479,
            "Mean Targets Length": 17.0005,
            "Max Inputs Length": 3133,
            "Max Targets Length": 19,
            "Min Inputs Length": 94,
            "Min Targets Length": 15,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/political-bias"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "Social issues",
                "Immigration policy",
                "Politics",
                "Media bias",
                "Crime and law enforcement",
                "Current events",
                "Gun control",
                "Political bias",
                "Communication"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsi-mbib_base-racial_bias": {
        "Unique Dataset Identifier": "tsi-mbib_base-racial_bias",
        "Dataset Name": "mbib_base-racial_bias",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis",
            "Question Answering",
            "Text Classification",
            "Bias Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8319,
            "Mean Inputs Length": 184.7527,
            "Mean Targets Length": 14.0041,
            "Max Inputs Length": 287,
            "Max Targets Length": 16,
            "Min Inputs Length": 91,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/racial-bias"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "Identity",
                "Social issues",
                "Discrimination",
                "LGBTQ+ rights",
                "Stereotypes and prejudice",
                "Stereotypes",
                "Religion",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsi-mbib_base-text_level_bias": {
        "Unique Dataset Identifier": "tsi-mbib_base-text_level_bias",
        "Dataset Name": "mbib_base-text_level_bias",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "GitHub URL": "https://github.com/Media-Bias-Group/Media-Bias-Identification-Benchmark",
        "Hugging Face URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base",
        "Paper Title": "Introducing MBIB - the first Media Bias Identification Benchmark Task and Dataset Collection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.13148",
        "Semantic Scholar Corpus ID": 258331925,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "Natural Language Inference",
            "Toxicity Detection",
            "Bias Detection",
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7665,
            "Mean Inputs Length": 280.0548,
            "Mean Targets Length": 17.9987,
            "Max Inputs Length": 10580,
            "Max Targets Length": 20,
            "Min Inputs Length": 98,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Konstanz",
            "Czech Technical University",
            "University of Gttingen",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://huggingface.co/datasets/mediabiasgroup/mbib-base"
            }
        ],
        "License Notes": "Dataset and license uploded to HuggingFace by the creator organization",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "mbib-base/text-level-bias"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mediabiasgroup/mbib-base",
            "HF Config": "cognitive-bias",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-25",
            "GitHub License": "GNU General Public License v3.0",
            "Text Topics": [
                "Social media",
                "Online communities",
                "Politics",
                "Social issues",
                "Identity",
                "General knowledge",
                "Communication",
                "International relations",
                "Language and communication"
            ],
            "Github Date": "",
            "HF Date": "2023-02-06",
            "HF Downloads (September 2023)": 253,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 12,
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wessel2023IntroducingM,\n author = {M. Wessel and Tom'avs Horych and Terry Ruas and Akiko Aizawa and Bela Gipp and Timo Spinde},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection},\n year = {2023}\n}\n"
    },
    "tsi-robustlr": {
        "Unique Dataset Identifier": "tsi-robustlr",
        "Dataset Name": "robustlr",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/INK-USC/RobustLR",
        "GitHub URL": "https://github.com/huggingface/datasets/blob/main/CONTRIBUTING.md#how-to-contribute-to-the-dataset-cards",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/robustLR",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2205.12598",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2317,
            "Mean Inputs Length": 1124.0242,
            "Mean Targets Length": 10.4782,
            "Max Inputs Length": 2560,
            "Max Targets Length": 14,
            "Min Inputs Length": 154,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "robustLR"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/robustLR",
            "HF Config": "tasksource--robustLR",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Language understanding",
                "Inference",
                "Linguistics",
                "Logic and reasoning",
                "General knowledge",
                "Family relationships",
                "Reasoning",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2023-05-26",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": ""
    },
    "tsi-v1-gen_train234_test2to10": {
        "Unique Dataset Identifier": "tsi-v1-gen_train234_test2to10",
        "Dataset Name": "v1-gen_train234_test2to10",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://www.cs.mcgill.ca/~ksinha4/clutrr/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/CLUTRR/v1",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1908.06177",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12064,
            "Mean Inputs Length": 321.9226,
            "Mean Targets Length": 8.5731,
            "Max Inputs Length": 893,
            "Max Targets Length": 16,
            "Min Inputs Length": 160,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "McGill University",
            "Universite de Montreal",
            "Montreal Institute of Learning Algorithms (Mila)",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "v1/gen_train234_test2to10"
        ],
        "Inferred Metadata": {
            "HF Dataset": "CLUTRR/v1",
            "HF Config": "gen_train23_test2to10",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Childcare",
                "Family relationships",
                "Daily routine",
                "Gift-giving traditions",
                "Social interactions",
                "Parenting",
                "Gender roles",
                "Social activities",
                "Personal relationships",
                "Genealogy"
            ],
            "Github Date": "",
            "HF Date": "2022-03-09",
            "HF Downloads (September 2023)": 53,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": ""
    },
    "tsi-logical_fallacy": {
        "Unique Dataset Identifier": "tsi-logical_fallacy",
        "Dataset Name": "logical_fallacy",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/causalNLP/logical-fallacy",
        "GitHub URL": "https://github.com/causalNLP/logical-fallacy",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/logical-fallacy",
        "Paper Title": "Logical Fallacy Detection",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2202.13758",
        "Semantic Scholar Corpus ID": 247158013,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2680,
            "Mean Inputs Length": 288.1978,
            "Mean Targets Length": 16.8104,
            "Max Inputs Length": 1209,
            "Max Targets Length": 23,
            "Min Inputs Length": 144,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "quizziz",
            "study.com",
            "proprofs",
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "Max Planck Institute",
            "ETH Zrich",
            "BITS Pilani",
            "Indian Institute of Technology",
            "Saarland University",
            "University of Michigan",
            "The University of Hong Kong"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "logical-fallacy"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/logical-fallacy",
            "HF Config": "tasksource--logical-fallacy",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-02-28",
            "GitHub License": "",
            "Text Topics": [
                "Logic",
                "Philosophy",
                "Science",
                "Logical fallacies",
                "Climate change",
                "Reasoning",
                "Fallacies"
            ],
            "Github Date": "",
            "HF Date": "2023-05-28",
            "HF Downloads (September 2023)": 47,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 15,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Jin2022LogicalFD,\n author = {Zhijing Jin and Abhinav Lalwani and Tejas Vaidhya and Xiaoyu Shen and Yiwen Ding and Zhiheng Lyu and Mrinmaya Sachan and Rada Mihalcea and B. Scholkopf},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Logical Fallacy Detection},\n volume = {abs/2202.13758},\n year = {2022}\n}\n"
    },
    "tsi-parade": {
        "Unique Dataset Identifier": "tsi-parade",
        "Dataset Name": "parade",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/heyunh2015/PARADE_dataset",
        "GitHub URL": "https://github.com/heyunh2015/PARADE_dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/parade",
        "Paper Title": "PARADE: A New Dataset for Paraphrase Identification Requiring Computer Science Domain Knowledge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/parade",
        "ArXiv URL": "https://arxiv.org/abs/2010.03725",
        "Semantic Scholar Corpus ID": 222209064,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Paraphrase Detection"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7550,
            "Mean Inputs Length": 301.1713,
            "Mean Targets Length": 13.1436,
            "Max Inputs Length": 541,
            "Max Targets Length": 15,
            "Min Inputs Length": 131,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "cluscite",
            "quizzlet"
        ],
        "Model Generated": [],
        "Creators": [
            "Texas A&M University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "parade"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/parade",
            "HF Config": "tasksource--parade",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Text Topics": [
                "Database management",
                "Statistics",
                "Data management",
                "Technology",
                "Information technology",
                "Computer programming",
                "Computer science"
            ],
            "Github Date": "",
            "HF Date": "2023-05-30",
            "HF Downloads (September 2023)": 32,
            "HF Likes (September 2023)": 0,
            "PwC Description": "PARADE contains paraphrases that overlap very little at the lexical and syntactic level but are semantically equivalent based on computer science domain knowledge, as well as non-paraphrases that overlap greatly at the lexical and syntactic level but are not semantically equivalent based on this domain knowledge.",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{He2020PARADEAN,\n author = {Yun He and Zhuoer Wang and Yin Zhang and Ruihong Huang and James Caverlee},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {PARADE: A New Dataset for Paraphrase Identification Requiring Computer Science Domain Knowledge},\n volume = {abs/2010.03725},\n year = {2020}\n}\n"
    },
    "tsi-cladder": {
        "Unique Dataset Identifier": "tsi-cladder",
        "Dataset Name": "cladder",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/causalNLP/cladder",
        "GitHub URL": "https://github.com/causalNLP/cladder",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/cladder",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8976,
            "Mean Inputs Length": 335.706,
            "Mean Targets Length": 3.5006,
            "Max Inputs Length": 1238,
            "Max Targets Length": 4,
            "Min Inputs Length": 177,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "cladder"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/cladder",
            "HF Config": "tasksource--cladder",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "MIT License",
            "Text Topics": [
                "Data analysis",
                "Statistical analysis",
                "Categorization and classification",
                "Mathematics",
                "Research methodology",
                "Probability and statistics",
                "Logic and reasoning",
                "Decision-making and reasoning",
                "Logic"
            ],
            "Github Date": "",
            "HF Date": "2023-05-27",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 9,
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "tsi-subjectivity": {
        "Unique Dataset Identifier": "tsi-subjectivity",
        "Dataset Name": "subjectivity",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/tasksource/subjectivity",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/subjectivity",
        "Paper Title": "A Corpus for Sentence-level Subjectivity Detection on English News Articles",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2305.18034",
        "Semantic Scholar Corpus ID": 258960244,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Text Classification",
            "Named Entity Recognition",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 731,
            "Mean Inputs Length": 205.8947,
            "Mean Targets Length": 4.3338,
            "Max Inputs Length": 785,
            "Max Targets Length": 5,
            "Min Inputs Length": 74,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "tribunemag.co.uk",
            "spectator.co.uk",
            "shtfplan.com",
            "vdare.com",
            "theweek.com",
            "frontpagemag.com",
            "economist.com",
            "theguardian.com"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Bologna"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "subjectivity"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/subjectivity",
            "HF Config": "tasksource--subjectivity",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-05-29",
            "GitHub License": "",
            "Text Topics": [
                "Economics",
                "Politics",
                "Education",
                "Taxation",
                "Finance",
                "Government and politics",
                "Communication",
                "Grammar"
            ],
            "Github Date": "",
            "HF Date": "2023-05-30",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Antici2023ACF,\n author = {Francesco Antici and Andrea Galassi and Federico Ruggeri and Katerina Korre and Arianna Muti and Alessandra Bardi and Alice Fedotova and A. Barr'on-Cedeno},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A Corpus for Sentence-level Subjectivity Detection on English News Articles},\n volume = {abs/2305.18034},\n year = {2023}\n}\n"
    },
    "tsi-moh": {
        "Unique Dataset Identifier": "tsi-moh",
        "Dataset Name": "moh",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/tasksource/MOH",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/MOH",
        "Paper Title": "Metaphor as a Medium for Emotion: An Empirical Study",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/S16-2003/",
        "Semantic Scholar Corpus ID": 989439,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Text Classification",
            "Word Sense Disambiguation",
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1367,
            "Mean Inputs Length": 126.0651,
            "Mean Targets Length": 9.09,
            "Max Inputs Length": 184,
            "Max Targets Length": 13,
            "Min Inputs Length": 99,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wordnet"
        ],
        "Model Generated": [],
        "Creators": [
            "National Research Council Canada",
            "University of Cambridge",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "MOH"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/MOH",
            "HF Config": "tasksource--MOH",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2016-08-01",
            "GitHub License": "",
            "Text Topics": [
                "Language and communication",
                "Communication",
                "Linguistics",
                "Literary analysis",
                "Education",
                "Figurative language",
                "Literary devices",
                "Language",
                "Literal interpretation"
            ],
            "Github Date": "",
            "HF Date": "2023-05-30",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 124,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Mohammad2016MetaphorAA,\n author = {Saif M. Mohammad and Ekaterina Shutova and Peter D. Turney},\n booktitle = {International Workshop on Semantic Evaluation},\n pages = {23-33},\n title = {Metaphor as a Medium for Emotion: An Empirical Study},\n year = {2016}\n}\n"
    },
    "tsi-vuac": {
        "Unique Dataset Identifier": "tsi-vuac",
        "Dataset Name": "vuac",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/tasksource/VUAC",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/VUAC",
        "Paper Title": "A method for linguistic metaphor identification : from MIP to MIPVU",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 60025535,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Natural Language Inference",
            "Named Entity Recognition",
            "Linguistic Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 14929,
            "Mean Inputs Length": 219.0377,
            "Mean Targets Length": 9.4053,
            "Max Inputs Length": 678,
            "Max Targets Length": 13,
            "Min Inputs Length": 83,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "VUAC"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/VUAC",
            "HF Config": "tasksource--VUAC",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2010-06-23",
            "GitHub License": "",
            "Text Topics": [
                "Language and communication",
                "Figurative language",
                "Politics",
                "Conversation",
                "Decision-making",
                "Language",
                "Communication",
                "Linguistics",
                "Literary analysis",
                "Daily routine"
            ],
            "Github Date": "",
            "HF Date": "2023-05-30",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 981,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Inproceedings{Steen2010AMF,\n author = {G. Steen},\n title = {A method for linguistic metaphor identification : from MIP to MIPVU},\n year = {2010}\n}\n"
    },
    "tsi-trofi": {
        "Unique Dataset Identifier": "tsi-trofi",
        "Dataset Name": "trofi",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/tasksource/TroFi",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/TroFi",
        "Paper Title": "Active Learning for the Identification of Nonliteral Language",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/W07-0104/",
        "Semantic Scholar Corpus ID": 14685368,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Natural Language Inference",
            "Textual Entailment",
            "Summarization",
            "Question Answering",
            "Part-of-Speech Tagging",
            "Linguistic Analysis"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1772,
            "Mean Inputs Length": 238.7895,
            "Mean Targets Length": 10.6326,
            "Max Inputs Length": 524,
            "Max Targets Length": 13,
            "Min Inputs Length": 96,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wsj",
            "wayne magnuson english idioms sayings & slang",
            "george lakoffs conceptual metaphor list"
        ],
        "Model Generated": [],
        "Creators": [
            "Simon Fraser University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://www2.cs.sfu.ca/~anoop/students/jbirke/LICENSE.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "TroFi"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/TroFi",
            "HF Config": "tasksource--TroFi",
            "HF Config License": "",
            "HF Yaml License": "GNU General Public License v3.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2007-04-26",
            "GitHub License": "",
            "Text Topics": [
                "Literary analysis",
                "Politics",
                "Literary devices",
                "Economics",
                "Communication",
                "Language and communication",
                "Figurative language",
                "Travel"
            ],
            "Github Date": "",
            "HF Date": "2023-05-30",
            "HF Downloads (September 2023)": 27,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 33,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Birke2007ActiveLF,\n author = {Julia Birke and Anoop Sarkar},\n booktitle = {Proceedings of the Workshop on Computational Approaches to Figurative Language - FigLanguages '07},\n journal = {Proceedings of the Workshop on Computational Approaches to Figurative Language - FigLanguages '07},\n title = {Active Learning for the Identification of Nonliteral Language},\n year = {2007}\n}\n"
    },
    "tsi-sharc_modified-mod": {
        "Unique Dataset Identifier": "tsi-sharc_modified-mod",
        "Dataset Name": "sharc_modified-mod",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/nikhilweee/neural-conv-qa",
        "GitHub URL": "https://github.com/nikhilweee/neural-conv-qa",
        "Hugging Face URL": "https://huggingface.co/datasets/sharc_modified",
        "Paper Title": "QED: A Framework and Dataset for Explanations in Question Answering",
        "Papers with Code URL": "https://paperswithcode.com/dataset/qed",
        "ArXiv URL": "https://arxiv.org/abs/1909.03759",
        "Semantic Scholar Corpus ID": 221655495,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 21890,
            "Mean Inputs Length": 492.3905,
            "Mean Targets Length": 9.3633,
            "Max Inputs Length": 1262,
            "Max Targets Length": 21,
            "Min Inputs Length": 144,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "IBM",
            "Indian Institute of Technology (BHU)"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "sharc_modified/mod"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sharc_modified",
            "HF Config": "mod",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-09-08",
            "GitHub License": "",
            "Text Topics": [
                "Veterans affairs",
                "Personal finance",
                "Taxation",
                "Government benefits",
                "Social welfare benefits",
                "Fraud prevention",
                "Government policies",
                "Financial assistance"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1215,
            "HF Likes (September 2023)": 0,
            "PwC Description": "QED is a linguistically principled framework for explanations in question answering. Given a question and a passage, QED represents an explanation of the answer as a combination of discrete, human-interpretable steps:\nsentence selection := identification of a sentence implying an answer to the question\nreferential equality := identification of noun phrases in the question and the answer sentence that refer to the same thing\npredicate entailment := confirmation that the predicate in the sentence entails the predicate in the question once referential equalities are abstracted away.\nThe QED dataset is an expert-annotated dataset of QED explanations build upon a subset of the Google Natural Questions dataset.",
            "S2 Citation Count (September 2023)": 45,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "ShARC"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lamm2020QEDAF,\n author = {Matthew Lamm and J. Palomaki and Chris Alberti and D. Andor and Eunsol Choi and Livio Baldini Soares and Michael Collins},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {790-806},\n title = {QED: A Framework and Dataset for Explanations in Question Answering},\n volume = {9},\n year = {2020}\n}\n"
    },
    "tsi-conceptrules_v2": {
        "Unique Dataset Identifier": "tsi-conceptrules_v2",
        "Dataset Name": "conceptrules_v2",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/Strong-AI-Lab/Multi-Step-Deductive-Reasoning-Over-Natural-Language",
        "GitHub URL": "https://github.com/Strong-AI-Lab/Multi-Step-Deductive-Reasoning-Over-Natural-Language",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/conceptrules_v2",
        "Paper Title": "Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2207.14000",
        "Semantic Scholar Corpus ID": 251135345,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 540.9467,
            "Mean Targets Length": 5.4987,
            "Max Inputs Length": 995,
            "Max Targets Length": 6,
            "Min Inputs Length": 334,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "The University of Auckland"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://drive.google.com/file/d/1lOCbW8bfZxj1RIzKDxn8xKg99XyYNj7z/view?usp=sharing"
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "conceptrules_v2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/conceptrules_v2",
            "HF Config": "tasksource--conceptrules_v2",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2022-07-28",
            "GitHub License": "",
            "Text Topics": [
                "Logic and reasoning",
                "Location",
                "Geography",
                "Logic",
                "Language understanding",
                "General knowledge",
                "Location and spatial relationships",
                "Categorization",
                "Daily routine",
                "Object placement"
            ],
            "Github Date": "",
            "HF Date": "2023-05-30",
            "HF Downloads (September 2023)": 24,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 4,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Bao2022MultiStepDR,\n author = {Qiming Bao and A. Peng and Tim Hartill and N. Tan and Zhenyun Deng and M. Witbrock and Jiamou Liu},\n booktitle = {International Workshop on Neural-Symbolic Learning and Reasoning},\n journal = {ArXiv},\n title = {Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation},\n volume = {abs/2207.14000},\n year = {2022}\n}\n"
    },
    "tsi-disrpt-eng.dep.scidtb": {
        "Unique Dataset Identifier": "tsi-disrpt-eng.dep.scidtb",
        "Dataset Name": "disrpt-eng.dep.scidtb",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://huggingface.co/datasets/metaeval/disrpt",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/disrpt",
        "Paper Title": "SciDTB: Discourse Dependency TreeBank for Scientific Abstracts",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1806.03653",
        "Semantic Scholar Corpus ID": 47021747,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6059,
            "Mean Inputs Length": 229.544,
            "Mean Targets Length": 11.8254,
            "Max Inputs Length": 557,
            "Max Targets Length": 18,
            "Min Inputs Length": 125,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "aclanthology.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "disrpt/eng.dep.scidtb"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/disrpt",
            "HF Config": "eng.dep.covdtb",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-06-10",
            "GitHub License": "",
            "Text Topics": [
                "Computational linguistics",
                "Machine learning",
                "Artificial intelligence",
                "Computer science",
                "Natural language processing",
                "Language learning",
                "Information retrieval"
            ],
            "Github Date": "",
            "HF Date": "2023-04-18",
            "HF Downloads (September 2023)": 53,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 37,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Yang2018SciDTBDD,\n author = {An Yang and Sujian Li},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {444-449},\n title = {SciDTB: Discourse Dependency TreeBank for Scientific Abstracts},\n year = {2018}\n}\n"
    },
    "tsi-conll2000": {
        "Unique Dataset Identifier": "tsi-conll2000",
        "Dataset Name": "conll2000",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://www.clips.uantwerpen.be/conll2000/chunking/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/conll2000",
        "Paper Title": "Introduction to the CoNLL-2000 Shared Task Chunking",
        "Papers with Code URL": "https://paperswithcode.com/dataset/conll-2000-1",
        "ArXiv URL": "https://arxiv.org/abs/cs/0009008",
        "Semantic Scholar Corpus ID": 8940645,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Part-of-Speech Tagging",
            "Text Classification",
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8937,
            "Mean Inputs Length": 275.0309,
            "Mean Targets Length": 239.7715,
            "Max Inputs Length": 596,
            "Max Targets Length": 806,
            "Min Inputs Length": 155,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "penn treebank"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "University of Antwerp",
            "Tilburg University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "conll2000"
        ],
        "Inferred Metadata": {
            "HF Dataset": "conll2000",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2000-09-13",
            "GitHub License": "",
            "Text Topics": [
                "Economics",
                "Finance",
                "Grammar",
                "Business",
                "Stock market",
                "Travel",
                "Language and Linguistics"
            ],
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 629,
            "HF Likes (September 2023)": 2,
            "PwC Description": "CoNLL-2000 is a dataset for dividing text into syntactically related non-overlapping groups of words, so-called text chunking.",
            "S2 Citation Count (September 2023)": 918,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sang2000IntroductionTT,\n author = {E. T. K. Sang and S. Buchholz},\n booktitle = {CoNLL/LLL},\n journal = {ArXiv},\n title = {Introduction to the CoNLL-2000 Shared Task Chunking},\n volume = {cs.CL/0009008},\n year = {2000}\n}\n"
    },
    "tsi-few_nerd-supervised": {
        "Unique Dataset Identifier": "tsi-few_nerd-supervised",
        "Dataset Name": "few_nerd-supervised",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://ningding97.github.io/fewnerd/",
        "GitHub URL": "https://ningding97.github.io/fewnerd/",
        "Hugging Face URL": "https://huggingface.co/datasets/DFKI-SLT/few-nerd",
        "Paper Title": "Few-NERD: A Few-shot Named Entity Recognition Dataset",
        "Papers with Code URL": "https://paperswithcode.com/dataset/few-nerd",
        "ArXiv URL": "https://arxiv.org/abs/2105.07464",
        "Semantic Scholar Corpus ID": 234742165,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification",
            "Question Answering",
            "BioMedical Question Answering",
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 355.6794,
            "Mean Targets Length": 264.7936,
            "Max Inputs Length": 1121,
            "Max Targets Length": 2884,
            "Min Inputs Length": 221,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Tsinghua University",
            "Shenzhen International Graduate School",
            "Alibaba Group"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://ningding97.github.io/fewnerd/"
            }
        ],
        "License Notes": "Dataset is few-shot style",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "few-nerd/supervised"
        ],
        "Inferred Metadata": {
            "HF Dataset": "DFKI-SLT/few-nerd",
            "HF Config": "supervised",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "http://creativecommons.org/licenses/by-sa/4.0/",
            "PwC Date": "2021-05-16",
            "S2 Date": "2021-05-16",
            "GitHub License": "",
            "Text Topics": [
                "Music",
                "Politics",
                "History",
                "Geography",
                "Architecture",
                "Travel",
                "Transportation",
                "Art",
                "Sports"
            ],
            "Github Date": "",
            "HF Date": "2021-07-06",
            "HF Downloads (September 2023)": 1548,
            "HF Likes (September 2023)": 13,
            "PwC Description": "Few-NERD is a large-scale, fine-grained manually annotated named entity recognition dataset, which contains 8 coarse-grained types, 66 fine-grained types, 188,200 sentences, 491,711 entities, and 4,601,223 tokens. Three benchmark tasks are built, one is supervised (Few-NERD (SUP)) and the other two are few-shot (Few-NERD (INTRA) and Few-NERD (INTER)).",
            "S2 Citation Count (September 2023)": 111,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Ding2021FewNERDAF,\n author = {Ning Ding and Guangwei Xu and Yulin Chen and Xiaobin Wang and Xu Han and Pengjun Xie and Haitao Zheng and Zhiyuan Liu},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Few-NERD: A Few-shot Named Entity Recognition Dataset},\n volume = {abs/2105.07464},\n year = {2021}\n}\n"
    },
    "tsi-zero_shot_label_nli": {
        "Unique Dataset Identifier": "tsi-zero_shot_label_nli",
        "Dataset Name": "zero_shot_label_nli",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/sileod/tasksource",
        "GitHub URL": "https://github.com/sileod/tasksource",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/zero-shot-label-nli",
        "Paper Title": "tasksource: A Dataset Harmonization Framework for Streamlined NLP Multi-Task Learning and Evaluation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tasksource",
        "ArXiv URL": "https://arxiv.org/abs/2301.05948",
        "Semantic Scholar Corpus ID": 258715337,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 30000,
            "Mean Inputs Length": 534.0042,
            "Mean Targets Length": 12.5097,
            "Max Inputs Length": 206445,
            "Max Targets Length": 14,
            "Min Inputs Length": 116,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "mixed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Lille"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "zero-shot-label-nli"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/zero-shot-label-nli",
            "HF Config": "tasksource--zero-shot-label-nli",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2023-01-14",
            "S2 Date": "2023-01-14",
            "GitHub License": "Apache License 2.0",
            "Text Topics": [
                "Linguistics",
                "Social media",
                "Communication",
                "Customer service",
                "Language and communication",
                "General knowledge",
                "Technology",
                "Language understanding"
            ],
            "Github Date": "",
            "HF Date": "2023-06-02",
            "HF Downloads (September 2023)": 627,
            "HF Likes (September 2023)": 3,
            "PwC Description": "Huggingface Datasets is a great library, but it lacks standardization, and datasets require preprocessing work to be used interchangeably. tasksource automates this and facilitates reproducible multi-task learning scaling.\n\nEach dataset is standardized to either MultipleChoice, Classification, or TokenClassification dataset with identical fields. We do not support generation tasks as they are addressed by promptsource. All implemented preprocessings are in tasks.py or tasks.md. A preprocessing is a function that accepts a dataset and returns the standardized dataset. Preprocessing code is concise and human-readable.",
            "S2 Citation Count (September 2023)": 0,
            "GitHub Stars": 93,
            "GitHub Topics": [
                "benchmark",
                "bigbench",
                "crossfit",
                "curated-datasets",
                "dataset-collection",
                "discriminative",
                "extreme-mtl",
                "extreme-multi-task-learning",
                "glue",
                "huggingface",
                "instruction-tuning",
                "meta-learning",
                "multi-task-learning",
                "multi-task-learning-scaling",
                "natural-language-inference",
                "nlp",
                "preprocessings",
                "scaling",
                "sentiment-analysis",
                "text-classification"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Inproceedings{Sileo2023tasksourceAD,\n author = {Damien Sileo},\n title = {tasksource: A Dataset Harmonization Framework for Streamlined NLP Multi-Task Learning and Evaluation},\n year = {2023}\n}\n"
    },
    "tsi-com2sense": {
        "Unique Dataset Identifier": "tsi-com2sense",
        "Dataset Name": "com2sense",
        "Collection": "Tasksource Instruct",
        "Collection URL": "https://github.com/sileod/tasksource",
        "Dataset URL": "https://github.com/PlusLabNLP/Com2Sense",
        "GitHub URL": "https://github.com/PlusLabNLP/Com2Sense",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/com2sense",
        "Paper Title": "COM2SENSE: A Commonsense Reasoning Benchmark with Complementary Sentences",
        "Papers with Code URL": "https://paperswithcode.com/dataset/com2sense",
        "ArXiv URL": "https://arxiv.org/abs/2106.00969",
        "Semantic Scholar Corpus ID": 235293697,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering",
            "Text Classification",
            "Dialog Generation",
            "Natural Language Inference"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1608,
            "Mean Inputs Length": 169.4633,
            "Mean Targets Length": 5.5,
            "Max Inputs Length": 374,
            "Max Targets Length": 6,
            "Min Inputs Length": 110,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced (amt)"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Southern California",
            "Sharif University of Technology",
            "UCLA"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "Nathan",
        "Dataset Filter IDs": [
            "com2sense"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/com2sense",
            "HF Config": "tasksource--com2sense",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2021-06-02",
            "S2 Date": "2021-06-02",
            "GitHub License": "",
            "Text Topics": [
                "Problem-solving",
                "Sports",
                "Decision-making",
                "Fitness",
                "Daily routine",
                "Time management",
                "General knowledge",
                "Diet",
                "Health"
            ],
            "Github Date": "",
            "HF Date": "2023-06-02",
            "HF Downloads (September 2023)": 53,
            "HF Likes (September 2023)": 0,
            "PwC Description": "Complementary Commonsense (Com2Sense) is a dataset for benchmarking commonsense reasoning ability of NLP models. This dataset contains 4k statement true/false sentence pairs. The dataset is crowdsourced and enhanced with an adversarial model-in-the-loop setup to incentivize challenging samples. To facilitate a systematic analysis of commonsense capabilities, the dataset is designed along the dimensions of knowledge domains, reasoning scenarios and numeracy.",
            "S2 Citation Count (September 2023)": 22,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Singh2021COM2SENSEAC,\n author = {Shikhar Singh and Nuan Wen and Yu Hou and Pegah Alipoormolabashi and Te-Lin Wu and Xuezhe Ma and Nanyun Peng},\n booktitle = {Findings},\n pages = {883-898},\n title = {COM2SENSE: A Commonsense Reasoning Benchmark with Complementary Sentences},\n year = {2021}\n}\n"
    }
}