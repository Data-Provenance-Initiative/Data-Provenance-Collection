{
    "toxicchat": {
        "Unique Dataset Identifier": "toxicchat",
        "Dataset Name": "ToxicChat",
        "Collection": "ToxicChat",
        "Collection URL": "https://lmsys.org/blog/2023-10-30-toxicchat/",
        "Paper Title": "ToxicChat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-AI Conversation",
        "Dataset URL": "https://huggingface.co/datasets/lmsys/toxic-chat",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/lmsys/toxic-chat",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2310.17389",
        "Semantic Scholar Corpus ID": "264491114",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Binary Classification of Hate Speech",
            "Binary Classification of Racial Bias",
            "Offensive Language Detection",
            "Stereotype Detection",
            "Toxicity Detection"
        ],
        "Text Sources": [
            "crowdsourced",
            "human"
        ],
        "Model Generated": ["Vicuna"],
        "Format": [
            "Zero-shot"
        ],
        "Human Annotation": "Yes",
        "Derived from Datasets": ["LMSYS-Chat-1M", "ShareGPT"],
        "Creators": ["UC San Diego"],
        "Licenses": [
            {
                "License": "OpenAI",
                "License URL": ""
            },
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://huggingface.co/datasets/lmsys/toxic-chat"
            }
        ],
        "License Notes": "Partially generated with Vicuna model, which itself is trained off of ShareGPT, which contains OpenAI generated outputs.",
        "License Verified By": "Zi Lin & Shayne",
        "Dataset Filter IDs": [
            "toxicchat0124"
        ]
    }
}