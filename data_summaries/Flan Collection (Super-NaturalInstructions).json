{
    "fc-sni-abductive_nli": {
        "Unique Dataset Identifier": "fc-sni-abductive_nli",
        "Dataset Name": "abductive_nli",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://leaderboard.allenai.org/anli/submissions/about",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Narrative Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13018,
            "Mean Inputs Length": 783.4634,
            "Mean Targets Length": 44.242,
            "Max Inputs Length": 1133,
            "Max Targets Length": 169,
            "Min Inputs Length": 537,
            "Min Targets Length": 10,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task067_abductivenli_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Problem-solving",
                "Education",
                "Travel",
                "Relationships",
                "Sports",
                "Health",
                "Food",
                "Daily routine",
                "Cooking"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-ade_corpus_v2": {
        "Unique Dataset Identifier": "fc-sni-ade_corpus_v2",
        "Dataset Name": "ade_corpus_v2",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/trunghlt/AdverseDrugReaction/tree/master/ADE-Corpus-V2",
        "GitHub URL": "https://github.com/trunghlt/AdverseDrugReaction/tree/master/ADE-Corpus-V2",
        "Hugging Face URL": "https://huggingface.co/datasets/ade_corpus_v2",
        "Paper Title": "Development of a benchmark corpus to support the automatic extraction of drug-related adverse effects from medical case reports",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 19111279,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5508,
            "Mean Inputs Length": 634.8994,
            "Mean Targets Length": 11.3337,
            "Max Inputs Length": 1419,
            "Max Targets Length": 48,
            "Min Inputs Length": 389,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Bonn-Aachen International Center for Information Technology (B-IT)",
            "Merck KGaA",
            "University of Sheffield"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1447_drug_extraction_ade"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ade_corpus_v2",
            "HF Config": "Ade_corpus_v2_classification",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-10-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3586,
            "HF Likes (September 2023)": 16,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 318,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Medicine and drugs",
                "Substance abuse",
                "Medicine and pharmacology",
                "Medicine",
                "Substance abuse and addiction",
                "Medicine and healthcare",
                "Mental health and well-being",
                "Drugs and their effects on the human body",
                "Pharmacology",
                "Mental and physical health"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Gurulingappa2012DevelopmentOA,\n author = {H. Gurulingappa and A. Rajput and A. Roberts and J. Fluck and M. Hofmann-Apitius and L. Toldo},\n booktitle = {Journal of Biomedical Informatics},\n journal = {Journal of biomedical informatics},\n pages = {\n          885-92\n        },\n title = {Development of a benchmark corpus to support the automatic extraction of drug-related adverse effects from medical case reports},\n volume = {45 5},\n year = {2012}\n}\n"
    },
    "fc-sni-adversarial_qa": {
        "Unique Dataset Identifier": "fc-sni-adversarial_qa",
        "Dataset Name": "adversarial_qa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://paperswithcode.com/dataset/adversarialqa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/adversarial_qa",
        "Paper Title": "Beat the AI: Investigating Adversarial Human Annotation for Reading Comprehension",
        "Papers with Code URL": "https://paperswithcode.com/dataset/adversarialqa",
        "ArXiv URL": "https://arxiv.org/abs/2002.00293",
        "Semantic Scholar Corpus ID": 211010520,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12988,
            "Mean Inputs Length": 1560.1825,
            "Mean Targets Length": 25.0899,
            "Max Inputs Length": 5121,
            "Max Targets Length": 911,
            "Min Inputs Length": 311,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University College London"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 3.0",
                "License URL": "https://creativecommons.org/licenses/by-sa/3.0/"
            }
        ],
        "License Notes": "Approved for training/fine-tuning only",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task1295_adversarial_qa_question_answering"
        ],
        "Inferred Metadata": {
            "HF Dataset": "adversarial_qa",
            "HF Config": "adversarialQA",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/3.0/",
            "PwC Date": "2020-02-02",
            "S2 Date": "2020-02-02",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 11578,
            "HF Likes (September 2023)": 27,
            "PwC Description": "We have created three new Reading Comprehension datasets constructed using an adversarial model-in-the-loop.\n\nWe use three different models; BiDAF (Seo et al., 2016), BERTLarge (Devlin et al., 2018), and RoBERTaLarge (Liu et al., 2019) in the annotation loop and construct three datasets; D(BiDAF), D(BERT), and D(RoBERTa), each with 10,000 training examples, 1,000 validation, and 1,000 test examples.\n\nThe adversarial human annotation paradigm ensures that these datasets consist of questions that current state-of-the-art models (at least the ones used as adversaries in the annotation loop) find challenging. The three AdversarialQA round 1 datasets provide a training and evaluation resource for such methods.",
            "S2 Citation Count (September 2023)": 110,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Education",
                "Russian Revolution",
                "Biology",
                "Tsarist autocracy",
                "Politics",
                "Reading comprehension",
                "Religion",
                "International relations"
            ]
        },
        "Derived from Datasets": [
            "SQuADv1"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Bartolo2020BeatTA,\n author = {Max Bartolo and A. Roberts and Johannes Welbl and Sebastian Riedel and Pontus Stenetorp},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {662-678},\n title = {Beat the AI: Investigating Adversarial Human Annotation for Reading Comprehension},\n volume = {8},\n year = {2020}\n}\n"
    },
    "fc-sni-adverserial_qa": {
        "Unique Dataset Identifier": "fc-sni-adverserial_qa",
        "Dataset Name": "adverserial_qa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/adversarial_qa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/adversarial_qa",
        "Paper Title": "Beat the AI: Investigating Adversarial Human Annotation for Reading Comprehension",
        "Papers with Code URL": "https://paperswithcode.com/dataset/adversarialqa",
        "ArXiv URL": "https://arxiv.org/abs/2002.00293",
        "Semantic Scholar Corpus ID": 211010520,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Answerability Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5280,
            "Mean Inputs Length": 1749.2714,
            "Mean Targets Length": 5.0284,
            "Max Inputs Length": 5765,
            "Max Targets Length": 15,
            "Min Inputs Length": 423,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University College London"
        ],
        "Licenses": [
            {
                "License": "MIT License",
                "License URL": "Unspecified"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1640_aqa1.0_answerable_unanswerable_question_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "adversarial_qa",
            "HF Config": "adversarialQA",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/3.0/",
            "PwC Date": "2020-02-02",
            "S2 Date": "2020-02-02",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "We have created three new Reading Comprehension datasets constructed using an adversarial model-in-the-loop.\n\nWe use three different models; BiDAF (Seo et al., 2016), BERTLarge (Devlin et al., 2018), and RoBERTaLarge (Liu et al., 2019) in the annotation loop and construct three datasets; D(BiDAF), D(BERT), and D(RoBERTa), each with 10,000 training examples, 1,000 validation, and 1,000 test examples.\n\nThe adversarial human annotation paradigm ensures that these datasets consist of questions that current state-of-the-art models (at least the ones used as adversaries in the annotation loop) find challenging. The three AdversarialQA round 1 datasets provide a training and evaluation resource for such methods.",
            "S2 Citation Count (September 2023)": 110,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "SQuADv1"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Bartolo2020BeatTA,\n author = {Max Bartolo and A. Roberts and Johannes Welbl and Sebastian Riedel and Pontus Stenetorp},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {662-678},\n title = {Beat the AI: Investigating Adversarial Human Annotation for Reading Comprehension},\n volume = {8},\n year = {2020}\n}\n"
    },
    "fc-sni-afs": {
        "Unique Dataset Identifier": "fc-sni-afs",
        "Dataset Name": "afs",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/pdf/1709.01887.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "Measuring the Similarity of Sentential Arguments in Dialog",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1709.01887",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Matching"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3934,
            "Mean Inputs Length": 1000.4756,
            "Mean Targets Length": 10.213,
            "Max Inputs Length": 1611,
            "Max Targets Length": 21,
            "Min Inputs Length": 581,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "createdebate.com",
            "4forums.com",
            "convinceme.net"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Santa Cruz"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://nlds.soe.ucsc.edu/node/44"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task145_afs_argument_similarity_death_penalty"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Capital punishment",
                "Ethics and morality",
                "Criminal justice system",
                "Law and justice",
                "Legal system"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-ag_news": {
        "Unique Dataset Identifier": "fc-sni-ag_news",
        "Dataset Name": "ag_news",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/ag_news",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ag_news",
        "Paper Title": "Character-level Convolutional Networks for Text Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ag-news",
        "ArXiv URL": "https://arxiv.org/abs/1509.01626",
        "Semantic Scholar Corpus ID": 368182,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7913,
            "Mean Inputs Length": 1008.2893,
            "Mean Targets Length": 1.5571,
            "Max Inputs Length": 2088,
            "Max Targets Length": 11,
            "Min Inputs Length": 567,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web",
            "amazon.com",
            "yelp",
            "sogou news",
            "dbpedia",
            "yahoo! answers",
            "ag news"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1541_agnews_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ag_news",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Non Commercial",
            "PwC License URL": "http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html",
            "PwC Date": "2015-01-01",
            "S2 Date": "2015-09-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "AG News (AG’s News Corpus) is a subdataset of AG's corpus of news articles constructed by assembling titles and description fields of articles from the 4 largest classes (“World”, “Sports”, “Business”, “Sci/Tech”) of AG’s Corpus. The AG News contains 30,000 training and 1,900 test samples per class.",
            "S2 Citation Count (September 2023)": 4622,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Article analysis",
                "Content labeling",
                "Natural language processing",
                "Article categorization",
                "Text classification"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Zhang2015CharacterlevelCN,\n author = {Xiang Zhang and J. Zhao and Yann LeCun},\n booktitle = {Neural Information Processing Systems},\n pages = {649-657},\n title = {Character-level Convolutional Networks for Text Classification},\n year = {2015}\n}\n"
    },
    "fc-sni-ai2_arithmetic_questions": {
        "Unique Dataset Identifier": "fc-sni-ai2_arithmetic_questions",
        "Dataset Name": "ai2_arithmetic_questions",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.org/data/arithmetic-questions",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 4894130,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 734,
            "Mean Inputs Length": 626.9183,
            "Mean Targets Length": 4.485,
            "Max Inputs Length": 1007,
            "Max Targets Length": 15,
            "Min Inputs Length": 345,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/Q15-1042.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task745_ai2_arithmetic_questions_arithmetic"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-12-18",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 178,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Math",
                "Decimal places",
                "Decimal numbers",
                "Education",
                "Shopping",
                "Mathematics",
                "Arithmetic",
                "Decimal computation",
                "Problem-solving"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Koncel-Kedziorski2015ParsingAW,\n author = {Rik Koncel-Kedziorski and Hannaneh Hajishirzi and Ashish Sabharwal and Oren Etzioni and S. Ang},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {585-597},\n title = {Parsing Algebraic Word Problems into Equations},\n volume = {3},\n year = {2015}\n}\n"
    },
    "fc-sni-air_dialogue": {
        "Unique Dataset Identifier": "fc-sni-air_dialogue",
        "Dataset Name": "air_dialogue",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/google/airdialogue",
        "GitHub URL": "https://github.com/google/airdialogue",
        "Hugging Face URL": "https://huggingface.co/datasets/air_dialogue",
        "Paper Title": "AirDialogue: An Environment for Goal-Oriented Dialogue Research",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/D18-1419/",
        "Semantic Scholar Corpus ID": 53080145,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Intent Identification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5169,
            "Mean Inputs Length": 1675.4864,
            "Mean Targets Length": 9.4914,
            "Max Inputs Length": 3915,
            "Max Targets Length": 24,
            "Min Inputs Length": 764,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Google",
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/D18-1419.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task573_air_dialogue_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "air_dialogue",
            "HF Config": "air_dialogue_data",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "CC BY-NC 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1076,
            "HF Likes (September 2023)": 6,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 48,
            "GitHub Stars": 40,
            "GitHub Topics": [],
            "Text Topics": [
                "Reservation management",
                "Reservation",
                "Customer service",
                "Reservation process",
                "Flight booking",
                "Travel",
                "Flight cancellation",
                "Booking",
                "Communication",
                "Flight reservations"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Wei2018AirDialogueAE,\n author = {Wei Wei and Quoc V. Le and Andrew M. Dai and Jia Li},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {3844-3854},\n title = {AirDialogue: An Environment for Goal-Oriented Dialogue Research},\n year = {2018}\n}\n"
    },
    "fc-sni-ajgt_twitter_ar": {
        "Unique Dataset Identifier": "fc-sni-ajgt_twitter_ar",
        "Dataset Name": "ajgt_twitter_ar",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/ajgt_twitter_ar",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ajgt_twitter_ar",
        "Paper Title": "Arabic Tweets Sentimental Analysis Using Machine Learning",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 37492873,
        "Languages": [
            "Arabic",
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3564,
            "Mean Inputs Length": 494.158,
            "Mean Targets Length": 8.6027,
            "Max Inputs Length": 1378,
            "Max Targets Length": 18,
            "Min Inputs Length": 313,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Abu Dhabi University",
            "The British University in Dubai"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1414_ajgt_twitter_ar_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2017-06-27",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 664,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 89,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Natural language processing",
                "Social media analysis",
                "Arabic language",
                "Arabic language processing",
                "Sentiment analysis"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Alomari2017ArabicTS,\n author = {K. Alomari and H. M. Elsherif and K. Shaalan},\n booktitle = {International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems},\n pages = {602-610},\n title = {Arabic Tweets Sentimental Analysis Using Machine Learning},\n year = {2017}\n}\n"
    },
    "fc-sni-allegro_reviews": {
        "Unique Dataset Identifier": "fc-sni-allegro_reviews",
        "Dataset Name": "allegro_reviews",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/allegro_reviews",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/allegro_reviews",
        "Paper Title": "KLEJ: Comprehensive Benchmark for Polish Language Understanding",
        "Papers with Code URL": "https://paperswithcode.com/dataset/allegro-reviews",
        "ArXiv URL": "https://arxiv.org/abs/2005.00630",
        "Semantic Scholar Corpus ID": 218487823,
        "Languages": [
            "Polish",
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3051,
            "Mean Inputs Length": 1330.7352,
            "Mean Targets Length": 8.2455,
            "Max Inputs Length": 6586,
            "Max Targets Length": 18,
            "Min Inputs Length": 316,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "allegro.pl"
        ],
        "Model Generated": [],
        "Creators": [
            "ML Research at Allegro",
            "AGH University of Science and Technology"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task634_allegro_reviews_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "allegro_reviews",
            "HF Config": "default",
            "HF Config License": "CC BY-SA 4.0",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 687,
            "HF Likes (September 2023)": 0,
            "PwC Description": "A comprehensive multi-task benchmark for the Polish language understanding, accompanied by an online leaderboard. It consists of a diverse set of tasks, adopted from existing datasets for named entity recognition, question-answering, textual entailment, and others.",
            "S2 Citation Count (September 2023)": 51,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Sentiment analysis",
                "Natural language processing",
                "Product reviews"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Rybak2020KLEJCB,\n author = {Piotr Rybak and Robert Mroczkowski and Janusz Tracz and Ireneusz Gawlik},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {KLEJ: Comprehensive Benchmark for Polish Language Understanding},\n volume = {abs/2005.00630},\n year = {2020}\n}\n"
    },
    "fc-sni-allocine": {
        "Unique Dataset Identifier": "fc-sni-allocine",
        "Dataset Name": "allocine",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/allocine",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/allocine",
        "Paper Title": "",
        "Papers with Code URL": "https://paperswithcode.com/dataset/allocine",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "French",
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4073,
            "Mean Inputs Length": 1655.3307,
            "Mean Targets Length": 1.5397,
            "Max Inputs Length": 5488,
            "Max Targets Length": 11,
            "Min Inputs Length": 174,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "allocine.fr"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1591_allocine_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "allocine",
            "HF Config": "allocine",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1062,
            "HF Likes (September 2023)": 6,
            "PwC Description": "A new dataset for sentiment analysis, scraped from Allociné.fr user reviews. It contains 100k positive and 100k negative reviews divided into 3 balanced splits: train (160k reviews), val (20k) and test (20k).",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "French language analysis",
                "Movie reviews",
                "Movie review",
                "Film analysis",
                "Language processing",
                "Sentiment analysis",
                "Film critique"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-amazon_and_yelp_summarization_dataset": {
        "Unique Dataset Identifier": "fc-sni-amazon_and_yelp_summarization_dataset",
        "Dataset Name": "amazon_and_yelp_summarization_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/abrazinskas/FewSum",
        "GitHub URL": "https://github.com/abrazinskas/FewSum",
        "Hugging Face URL": "",
        "Paper Title": "Few-Shot Learning for Opinion Summarization",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2004.14884",
        "Semantic Scholar Corpus ID": 222225253,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Summarization"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 319,
            "Mean Inputs Length": 4836.9028,
            "Mean Targets Length": 292.5705,
            "Max Inputs Length": 8316,
            "Max Targets Length": 502,
            "Min Inputs Length": 2450,
            "Min Targets Length": 155,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "amazon.com",
            "yelp"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Edinburgh",
            "University of Amsterdam"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/2004.14884.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task672_amazon_and_yelp_summarization_dataset_summarization"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-30",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 47,
            "GitHub Stars": 35,
            "GitHub Topics": [
                "deep-learning",
                "machine-learning",
                "natural-language-processing",
                "opinion-summarization",
                "summarization"
            ],
            "Text Topics": [
                "Food and dining experiences",
                "Product reviews",
                "Pricing and value for money",
                "Food and dining experience",
                "Customer service and staff",
                "Food and dining",
                "Restaurant recommendations",
                "Customer service",
                "Restaurant reviews"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Bravzinskas2020FewShotLF,\n author = {Arthur Bravzinskas and Mirella Lapata and Ivan Titov},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {4119-4135},\n title = {Few-Shot Learning for Opinion Summarization},\n year = {2020}\n}\n"
    },
    "fc-sni-amazon_fine_food_reviews": {
        "Unique Dataset Identifier": "fc-sni-amazon_fine_food_reviews",
        "Dataset Name": "amazon_fine_food_reviews",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://metatext.io/datasets/amazon-fine-food-reviews",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/kfuangsung/AmazonFineFoodReviews",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13015,
            "Mean Inputs Length": 976.2261,
            "Mean Targets Length": 8.5897,
            "Max Inputs Length": 10184,
            "Max Targets Length": 18,
            "Min Inputs Length": 227,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "amazon.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "http://i.stanford.edu/~julian/pdfs/www13.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task586_amazonfood_polarity_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "kfuangsung/AmazonFineFoodReviews",
            "HF Config": "kfuangsung--AmazonFineFoodReviews",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-08-04",
            "HF Downloads (September 2023)": 25,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Natural language processing",
                "Pet care",
                "Sentiment analysis",
                "Customer reviews",
                "Food and beverages",
                "Food quality",
                "Customer satisfaction"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-amazon_polarity": {
        "Unique Dataset Identifier": "fc-sni-amazon_polarity",
        "Dataset Name": "amazon_polarity",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/amazon_polarity",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/amazon_polarity",
        "Paper Title": "Character-level Convolutional Networks for Text Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/yahoo-answers",
        "ArXiv URL": "https://arxiv.org/abs/1509.01626",
        "Semantic Scholar Corpus ID": 368182,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13014,
            "Mean Inputs Length": 827.6641,
            "Mean Targets Length": 8.5993,
            "Max Inputs Length": 2868,
            "Max Targets Length": 18,
            "Min Inputs Length": 182,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web",
            "amazon.com",
            "yelp",
            "sogou news",
            "dbpedia",
            "yahoo! answers",
            "ag news"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/1509.01626.pdf"
            }
        ],
        "License Notes": "Competitor dataset",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task493_review_polarity_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "amazon_polarity",
            "HF Config": "amazon_polarity",
            "HF Config License": "Apache License 2.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2015-09-04",
            "S2 Date": "2015-09-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "The Yahoo! Answers topic classification dataset is constructed using 10 largest main categories. Each class contains 140,000 training samples and 6,000 testing samples. Therefore, the total number of training samples is 1,400,000 and testing samples 60,000 in this dataset. From all the answers and other meta-information, we only used the best answer content and the main category information.",
            "S2 Citation Count (September 2023)": 4622,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Book reviews",
                "E-commerce",
                "Music",
                "Review classification",
                "Natural language processing",
                "Customer reviews",
                "Customer satisfaction",
                "Sentiment analysis",
                "Literature",
                "Product reviews"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Zhang2015CharacterlevelCN,\n author = {Xiang Zhang and J. Zhao and Yann LeCun},\n booktitle = {Neural Information Processing Systems},\n pages = {649-657},\n title = {Character-level Convolutional Networks for Text Classification},\n year = {2015}\n}\n"
    },
    "fc-sni-amazon_us_reviews": {
        "Unique Dataset Identifier": "fc-sni-amazon_us_reviews",
        "Dataset Name": "amazon_us_reviews",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/amazon_us_reviews",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/amazon_us_reviews",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Title Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12362,
            "Mean Inputs Length": 825.258,
            "Mean Targets Length": 25.2022,
            "Max Inputs Length": 28001,
            "Max Targets Length": 858,
            "Min Inputs Length": 113,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "amazon.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://s3.amazonaws.com/amazon-reviews-pds/license.txt"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1342_amazon_us_reviews_title"
        ],
        "Inferred Metadata": {
            "HF Dataset": "amazon_us_reviews",
            "HF Config": "Wireless_v1_00",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 133188,
            "HF Likes (September 2023)": 45,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Customer reviews",
                "Technology",
                "Product quality",
                "E-commerce",
                "Online shopping",
                "Customer satisfaction",
                "Product review",
                "E-commerce and online shopping",
                "Consumer electronics"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-ambigqa": {
        "Unique Dataset Identifier": "fc-sni-ambigqa",
        "Dataset Name": "ambigqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://nlp.cs.washington.edu/ambigqa/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ambig_qa",
        "Paper Title": "AMBIGQA: Answering Ambiguous Open-domain Questions",
        "Papers with Code URL": "https://paperswithcode.com/dataset/natural-questions",
        "ArXiv URL": "https://arxiv.org/abs/2004.10645",
        "Semantic Scholar Corpus ID": 216056269,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10509,
            "Mean Inputs Length": 461.669,
            "Mean Targets Length": 18.2936,
            "Max Inputs Length": 743,
            "Max Targets Length": 334,
            "Min Inputs Length": 319,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "Facebook AI Research",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/2004.10645.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task669_ambigqa_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ambig_qa",
            "HF Config": "full",
            "HF Config License": "CC BY-SA 3.0",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/3.0/",
            "PwC Date": "2019-01-01",
            "S2 Date": "2020-04-22",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1399,
            "HF Likes (September 2023)": 2,
            "PwC Description": "The Natural Questions corpus is a question answering dataset containing 307,373 training examples, 7,830 development examples, and 7,842 test examples. Each example is comprised of a google.com query and a corresponding Wikipedia page. Each Wikipedia page has a passage (or long answer) annotated on the page that answers the question and one or more short spans from the annotated passage containing the actual answer. The long and the short answer annotations can however be empty. If they are both empty, then there is no answer on the page at all. If the long answer annotation is non-empty, but the short answer annotation is empty, then the annotated passage answers the question but no explicit short answer could be found. Finally 1% of the documents have a passage annotated with a short answer that is “yes” or “no”, instead of a list of short spans.",
            "S2 Citation Count (September 2023)": 137,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Question answering",
                "Open-domain question answering",
                "General knowledge",
                "Sports",
                "Music",
                "Geography",
                "Trivia",
                "Dates",
                "History",
                "Entertainment"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Min2020AmbigQAAA,\n author = {Sewon Min and Julian Michael and Hannaneh Hajishirzi and Luke Zettlemoyer},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {5783-5797},\n title = {AmbigQA: Answering Ambiguous Open-domain Questions},\n year = {2020}\n}\n"
    },
    "fc-sni-ancora_ca_ner": {
        "Unique Dataset Identifier": "fc-sni-ancora_ca_ner",
        "Dataset Name": "ancora_ca_ner",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/bsc/ancora-ca-ner",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/bsc/ancora-ca-ner",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "Catalan",
            "English"
        ],
        "Task Categories": [
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 298,
            "Mean Inputs Length": 1671.9396,
            "Mean Targets Length": 363.5336,
            "Max Inputs Length": 3530,
            "Max Targets Length": 1443,
            "Min Inputs Length": 999,
            "Min Targets Length": 66,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://zenodo.org/record/4761746"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task960_ancora-ca-ner_named_entity_recognition"
        ],
        "Inferred Metadata": {
            "HF Dataset": "BSC-LT/ancora-ca-ner",
            "HF Config": "AncoraCaNer",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-anem": {
        "Unique Dataset Identifier": "fc-sni-anem",
        "Dataset Name": "anem",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/juand-r/entity-recognition-datasets/tree/master/data/AnEM",
        "GitHub URL": "https://github.com/juand-r/entity-recognition-datasets/tree/master/data/AnEM",
        "Hugging Face URL": "https://huggingface.co/datasets/bigbio/an_em",
        "Paper Title": "Open-domain Anatomical Entity Mention Detection ",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 13066880,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 276,
            "Mean Inputs Length": 658.2971,
            "Mean Targets Length": 6.337,
            "Max Inputs Length": 1390,
            "Max Targets Length": 19,
            "Min Inputs Length": 341,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "University of Manchester",
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 3.0",
                "License URL": "https://github.com/juand-r/entity-recognition-datasets/blob/master/data/AnEM/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1485_organ_extraction_anem_dataset"
        ],
        "Inferred Metadata": {
            "HF Dataset": "bigbio/an_em",
            "HF Config": "an_em_source",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-07-12",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2022-11-13",
            "HF Downloads (September 2023)": 74,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 62,
            "GitHub Stars": 1369,
            "GitHub Topics": [
                "annotations",
                "corpora",
                "datasets",
                "entity-extraction",
                "entity-recognition",
                "named-entity-recognition",
                "natural-language-processing",
                "ner",
                "nlp",
                "nlp-resources"
            ],
            "Text Topics": [
                "Medical Science",
                "Human body",
                "Biology",
                "Anatomy and Physiology"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Inproceedings{Ohta2012OpendomainAE,\n author = {Tomoko Ohta and Sampo Pyysalo and Junichi Tsujii and S. Ananiadou},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {27-36},\n title = {Open-domain Anatomical Entity Mention Detection},\n year = {2012}\n}\n"
    },
    "fc-sni-anli": {
        "Unique Dataset Identifier": "fc-sni-anli",
        "Dataset Name": "anli",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/facebookresearch/anli",
        "GitHub URL": "https://github.com/facebookresearch/anli",
        "Hugging Face URL": "https://huggingface.co/datasets/anli",
        "Paper Title": "Adversarial NLI: A New Benchmark for Natural Language Understanding",
        "Papers with Code URL": "https://paperswithcode.com/dataset/anli",
        "ArXiv URL": "https://arxiv.org/abs/1910.14599",
        "Semantic Scholar Corpus ID": 207756753,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1982,
            "Mean Inputs Length": 1125.166,
            "Mean Targets Length": 10.5474,
            "Max Inputs Length": 1977,
            "Max Targets Length": 23,
            "Min Inputs Length": 595,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "commoncrawl.org",
            "wikihow.com",
            "crowdsourced",
            "project gutenberg"
        ],
        "Model Generated": [],
        "Creators": [
            "UNC Chapel Hill",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://arxiv.org/pdf/1910.14599.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1385_anli_r1_entailment"
        ],
        "Inferred Metadata": {
            "HF Dataset": "anli",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "CC BY-NC 4.0",
            "PwC License Name": "CC BY-NC 4.0",
            "PwC License URL": "https://github.com/facebookresearch/anli/blob/master/LICENSE",
            "PwC Date": "2019-01-01",
            "S2 Date": "2019-10-31",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 18254,
            "HF Likes (September 2023)": 24,
            "PwC Description": "The Adversarial Natural Language Inference (ANLI, Nie et al.) is a new large-scale NLI benchmark dataset, collected via an iterative, adversarial human-and-model-in-the-loop procedure. Particular, the data is selected to be difficult to the state-of-the-art models, including BERT and RoBERTa.",
            "S2 Citation Count (September 2023)": 601,
            "GitHub Stars": 364,
            "GitHub Topics": [],
            "Text Topics": [
                "Language understanding",
                "Philosophy",
                "Reasoning",
                "Logic",
                "Critical thinking",
                "Natural language processing",
                "Science",
                "Education"
            ]
        },
        "Derived from Datasets": [
            "StoryCloze",
            "The Children’s Book Test dataset",
            "RTE5",
            "Manually Annotated Sub-Corpus (MASC) of the Open American National Corpus"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Nie2019AdversarialNA,\n author = {Yixin Nie and Adina Williams and Emily Dinan and Mohit Bansal and J. Weston and Douwe Kiela},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Adversarial NLI: A New Benchmark for Natural Language Understanding},\n volume = {abs/1910.14599},\n year = {2019}\n}\n"
    },
    "fc-sni-app_reviews": {
        "Unique Dataset Identifier": "fc-sni-app_reviews",
        "Dataset Name": "app_reviews",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/app_reviews",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/app_reviews",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 593,
            "Mean Inputs Length": 412.9696,
            "Mean Targets Length": 8.5295,
            "Max Inputs Length": 1086,
            "Max Targets Length": 18,
            "Min Inputs Length": 125,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "google play store"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/sealuzh/user_quality/blob/master/csv_files/versions.csv"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task761_app_review_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "app_reviews",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5175,
            "HF Likes (September 2023)": 11,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Mobile applications",
                "App review",
                "User experience and interface design",
                "App functionality",
                "Technology",
                "Bluetooth connectivity and notification settings",
                "User experience"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-aqua": {
        "Unique Dataset Identifier": "fc-sni-aqua",
        "Dataset Name": "aqua",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/deepmind/AQuA",
        "GitHub URL": "https://github.com/deepmind/AQuA",
        "Hugging Face URL": "https://huggingface.co/datasets/aqua_rat",
        "Paper Title": "Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems",
        "Papers with Code URL": "https://paperswithcode.com/dataset/aqua-rat",
        "ArXiv URL": "https://arxiv.org/abs/1705.04146",
        "Semantic Scholar Corpus ID": 12777818,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12987,
            "Mean Inputs Length": 878.9369,
            "Mean Targets Length": 8.5616,
            "Max Inputs Length": 1963,
            "Max Targets Length": 18,
            "Min Inputs Length": 432,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "gmat",
            "gre exams"
        ],
        "Model Generated": [],
        "Creators": [
            "DeepMind",
            "University of Oxford"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/deepmind/AQuA/blob/master/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task750_aqua_multiple_choice_answering"
        ],
        "Inferred Metadata": {
            "HF Dataset": "aqua_rat",
            "HF Config": "raw",
            "HF Config License": "Apache License 2.0",
            "HF Yaml License": "",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "https://www.apache.org/licenses/LICENSE-2.0",
            "PwC Date": "",
            "S2 Date": "2017-05-11",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2740,
            "HF Likes (September 2023)": 4,
            "PwC Description": "Algebra Question Answering with Rationales (AQUA-RAT) is a dataset that contains algebraic word problems with rationales. The dataset consists of about 100,000 algebraic word problems with natural language rationales. Each problem is a json object consisting of four parts:\n* question - A natural language definition of the problem to solve\n* options - 5 possible options (A, B, C, D and E), among which one is correct\n* rationale - A natural language description of the solution to the problem\n* correct - The correct option",
            "S2 Citation Count (September 2023)": 271,
            "GitHub Stars": 248,
            "GitHub Topics": [],
            "Text Topics": [
                "Problem-solving",
                "Mathematics",
                "Critical thinking",
                "Education",
                "Math"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Ling2017ProgramIB,\n author = {Wang Ling and Dani Yogatama and Chris Dyer and Phil Blunsom},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {158-167},\n title = {Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems},\n year = {2017}\n}\n"
    },
    "fc-sni-aquamuse": {
        "Unique Dataset Identifier": "fc-sni-aquamuse",
        "Dataset Name": "aquamuse",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/aquamuse",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/aquamuse",
        "Paper Title": "AQUAMUSE: Automatically Generating Datasets for Query-Based Multi-Document Summarization",
        "Papers with Code URL": "https://paperswithcode.com/dataset/aquamuse",
        "ArXiv URL": "https://arxiv.org/abs/2010.12694",
        "Semantic Scholar Corpus ID": 225067629,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1959,
            "Mean Inputs Length": 1239.4038,
            "Mean Targets Length": 49.0368,
            "Max Inputs Length": 3376,
            "Max Targets Length": 100,
            "Min Inputs Length": 265,
            "Min Targets Length": 29,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "commoncrawl.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/2010.12694.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task519_aquamuse_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-23",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 336,
            "HF Likes (September 2023)": 6,
            "PwC Description": "5,519 query-based summaries, each associated with an average of 6 input documents selected from an index of 355M documents from Common Crawl.",
            "S2 Citation Count (September 2023)": 27,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Geography",
                "Sports",
                "General knowledge",
                "Literature",
                "Education",
                "Technology",
                "Instagram"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Kulkarni2020AQuaMuSeAG,\n author = {Sayali Kulkarni and Sheide Chammas and Wan Zhu and Fei Sha and Eugene Ie},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {AQuaMuSe: Automatically Generating Datasets for Query-Based Multi-Document Summarization},\n volume = {abs/2010.12694},\n year = {2020}\n}\n"
    },
    "fc-sni-arc": {
        "Unique Dataset Identifier": "fc-sni-arc",
        "Dataset Name": "arc",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.org/data/arc",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ai2_arc",
        "Paper Title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/arc",
        "ArXiv URL": "https://arxiv.org/abs/1803.05457",
        "Semantic Scholar Corpus ID": 3922816,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10394,
            "Mean Inputs Length": 800.5315,
            "Mean Targets Length": 1.5744,
            "Max Inputs Length": 2078,
            "Max Targets Length": 11,
            "Min Inputs Length": 418,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "web exams",
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://allenai.org/data/arc"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task228_arc_answer_generation_easy"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ai2_arc",
            "HF Config": "ARC-Challenge",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://allenai.org/data/arc",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-03-14",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 171230,
            "HF Likes (September 2023)": 21,
            "PwC Description": "The AI2’s Reasoning Challenge (ARC) dataset is a multiple-choice question-answering dataset, containing questions from science exams from grade 3 to grade 9. The dataset is split in two partitions: Easy and Challenge, where the latter partition contains the more difficult questions that require reasoning. Most of the questions have 4 answer choices, with <1% of all the questions having either 3 or 5 answer choices. ARC includes a supporting KB of 14.3M unstructured text passages.",
            "S2 Citation Count (September 2023)": 458,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Science",
                "Reasoning",
                "General knowledge",
                "Knowledge",
                "Trivia"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Clark2018ThinkYH,\n author = {Peter Clark and Isaac Cowhey and Oren Etzioni and Tushar Khot and Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge},\n volume = {abs/1803.05457},\n year = {2018}\n}\n"
    },
    "fc-sni-argkp": {
        "Unique Dataset Identifier": "fc-sni-argkp",
        "Dataset Name": "argkp",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/IBM/KPA_2021_shared_task",
        "GitHub URL": "https://github.com/IBM/KPA_2021_shared_task",
        "Hugging Face URL": "",
        "Paper Title": "Quantitative Argument Summarization and Beyond: Cross-Domain Key Point Analysis ",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2005.01619",
        "Semantic Scholar Corpus ID": 222290752,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Matching"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12936,
            "Mean Inputs Length": 729.5161,
            "Mean Targets Length": 5.1189,
            "Max Inputs Length": 1374,
            "Max Targets Length": 15,
            "Min Inputs Length": 368,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "IBM"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 3.0",
                "License URL": "https://research.ibm.com/haifa/dept/vst/debating_data.shtml"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1285_kpa_keypoint_matching"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-11",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 25,
            "GitHub Stars": 25,
            "GitHub Topics": [],
            "Text Topics": [
                "Politics",
                "Ethics",
                "Critical thinking",
                "Ethics and morality",
                "Debate",
                "Social issues",
                "Medical ethics",
                "Government"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Bar-Haim2020QuantitativeAS,\n author = {Roy Bar-Haim and Yoav Kantor and Lilach Eden and Roni Friedman and Dan Lahav and N. Slonim},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {39-49},\n title = {Quantitative Argument Summarization and beyond: Cross-Domain Key Point Analysis},\n year = {2020}\n}\n"
    },
    "fc-sni-asian_language_treebank": {
        "Unique Dataset Identifier": "fc-sni-asian_language_treebank",
        "Dataset Name": "asian_language_treebank",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www2.nict.go.jp/astrec-att/member/mutiyama/ALT/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 45848332,
        "Languages": [
            "Indonesian",
            "Japanese",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12927,
            "Mean Inputs Length": 497.9297,
            "Mean Targets Length": 152.3672,
            "Max Inputs Length": 1281,
            "Max Targets Length": 617,
            "Min Inputs Length": 200,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "National Institute of Information and Communication Technology",
            "Yangon University of Computer Studies",
            "Badan Pengkajian dan Penerapan Teknologi",
            "Singapore Institute for Infocomm Research",
            "Vietnam Institute of Information Technology"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://www2.nict.go.jp/astrec-att/member/mutiyama/ALT/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1115_alt_ja_id_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2016-10-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 64,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Translation",
                "Politics",
                "Geography",
                "Natural disasters",
                "Sports",
                "Language learning",
                "Cultural exchange"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Conference{Riza2016IntroductionOT,\n author = {Hammam Riza and Michael Purwoadi and Gunarso and Teduh Uliniansyah and Aw Ai Ti and Sharifah Mahani Aljunied and Luong Chi Mai and V. Thang and N. Thai and Vichet Chea and Rapid Sun and Sethserey Sam and Sopheap Seng and K. Soe and K. Nwet and M. Utiyama and Chenchen Ding},\n booktitle = {Oriental COCOSDA International Conference on Speech Database and Assessments},\n journal = {2016 Conference of The Oriental Chapter of International Committee for Coordination and Standardization of Speech Databases and Assessment Techniques (O-COCOSDA)},\n pages = {1-6},\n title = {Introduction of the Asian Language Treebank},\n year = {2016}\n}\n"
    },
    "fc-sni-asset": {
        "Unique Dataset Identifier": "fc-sni-asset",
        "Dataset Name": "asset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/facebookresearch/asset",
        "GitHub URL": "https://github.com/facebookresearch/asset",
        "Hugging Face URL": "https://huggingface.co/datasets/asset",
        "Paper Title": "ASSET: A Dataset for Tuning and Evaluation of Sentence Simplification Models with Multiple Rewriting Transformations",
        "Papers with Code URL": "https://paperswithcode.com/dataset/asset",
        "ArXiv URL": "https://arxiv.org/abs/2005.00481",
        "Semantic Scholar Corpus ID": 218470237,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Simplification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3952,
            "Mean Inputs Length": 844.3998,
            "Mean Targets Length": 99.5552,
            "Max Inputs Length": 1534,
            "Max Targets Length": 324,
            "Min Inputs Length": 507,
            "Min Targets Length": 21,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Sheffield",
            "Inria",
            "Facebook AI Research",
            "Imperial College London"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/asset/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task111_asset_sentence_simplification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "asset",
            "HF Config": "simplification",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-05-01",
            "S2 Date": "2020-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "ASSET is a new dataset for assessing sentence simplification in English. ASSET is a crowdsourced multi-reference corpus where each simplification was produced by executing several rewriting transformations.",
            "S2 Citation Count (September 2023)": 85,
            "GitHub Stars": 52,
            "GitHub Topics": [],
            "Text Topics": [
                "Simplification",
                "History",
                "Sports",
                "Geography",
                "Language proficiency",
                "Paraphrasing",
                "Music",
                "Translation",
                "Cultural understanding",
                "Language learning"
            ]
        },
        "Derived from Datasets": [
            "TurkCorpus"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Alva-Manchego2020ASSETAD,\n author = {Fernando Alva-Manchego and Louis Martin and Antoine Bordes and Carolina Scarton and Benoît Sagot and Lucia Specia},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {4668-4679},\n title = {ASSET: A Dataset for Tuning and Evaluation of Sentence Simplification Models with Multiple Rewriting Transformations},\n year = {2020}\n}\n"
    },
    "fc-sni-atomic": {
        "Unique Dataset Identifier": "fc-sni-atomic",
        "Dataset Name": "atomic",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.org/data/atomic-2020",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/atomic",
        "Paper Title": "COMET-ATOMIC 2020: On Symbolic and Neural Commonsense Knowledge Graphs ",
        "Papers with Code URL": "https://paperswithcode.com/dataset/atomic",
        "ArXiv URL": "https://arxiv.org/abs/2010.05953",
        "Semantic Scholar Corpus ID": 222310337,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Commonsense Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12985,
            "Mean Inputs Length": 888.4595,
            "Mean Targets Length": 3.1004,
            "Max Inputs Length": 1123,
            "Max Targets Length": 13,
            "Min Inputs Length": 746,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "conceptnet"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "Paul G. Allen School of Computer Science & Engineering",
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://allenai.org/data/atomic-2020"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1196_atomic_classification_oeffect"
        ],
        "Inferred Metadata": {
            "HF Dataset": "atomic",
            "HF Config": "atomic",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-12",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 588,
            "HF Likes (September 2023)": 5,
            "PwC Description": "ATOMIC is an atlas of everyday commonsense reasoning, organized through 877k textual descriptions of inferential knowledge. Compared to existing resources that center around taxonomic knowledge, ATOMIC focuses on inferential knowledge organized as typed if-then relations with variables (e.g., \"if X pays Y a compliment, then Y will likely return the compliment\").",
            "S2 Citation Count (September 2023)": 232,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Social interactions",
                "Language understanding",
                "Personal relationships",
                "Social relationships and interactions",
                "Natural language processing",
                "Dialogue systems",
                "Personal identity and self-expression",
                "Language and communication",
                "Social interactions and relationships",
                "Event planning"
            ]
        },
        "Derived from Datasets": [
            "Atomic (Sap et al 2019)"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Hwang2020COMETATOMIC2O,\n author = {Jena D. Hwang and Chandra Bhagavatula and Ronan Le Bras and Jeff Da and Keisuke Sakaguchi and Antoine Bosselut and Yejin Choi},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {6384-6392},\n title = {COMET-ATOMIC 2020: On Symbolic and Neural Commonsense Knowledge Graphs},\n year = {2020}\n}\n"
    },
    "fc-sni-babi": {
        "Unique Dataset Identifier": "fc-sni-babi",
        "Dataset Name": "babi",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://research.fb.com/downloads/babi/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1502.05698",
        "Semantic Scholar Corpus ID": 3178759,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1986,
            "Mean Inputs Length": 658.4129,
            "Mean Targets Length": 14.8701,
            "Max Inputs Length": 1311,
            "Max Targets Length": 26,
            "Min Inputs Length": 327,
            "Min Targets Length": 14,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "huggingface.co/datasets/facebook/babi_qa"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task082_babi_t1_single_supporting_fact_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2015-02-19",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1028,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Trivia",
                "Information retrieval",
                "Geography",
                "Language understanding",
                "Travel",
                "General knowledge",
                "Identity"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weston2015TowardsAQ,\n author = {J. Weston and Antoine Bordes and S. Chopra and Tomas Mikolov},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Artificial Intelligence},\n title = {Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n year = {2015}\n}\n"
    },
    "fc-sni-bard": {
        "Unique Dataset Identifier": "fc-sni-bard",
        "Dataset Name": "bard",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/NancyFulda/BYU-Analogical-Reasoning-Dataset",
        "GitHub URL": "https://github.com/NancyFulda/BYU-Analogical-Reasoning-Dataset",
        "Hugging Face URL": "",
        "Paper Title": "Harvesting Common-sense Navigational Knowledge for Robotics from Uncurated Text Corpora",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 29505106,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Word Analogy"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 404,
            "Mean Inputs Length": 479.3094,
            "Mean Targets Length": 5.7129,
            "Max Inputs Length": 673,
            "Max Targets Length": 16,
            "Min Inputs Length": 370,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/NancyFulda/BYU-Analogical-Reasoning-Dataset/blob/master/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1152_bard_analogical_reasoning_causation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2017-10-18",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 16,
            "GitHub Stars": 2,
            "GitHub Topics": [
                "ai",
                "common-sense",
                "commonsense-reasoning",
                "knowledgebase",
                "machine-learning",
                "natural-language-processing",
                "robotics",
                "word-embedding",
                "word-embeddings"
            ],
            "Text Topics": [
                "Accountability",
                "Logic",
                "Decision-making",
                "Analogical reasoning",
                "Consequences of actions",
                "Education",
                "Analogies",
                "Consequences",
                "Critical thinking",
                "Cause and effect"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Fulda2017HarvestingCN,\n author = {Nancy Fulda and Nathan Tibbetts and Zachary Brown and D. Wingate},\n booktitle = {Conference on Robot Learning},\n pages = {525-534},\n title = {Harvesting Common-sense Navigational Knowledge for Robotics from Uncurated Text Corpora},\n year = {2017}\n}\n"
    },
    "fc-sni-bc2gm_corpus": {
        "Unique Dataset Identifier": "fc-sni-bc2gm_corpus",
        "Dataset Name": "bc2gm_corpus",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://metatext.io/datasets/biocreative-ii-gene-mention-recognition-(bc2gm)",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/bc2gm_corpus",
        "Paper Title": "Overview of BioCreative II gene mention recognition",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 215780186,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2132,
            "Mean Inputs Length": 564.8879,
            "Mean Targets Length": 13.6266,
            "Max Inputs Length": 1292,
            "Max Targets Length": 38,
            "Min Inputs Length": 207,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://link.springer.com/content/pdf/10.1186/gb-2008-9-s2-s2.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1481_gene_extraction_bc2gm_dataset"
        ],
        "Inferred Metadata": {
            "HF Dataset": "bc2gm_corpus",
            "HF Config": "bc2gm_corpus",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2008-09-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 404,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Medical research",
                "Neuroscience",
                "Genetics",
                "Protein structure and function",
                "Biotechnology",
                "Pharmacology",
                "Biochemistry"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Smith2008OverviewOB,\n author = {Larry L. Smith and L. Tanabe and Rie Ando and Cheng-Ju Kuo and I. Chung and Chun-Nan Hsu and Yu-Shi Lin and Roman Klinger and C. Friedrich and Kuzman Ganchev and Manabu Torii and Hongfang Liu and B. Haddow and C. Struble and R. Povinelli and Andreas Vlachos and W. Baumgartner and L. Hunter and Bob Carpenter and Richard Tzong-Han Tsai and Hong-Jie Dai and Feng Liu and Yifei Chen and Chengjie Sun and S. Katrenko and P. Adriaans and C. Blaschke and Rafael Torres and M. Neves and Preslav Nakov and A. Divoli and M. Maña-López and J. Mata and W. Wilbur},\n booktitle = {Genome Biology},\n journal = {Genome Biology},\n pages = {S2 - S2},\n title = {Overview of BioCreative II gene mention recognition},\n volume = {9},\n year = {2008}\n}\n"
    },
    "fc-sni-bengali_hate_speech_dataset": {
        "Unique Dataset Identifier": "fc-sni-bengali_hate_speech_dataset",
        "Dataset Name": "bengali_hate_speech_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/rezacsedu/Bengali-Hate-Speech-Dataset",
        "GitHub URL": "https://github.com/rezacsedu/Bengali-Hate-Speech-Dataset",
        "Hugging Face URL": "",
        "Paper Title": "Classification Benchmarks for Under-resourced Bengali Language based on Multichannel Convolutional-LSTM Network",
        "Papers with Code URL": "https://paperswithcode.com/dataset/bengali-hate-speech",
        "ArXiv URL": "https://arxiv.org/abs/2004.07807",
        "Semantic Scholar Corpus ID": 215786049,
        "Languages": [
            "Bengali",
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11346,
            "Mean Inputs Length": 566.2279,
            "Mean Targets Length": 11.0551,
            "Max Inputs Length": 1322,
            "Max Targets Length": 22,
            "Min Inputs Length": 346,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "daily prothom alo",
            "daily jugontor",
            "daily nayadiganta",
            "anandabazar patrika",
            "dainik jugasankha",
            "bbc",
            "deutsche welle",
            "ntv",
            "etv bangla",
            "zee news",
            "books",
            "blogs",
            "sports portal",
            "twitter",
            "facebook",
            "linkedin"
        ],
        "Model Generated": [],
        "Creators": [
            "RWTH Aachen University",
            "National University of Ireland Galway",
            "Vrije Universiteit Amsterdam"
        ],
        "Licenses": [
            {
                "License": "Academic Research Purposes Only",
                "License URL": "https://github.com/rezacsedu/Bengali-Hate-Speech-Dataset/tree/main#data-availability"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1490_bengali_personal_hate_speech_binary_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-11",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "Introduces three datasets of expressing hate, commonly used topics, and opinions for hate speech detection, document classification, and sentiment analysis, respectively.",
            "S2 Citation Count (September 2023)": 34,
            "GitHub Stars": 15,
            "GitHub Topics": [
                "bengali",
                "bengali-nlp",
                "hate-speech-detection",
                "machine-learning",
                "nlp",
                "word-embeddings"
            ],
            "Text Topics": [
                "Online harassment",
                "Discrimination and prejudice",
                "Hate speech classification",
                "Social media moderation",
                "Language processing",
                "Discrimination and protected characteristics",
                "Natural language processing",
                "Hate speech detection"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Karim2020ClassificationBF,\n author = {Md. Rezaul Karim and Bharathi Raja Chakravarthi and Mihael Arcan and John P. McCrae and Michael Cochez},\n booktitle = {International Conference on Data Science and Advanced Analytics},\n journal = {2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA)},\n pages = {390-399},\n title = {Classification Benchmarks for Under-resourced Bengali Language based on Multichannel Convolutional-LSTM Network},\n year = {2020}\n}\n"
    },
    "fc-sni-bengali_restaurant_reviews": {
        "Unique Dataset Identifier": "fc-sni-bengali_restaurant_reviews",
        "Dataset Name": "bengali_restaurant_reviews",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/eftekhar-hossain/Bengali-Restaurant-Reviews",
        "GitHub URL": "https://github.com/eftekhar-hossain/Bengali-Restaurant-Reviews",
        "Hugging Face URL": "",
        "Paper Title": "Sentiment Analysis of Bengali Texts on Online Restaurant Reviews Using Multinomial Naïve Bayes",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 209458562,
        "Languages": [
            "Bengali",
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2820,
            "Mean Inputs Length": 488.3599,
            "Mean Targets Length": 8.6039,
            "Max Inputs Length": 1955,
            "Max Targets Length": 18,
            "Min Inputs Length": 184,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Chittagong University of Engineering and Technology"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://ieeexplore.ieee.org/abstract/document/8934655"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1496_bengali_reviews_sentiment_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-05-01",
            "GitHub License": "GNU General Public License v3.0",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 37,
            "GitHub Stars": 8,
            "GitHub Topics": [
                "bengali-language-processing",
                "dataset",
                "flask",
                "heroku",
                "machine-learning",
                "restaurant-reviews",
                "sentiment-analysis"
            ],
            "Text Topics": [
                "Natural Language Processing",
                "Sentiment analysis",
                "Bengali Language",
                "Restaurant reviews",
                "Natural language processing",
                "Sentiment Analysis",
                "Bengali cuisine",
                "Bengali language analysis",
                "Bengali language"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Conference{Sharif2019SentimentAO,\n author = {Omar Sharif and M. M. Hoque and E. Hossain},\n booktitle = {2019 1st International Conference on Advances in Science, Engineering and Robotics Technology (ICASERT)},\n journal = {2019 1st International Conference on Advances in Science, Engineering and Robotics Technology (ICASERT)},\n pages = {1-6},\n title = {Sentiment Analysis of Bengali Texts on Online Restaurant Reviews Using Multinomial Naïve Bayes},\n year = {2019}\n}\n"
    },
    "fc-sni-bianet": {
        "Unique Dataset Identifier": "fc-sni-bianet",
        "Dataset Name": "bianet",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/bianet",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/bianet",
        "Paper Title": "Bianet: A Parallel News Corpus in Turkish, Kurdish and English",
        "Papers with Code URL": "https://paperswithcode.com/dataset/bianet",
        "ArXiv URL": "https://arxiv.org/abs/1805.05095",
        "Semantic Scholar Corpus ID": 44143716,
        "Languages": [
            "Kurdish",
            "English"
        ],
        "Task Categories": [
            "Text Matching"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 384,
            "Mean Inputs Length": 895.9297,
            "Mean Targets Length": 3.0911,
            "Max Inputs Length": 1996,
            "Max Targets Length": 13,
            "Min Inputs Length": 349,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "Universit`a degli Studi di Trento"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://d-ataman.github.io/bianet/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task910_bianet_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "bianet",
            "HF Config": "en_to_ku",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-05-14",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 974,
            "HF Likes (September 2023)": 0,
            "PwC Description": "Bianet is a parallel news corpus in Turkish, Kurdish and English\nIt contains 3,214 Turkish articles with their sentence-aligned Kurdish or English translations from the Bianet online newspaper.",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language learning",
                "Cross-cultural communication",
                "Language",
                "Translation"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Ataman2018BianetAP,\n author = {Duygu Ataman},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Bianet: A Parallel News Corpus in Turkish, Kurdish and English},\n volume = {abs/1805.05095},\n year = {2018}\n}\n"
    },
    "fc-sni-billsum": {
        "Unique Dataset Identifier": "fc-sni-billsum",
        "Dataset Name": "billsum",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/billsum",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/billsum",
        "Paper Title": "BillSum: A Corpus for Automatic Summarization of US Legislation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/billsum",
        "ArXiv URL": "https://arxiv.org/abs/1910.00523",
        "Semantic Scholar Corpus ID": 203610181,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Summarization"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8446,
            "Mean Inputs Length": 17643.3274,
            "Mean Targets Length": 1181.483,
            "Max Inputs Length": 60124,
            "Max Targets Length": 4995,
            "Min Inputs Length": 5138,
            "Min Targets Length": 65,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "us congressional bills",
            "california state bills"
        ],
        "Model Generated": [],
        "Creators": [
            "FiscalNote Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/1910.00523"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1658_billsum_summarization"
        ],
        "Inferred Metadata": {
            "HF Dataset": "billsum",
            "HF Config": "default",
            "HF Config License": "CC0 1.0",
            "HF Yaml License": "CC0 1.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2019-10-01",
            "S2 Date": "2019-10-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 6198,
            "HF Likes (September 2023)": 20,
            "PwC Description": "BillSum is the first dataset for summarization of US Congressional and California state bills.\n\nThe BillSum dataset consists of three parts: US training bills, US test bills and California test bills. The US bills were collected from the Govinfo service provided by the United States Government Publishing Office (GPO). The corpus consists of bills from the 103rd-115th (1993-2018) sessions of Congress. The data was split into 18,949 train bills and 3,269 test bills. For California, bills from the 2015-2016 session were scraped directly from the legislature’s website; the summaries were written by their Legislative Counsel.\n\nThe BillSum corpus focuses on mid-length legislation from 5,000 to 20,000 character in length. The authors chose to measure the text length in characters, instead of words or sentences, because the texts have complex structure that makes it difficult to consistently measure words. The range was chosen because on one side, short bills introduce minor changes and do not require summaries. While the CRS produces summaries for them, they often contain most of the text of the bill. On the\nother side, very long legislation is often composed of several large sections.",
            "S2 Citation Count (September 2023)": 84,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Government",
                "Legislation",
                "Taxation",
                "Legislation and policy",
                "Government policy",
                "Legal liability",
                "Government policies",
                "Legal procedures",
                "Nonprofit organizations",
                "Education policy"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Kornilova2019BillSumAC,\n author = {Anastassia Kornilova and Vladimir Eidelman},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {BillSum: A Corpus for Automatic Summarization of US Legislation},\n volume = {abs/1910.00523},\n year = {2019}\n}\n"
    },
    "fc-sni-biocreative_v": {
        "Unique Dataset Identifier": "fc-sni-biocreative_v",
        "Dataset Name": "biocreative_v",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://biocreative.bioinformatics.udel.edu/tasks/biocreative-v/track-3-cdr/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 151,
            "Mean Inputs Length": 747.9007,
            "Mean Targets Length": 13.5033,
            "Max Inputs Length": 1205,
            "Max Targets Length": 29,
            "Min Inputs Length": 485,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://biocreative.bioinformatics.udel.edu/tasks/biocreative-v/track-3-cdr/"
            },
            {
                "License": "Request Form",
                "License URL": "https://biocreative.bioinformatics.udel.edu/tasks/biocreative-v/track-3-cdr/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1449_disease_entity_extraction_bc5cdr_dataset"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Mental health",
                "Diseases and disorders",
                "Disease",
                "Diseases",
                "Disorders",
                "Neurology",
                "Medicine"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-bless": {
        "Unique Dataset Identifier": "fc-sni-bless",
        "Dataset Name": "bless",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://aclanthology.org/W11-2501/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "How we BLESSed distributional semantic evaluation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/W11-2501/",
        "Semantic Scholar Corpus ID": 13364281,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Word Relation Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4717,
            "Mean Inputs Length": 1087.5622,
            "Mean Targets Length": 5.5828,
            "Max Inputs Length": 1286,
            "Max Targets Length": 16,
            "Min Inputs Length": 970,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conceptnet",
            "ukwac"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Trento",
            "University of Pisa"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1418_bless_semantic_relation_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2011-07-31",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 303,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Cognitive Science and Conceptual Mapping",
                "Word relations",
                "Semantics",
                "Word relationships",
                "Language and Linguistics",
                "Semantics and Word Relations",
                "Language and semantics"
            ]
        },
        "Derived from Datasets": [
            "McRae Norms collection"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Baroni2011HowWB,\n author = {Marco Baroni and Alessandro Lenci},\n booktitle = {GEometrical Models of Natural Language Semantics},\n pages = {1-10},\n title = {How we BLESSed distributional semantic evaluation},\n year = {2011}\n}\n"
    },
    "fc-sni-blimp": {
        "Unique Dataset Identifier": "fc-sni-blimp",
        "Dataset Name": "blimp",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/blimp",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/blimp",
        "Paper Title": "BLiMP: A Benchmark of Linguistic Minimal Pairs for English",
        "Papers with Code URL": "https://paperswithcode.com/dataset/blimp",
        "ArXiv URL": "https://arxiv.org/abs/1912.00582",
        "Semantic Scholar Corpus ID": 208527435,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Linguistic Probing"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1984,
            "Mean Inputs Length": 613.3972,
            "Mean Targets Length": 4.1406,
            "Max Inputs Length": 763,
            "Max Targets Length": 14,
            "Min Inputs Length": 494,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "New York University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/1912.00582.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1559_blimp_binary_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "blimp",
            "HF Config": "adjunct_island",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2019-12-02",
            "S2 Date": "2019-12-02",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 61319,
            "HF Likes (September 2023)": 30,
            "PwC Description": "BLiMP is a challenge set for evaluating what language models (LMs) know about major grammatical phenomena in English. BLiMP consists of 67 sub-datasets, each containing 1000 minimal pairs isolating specific contrasts in syntax, morphology, or semantics. The data is automatically generated according to expert-crafted grammars. Aggregate human agreement with the labels is 96.4%.",
            "S2 Citation Count (September 2023)": 231,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language learning",
                "Language analysis",
                "Grammar",
                "Sentence structure",
                "Language understanding",
                "Sentence classification",
                "Language proficiency",
                "Linguistics"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Warstadt2019BLiMPTB,\n author = {Alex Warstadt and Alicia Parrish and Haokun Liu and Anhad Mohananey and Wei Peng and Sheng-Fu Wang and Samuel R. Bowman},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {377-392},\n title = {BLiMP: The Benchmark of Linguistic Minimal Pairs for English},\n volume = {8},\n year = {2019}\n}\n"
    },
    "fc-sni-boolq": {
        "Unique Dataset Identifier": "fc-sni-boolq",
        "Dataset Name": "boolq",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/google-research-datasets/boolean-questions",
        "GitHub URL": "https://github.com/google-research-datasets/boolean-questions",
        "Hugging Face URL": "https://huggingface.co/datasets/boolq",
        "Paper Title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions",
        "Papers with Code URL": "https://paperswithcode.com/dataset/boolq",
        "ArXiv URL": "https://arxiv.org/abs/1905.10044",
        "Semantic Scholar Corpus ID": 165163607,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3855,
            "Mean Inputs Length": 1548.9424,
            "Mean Targets Length": 44.1808,
            "Max Inputs Length": 5382,
            "Max Targets Length": 108,
            "Min Inputs Length": 268,
            "Min Targets Length": 26,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "google search"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 3.0",
                "License URL": "https://github.com/google-research-datasets/boolean-questions#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1660_super_glue_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "boolq",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/3.0/",
            "PwC Date": "2019-01-01",
            "S2 Date": "2019-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 11858,
            "HF Likes (September 2023)": 22,
            "PwC Description": "BoolQ is a question answering dataset for yes/no questions containing 15942 examples. These questions are naturally occurring – they are generated in unprompted and unconstrained settings.\nEach example is a triplet of (question, passage, answer), with the title of the page as optional additional context.\n\nQuestions are gathered from anonymized, aggregated queries to the Google search engine. Queries that are likely to be yes/no questions are heuristically identified and questions are only kept if a Wikipedia page is returned as one of the first five results, in which case the question and Wikipedia page are given to a human annotator for further processing. Annotators label question/article pairs in a three-step process. First, they decide if the question is good, meaning it is comprehensible, unambiguous, and requesting factual information. This judgment is made before the annotator sees the Wikipedia page. Next, for good questions, annotators find a passage within the document that contains enough information to answer the question. Annotators can mark questions as “not answerable” if the Wikipedia article does not contain the requested information. Finally, annotators mark whether the question’s answer is “yes” or “no”. Only questions that were marked as having a yes/no answer are used, and each question is paired with the selected passage instead of the entire document.",
            "S2 Citation Count (September 2023)": 457,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Local government",
                "Real estate",
                "General knowledge",
                "Travel",
                "Taxation",
                "Biology",
                "Sports",
                "Information retrieval"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Clark2019BoolQET,\n author = {Christopher Clark and Kenton Lee and Ming-Wei Chang and T. Kwiatkowski and Michael Collins and Kristina Toutanova},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},\n volume = {abs/1905.10044},\n year = {2019}\n}\n"
    },
    "fc-sni-break": {
        "Unique Dataset Identifier": "fc-sni-break",
        "Dataset Name": "break",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.github.io/Break/",
        "GitHub URL": "https://allenai.github.io/Break/",
        "Hugging Face URL": "https://huggingface.co/datasets/break_data",
        "Paper Title": "Break It Down: A Question Understanding Benchmark",
        "Papers with Code URL": "https://paperswithcode.com/dataset/break",
        "ArXiv URL": "https://arxiv.org/abs/2001.11770v1",
        "Semantic Scholar Corpus ID": 211003735,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Decomposition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13078,
            "Mean Inputs Length": 2755.2677,
            "Mean Targets Length": 137.047,
            "Max Inputs Length": 3713,
            "Max Targets Length": 632,
            "Min Inputs Length": 2433,
            "Min Targets Length": 23,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Tel Aviv University",
            "Bar-Ilan University",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/2001.11770v1"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task176_break_decompose_questions"
        ],
        "Inferred Metadata": {
            "HF Dataset": "break_data",
            "HF Config": "QDMR-high-level",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2020-01-31",
            "S2 Date": "2020-01-31",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1730,
            "HF Likes (September 2023)": 0,
            "PwC Description": "Break is a question understanding dataset, aimed at training models to reason over complex questions. It features 83,978 natural language questions, annotated with a new meaning representation, Question Decomposition Meaning Representation (QDMR). Each example has the natural question along with its QDMR representation. Break contains human composed questions, sampled from 10 leading question-answering benchmarks over text, images and databases. This dataset was created by a team of NLP researchers at Tel Aviv University and Allen Institute for AI.",
            "S2 Citation Count (September 2023)": 134,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Mathematics",
                "Question decomposition",
                "Sports",
                "Task decomposition",
                "Data analysis",
                "Logic",
                "Information retrieval"
            ]
        },
        "Derived from Datasets": [
            "Academic",
            "ATIS",
            "GeoQuery",
            "Spider",
            "CLEVR",
            "NLVR2",
            "ComQA",
            "CWQ",
            "DROP",
            "HotPotQA-Hard"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Wolfson2020BreakID,\n author = {Tomer Wolfson and Mor Geva and Ankit Gupta and Matt Gardner and Yoav Goldberg and Daniel Deutch and Jonathan Berant},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {183-198},\n title = {Break It Down: A Question Understanding Benchmark},\n volume = {8},\n year = {2020}\n}\n"
    },
    "fc-sni-broad_twitter_corpus": {
        "Unique Dataset Identifier": "fc-sni-broad_twitter_corpus",
        "Dataset Name": "broad_twitter_corpus",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/juand-r/entity-recognition-datasets/tree/master/data/BTC",
        "GitHub URL": "https://github.com/juand-r/entity-recognition-datasets/tree/master/data/BTC",
        "Hugging Face URL": "https://huggingface.co/datasets/strombergnlp/broad_twitter_corpus",
        "Paper Title": "Broad Twitter Corpus: A Diverse Named Entity Recognition Resource",
        "Papers with Code URL": "https://paperswithcode.com/dataset/broad-twitter-corpus",
        "ArXiv URL": "https://aclanthology.org/C16-1111/",
        "Semantic Scholar Corpus ID": 16633800,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 327,
            "Mean Inputs Length": 466.8654,
            "Mean Targets Length": 14.2355,
            "Max Inputs Length": 722,
            "Max Targets Length": 34,
            "Min Inputs Length": 237,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Sheffield"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://github.com/juand-r/entity-recognition-datasets/blob/master/data/BTC/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1452_location_entity_extraction_btc_corpus"
        ],
        "Inferred Metadata": {
            "HF Dataset": "strombergnlp/broad_twitter_corpus",
            "HF Config": "broad-twitter-corpus",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "",
            "PwC Date": "2016-12-01",
            "S2 Date": "2016-12-01",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2022-04-28",
            "HF Downloads (September 2023)": 141,
            "HF Likes (September 2023)": 2,
            "PwC Description": "This paper introduces the Broad Twitter Corpus (BTC), which is not only significantly bigger, but sampled across different regions, temporal periods, and types of Twitter users. The gold-standard named entity annotations are made by a combination of NLP experts and crowd workers, which enables us to harness crowd recall while maintaining high quality. We also measure the entity drift observed in our dataset (i.e. how entity representation varies over time), and compare to newswire.",
            "S2 Citation Count (September 2023)": 87,
            "GitHub Stars": 1369,
            "GitHub Topics": [
                "annotations",
                "corpora",
                "datasets",
                "entity-extraction",
                "entity-recognition",
                "named-entity-recognition",
                "natural-language-processing",
                "ner",
                "nlp",
                "nlp-resources"
            ],
            "Text Topics": [
                "General knowledge",
                "Social media",
                "Travel",
                "Current events",
                "Location identification",
                "Politics",
                "Geography",
                "Language learning"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Derczynski2016BroadTC,\n author = {Leon Derczynski and Kalina Bontcheva and Ian Roberts},\n booktitle = {International Conference on Computational Linguistics},\n pages = {1169-1179},\n title = {Broad Twitter Corpus: A Diverse Named Entity Recognition Resource},\n year = {2016}\n}\n"
    },
    "fc-sni-brown_corpus": {
        "Unique Dataset Identifier": "fc-sni-brown_corpus",
        "Dataset Name": "brown_corpus",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "http://korpus.uib.no/icame/brown/bcm.html",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "A Visuospatial Dataset for Naturalistic Verb Learning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/new-brown-corpus",
        "ArXiv URL": "https://arxiv.org/abs/2010.15225",
        "Semantic Scholar Corpus ID": 225103287,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Part-of-Speech Tagging"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13080,
            "Mean Inputs Length": 2430.795,
            "Mean Targets Length": 3.5538,
            "Max Inputs Length": 3720,
            "Max Targets Length": 14,
            "Min Inputs Length": 2077,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "virtual reality collection",
            "human"
        ],
        "Model Generated": [],
        "Creators": [
            "Brown University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "http://korpus.uib.no/icame/brown/bcm.html#bc7"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1168_brown_coarse_pos_tagging"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-28",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "A new dataset for training and evaluating grounded language models.",
            "S2 Citation Count (September 2023)": 6,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Part-of-speech tagging",
                "Parts-of-speech tagging",
                "Language processing",
                "Natural language processing",
                "Natural Language Processing",
                "Linguistics",
                "Language learning"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Ebert2020AVD,\n author = {Dylan Ebert and Ellie Pavlick},\n booktitle = {STARSEM},\n pages = {143-153},\n title = {A Visuospatial Dataset for Naturalistic Verb Learning},\n year = {2020}\n}\n"
    },
    "fc-sni-cad": {
        "Unique Dataset Identifier": "fc-sni-cad",
        "Dataset Name": "cad",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/dongpng/cad_naacl2021",
        "GitHub URL": "https://github.com/dongpng/cad_naacl2021",
        "Hugging Face URL": "",
        "Paper Title": "Introducing CAD: the Contextual Abuse Dataset",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/2021.naacl-main.182/",
        "Semantic Scholar Corpus ID": 235097313,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8102,
            "Mean Inputs Length": 1672.5917,
            "Mean Targets Length": 2.8203,
            "Max Inputs Length": 11750,
            "Max Targets Length": 13,
            "Min Inputs Length": 1306,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "Alan Turing Institute",
            "Utrecht University",
            "University of Oxford",
            "University of Liverpool",
            "George Washington University"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://zenodo.org/record/4881008"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task108_contextualabusedetection_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-06-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 48,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Online abuse",
                "Abusive content detection",
                "Text analysis",
                "Content moderation",
                "Identity-based discrimination",
                "Language processing",
                "Abusive language",
                "Natural language processing"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Vidgen2021IntroducingCT,\n author = {Bertie Vidgen and Dong Nguyen and H. Margetts and Patrícia G. C. Rossini and Rebekah Tromble},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {2289-2303},\n title = {Introducing CAD: the Contextual Abuse Dataset},\n year = {2021}\n}\n"
    },
    "fc-sni-cail2018": {
        "Unique Dataset Identifier": "fc-sni-cail2018",
        "Dataset Name": "cail2018",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/cail2018",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/cail2018",
        "Paper Title": "CAIL2018: A Large-Scale Legal Dataset for Judgment Prediction",
        "Papers with Code URL": "https://paperswithcode.com/dataset/chinese-ai-and-law-cail-2018",
        "ArXiv URL": "https://arxiv.org/abs/1807.02478",
        "Semantic Scholar Corpus ID": 49652844,
        "Languages": [
            "Chinese",
            "English"
        ],
        "Task Categories": [
            "Information Extraction"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1982,
            "Mean Inputs Length": 1006.6731,
            "Mean Targets Length": 3.1715,
            "Max Inputs Length": 13930,
            "Max Targets Length": 13,
            "Min Inputs Length": 185,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wenshu.court.gov.cn"
        ],
        "Model Generated": [],
        "Creators": [
            "Tsinghua University",
            "Peking University",
            "Chinese Academy of Sciences",
            "China Justice Big Data Institute",
            "Supreme People’s Court"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/thunlp/CAIL"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1666_cail2018_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "cail2018",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-07-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 499,
            "HF Likes (September 2023)": 6,
            "PwC Description": "Large-scale Chinese legal dataset for judgment prediction. \\dataset contains more than 2.6  million criminal cases published by the Supreme People's Court of China, which are several times larger than other datasets in existing works on judgment prediction.",
            "S2 Citation Count (September 2023)": 154,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Criminal law",
                "Chinese language and translation",
                "Legal proceedings",
                "Criminal law and legal proceedings",
                "Legal system and criminal cases",
                "Financial fraud",
                "Crime investigation",
                "Criminal cases"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Xiao2018CAIL2018AL,\n author = {Chaojun Xiao and Haoxiang Zhong and Zhipeng Guo and Cunchao Tu and Zhiyuan Liu and Maosong Sun and Yansong Feng and Xianpei Han and Zhen Hu and Heng Wang and Jianfeng Xu},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {CAIL2018: A Large-Scale Legal Dataset for Judgment Prediction},\n volume = {abs/1807.02478},\n year = {2018}\n}\n"
    },
    "fc-sni-casehold": {
        "Unique Dataset Identifier": "fc-sni-casehold",
        "Dataset Name": "casehold",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/reglab/casehold",
        "GitHub URL": "https://github.com/reglab/casehold",
        "Hugging Face URL": "https://huggingface.co/datasets/casehold/casehold",
        "Paper Title": "When Does Pretraining Help? Assessing Self-Supervised Learning for Law and the CaseHOLD Dataset",
        "Papers with Code URL": "https://paperswithcode.com/dataset/casehold",
        "ArXiv URL": "https://arxiv.org/abs/2104.08671",
        "Semantic Scholar Corpus ID": 233296302,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Fill in The Blank"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13213,
            "Mean Inputs Length": 3582.9664,
            "Mean Targets Length": 3.5825,
            "Max Inputs Length": 26246,
            "Max Targets Length": 13,
            "Min Inputs Length": 1141,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "harvard caselaw project",
            "casetext company"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task268_casehold_legal_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "casehold/casehold",
            "HF Config": "all",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2021-04-18",
            "S2 Date": "2021-04-18",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "2023-03-27",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "CaseHOLD (Case Holdings On Legal Decisions) is a law dataset comprised of over 53,000+ multiple choice questions to identify the relevant holding of a cited case. This dataset presents a fundamental task to lawyers and is both legally meaningful and difficult from an NLP perspective (F1 of 0.4 with a BiLSTM baseline). The citing context from the judicial decision serves as the prompt for the question. The answer choices are holding statements derived from citations following text in a legal decision. There are five answer choices for each citing text. The correct answer is the holding statement that corresponds to the citing text. The four incorrect answers are other holding statements.\n\nTo read more about the dataset, please see our paper or our blogpost.",
            "S2 Citation Count (September 2023)": 94,
            "GitHub Stars": 58,
            "GitHub Topics": [],
            "Text Topics": [
                "Judicial process",
                "Legal reasoning",
                "Legal citation and holdings",
                "Legal analysis",
                "Legal citation interpretation",
                "Judicial decision-making"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zheng2021WhenDP,\n author = {Lucia Zheng and Neel Guha and Brandon R. Anderson and Peter Henderson and Daniel E. Ho},\n booktitle = {International Conference on Artificial Intelligence and Law},\n journal = {Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law},\n title = {When does pretraining help?: assessing self-supervised learning for law and the CaseHOLD dataset of 53,000+ legal holdings},\n year = {2021}\n}\n"
    },
    "fc-sni-casino": {
        "Unique Dataset Identifier": "fc-sni-casino",
        "Dataset Name": "casino",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://aclanthology.org/2021.naacl-main.254.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/casino",
        "Paper Title": "CaSiNo: A Corpus of Campsite Negotiation Dialogues for Automatic Negotiation Systems",
        "Papers with Code URL": "https://paperswithcode.com/dataset/casino",
        "ArXiv URL": "https://arxiv.org/abs/2103.15721",
        "Semantic Scholar Corpus ID": 232417432,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Negotiation Strategy Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1554,
            "Mean Inputs Length": 1223.5122,
            "Mean Targets Length": 3.094,
            "Max Inputs Length": 3131,
            "Max Targets Length": 13,
            "Min Inputs Length": 562,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Southern California",
            "Rollins College",
            "CUNY Lehman College"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/2103.15721"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task353_casino_classification_negotiation_elicit_pref"
        ],
        "Inferred Metadata": {
            "HF Dataset": "casino",
            "HF Config": "default",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://github.com/kushalchawla/CaSiNo/blob/main/LICENSE",
            "PwC Date": "2021-03-29",
            "S2 Date": "2021-03-29",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 643,
            "HF Likes (September 2023)": 2,
            "PwC Description": "CaSiNo is a dataset of 1030 negotiation dialogues in English. To create the dataset, two participates take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. This design keeps the task tractable, while still facilitating linguistically rich and personal conversations.",
            "S2 Citation Count (September 2023)": 16,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Outdoor activities",
                "Communication strategies",
                "Resource management",
                "Interpersonal communication",
                "Camping and outdoor activities",
                "Negotiation skills",
                "Personal preferences and requirements",
                "Camping essentials"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chawla2021CaSiNoAC,\n author = {Kushal Chawla and Jaysa Ramirez and Rene Clever and Gale M. Lucas and Jonathan May and J. Gratch},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {CaSiNo: A Corpus of Campsite Negotiation Dialogues for Automatic Negotiation Systems},\n volume = {abs/2103.15721},\n year = {2021}\n}\n"
    },
    "fc-sni-catalonia_independence_corpus": {
        "Unique Dataset Identifier": "fc-sni-catalonia_independence_corpus",
        "Dataset Name": "catalonia_independence_corpus",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/ixa-ehu/catalonia-independence-corpus",
        "GitHub URL": "https://github.com/ixa-ehu/catalonia-independence-corpus",
        "Hugging Face URL": "https://huggingface.co/datasets/catalonia_independence",
        "Paper Title": "Multilingual Stance Detection in Tweets: The Catalonia Independence Corpus",
        "Papers with Code URL": "https://paperswithcode.com/dataset/cic",
        "ArXiv URL": "https://aclanthology.org/2020.lrec-1.171/",
        "Semantic Scholar Corpus ID": 218973852,
        "Languages": [
            "Catalan",
            "Spanish",
            "English"
        ],
        "Task Categories": [
            "Stance Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9882,
            "Mean Inputs Length": 891.4486,
            "Mean Targets Length": 6.8062,
            "Max Inputs Length": 1844,
            "Max Targets Length": 17,
            "Min Inputs Length": 503,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "University of the Basque Country",
            "Intercom Strategys"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "https://github.com/ixa-ehu/catalonia-independence-corpus/blob/master/LICENSE.md"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1646_dataset_card_for_catalonia_independence_corpus_text_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "catalonia_independence",
            "HF Config": "catalan",
            "HF Config License": "CC BY-NC-SA 4.0",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-03-31",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "The dataset is annotated with stance towards one topic, namely, the independence of Catalonia.",
            "S2 Citation Count (September 2023)": 17,
            "GitHub Stars": 3,
            "GitHub Topics": [],
            "Text Topics": [
                "Social issues",
                "Language processing",
                "Political Science",
                "Stance detection",
                "Catalan independence",
                "Language and culture",
                "Politics",
                "Political discourse",
                "Language and Linguistics",
                "Social media analysis"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zotova2020MultilingualSD,\n author = {Elena Zotova and Rodrigo Agerri and Manuel Núñez and German Rigau},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {1368-1375},\n title = {Multilingual Stance Detection in Tweets: The Catalonia Independence Corpus},\n year = {2020}\n}\n"
    },
    "fc-sni-ccaligned_multilingual": {
        "Unique Dataset Identifier": "fc-sni-ccaligned_multilingual",
        "Dataset Name": "ccaligned_multilingual",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/ccaligned_multilingual",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ccaligned_multilingual",
        "Paper Title": "CCAligned: A Massive Collection of Cross-Lingual Web-Document Pairs",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ccaligned",
        "ArXiv URL": "https://arxiv.org/abs/1911.06154",
        "Semantic Scholar Corpus ID": 208006253,
        "Languages": [
            "Telugu",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9662,
            "Mean Inputs Length": 295.6045,
            "Mean Targets Length": 65.3204,
            "Max Inputs Length": 2443,
            "Max Targets Length": 1043,
            "Min Inputs Length": 85,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "commoncrawl.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Facebook AI Research",
            "Johns Hopkins University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://www.aclweb.org/anthology/2020.emnlp-main.480.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1616_cc_alligned_translate_eng_tel"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ccaligned_multilingual",
            "HF Config": "documents-zz_TR",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2019-11-10",
            "S2 Date": "2019-11-10",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1560,
            "HF Likes (September 2023)": 3,
            "PwC Description": "CCAligned consists of parallel or comparable web-document pairs in 137 languages aligned with English. These web-document pairs were constructed by performing language identification on raw web-documents, and ensuring corresponding language codes were corresponding in the URLs of web documents. This pattern matching approach yielded more than 100 million aligned documents paired with English. Recognizing that each English document was often aligned to multiple documents in different target language, it is possible to join on English documents to obtain aligned documents that directly pair two non-English documents (e.g., Arabic-French).",
            "S2 Citation Count (September 2023)": 121,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language",
                "Cultural differences",
                "Linguistics",
                "Cultural exchange",
                "Communication",
                "Multilingual communication",
                "Language learning",
                "Translation",
                "Language translation"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{El-Kishky2019AMC,\n author = {Ahmed El-Kishky and Vishrav Chaudhary and Francisco Guzmán and Philipp Koehn},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {A Massive Collection of Cross-Lingual Web-Document Pairs},\n volume = {abs/1911.06154},\n year = {2019}\n}\n"
    },
    "fc-sni-cdt": {
        "Unique Dataset Identifier": "fc-sni-cdt",
        "Dataset Name": "cdt",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/cdt",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/cdt",
        "Paper Title": "KLEJ: Comprehensive Benchmark for Polish Language Understanding",
        "Papers with Code URL": "https://paperswithcode.com/dataset/klej",
        "ArXiv URL": "https://arxiv.org/abs/2005.00630",
        "Semantic Scholar Corpus ID": 218487823,
        "Languages": [
            "Polish",
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3382,
            "Mean Inputs Length": 386.9116,
            "Mean Targets Length": 1.5216,
            "Max Inputs Length": 679,
            "Max Targets Length": 11,
            "Min Inputs Length": 168,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "allegro.pl"
        ],
        "Model Generated": [],
        "Creators": [
            "ML Research at Allegro",
            "AGH University of Science and Technology"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://klejbenchmark.com/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task838_cdt_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "cdt",
            "HF Config": "default",
            "HF Config License": "BSD 3-Clause License",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-05-01",
            "S2 Date": "2020-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 614,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The KLEJ benchmark (Kompleksowa Lista Ewaluacji Językowych) is a set of nine evaluation tasks for the Polish language understanding task.\n\nKey benchmark features:\n\n\nIt contains a diverse set of tasks from different domains and with different objectives.\nMost tasks are created from existing datasets but the authors also released the new sentiment analysis dataset from an e-commerce domain.\nIt includes tasks which have relatively small datasets and require extensive external knowledge to solve them. It promotes the usage of transfer learning instead of training separate models from scratch.\n\nThe name KLEJ (English: GLUE) is an abbreviation for Kompleksowa Lista Ewaluacji Językowych (English: Comprehensive List of Language Evaluations) and refers to the GLUE benchmark.",
            "S2 Citation Count (September 2023)": 51,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Polish language",
                "Cyberbullying",
                "Social media communication",
                "Social media analysis",
                "Text classification",
                "Natural language processing",
                "Online communication",
                "Polish language and culture"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Rybak2020KLEJCB,\n author = {Piotr Rybak and Robert Mroczkowski and Janusz Tracz and Ireneusz Gawlik},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {KLEJ: Comprehensive Benchmark for Polish Language Understanding},\n volume = {abs/2005.00630},\n year = {2020}\n}\n"
    },
    "fc-sni-cedr": {
        "Unique Dataset Identifier": "fc-sni-cedr",
        "Dataset Name": "cedr",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/sag111/CEDR",
        "GitHub URL": "https://github.com/sag111/CEDR",
        "Hugging Face URL": "https://huggingface.co/datasets/cedr",
        "Paper Title": "Data-Driven Model for Emotion Detection in Russian Texts",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 237435794,
        "Languages": [
            "Russian",
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8558,
            "Mean Inputs Length": 562.8673,
            "Mean Targets Length": 5.7769,
            "Max Inputs Length": 977,
            "Max Targets Length": 18,
            "Min Inputs Length": 324,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Kurchatov Institute",
            "MEPhI National Research Nuclear University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://www.sciencedirect.com/science/article/pii/S1877050921013247"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1662_cedr_ru_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "cedr",
            "HF Config": "main",
            "HF Config License": "Apache License 2.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 2,
            "GitHub Stars": 4,
            "GitHub Topics": [],
            "Text Topics": [
                "Russian culture",
                "Russian language",
                "Emotion classification",
                "Psychology of emotions",
                "Emotion recognition",
                "Language learning",
                "Emotion recognition and classification",
                "Natural language processing",
                "Russian language and culture"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Sboev2020DataDrivenMF,\n author = {A. Sboev and A. Naumov and R. Rybka},\n booktitle = {BICA*AI},\n pages = {637-642},\n title = {Data-Driven Model for Emotion Detection in Russian Texts},\n year = {2020}\n}\n"
    },
    "fc-sni-cfq_mcd1": {
        "Unique Dataset Identifier": "fc-sni-cfq_mcd1",
        "Dataset Name": "cfq_mcd1",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.tensorflow.org/datasets/catalog/cfq",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/cfq",
        "Paper Title": "Measuring Compositional Generalization: A Comprehensive Method on Realistic Data",
        "Papers with Code URL": "https://paperswithcode.com/dataset/cfq",
        "ArXiv URL": "https://arxiv.org/abs/1912.09713",
        "Semantic Scholar Corpus ID": 209439843,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text to Code"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 796,
            "Mean Inputs Length": 2695.5377,
            "Mean Targets Length": 448.5025,
            "Max Inputs Length": 4422,
            "Max Targets Length": 1188,
            "Min Inputs Length": 2165,
            "Min Targets Length": 53,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "Google Research",
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://openreview.net/forum?id=SygcCnNKwr"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task868_cfq_mcd1_explanation_to_sql"
        ],
        "Inferred Metadata": {
            "HF Dataset": "cfq",
            "HF Config": "mcd1",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-12-20",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "A large and realistic natural language question answering dataset.",
            "S2 Citation Count (September 2023)": 232,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Data manipulation",
                "Database management",
                "Data analysis",
                "SQL queries",
                "Data retrieval",
                "Table structure",
                "Data modeling"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Keysers2019MeasuringCG,\n author = {Daniel Keysers and Nathanael Schärli and Nathan Scales and Hylke Buisman and Daniel Furrer and S. Kashubin and Nikola Momchev and Danila Sinopalnikov and Lukasz Stafiniak and Tibor Tihon and Dmitry Tsarkov and Xiao Wang and Marc van Zee and O. Bousquet},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Measuring Compositional Generalization: A Comprehensive Method on Realistic Data},\n volume = {abs/1912.09713},\n year = {2019}\n}\n"
    },
    "fc-sni-chemprot_corpus": {
        "Unique Dataset Identifier": "fc-sni-chemprot_corpus",
        "Dataset Name": "chemprot_corpus",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://paperswithcode.com/dataset/chemprot",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/bigbio/chemprot",
        "Paper Title": "",
        "Papers with Code URL": "https://paperswithcode.com/dataset/chemprot",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 550,
            "Mean Inputs Length": 484.5836,
            "Mean Targets Length": 17.3255,
            "Max Inputs Length": 935,
            "Max Targets Length": 57,
            "Min Inputs Length": 233,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://biocreative.bioinformatics.udel.edu/news/corpora/chemprot-corpus-biocreative-vi/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1482_gene_extraction_chemprot_dataset"
        ],
        "Inferred Metadata": {
            "HF Dataset": "bigbio/chemprot",
            "HF Config": "chemprot_full_source",
            "HF Config License": "CC0 1.0",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-11-13",
            "HF Downloads (September 2023)": 428,
            "HF Likes (September 2023)": 1,
            "PwC Description": "ChemProt consists of 1,820 PubMed abstracts with chemical-protein interactions annotated by domain experts and was used in the BioCreative VI text mining chemical-protein interactions shared task.",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Genetics",
                "Molecular biology",
                "Biochemistry",
                "Medicine",
                "Nutrition",
                "Medical research",
                "Pharmacology",
                "Neuroscience"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-circa": {
        "Unique Dataset Identifier": "fc-sni-circa",
        "Dataset Name": "circa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/circa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/circa",
        "Paper Title": "\"I'd rather just go to bed\": Understanding Indirect Answers",
        "Papers with Code URL": "https://paperswithcode.com/dataset/circa",
        "ArXiv URL": "https://arxiv.org/abs/2010.03450",
        "Semantic Scholar Corpus ID": 222177178,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Dialogue Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5861,
            "Mean Inputs Length": 277.267,
            "Mean Targets Length": 27.9326,
            "Max Inputs Length": 531,
            "Max Targets Length": 93,
            "Min Inputs Length": 122,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Google Research",
            "University of Pennsylvania"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/google-research-datasets/circa#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task565_circa_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "circa",
            "HF Config": "default",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-10-07",
            "S2 Date": "2020-10-07",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1128,
            "HF Likes (September 2023)": 2,
            "PwC Description": "The Circa (meaning ‘approximately’) dataset aims to help machine learning systems to solve the problem of interpreting indirect answers to polar questions.\n\nThe dataset contains pairs of yes/no questions and indirect answers, together with annotations for the interpretation of the answer. The data is collected in 10 different social conversational situations (eg. food preferences of a friend). Examples:\n\n```\nQ: Are you vegan?\nA: I love burgers too much. [No]\n\nQ: Do you like spicy food?\nA: I put hot sauce on everything. [Yes] \n\nQ: Would you like to go see live music?\nA: If it’s not too crowded. [Yes, upon a condition]\n```\n\nCurrently, the Circa annotations focus on a few classes such as ‘yes’, ‘no’ and ‘yes, upon condition’. The data can be used to build machine learning models which can replicate these classes on new question-answer pairs, and allow evaluation of methods for doing so.",
            "S2 Citation Count (September 2023)": 24,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Literature",
                "Daily routine",
                "Food preferences",
                "Travel",
                "Leisure activities",
                "Music",
                "Personal preferences",
                "Entertainment"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Louis2020IDRJ,\n author = {Annie Louis and D. Roth and Filip Radlinski},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {“I’D Rather Just Go to Bed”: Understanding Indirect Answers},\n volume = {abs/2010.03450},\n year = {2020}\n}\n"
    },
    "fc-sni-civil_comments": {
        "Unique Dataset Identifier": "fc-sni-civil_comments",
        "Dataset Name": "civil_comments",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/civil_comments",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/civil_comments",
        "Paper Title": "Nuanced Metrics for Measuring Unintended Bias with Real Data for Text Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/civil-comments",
        "ArXiv URL": "https://arxiv.org/abs/1903.04561",
        "Semantic Scholar Corpus ID": 75135222,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2031,
            "Mean Inputs Length": 714.6775,
            "Mean Targets Length": 3.1029,
            "Max Inputs Length": 2542,
            "Max Targets Length": 13,
            "Min Inputs Length": 190,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "drupal.org/project/civilcomments"
        ],
        "Model Generated": [],
        "Creators": [
            "Jigsaw"
        ],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification/overview/faq"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1720_civil_comments_toxicity_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "civil_comments",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC0 1.0",
            "PwC License Name": "CC0 1.0",
            "PwC License URL": "",
            "PwC Date": "2019-07-19",
            "S2 Date": "2019-03-11",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 4627,
            "HF Likes (September 2023)": 1,
            "PwC Description": "At the end of 2017 the Civil Comments platform shut down and chose make their ~2m public comments from their platform available in a lasting open archive so that researchers could understand and improve civility in online conversations for years to come. Jigsaw sponsored this effort and extended annotation of this data by human raters for various toxic conversational attributes.\n\nIn the data supplied for this competition, the text of the individual comment is found in the comment_text column. Each comment in Train has a toxicity label (target), and models should predict the target toxicity for the Test data. This attribute (and all others) are fractional values which represent the fraction of human raters who believed the attribute applied to the given comment.\n\nThe data also has several additional toxicity subtype attributes. Models do not need to predict these attributes for the competition, they are included as an additional avenue for research. Subtype attributes are:\n\n\nsevere_toxicity\nobscene\nthreat\ninsult\nidentity_attack\nsexual_explicit\n\nAdditionally, a subset of comments have been labelled with a variety of identity attributes, representing the identities that are mentioned in the comment. The columns corresponding to identity attributes are listed below. Only identities with more than 500 examples in the test set (combined public and private) will be included in the evaluation calculation. These identities are shown in bold.\n\n\nmale\nfemale\ntransgender\nother_gender\nheterosexual\nhomosexual_gay_or_lesbian\nbisexual\nother_sexual_orientation\nchristian\njewish\nmuslim\nhindu\nbuddhist\natheist\nother_religion\nblack\nwhite\nasian\nlatino\nother_race_or_ethnicity\nphysical_disability\nintellectual_or_learning_disability\npsychiatric_or_mental_illness\nother_disability",
            "S2 Citation Count (September 2023)": 317,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Online behavior and etiquette",
                "Social media etiquette",
                "Social media",
                "Cyberbullying",
                "Social issues",
                "Toxicity in online communities",
                "Politics",
                "Online communication",
                "Online behavior",
                "Toxicity in social interactions"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Book{Borkan2019NuancedMF,\n author = {Daniel Borkan and Lucas Dixon and Jeffrey Scott Sorensen and Nithum Thain and Lucy Vasserman},\n booktitle = {The Web Conference},\n journal = {Companion Proceedings of The 2019 World Wide Web Conference},\n title = {Nuanced Metrics for Measuring Unintended Bias with Real Data for Text Classification},\n year = {2019}\n}\n"
    },
    "fc-sni-clariq": {
        "Unique Dataset Identifier": "fc-sni-clariq",
        "Dataset Name": "clariq",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/aliannejadi/ClariQ",
        "GitHub URL": "https://github.com/aliannejadi/ClariQ",
        "Hugging Face URL": "https://huggingface.co/datasets/conv_ai_3",
        "Paper Title": "ConvAI3: Generating Clarifying Questions for Open-Domain Dialogue Systems (ClariQ)",
        "Papers with Code URL": "https://paperswithcode.com/dataset/clariq",
        "ArXiv URL": "https://arxiv.org/abs/2009.11352",
        "Semantic Scholar Corpus ID": 221879101,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 472,
            "Mean Inputs Length": 534.4915,
            "Mean Targets Length": 51.3729,
            "Max Inputs Length": 782,
            "Max Targets Length": 164,
            "Min Inputs Length": 353,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Amsterdam",
            "Microsoft Research",
            "Google Research",
            "University of Glasgow",
            "MIPT"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task166_clariq_sentence_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "conv_ai_3",
            "HF Config": "conv_ai_3",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-09-23",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "ClariQ is an extension of the Qulac dataset with additional new topics, questions, and answers in the training set. The test set is completely unseen and newly collected. Like Qulac, ClariQ consists of single-turn conversations (initial_request, followed by clarifying question and answer). In addition, it comes with synthetic multi-turn conversations (up to three turns). ClariQ features approximately 18K single-turn conversations, as well as 1.8 million multi-turn conversations.",
            "S2 Citation Count (September 2023)": 58,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "User queries",
                "Information retrieval",
                "Communication",
                "History",
                "Dialogue Systems",
                "Dialogue systems",
                "Natural language processing",
                "User Interaction",
                "Natural language understanding"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Aliannejadi2020ConvAI3GC,\n author = {Mohammad Aliannejadi and Julia Kiseleva and A. Chuklin and Jeffrey Dalton and M. Burtsev},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {ConvAI3: Generating Clarifying Questions for Open-Domain Dialogue Systems (ClariQ)},\n volume = {abs/2009.11352},\n year = {2020}\n}\n"
    },
    "fc-sni-clickbait_news_bg": {
        "Unique Dataset Identifier": "fc-sni-clickbait_news_bg",
        "Dataset Name": "clickbait_news_bg",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/clickbait_news_bg",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/clickbait_news_bg",
        "Paper Title": "We Built a Fake News / Click Bait Filter: What Happened Next Will Blow Your Mind!",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1803.03786",
        "Semantic Scholar Corpus ID": 3870135,
        "Languages": [
            "Bulgarian",
            "English"
        ],
        "Task Categories": [
            "Title Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 974,
            "Mean Inputs Length": 3292.4476,
            "Mean Targets Length": 64.4723,
            "Max Inputs Length": 26175,
            "Max Targets Length": 162,
            "Min Inputs Length": 509,
            "Min Targets Length": 18,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "bapra.bg"
        ],
        "Model Generated": [],
        "Creators": [
            "Sofia University",
            "Qatar Computing Research Institute"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://www.acl-bg.org/proceedings/2017/RANLP%202017/pdf/RANLP045.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1561_clickbait_new_bg_summarization"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2017-11-10",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 603,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 47,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Politics",
                "News and current events",
                "International relations",
                "Sports",
                "Language and communication",
                "Language and translation",
                "Current affairs",
                "Language and Communication"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Karadzhov2017WeBA,\n author = {Georgi Karadzhov and Pepa Gencheva and Preslav Nakov and Ivan Koychev},\n booktitle = {Recent Advances in Natural Language Processing},\n journal = {ArXiv},\n title = {We Built a Fake News / Click Bait Filter: What Happened Next Will Blow Your Mind!},\n volume = {abs/1803.03786},\n year = {2017}\n}\n"
    },
    "fc-sni-cls": {
        "Unique Dataset Identifier": "fc-sni-cls",
        "Dataset Name": "cls",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://aclanthology.org/P10-1114/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "Cross-Language Text Classification Using Structural Correspondence Learning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/P10-1114/",
        "Semantic Scholar Corpus ID": 12360898,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3923,
            "Mean Inputs Length": 1868.7777,
            "Mean Targets Length": 3.5975,
            "Max Inputs Length": 21597,
            "Max Targets Length": 13,
            "Min Inputs Length": 300,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "amazon.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Bauhaus-Universitat Weimar"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task476_cls_english_books_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2010-07-11",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 297,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Natural language processing",
                "Product classification",
                "Sentiment analysis",
                "Pets",
                "Book preferences",
                "Product reviews",
                "Book reviews",
                "Literature",
                "Advertising",
                "English language"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Prettenhofer2010CrossLanguageTC,\n author = {P. Prettenhofer and Benno Stein},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1118-1127},\n title = {Cross-Language Text Classification Using Structural Correspondence Learning},\n year = {2010}\n}\n"
    },
    "fc-sni-clue_cmrc2018": {
        "Unique Dataset Identifier": "fc-sni-clue_cmrc2018",
        "Dataset Name": "clue_cmrc2018",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/ymcui/cmrc2018",
        "GitHub URL": "https://github.com/ymcui/cmrc2018",
        "Hugging Face URL": "https://huggingface.co/datasets/cmrc2018",
        "Paper Title": "A Span-Extraction Dataset for Chinese Machine Reading Comprehension",
        "Papers with Code URL": "https://paperswithcode.com/dataset/cmrc",
        "ArXiv URL": "https://arxiv.org/abs/1810.07366",
        "Semantic Scholar Corpus ID": 52984852,
        "Languages": [
            "Chinese",
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1024,
            "Mean Inputs Length": 1147.9971,
            "Mean Targets Length": 15.1982,
            "Max Inputs Length": 2674,
            "Max Targets Length": 38,
            "Min Inputs Length": 380,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Harbin Institute of Technology",
            "iFLYTEK Research",
            "iFLYTEK Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/D19-1600.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1402_clue_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "cmrc2018",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://github.com/ymcui/cmrc2018/blob/master/LICENCE",
            "PwC Date": "2019-01-01",
            "S2 Date": "",
            "GitHub License": "CC BY-SA 4.0",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1165,
            "HF Likes (September 2023)": 10,
            "PwC Description": "CMRC is a dataset is annotated by human experts with near 20,000 questions as well as a challenging set which is composed of the questions that need reasoning over multiple clues.",
            "S2 Citation Count (September 2023)": 138,
            "GitHub Stars": 382,
            "GitHub Topics": [
                "bert",
                "natural-language-processing",
                "question-answering",
                "reading-comprehension"
            ],
            "Text Topics": [
                "Sports",
                "Reading comprehension",
                "Chinese history",
                "Entertainment",
                "History",
                "Geography",
                "Chinese culture",
                "Chinese language and culture"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Cui2019ASD,\n author = {Yiming Cui and Ting Liu and Li Xiao and Zhipeng Chen and Wentao Ma and Wanxiang Che and Shijin Wang and Guoping Hu},\n booktitle = {EMNLP-IJCNLP},\n pages = {5882-5888},\n title = {A Span-Extraction Dataset for Chinese Machine Reading Comprehension},\n year = {2019}\n}\n"
    },
    "fc-sni-cmrc2018": {
        "Unique Dataset Identifier": "fc-sni-cmrc2018",
        "Dataset Name": "cmrc2018",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/chr_en",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/chr_en",
        "Paper Title": "ChrEn: Cherokee-English Machine Translation for Endangered Language Revitalization",
        "Papers with Code URL": "https://paperswithcode.com/dataset/chren",
        "ArXiv URL": "https://arxiv.org/abs/2010.04791",
        "Semantic Scholar Corpus ID": 222291378,
        "Languages": [
            "Chinese",
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 366,
            "Mean Inputs Length": 1494.6093,
            "Mean Targets Length": 16.5765,
            "Max Inputs Length": 2946,
            "Max Targets Length": 60,
            "Min Inputs Length": 785,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "UNC Chapel Hill"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/2010.04791"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1569_cmrc2018_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-10-09",
            "S2 Date": "2020-10-09",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1220,
            "HF Likes (September 2023)": 3,
            "PwC Description": "Cherokee-English Parallel Dataset is a low-resource dataset of 14,151 pairs of sentences with around\n313K English tokens and 206K Cherokee tokens. The parallel corpus is accompanied by a monolingual Cherokee dataset of 5,120 sentences. Both datasets are mostly derived from Cherokee monolingual books.",
            "S2 Citation Count (September 2023)": 18,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "History",
                "Language learning",
                "Geography",
                "Chinese history",
                "Travel",
                "Chinese culture",
                "Reading comprehension"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Zhang2020ChrEnCM,\n author = {Shiyue Zhang and B. Frey and Mohit Bansal},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {577-595},\n title = {ChrEn: Cherokee-English Machine Translation for Endangered Language Revitalization},\n year = {2020}\n}\n"
    },
    "fc-sni-coached_conv_pref": {
        "Unique Dataset Identifier": "fc-sni-coached_conv_pref",
        "Dataset Name": "coached_conv_pref",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://research.google/tools/datasets/coached-conversational-preference-elicitation/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/coached_conv_pref",
        "Paper Title": "Coached Conversational Preference Elicitation: A Case Study in Understanding Movie Preferences",
        "Papers with Code URL": "https://paperswithcode.com/dataset/coached-conversational-preference-elicitation",
        "ArXiv URL": "https://aclanthology.org/W19-5941/",
        "Semantic Scholar Corpus ID": 203045663,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Speaker Identification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 980,
            "Mean Inputs Length": 1312.2337,
            "Mean Targets Length": 7.7571,
            "Max Inputs Length": 3155,
            "Max Targets Length": 19,
            "Min Inputs Length": 512,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Google"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://github.com/google-research-datasets/ccpe#copyright-notice"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task925_coached_conv_pref_classifier"
        ],
        "Inferred Metadata": {
            "HF Dataset": "coached_conv_pref",
            "HF Config": "coached_conv_pref",
            "HF Config License": "CC BY-SA 4.0",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/4.0/",
            "PwC Date": "",
            "S2 Date": "2019-09-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 584,
            "HF Likes (September 2023)": 2,
            "PwC Description": "Coached Conversational Preference Elicitation is a dataset consisting of 502 English dialogs with 12,000 annotated utterances between a user and an assistant discussing movie preferences in natural language. It was collected using a Wizard-of-Oz methodology between two paid crowd-workers, where one worker plays the role of an 'assistant', while the other plays the role of a 'user'.",
            "S2 Citation Count (September 2023)": 80,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Artificial intelligence",
                "Conversational agents",
                "Technology",
                "General knowledge",
                "Movies",
                "Natural language processing",
                "Question answering",
                "Personal preferences"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Radlinski2019CoachedCP,\n author = {Filip Radlinski and K. Balog and B. Byrne and K. Krishnamoorthi},\n booktitle = {SIGDIAL Conferences},\n pages = {353-360},\n title = {Coached Conversational Preference Elicitation: A Case Study in Understanding Movie Preferences},\n year = {2019}\n}\n"
    },
    "fc-sni-cod3s": {
        "Unique Dataset Identifier": "fc-sni-cod3s",
        "Dataset Name": "cod3s",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://aclanthology.org/2020.emnlp-main.421.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "COD3S: Diverse Generation with Discrete Semantic Signatures",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.02882",
        "Semantic Scholar Corpus ID": 222141569,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Cause Effect Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4583,
            "Mean Inputs Length": 457.8239,
            "Mean Targets Length": 11.6987,
            "Max Inputs Length": 692,
            "Max Targets Length": 23,
            "Min Inputs Length": 292,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "commoncrawl.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Johns Hopkins University",
            "New York University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task391_causal_relationship"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-06",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Causation analysis",
                "Logic",
                "Reasoning",
                "Daily routine",
                "Linguistics",
                "Sentence comprehension",
                "Causation"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Weir2020COD3SDG,\n author = {Nathaniel Weir and João Sedoc and Benjamin Van Durme},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {5199-5211},\n title = {COD3S: Diverse Generation with Discrete Semantic Signatures},\n year = {2020}\n}\n"
    },
    "fc-sni-coda_19": {
        "Unique Dataset Identifier": "fc-sni-coda_19",
        "Dataset Name": "coda_19",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/windx0303/CODA-19/tree/master/data",
        "GitHub URL": "https://github.com/windx0303/CODA-19/tree/master/data",
        "Hugging Face URL": "",
        "Paper Title": "CODA-19: Using a Non-Expert Crowd to Annotate Research Aspects on 10,000+ Abstracts in the COVID-19 Open Research Dataset",
        "Papers with Code URL": "https://paperswithcode.com/dataset/coda-19",
        "ArXiv URL": "https://arxiv.org/abs/2005.02367",
        "Semantic Scholar Corpus ID": 221139740,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Title Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12903,
            "Mean Inputs Length": 3115.6541,
            "Mean Targets Length": 107.3175,
            "Max Inputs Length": 13404,
            "Max Targets Length": 1132,
            "Min Inputs Length": 699,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "academic papers"
        ],
        "Model Generated": [],
        "Creators": [
            "Pennsylvania State University",
            "UC San Francisco",
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/2005.02367.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1161_coda19_title_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-05-05",
            "S2 Date": "2020-05-05",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "CODA-19 is a human-annotated dataset that denotes the Background, Purpose, Method, Finding/Contribution, and Other for 10,966 English abstracts in the COVID-19 Open Research Dataset.\n\nCODA-19 was created by 248 crowd workers from Amazon Mechanical Turk collectively within ten days. Each abstract was annotated by nine different workers, and the final labels were obtained by majority voting.\n\nCODA-19's labels have an accuracy of 82% and an inter-annotator agreement (Cohen's kappa) of 0.74 when compared against expert labels on 129 abstracts.",
            "S2 Citation Count (September 2023)": 25,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Immunology",
                "Molecular biology",
                "Virology",
                "Research paper analysis",
                "Biology",
                "Public health",
                "Infectious diseases",
                "Epidemiology",
                "Medical research"
            ]
        },
        "Derived from Datasets": [
            "CORD-19 dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Huang2020CODA19UA,\n author = {Ting-Hao 'Kenneth' Huang and Huang Chieh-Yang and C. C. Ding and Yen-Chia Hsu and C. Lee Giles},\n booktitle = {NLPCOVID19},\n journal = {arXiv: Computation and Language},\n title = {CODA-19: Using a Non-Expert Crowd to Annotate Research Aspects on 10,000+ Abstracts in the COVID-19 Open Research Dataset},\n year = {2020}\n}\n"
    },
    "fc-sni-codah": {
        "Unique Dataset Identifier": "fc-sni-codah",
        "Dataset Name": "codah",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://aclanthology.org/W19-2008.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/codah",
        "Paper Title": " CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense",
        "Papers with Code URL": "https://paperswithcode.com/dataset/codah",
        "ArXiv URL": "https://arxiv.org/abs/1904.04365",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Fill in The Blank"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5527,
            "Mean Inputs Length": 927.0695,
            "Mean Targets Length": 12.5916,
            "Max Inputs Length": 1709,
            "Max Targets Length": 22,
            "Min Inputs Length": 464,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Northwestern University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task156_codah_classification_adversarial"
        ],
        "Inferred Metadata": {
            "HF Dataset": "codah",
            "HF Config": "codah",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "The COmmonsense Dataset Adversarially-authored by Humans (CODAH) is an evaluation set for commonsense question-answering in the sentence completion style of SWAG. As opposed to other automatically generated NLI datasets, CODAH is adversarially constructed by humans who can view feedback from a pre-trained model and use this information to design challenging commonsense questions. It contains 2801 questions in total, and uses 5-fold cross validation for evaluation.",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language understanding",
                "Common sense",
                "Common sense reasoning",
                "Language comprehension",
                "Problem-solving",
                "Idioms",
                "Critical thinking",
                "Task completion",
                "Cognitive abilities",
                "Cognitive reasoning"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": ""
    },
    "fc-sni-codexglue": {
        "Unique Dataset Identifier": "fc-sni-codexglue",
        "Dataset Name": "codexglue",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/microsoft/CodeXGLUE",
        "GitHub URL": "https://github.com/microsoft/CodeXGLUE",
        "Hugging Face URL": "https://huggingface.co/datasets/0n1xus/codexglue",
        "Paper Title": "CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/codexglue",
        "ArXiv URL": "https://arxiv.org/abs/2102.04664",
        "Semantic Scholar Corpus ID": 231855531,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 765,
            "Mean Inputs Length": 986.7542,
            "Mean Targets Length": 1.5621,
            "Max Inputs Length": 2730,
            "Max Targets Length": 11,
            "Min Inputs Length": 300,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "Sun Yat-Sen University",
            "Beihang University",
            "Microsoft"
        ],
        "Licenses": [
            {
                "License": "C-UDA",
                "License URL": "https://github.com/microsoft/CodeXGLUE#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task921_code_x_glue_information_retreival"
        ],
        "Inferred Metadata": {
            "HF Dataset": "0n1xus/codexglue",
            "HF Config": "code-to-code-trans",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "C-UDA",
            "PwC License URL": "https://github.com/microsoft/CodeXGLUE#license",
            "PwC Date": "2021-02-09",
            "S2 Date": "2021-02-09",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2021-11-18",
            "HF Downloads (September 2023)": 731,
            "HF Likes (September 2023)": 3,
            "PwC Description": "CodeXGLUE is a benchmark dataset and open challenge for code intelligence. It includes a collection of code intelligence tasks and a platform for model evaluation and comparison. CodeXGLUE stands for General Language Understanding Evaluation benchmark for CODE. It includes 14 datasets for 10 diversified code intelligence tasks covering the following scenarios:\n\n\ncode-code (clone detection, defect detection, cloze test, code completion, code repair, and code-to-code translation)\ntext-code (natural language code search, text-to-code generation)\ncode-text (code summarization)\ntext-text (documentation translation)\n\nA brief summary of CodeXGLUE is provided in the figure, including tasks, datasets, language, sizes in various states, baseline systems, providers, and short definitions of each task. Datasets highlighted in BLUE are newly introduced.",
            "S2 Citation Count (September 2023)": 459,
            "GitHub Stars": 1218,
            "GitHub Topics": [],
            "Text Topics": [
                "Programming languages",
                "Control flow",
                "C++",
                "C++ programming",
                "Recursion",
                "Coding",
                "C++ language",
                "Programming",
                "Looping",
                "Control structures"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Lu2021CodeXGLUEAM,\n author = {Shuai Lu and Daya Guo and Shuo Ren and Junjie Huang and Alexey Svyatkovskiy and Ambrosio Blanco and Colin B. Clement and Dawn Drain and Daxin Jiang and Duyu Tang and Ge Li and Lidong Zhou and Linjun Shou and Long Zhou and Michele Tufano and Ming Gong and Ming Zhou and Nan Duan and Neel Sundaresan and Shao Kun Deng and Shengyu Fu and Shujie Liu},\n booktitle = {NeurIPS Datasets and Benchmarks},\n journal = {ArXiv},\n title = {CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation},\n volume = {abs/2102.04664},\n year = {2021}\n}\n"
    },
    "fc-sni-com_qa": {
        "Unique Dataset Identifier": "fc-sni-com_qa",
        "Dataset Name": "com_qa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/com_qa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/com_qa",
        "Paper Title": "ComQA: A Community-sourced Dataset for Complex Factoid Question Answering with Paraphrase Clusters",
        "Papers with Code URL": "https://paperswithcode.com/dataset/comqa",
        "ArXiv URL": "https://arxiv.org/abs/1809.09528",
        "Semantic Scholar Corpus ID": 52824771,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Rewriting"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3587,
            "Mean Inputs Length": 499.3365,
            "Mean Targets Length": 43.9652,
            "Max Inputs Length": 803,
            "Max Targets Length": 118,
            "Min Inputs Length": 319,
            "Min Targets Length": 14,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "answers.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Amazon",
            "Saarland University",
            "Bloomberg"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://qa.mpi-inf.mpg.de/comqa/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task442_com_qa_paraphrase_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "com_qa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-09-25",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "ComQA is a large dataset of real user questions that exhibit different challenging aspects such as compositionality, temporal reasoning, and comparisons. ComQA questions come from the WikiAnswers community QA platform, which typically contains questions that are not satisfactorily answerable by existing search engine technology.",
            "S2 Citation Count (September 2023)": 51,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Trivia",
                "General knowledge",
                "Entertainment",
                "History",
                "Biography",
                "Sports",
                "Paraphrasing"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Abujabal2018ComQAAC,\n author = {Abdalghani Abujabal and Rishiraj Saha Roy and Mohamed Yahya and G. Weikum},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {ComQA: A Community-sourced Dataset for Complex Factoid Question Answering with Paraphrase Clusters},\n volume = {abs/1809.09528},\n year = {2018}\n}\n"
    },
    "fc-sni-com2sense": {
        "Unique Dataset Identifier": "fc-sni-com2sense",
        "Dataset Name": "com2sense",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/PlusLabNLP/Com2Sense",
        "GitHub URL": "https://github.com/PlusLabNLP/Com2Sense",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/com2sense",
        "Paper Title": "COM2SENSE: A Commonsense Reasoning Benchmark with Complementary Sentences",
        "Papers with Code URL": "https://paperswithcode.com/dataset/com2sense",
        "ArXiv URL": "https://arxiv.org/abs/2106.00969",
        "Semantic Scholar Corpus ID": 235293697,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Commonsense Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3868,
            "Mean Inputs Length": 485.4005,
            "Mean Targets Length": 5.099,
            "Max Inputs Length": 856,
            "Max Targets Length": 15,
            "Min Inputs Length": 277,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced (amt)"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Southern California",
            "Sharif University of Technology",
            "UCLA"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/2106.00969"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task116_com2sense_commonsense_reasoning"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/com2sense",
            "HF Config": "tasksource--com2sense",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2021-06-02",
            "S2 Date": "2021-06-02",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2023-06-02",
            "HF Downloads (September 2023)": 40,
            "HF Likes (September 2023)": 0,
            "PwC Description": "Complementary Commonsense (Com2Sense) is a dataset for benchmarking commonsense reasoning ability of NLP models. This dataset contains 4k statement true/false sentence pairs. The dataset is crowdsourced and enhanced with an adversarial model-in-the-loop setup to incentivize challenging samples. To facilitate a systematic analysis of commonsense capabilities, the dataset is designed along the dimensions of knowledge domains, reasoning scenarios and numeracy.",
            "S2 Citation Count (September 2023)": 22,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Physics",
                "Everyday events",
                "Daily routine",
                "Comprehension",
                "Common sense",
                "Time management",
                "General knowledge",
                "Everyday life",
                "Plausibility",
                "General statements"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Singh2021COM2SENSEAC,\n author = {Shikhar Singh and Nuan Wen and Yu Hou and Pegah Alipoormolabashi and Te-Lin Wu and Xuezhe Ma and Nanyun Peng},\n booktitle = {Findings},\n pages = {883-898},\n title = {COM2SENSE: A Commonsense Reasoning Benchmark with Complementary Sentences},\n year = {2021}\n}\n"
    },
    "fc-sni-commongen": {
        "Unique Dataset Identifier": "fc-sni-commongen",
        "Dataset Name": "commongen",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://inklab.usc.edu/CommonGen/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/common_gen",
        "Paper Title": "CommonGen: A Constrained Text Generation Challenge for Generative Commonsense Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/commongen",
        "ArXiv URL": "https://arxiv.org/abs/1911.03705",
        "Semantic Scholar Corpus ID": 218500588,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Data to Text"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10840,
            "Mean Inputs Length": 528.222,
            "Mean Targets Length": 39.8375,
            "Max Inputs Length": 737,
            "Max Targets Length": 90,
            "Min Inputs Length": 393,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flickr",
            "crowdsourced",
            "undisclosed web",
            "amazon.com"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Southern California",
            "AI2",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/1911.03705.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task102_commongen_sentence_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "common_gen",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Custom",
            "PwC License URL": "https://inklab.usc.edu/CommonGen/",
            "PwC Date": "",
            "S2 Date": "2020-02-14",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 6667,
            "HF Likes (September 2023)": 13,
            "PwC Description": "CommonGen is constructed through a combination of crowdsourced and existing caption corpora, consists of 79k commonsense descriptions over 35k unique concept-sets.",
            "S2 Citation Count (September 2023)": 222,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Outdoor activities",
                "Home decor",
                "Transportation",
                "Geography",
                "Everyday situations",
                "Sports",
                "Interior design",
                "Daily routine"
            ]
        },
        "Derived from Datasets": [
            "Flickr30k",
            "MSCOCO",
            "Conceptual Captions",
            "LSMDC video captions",
            "ActivityNet",
            "VATEX"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lin2020CommonGenAC,\n author = {Bill Yuchen Lin and Minghan Shen and Wangchunshu Zhou and Pei Zhou and Chandra Bhagavatula and Yejin Choi and Xiang Ren},\n booktitle = {Findings},\n pages = {1823-1840},\n title = {CommonGen: A Constrained Text Generation Challenge for Generative Commonsense Reasoning},\n year = {2020}\n}\n"
    },
    "fc-sni-commonsenseqa": {
        "Unique Dataset Identifier": "fc-sni-commonsenseqa",
        "Dataset Name": "commonsenseqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.tau-nlp.org/commonsenseqa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/commonsense_qa",
        "Paper Title": "CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/commonsenseqa",
        "ArXiv URL": "https://arxiv.org/abs/1811.00937",
        "Semantic Scholar Corpus ID": 53296520,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2483,
            "Mean Inputs Length": 743.1373,
            "Mean Targets Length": 1.584,
            "Max Inputs Length": 1244,
            "Max Targets Length": 11,
            "Min Inputs Length": 500,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conceptnet",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Tel Aviv University",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/1811.00937"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task073_commonsenseqa_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "commonsense_qa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2019-01-01",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 10965,
            "HF Likes (September 2023)": 20,
            "PwC Description": "The CommonsenseQA is a dataset for commonsense question answering task. The dataset consists of 12,247 questions with 5 choices each.\nThe dataset was generated by Amazon Mechanical Turk workers in the following process (an example is provided in parentheses):\n\n\na crowd worker observes a source concept from ConceptNet (“River”) and three target concepts (“Waterfall”, “Bridge”, “Valley”) that are all related by the same ConceptNet relation (“AtLocation”),\nthe worker authors three questions, one per target concept, such that only that particular target concept is the answer, while the other two distractor concepts are not, (“Where on a river can you hold a cup upright to catch water on a sunny day?”, “Where can I stand on a river to see water falling without getting wet?”, “I’m crossing the river, my feet are wet but my body is dry, where am I?”)\nfor each question, another worker chooses one additional distractor from Concept Net (“pebble”, “stream”, “bank”), and the author another distractor (“mountain”, “bottom”, “island”) manually.",
            "S2 Citation Count (September 2023)": 685,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Common sense",
                "Reasoning",
                "Logic",
                "Decision-making",
                "Commonsense reasoning",
                "Critical thinking",
                "General knowledge"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Talmor2019CommonsenseQAAQ,\n author = {Alon Talmor and Jonathan Herzig and Nicholas Lourie and Jonathan Berant},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n volume = {abs/1811.00937},\n year = {2019}\n}\n"
    },
    "fc-sni-conala": {
        "Unique Dataset Identifier": "fc-sni-conala",
        "Dataset Name": "conala",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/pdf/1805.08949.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/neulab/conala",
        "Paper Title": "Learning to Mine Aligned Code and\nNatural Language Pairs from Stack Overflow",
        "Papers with Code URL": "https://paperswithcode.com/dataset/conala",
        "ArXiv URL": "https://arxiv.org/abs/1805.08949",
        "Semantic Scholar Corpus ID": 43922261,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Program Execution"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10017,
            "Mean Inputs Length": 262.871,
            "Mean Targets Length": 20.527,
            "Max Inputs Length": 597,
            "Max Targets Length": 66,
            "Min Inputs Length": 94,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "stackexchange.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task079_conala_concat_strings"
        ],
        "Inferred Metadata": {
            "HF Dataset": "neulab/conala",
            "HF Config": "curated",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2018-05-23",
            "S2 Date": "2018-05-23",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-09-14",
            "HF Downloads (September 2023)": 795,
            "HF Likes (September 2023)": 41,
            "PwC Description": "The CMU CoNaLa, the Code/Natural Language Challenge dataset is a joint project from the Carnegie Mellon University NeuLab and Strudel labs. Its purpose is for testing the generation of code snippets from natural language. The data comes from StackOverflow questions. There are 2379 training and 500 test examples that were manually annotated. Every example has a natural language intent and its corresponding python snippet.  In addition to the manually annotated dataset, there are also 598,237 mined intent-snippet pairs. These examples are similar to the hand-annotated ones except that they contain a probability if the pair is valid.",
            "S2 Citation Count (September 2023)": 177,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language learning",
                "Data processing",
                "Language processing",
                "Language and communication",
                "String manipulation",
                "Problem-solving",
                "String concatenation",
                "Text concatenation",
                "Programming",
                "Text manipulation"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Yin2018LearningTM,\n author = {Pengcheng Yin and Bowen Deng and Edgar Chen and Bogdan Vasilescu and Graham Neubig},\n booktitle = {IEEE Working Conference on Mining Software Repositories},\n journal = {2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)},\n pages = {476-486},\n title = {Learning to Mine Aligned Code and Natural Language Pairs from Stack Overflow},\n year = {2018}\n}\n"
    },
    "fc-sni-conll2022": {
        "Unique Dataset Identifier": "fc-sni-conll2022",
        "Dataset Name": "conll2022",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/viewer/?dataset=conll2002",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/viewer/?dataset=conll2002",
        "Paper Title": "Introduction to the CoNLL-2002 Shared Task: Language-Independent Named Entity Recognition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/conll-2002",
        "ArXiv URL": "https://arxiv.org/abs/cs/0209010",
        "Semantic Scholar Corpus ID": 3262157,
        "Languages": [
            "Dutch",
            "English"
        ],
        "Task Categories": [
            "Part-of-Speech Tagging"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9421,
            "Mean Inputs Length": 663.353,
            "Mean Targets Length": 61.2575,
            "Max Inputs Length": 3275,
            "Max Targets Length": 3535,
            "Min Inputs Length": 412,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "de morgen newspaper",
            "spanish efe news agency"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Antwerp"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/W02-2024.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1543_conll2002_parts_of_speech_tagging_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "conll2002",
            "HF Config": "es",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2002-01-01",
            "S2 Date": "2002-08-31",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "The shared task of CoNLL-2002 concerns language-independent named entity recognition. The types of named entities include: persons, locations, organizations and names of miscellaneous entities that do not belong to the previous three groups. The participants of the shared task were offered training and test data for at least two languages. Information sources other than the training data might have been used in this shared task.",
            "S2 Citation Count (September 2023)": 753,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Linguistics",
                "Translation",
                "Part-of-speech tagging",
                "Grammar analysis",
                "Dutch language",
                "Language learning",
                "Grammar"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sang2002IntroductionTT,\n author = {E. T. K. Sang},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {Introduction to the CoNLL-2002 Shared Task: Language-Independent Named Entity Recognition},\n volume = {cs.CL/0209010},\n year = {2002}\n}\n"
    },
    "fc-sni-conllpp": {
        "Unique Dataset Identifier": "fc-sni-conllpp",
        "Dataset Name": "conllpp",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/conllpp",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/conllpp",
        "Paper Title": "CrossWeigh: Training Named Entity Tagger from Imperfect Annotations",
        "Papers with Code URL": "https://paperswithcode.com/dataset/conll",
        "ArXiv URL": "https://arxiv.org/abs/1909.01441",
        "Semantic Scholar Corpus ID": 202540591,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7450,
            "Mean Inputs Length": 864.8921,
            "Mean Targets Length": 97.7893,
            "Max Inputs Length": 1838,
            "Max Targets Length": 472,
            "Min Inputs Length": 465,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reuters.com",
            "frankfurter rundshau newspaper"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Illinois Urbana-Champaign"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/D19-1519.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task610_conllpp_ner"
        ],
        "Inferred Metadata": {
            "HF Dataset": "conllpp",
            "HF Config": "conllpp",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-09-03",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 4304,
            "HF Likes (September 2023)": 4,
            "PwC Description": "CoNLL++ is a corrected version of the CoNLL03 NER dataset where 5.38% of the test sentences have been fixed.",
            "S2 Citation Count (September 2023)": 67,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Natural Language Processing",
                "Named entity recognition",
                "Language Processing",
                "Named Entity Recognition (NER)",
                "Named Entity Recognition",
                "Text analysis",
                "Sports",
                "Geography",
                "Natural Language Processing (NLP)",
                "Language processing"
            ]
        },
        "Derived from Datasets": [
            "CoNLL2003 NER dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Wang2019CrossWeighTN,\n author = {Zihan Wang and Jingbo Shang and Liyuan Liu and Lihao Lu and Jiacheng Liu and Jiawei Han},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {5153-5162},\n title = {CrossWeigh: Training Named Entity Tagger from Imperfect Annotations},\n year = {2019}\n}\n"
    },
    "fc-sni-conv_ai_2": {
        "Unique Dataset Identifier": "fc-sni-conv_ai_2",
        "Dataset Name": "conv_ai_2",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/conv_ai_2",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/conv_ai_2",
        "Paper Title": "The Second Conversational Intelligence Challenge (ConvAI2)",
        "Papers with Code URL": "https://paperswithcode.com/dataset/convai2",
        "ArXiv URL": "https://arxiv.org/abs/1902.00098",
        "Semantic Scholar Corpus ID": 59553505,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Speaker Identification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 227,
            "Mean Inputs Length": 2338.1278,
            "Mean Targets Length": 4.5419,
            "Max Inputs Length": 5882,
            "Max Targets Length": 15,
            "Min Inputs Length": 852,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "Facebook AI Research",
            "Moscow Institute of Physics and Technology",
            "Universite de Montreal",
            "McGill University",
            "Carnegie Mellon University",
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task855_conv_ai_2_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "conv_ai_2",
            "HF Config": "conv_ai_2",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Custom",
            "PwC License URL": "http://convai.io/",
            "PwC Date": "2019-01-01",
            "S2 Date": "2019-01-31",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1338,
            "HF Likes (September 2023)": 25,
            "PwC Description": "The ConvAI2 NeurIPS competition aimed at finding approaches to creating high-quality dialogue agents capable of meaningful open domain conversation. The ConvAI2 dataset for training models is based on the PERSONA-CHAT dataset. The speaker pairs each have assigned profiles coming from a set of 1155 possible personas (at training time), each consisting of at least 5 profile sentences, setting aside 100 never seen before personas for validation. As the original PERSONA-CHAT test set was released, a new hidden test set consisted of 100 new personas and over 1,015 dialogs was created by crowdsourced workers.\n\nTo avoid modeling that takes advantage of trivial word overlap, additional rewritten sets of the same train and test personas were crowdsourced, with related sentences that are rephrases, generalizations or specializations, rendering the task much more challenging. For example “I just got my nails done” is revised as “I love to pamper myself on a regular basis” and “I am on a diet now” is revised as “I need to lose weight.”\n\nThe training, validation and hidden test sets consists of 17,878, 1,000 and 1,015 dialogues, respectively.",
            "S2 Citation Count (September 2023)": 288,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language understanding",
                "Social media",
                "Social interaction",
                "Human-computer interaction",
                "Artificial Intelligence",
                "Communication",
                "Technology"
            ]
        },
        "Derived from Datasets": [
            "Persona-chat dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Dinan2019TheSC,\n author = {Emily Dinan and V. Logacheva and Valentin Malykh and Alexander H. Miller and Kurt Shuster and Jack Urbanek and Douwe Kiela and Arthur Szlam and Iulian Serban and Ryan Lowe and Shrimai Prabhumoye and A. Black and Alexander I. Rudnicky and Jason Williams and Joelle Pineau and M. Burtsev and J. Weston},\n booktitle = {The NeurIPS '18 Competition},\n journal = {ArXiv},\n title = {The Second Conversational Intelligence Challenge (ConvAI2)},\n volume = {abs/1902.00098},\n year = {2019}\n}\n"
    },
    "fc-sni-copa_hr": {
        "Unique Dataset Identifier": "fc-sni-copa_hr",
        "Dataset Name": "copa_hr",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/classla/copa_hr",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/classla/copa_hr",
        "Paper Title": "BERTić - The Transformer Language Model for Bosnian, Croatian, Montenegrin and Serbian",
        "Papers with Code URL": "https://paperswithcode.com/dataset/copa-hr",
        "ArXiv URL": "https://arxiv.org/abs/2005.00333",
        "Semantic Scholar Corpus ID": 233296168,
        "Languages": [
            "Croatian",
            "English"
        ],
        "Task Categories": [
            "Cause Effect Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1952,
            "Mean Inputs Length": 920.8417,
            "Mean Targets Length": 27.4734,
            "Max Inputs Length": 1260,
            "Max Targets Length": 71,
            "Min Inputs Length": 675,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "human"
        ],
        "Model Generated": [],
        "Creators": [
            "Joˇzef Stefan Institute",
            "Faculty of Humanities and Social Sciences\nIvana Luˇci´ca"
        ],
        "Licenses": [
            {
                "License": "BSD 2-Clause License",
                "License URL": "https://people.ict.usc.edu/~gordon/copa.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1626_copa_hr_question_answering"
        ],
        "Inferred Metadata": {
            "HF Dataset": "classla/copa_hr",
            "HF Config": "copa_hr",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/4.0/",
            "PwC Date": "2021-04-19",
            "S2 Date": "2021-04-19",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2021-04-28",
            "HF Downloads (September 2023)": 537,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The COPA-HR dataset (Choice of plausible alternatives in Croatian) is a translation of the English COPA dataset by following the XCOPA dataset translation methodology. The dataset consists of 1000 premises (My body cast a shadow over the grass), each given a question (What is the cause?), and two choices (The sun was rising; The grass was cut), with a label encoding which of the choices is more plausible given the annotator or translator (The sun was rising).",
            "S2 Citation Count (September 2023)": 25,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Travel",
                "Cultural understanding",
                "Croatian culture",
                "Croatian language",
                "Daily routine",
                "Linguistics",
                "Health",
                "Language learning",
                "Cultural differences",
                "Translation"
            ]
        },
        "Derived from Datasets": [
            "COPA dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Ljubešić2021BERTićT,\n author = {N. Ljubešić and D. Lauc},\n booktitle = {Workshop on Balto-Slavic Natural Language Processing},\n journal = {ArXiv},\n title = {BERTić - The Transformer Language Model for Bosnian, Croatian, Montenegrin and Serbian},\n volume = {abs/2104.09243},\n year = {2021}\n}\n"
    },
    "fc-sni-cosmosqa": {
        "Unique Dataset Identifier": "fc-sni-cosmosqa",
        "Dataset Name": "cosmosqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://leaderboard.allenai.org/cosmosqa/submissions/about",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/cosmos_qa",
        "Paper Title": "Cosmos QA: Machine Reading Comprehension with Contextual Commonsense Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/cosmosqa",
        "ArXiv URL": "https://arxiv.org/abs/1909.00277",
        "Semantic Scholar Corpus ID": 202540590,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 239,
            "Mean Inputs Length": 894.1883,
            "Mean Targets Length": 3.6987,
            "Max Inputs Length": 1914,
            "Max Targets Length": 13,
            "Min Inputs Length": 396,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web",
            "icwsm.org/data"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Illinois Urbana-Champaign",
            "AI2",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://huggingface.co/datasets/cosmos_qa#licensing-information"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task022_cosmosqa_passage_inappropriate_binary"
        ],
        "Inferred Metadata": {
            "HF Dataset": "cosmos_qa",
            "HF Config": "default",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2019-01-01",
            "S2 Date": "2019-08-31",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 6722,
            "HF Likes (September 2023)": 6,
            "PwC Description": "CosmosQA is a large-scale dataset of 35.6K problems that require commonsense-based reading comprehension, formulated as multiple-choice questions. It focuses on reading between the lines over a diverse collection of people’s everyday narratives, asking questions concerning on the likely causes or effects of events that require reasoning beyond the exact text spans in the context.",
            "S2 Citation Count (September 2023)": 295,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Education",
                "Reading comprehension",
                "Content moderation",
                "Daily routine",
                "Language understanding",
                "Relationships",
                "Personal experiences",
                "Context analysis",
                "Sleep",
                "Communication"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Huang2019CosmosQM,\n author = {Lifu Huang and Ronan Le Bras and Chandra Bhagavatula and Yejin Choi},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {2391-2401},\n title = {Cosmos QA: Machine Reading Comprehension with Contextual Commonsense Reasoning},\n year = {2019}\n}\n"
    },
    "fc-sni-country_abbreviation_dataset": {
        "Unique Dataset Identifier": "fc-sni-country_abbreviation_dataset",
        "Dataset Name": "country_abbreviation_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://data.world/samayo/country-abbreviation/workspace/file?filename=country-abbreviation.json",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 479,
            "Mean Inputs Length": 203.4259,
            "Mean Targets Length": 2.6284,
            "Max Inputs Length": 372,
            "Max Targets Length": 12,
            "Min Inputs Length": 115,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "data.world/samayo/country-abbreviation/workspace/"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1314_country_abbreviation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Cultural diversity",
                "Country abbreviations",
                "Abbreviations",
                "Geography",
                "Country names",
                "Language and linguistics",
                "General knowledge",
                "Language",
                "Cultural identity"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-country_barcode_prefix_dataset": {
        "Unique Dataset Identifier": "fc-sni-country_barcode_prefix_dataset",
        "Dataset Name": "country_barcode_prefix_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://data.world/samayo/countries-by-barcode-prefix/workspace/file?filename=country-by-barcode-prefix.json",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 191,
            "Mean Inputs Length": 450.3979,
            "Mean Targets Length": 3.644,
            "Max Inputs Length": 591,
            "Max Targets Length": 13,
            "Min Inputs Length": 379,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "github"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1319_country_by_barcode_prefix"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "International trade and commerce",
                "Country identification",
                "Barcode systems",
                "Barcodes",
                "Country-specific regulations and standards",
                "Barcodes and product identification",
                "International trade",
                "Product labeling"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-country_calling_code_dataset": {
        "Unique Dataset Identifier": "fc-sni-country_calling_code_dataset",
        "Dataset Name": "country_calling_code_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://data.world/samayo/country-calling-code/workspace/file?filename=country-by-calling-code.json",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 555,
            "Mean Inputs Length": 290.0595,
            "Mean Targets Length": 4.5586,
            "Max Inputs Length": 462,
            "Max Targets Length": 21,
            "Min Inputs Length": 197,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "data.world/samayo/country-abbreviation/workspace/"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1317_country_calling_code"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "International calling",
                "Travel",
                "Language and communication",
                "Culture",
                "Geography",
                "Cultural awareness",
                "Telecommunications",
                "International calling codes"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-country_capital_city_dataset": {
        "Unique Dataset Identifier": "fc-sni-country_capital_city_dataset",
        "Dataset Name": "country_capital_city_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://data.world/samayo/country-capital-city/workspace/file?filename=country-by-capital-city.json",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 475,
            "Mean Inputs Length": 198.5684,
            "Mean Targets Length": 8.4442,
            "Max Inputs Length": 360,
            "Max Targets Length": 23,
            "Min Inputs Length": 109,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "data.world/samayo/country-abbreviation/workspace/"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1146_country_capital"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "General knowledge",
                "Religion",
                "Capital cities",
                "Geography",
                "International relations",
                "Politics",
                "Translation",
                "Culture"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-country_continent_dataset": {
        "Unique Dataset Identifier": "fc-sni-country_continent_dataset",
        "Dataset Name": "country_continent_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/drmonkeyninja/country.json/blob/master/src/country-continent.json",
        "GitHub URL": "https://github.com/drmonkeyninja/country.json/blob/master/src/country-continent.json",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 477,
            "Mean Inputs Length": 208.717,
            "Mean Targets Length": 7.9287,
            "Max Inputs Length": 386,
            "Max Targets Length": 23,
            "Min Inputs Length": 116,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "github"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1321_country_continent"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ],
            "Text Topics": [
                "History",
                "Geography",
                "Trivia",
                "Education",
                "Travel",
                "General knowledge",
                "Cultural awareness"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-country_currency_dataset": {
        "Unique Dataset Identifier": "fc-sni-country_currency_dataset",
        "Dataset Name": "country_currency_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://data.world/samayo/country-currency/file/country-by-currency-name.json",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 474,
            "Mean Inputs Length": 178.9325,
            "Mean Targets Length": 13.4536,
            "Max Inputs Length": 308,
            "Max Targets Length": 27,
            "Min Inputs Length": 92,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "data.world/samayo/country-abbreviation/workspace/"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1147_country_currency"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Brazil",
                "Currency",
                "African countries",
                "General knowledge",
                "European Union",
                "Travel",
                "Geography"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-country_domain_tld_dataset": {
        "Unique Dataset Identifier": "fc-sni-country_domain_tld_dataset",
        "Dataset Name": "country_domain_tld_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://data.world/samayo/countries-tld/workspace/file?filename=country-by-domain-tld.json",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 500,
            "Mean Inputs Length": 359.65,
            "Mean Targets Length": 3.592,
            "Max Inputs Length": 515,
            "Max Targets Length": 13,
            "Min Inputs Length": 277,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "data.world/samayo/country-abbreviation/workspace/"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1320_country_domain_tld"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Internet",
                "Internet domains",
                "Geography",
                "Internet and technology",
                "Country-specific information",
                "Language",
                "Language and communication",
                "Internet and website domains",
                "Country information",
                "Country codes"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-country_government_type_dataset": {
        "Unique Dataset Identifier": "fc-sni-country_government_type_dataset",
        "Dataset Name": "country_government_type_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/drmonkeyninja/country.json/blob/master/src/country-government-type.json",
        "GitHub URL": "https://github.com/drmonkeyninja/country.json/blob/master/src/country-government-type.json",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 443,
            "Mean Inputs Length": 449.93,
            "Mean Targets Length": 16.3093,
            "Max Inputs Length": 627,
            "Max Targets Length": 54,
            "Min Inputs Length": 358,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "github"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1322_country_government_type"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ],
            "Text Topics": [
                "International relations",
                "Geography",
                "Government systems",
                "Political systems",
                "Country governance",
                "Politics",
                "World politics",
                "World history",
                "Government types",
                "Country classification"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-country_independence_year_dataset": {
        "Unique Dataset Identifier": "fc-sni-country_independence_year_dataset",
        "Dataset Name": "country_independence_year_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/drmonkeyninja/country.json/blob/master/src/country-independence-date.json",
        "GitHub URL": "https://github.com/drmonkeyninja/country.json/blob/master/src/country-independence-date.json",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 384,
            "Mean Inputs Length": 380.388,
            "Mean Targets Length": 4.6198,
            "Max Inputs Length": 529,
            "Max Targets Length": 14,
            "Min Inputs Length": 302,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "github"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1426_country_independence_year"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ],
            "Text Topics": [
                "History",
                "Geography",
                "Politics",
                "General knowledge"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-country_iso_numeric_dataset": {
        "Unique Dataset Identifier": "fc-sni-country_iso_numeric_dataset",
        "Dataset Name": "country_iso_numeric_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/drmonkeyninja/country.json/blob/master/src/country-iso-numeric.json",
        "GitHub URL": "https://github.com/drmonkeyninja/country.json/blob/master/src/country-iso-numeric.json",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 479,
            "Mean Inputs Length": 389.2818,
            "Mean Targets Length": 3.6138,
            "Max Inputs Length": 543,
            "Max Targets Length": 13,
            "Min Inputs Length": 308,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "github"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1425_country_iso_numeric"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ],
            "Text Topics": [
                "International organizations",
                "Country codes",
                "Standardization",
                "Geography"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-country_national_dish_dataset": {
        "Unique Dataset Identifier": "fc-sni-country_national_dish_dataset",
        "Dataset Name": "country_national_dish_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/drmonkeyninja/country.json/blob/master/src/country-by-national-dish.json",
        "GitHub URL": "https://github.com/drmonkeyninja/country.json/blob/master/src/country-by-national-dish.json",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 333,
            "Mean Inputs Length": 326.7177,
            "Mean Targets Length": 19.5916,
            "Max Inputs Length": 477,
            "Max Targets Length": 66,
            "Min Inputs Length": 231,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "github"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1318_country_national_dish"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ],
            "Text Topics": [
                "Food",
                "Geography and culture",
                "Cultural traditions",
                "Geography and countries",
                "National identity",
                "Culture and traditions",
                "Geography",
                "Food and cuisine",
                "Culture"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-country_region_in_world_dataset": {
        "Unique Dataset Identifier": "fc-sni-country_region_in_world_dataset",
        "Dataset Name": "country_region_in_world_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/drmonkeyninja/country.json/blob/master/src/country-region-in-world.json",
        "GitHub URL": "https://github.com/drmonkeyninja/country.json/blob/master/src/country-region-in-world.json",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 483,
            "Mean Inputs Length": 671.8758,
            "Mean Targets Length": 14.3478,
            "Max Inputs Length": 852,
            "Max Targets Length": 35,
            "Min Inputs Length": 575,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "github"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1427_country_region_in_world"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 0,
            "GitHub Topics": [
                ""
            ],
            "Text Topics": [
                "Geography",
                "World regions",
                "Travel",
                "Culture"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-craigslist_bargains": {
        "Unique Dataset Identifier": "fc-sni-craigslist_bargains",
        "Dataset Name": "craigslist_bargains",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/craigslist_bargains",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/craigslist_bargains",
        "Paper Title": "Decoupling Strategy and Generation in Negotiation Dialogues",
        "Papers with Code URL": "https://paperswithcode.com/dataset/craigslistbargains",
        "ArXiv URL": "https://arxiv.org/abs/1808.09637",
        "Semantic Scholar Corpus ID": 52119091,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Dialogue State Tracking"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 384,
            "Mean Inputs Length": 2171.737,
            "Mean Targets Length": 8.4974,
            "Max Inputs Length": 3940,
            "Max Targets Length": 18,
            "Min Inputs Length": 1258,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "craigslist.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/stanfordnlp/cocoa/tree/master#cocoa-collaborative-communicating-agents"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task766_craigslist_bargains_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "craigslist_bargains",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-08-29",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1137,
            "HF Likes (September 2023)": 6,
            "PwC Description": "A richer dataset based on real items on Craigslist.",
            "S2 Citation Count (September 2023)": 99,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Sales strategies",
                "Sales",
                "Business",
                "Sales techniques",
                "Communication",
                "Negotiation skills"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{He2018DecouplingSA,\n author = {He He and Derek Chen and Anusha Balakrishnan and Percy Liang},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Decoupling Strategy and Generation in Negotiation Dialogues},\n volume = {abs/1808.09637},\n year = {2018}\n}\n"
    },
    "fc-sni-creak_2018": {
        "Unique Dataset Identifier": "fc-sni-creak_2018",
        "Dataset Name": "creak_2018",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/pdf/2109.01653.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/amydeng2000/CREAK",
        "Paper Title": "CREAK: A Dataset for Commonsense Reasoning over Entity Knowledge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/creak",
        "ArXiv URL": "https://arxiv.org/abs/2109.01653",
        "Semantic Scholar Corpus ID": 237417284,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Fact Verification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11945,
            "Mean Inputs Length": 747.9675,
            "Mean Targets Length": 5.082,
            "Max Inputs Length": 2260,
            "Max Targets Length": 15,
            "Min Inputs Length": 493,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "The University of Texas at Austin"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task403_creak_commonsense_inference"
        ],
        "Inferred Metadata": {
            "HF Dataset": "amydeng2000/CREAK",
            "HF Config": "amydeng2000--CREAK",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/4.0/legalcode",
            "PwC Date": "2021-09-03",
            "S2 Date": "2021-09-03",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-11-16",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "A testbed for commonsense reasoning about entity knowledge, bridging fact-checking about entities with commonsense inferences.",
            "S2 Citation Count (September 2023)": 30,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Logic",
                "Fact-checking",
                "Reasoning and logic",
                "Critical thinking",
                "Education",
                "Knowledge evaluation",
                "General knowledge"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Onoe2021CREAKAD,\n author = {Yasumasa Onoe and Michael J.Q. Zhang and Eunsol Choi and Greg Durrett},\n booktitle = {NeurIPS Datasets and Benchmarks},\n journal = {ArXiv},\n title = {CREAK: A Dataset for Commonsense Reasoning over Entity Knowledge},\n volume = {abs/2109.01653},\n year = {2021}\n}\n"
    },
    "fc-sni-crows_pairs": {
        "Unique Dataset Identifier": "fc-sni-crows_pairs",
        "Dataset Name": "crows_pairs",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/nyu-mll/crows-pairs",
        "GitHub URL": "https://github.com/nyu-mll/crows-pairs",
        "Hugging Face URL": "https://huggingface.co/datasets/crows_pairs",
        "Paper Title": "CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models",
        "Papers with Code URL": "https://paperswithcode.com/dataset/crows-pairs",
        "ArXiv URL": "https://arxiv.org/abs/2010.00133",
        "Semantic Scholar Corpus ID": 222090785,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Stereotype Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6021,
            "Mean Inputs Length": 644.6014,
            "Mean Targets Length": 13.1025,
            "Max Inputs Length": 1040,
            "Max Targets Length": 25,
            "Min Inputs Length": 412,
            "Min Targets Length": 10,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/nyu-mll/crows-pairs#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task316_crows-pairs_classification_stereotype"
        ],
        "Inferred Metadata": {
            "HF Dataset": "crows_pairs",
            "HF Config": "crows_pairs",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-09-30",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2560,
            "HF Likes (September 2023)": 3,
            "PwC Description": "CrowS-Pairs has 1508 examples that cover stereotypes dealing with nine types of bias, like race, religion, and age. In CrowS-Pairs a model is presented with two sentences: one that is more stereotyping and another that is less stereotyping. The data focuses on stereotypes about historically disadvantaged groups and contrasts them with advantaged groups.",
            "S2 Citation Count (September 2023)": 257,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Nangia2020CrowSPairsAC,\n author = {Nikita Nangia and Clara Vania and Rasika Bhalerao and Samuel R. Bowman},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {1953-1967},\n title = {CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models},\n year = {2020}\n}\n"
    },
    "fc-sni-cuad": {
        "Unique Dataset Identifier": "fc-sni-cuad",
        "Dataset Name": "cuad",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/cuad",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/cuad",
        "Paper Title": "CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review",
        "Papers with Code URL": "https://paperswithcode.com/dataset/cuad",
        "ArXiv URL": "https://arxiv.org/abs/2103.06268",
        "Semantic Scholar Corpus ID": 232170369,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 837,
            "Mean Inputs Length": 83185.5675,
            "Mean Targets Length": 322.5436,
            "Max Inputs Length": 476927,
            "Max Targets Length": 1659,
            "Min Inputs Length": 1688,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "sec.gov/edgar/about"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Berkeley",
            "The Nueva School"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://www.atticusprojectai.org/cuad"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task597_cuad_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "cuad",
            "HF Config": "default",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2021-03-10",
            "S2 Date": "2021-03-10",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1607,
            "HF Likes (September 2023)": 27,
            "PwC Description": "Contract Understanding Atticus Dataset (CUAD) is a dataset for legal contract review. CUAD was created with dozens of legal experts from The Atticus Project\nand consists of over 13,000 annotations. The task is to highlight salient portions of a contract that are important for a human to review.",
            "S2 Citation Count (September 2023)": 65,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Contractual obligations",
                "Legal contracts and clauses",
                "Business agreements",
                "Insurance policies and coverage",
                "Risk management and liability",
                "Insurance policies and requirements",
                "Insurance policies",
                "Licensing agreements",
                "Intellectual property rights"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hendrycks2021CUADAE,\n author = {Dan Hendrycks and Collin Burns and Anya Chen and Spencer Ball},\n booktitle = {NeurIPS Datasets and Benchmarks},\n journal = {ArXiv},\n title = {CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review},\n volume = {abs/2103.06268},\n year = {2021}\n}\n"
    },
    "fc-sni-curated_from_stack_overflow___english.": {
        "Unique Dataset Identifier": "fc-sni-curated_from_stack_overflow___english.",
        "Dataset Name": "curated_from_stack_overflow___english.",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://data.stackexchange.com/english/queries",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 805,
            "Mean Inputs Length": 1746.9627,
            "Mean Targets Length": 723.2236,
            "Max Inputs Length": 12508,
            "Max Targets Length": 8283,
            "Min Inputs Length": 705,
            "Min Targets Length": 29,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "stackexchange.com"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task225_english_language_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language and Linguistics",
                "Linguistics",
                "English language and grammar",
                "Vocabulary and Definitions",
                "Grammar",
                "Language and grammar",
                "General knowledge",
                "Language and Communication",
                "Language and linguistics",
                "Language usage"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-curiosity_dialogs": {
        "Unique Dataset Identifier": "fc-sni-curiosity_dialogs",
        "Dataset Name": "curiosity_dialogs",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/facebookresearch/curiosity",
        "GitHub URL": "https://github.com/facebookresearch/curiosity",
        "Hugging Face URL": "https://huggingface.co/datasets/curiosity_dialogs",
        "Paper Title": "Information Seeking in the Spirit of Learning: A Dataset for Conversational Curiosity",
        "Papers with Code URL": "https://paperswithcode.com/dataset/curiosity",
        "ArXiv URL": "https://arxiv.org/abs/2005.00172",
        "Semantic Scholar Corpus ID": 218470317,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Dialogue Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12999,
            "Mean Inputs Length": 978.6289,
            "Mean Targets Length": 137.7837,
            "Max Inputs Length": 3689,
            "Max Targets Length": 834,
            "Min Inputs Length": 322,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Maryland",
            "Meta"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/2020.emnlp-main.655.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task576_curiosity_dialogs_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "curiosity_dialogs",
            "HF Config": "curiosity_dialogs",
            "HF Config License": "Custom",
            "HF Yaml License": "CC BY-NC 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 592,
            "HF Likes (September 2023)": 5,
            "PwC Description": "The Curiosity dataset consists of 14K dialogs (with 181K utterances) with fine-grained knowledge groundings, dialog act annotations, and other auxiliary annotation. In this dataset users and virtual assistants converse about geographic topics like geopolitical entities and locations. This dataset is annotated with pre-existing user knowledge, message-level dialog acts, grounding to Wikipedia, and user reactions to messages.",
            "S2 Citation Count (September 2023)": 7,
            "GitHub Stars": 10,
            "GitHub Topics": [],
            "Text Topics": [
                "Education",
                "International relations",
                "Cultural diversity",
                "Travel",
                "Religion",
                "History",
                "General knowledge",
                "Culture",
                "Demographics",
                "Geography"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Rodriguez2020InformationSI,\n author = {Pedro Rodriguez and Paul A. Crook and Seungwhan Moon and Zhiguang Wang},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {8153-8172},\n title = {Information Seeking in the Spirit of Learning: A Dataset for Conversational Curiosity},\n year = {2020}\n}\n"
    },
    "fc-sni-dailydialog": {
        "Unique Dataset Identifier": "fc-sni-dailydialog",
        "Dataset Name": "dailydialog",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/daily_dialog",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/daily_dialog",
        "Paper Title": "DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset",
        "Papers with Code URL": "https://paperswithcode.com/dataset/dailydialog",
        "ArXiv URL": "https://arxiv.org/abs/1710.03957",
        "Semantic Scholar Corpus ID": 11267601,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Dialogue Act Recognition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 999,
            "Mean Inputs Length": 603.1972,
            "Mean Targets Length": 10.2192,
            "Max Inputs Length": 1727,
            "Max Targets Length": 21,
            "Min Inputs Length": 422,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Chinese Academy of Science",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "http://yanran.li/dailydialog"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1531_daily_dialog_type_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "daily_dialog",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Academic Research Purposes Only",
            "PwC License URL": "http://yanran.li/dailydialog",
            "PwC Date": "2017-01-01",
            "S2 Date": "2017-10-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 7596,
            "HF Likes (September 2023)": 59,
            "PwC Description": "DailyDialog is a high-quality multi-turn open-domain English dialog dataset. It contains 13,118 dialogues split into a training set with 11,118 dialogues and validation and test sets with 1000 dialogues each. On average there are around 8 speaker turns per dialogue with around 15 tokens per turn.",
            "S2 Citation Count (September 2023)": 856,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Information-seeking",
                "Conversation analysis",
                "Language",
                "Information retrieval",
                "Education",
                "Language understanding",
                "Natural language processing"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Li2017DailyDialogAM,\n author = {Yanran Li and Hui Su and Xiaoyu Shen and Wenjie Li and Ziqiang Cao and Shuzi Niu},\n booktitle = {International Joint Conference on Natural Language Processing},\n journal = {ArXiv},\n title = {DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset},\n volume = {abs/1710.03957},\n year = {2017}\n}\n"
    },
    "fc-sni-dais": {
        "Unique Dataset Identifier": "fc-sni-dais",
        "Dataset Name": "dais",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/taka-yamakoshi/neural_constructions",
        "GitHub URL": "https://github.com/taka-yamakoshi/neural_constructions",
        "Hugging Face URL": "",
        "Paper Title": "Investigating representations of verb bias in neural language models",
        "Papers with Code URL": "https://paperswithcode.com/dataset/dais",
        "ArXiv URL": "https://arxiv.org/abs/2010.02375v2",
        "Semantic Scholar Corpus ID": 222140794,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Paraphrase Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9990,
            "Mean Inputs Length": 400.777,
            "Mean Targets Length": 40.6666,
            "Max Inputs Length": 608,
            "Max Targets Length": 75,
            "Min Inputs Length": 249,
            "Min Targets Length": 22,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Princeton University",
            "University of Tokyo"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/2010.02375v2.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task132_dais_text_modification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-05",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "A large benchmark dataset containing 50K human judgments for 5K distinct sentence pairs in the English dative alternation. This dataset includes 200 unique verbs and systematically varies the definiteness and length of arguments.",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language",
                "Grammar and sentence structure",
                "Language and communication",
                "Language learning",
                "Language construction",
                "Daily routine",
                "Translation",
                "Communication",
                "Grammar"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Hawkins2020InvestigatingRO,\n author = {Robert D. Hawkins and Takateru Yamakoshi and T. Griffiths and A. Goldberg},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {4653-4663},\n title = {Investigating Representations of Verb Bias in Neural Language Models},\n year = {2020}\n}\n"
    },
    "fc-sni-dbpedia_14": {
        "Unique Dataset Identifier": "fc-sni-dbpedia_14",
        "Dataset Name": "dbpedia_14",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/dbpedia_14",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/dbpedia_14",
        "Paper Title": "DBpedia – A large-scale, multilingual knowledge base extracted from Wikipedia ",
        "Papers with Code URL": "https://paperswithcode.com/dataset/dbpedia",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 1181640,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6092,
            "Mean Inputs Length": 1017.7774,
            "Mean Targets Length": 1.9291,
            "Max Inputs Length": 1986,
            "Max Targets Length": 12,
            "Min Inputs Length": 481,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Leipzig",
            "University of Mannheim",
            "OpenLink Software",
            "Hasso-Plattner-Institute for IT-Systems Engineering",
            "Neofonie GmbH",
            "Kno.e.sis",
            "Brox IT-Solutions GmbH"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://www.researchgate.net/publication/259828897_DBpedia_-_A_Large-scale_Multilingual_Knowledge_Base_Extracted_from_Wikipedia"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task629_dbpedia_14_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "dbpedia_14",
            "HF Config": "dbpedia_14",
            "HF Config License": "CC BY-SA 3.0",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "https://en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License",
            "PwC Date": "2007-01-01",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "DBpedia (from \"DB\" for \"database\") is a project aiming to extract structured content from the information created in the Wikipedia project. DBpedia allows users to semantically query relationships and properties of Wikipedia resources, including links to other related datasets.",
            "S2 Citation Count (September 2023)": 2816,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Classification",
                "Machine learning",
                "Text analysis",
                "Document categorization",
                "Text categorization",
                "Natural language processing",
                "Text classification",
                "Document analysis"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Lehmann2015DBpediaA,\n author = {Jens Lehmann and Robert Isele and Max Jakob and Anja Jentzsch and D. Kontokostas and Pablo N. Mendes and Sebastian Hellmann and M. Morsey and Patrick van Kleef and S. Auer and Christian Bizer},\n booktitle = {Semantic Web},\n journal = {Semantic Web},\n pages = {167-195},\n title = {DBpedia - A large-scale, multilingual knowledge base extracted from Wikipedia},\n volume = {6},\n year = {2015}\n}\n"
    },
    "fc-sni-ddo": {
        "Unique Dataset Identifier": "fc-sni-ddo",
        "Dataset Name": "ddo",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://esdurmus.github.io/ddo.md",
        "GitHub URL": "https://esdurmus.github.io/ddo.md",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1906.11310",
        "Semantic Scholar Corpus ID": 195699380,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 806,
            "Mean Inputs Length": 1621.4069,
            "Mean Targets Length": 5.5633,
            "Max Inputs Length": 2183,
            "Max Targets Length": 19,
            "Min Inputs Length": 1319,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "debate.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Cornell University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 3.0",
                "License URL": "https://esdurmus.github.io/ddo.md"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task375_classify_type_of_sentence_in_debate"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-26",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 18,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Debate techniques",
                "Language learning",
                "Politics",
                "Debate",
                "Ethics",
                "Education",
                "Language",
                "Communication",
                "Government policies",
                "Public policy"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Durmus2019ACF,\n author = {Esin Durmus and Claire Cardie},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {A Corpus for Modeling User and Language Effects in Argumentation on Online Debating},\n volume = {abs/1906.11310},\n year = {2019}\n}\n"
    },
    "fc-sni-deal_or_no_dialog": {
        "Unique Dataset Identifier": "fc-sni-deal_or_no_dialog",
        "Dataset Name": "deal_or_no_dialog",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/deal_or_no_dialog",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/deal_or_no_dialog",
        "Paper Title": "Deal or No Deal? End-to-End Learning of Negotiation Dialogues",
        "Papers with Code URL": "https://paperswithcode.com/dataset/negotiation-dialogues-dataset",
        "ArXiv URL": "https://arxiv.org/abs/1706.05125",
        "Semantic Scholar Corpus ID": 2454882,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Dialogue State Tracking"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8524,
            "Mean Inputs Length": 624.9673,
            "Mean Targets Length": 3.3322,
            "Max Inputs Length": 2558,
            "Max Targets Length": 13,
            "Min Inputs Length": 158,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "original"
        ],
        "Model Generated": [],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/1706.05125"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1384_deal_or_no_dialog_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "deal_or_no_dialog",
            "HF Config": "dialogues",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2017-06-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 814,
            "HF Likes (September 2023)": 5,
            "PwC Description": "This dataset consists of 5808 dialogues, based on 2236 unique scenarios. Each dialogue is converted into two training examples in the dataset, showing the complete conversation from the perspective of each agent. The perspectives differ on their input goals, output choice, and in special tokens marking whether a statement was read or written.",
            "S2 Citation Count (September 2023)": 315,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Personal preferences",
                "Negotiation",
                "Decision-making",
                "Personal belongings",
                "Agreement",
                "Exchange of goods",
                "Conflict resolution",
                "Bartering",
                "Problem-solving"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lewis2017DealON,\n author = {M. Lewis and Denis Yarats and Yann Dauphin and Devi Parikh and Dhruv Batra},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Deal or No Deal? End-to-End Learning of Negotiation Dialogues},\n volume = {abs/1706.05125},\n year = {2017}\n}\n"
    },
    "fc-sni-deceptive_opinion_spam_dataset": {
        "Unique Dataset Identifier": "fc-sni-deceptive_opinion_spam_dataset",
        "Dataset Name": "deceptive_opinion_spam_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://myleott.com/op-spam.html",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3159,
            "Mean Inputs Length": 1571.5239,
            "Mean Targets Length": 8.566,
            "Max Inputs Length": 8141,
            "Max Targets Length": 18,
            "Min Inputs Length": 259,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 3.0",
                "License URL": "https://myleott.com/op-spam.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task902_deceptive_opinion_spam_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Event experiences",
                "Sentiment analysis",
                "Travel",
                "Hotel reviews",
                "Hotel experience",
                "Travel experiences",
                "Customer service"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-defeasible_nli_atomic": {
        "Unique Dataset Identifier": "fc-sni-defeasible_nli_atomic",
        "Dataset Name": "defeasible_nli_atomic",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/rudinger/defeasible-nli",
        "GitHub URL": "https://github.com/rudinger/defeasible-nli",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/defeasible-nli",
        "Paper Title": "Thinking Like a Skeptic: Defeasible Inference in Natural Language",
        "Papers with Code URL": "https://paperswithcode.com/dataset/snli",
        "ArXiv URL": "https://aclanthology.org/2020.findings-emnlp.418/",
        "Semantic Scholar Corpus ID": 226283602,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12910,
            "Mean Inputs Length": 1070.861,
            "Mean Targets Length": 10.563,
            "Max Inputs Length": 1439,
            "Max Targets Length": 22,
            "Min Inputs Length": 851,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "University of Washington",
            "University of Maryland"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://ojs.aaai.org//index.php/AAAI/article/view/4160, https://www.aclweb.org/anthology/D15-1075/, https://www.aclweb.org/anthology/2020.emnlp-main.48/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task935_defeasible_nli_atomic_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/defeasible-nli",
            "HF Config": "atomic",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/4.0/",
            "PwC Date": "2015-01-01",
            "S2 Date": "2020-11-01",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2023-02-02",
            "HF Downloads (September 2023)": 100,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The SNLI dataset (Stanford Natural Language Inference) consists of 570k sentence-pairs manually labeled as entailment, contradiction, and neutral. Premises are image captions from Flickr30k, while hypotheses were generated by crowd-sourced annotators who were shown a premise and asked to generate entailing, contradicting, and neutral sentences. Annotators were instructed to judge the relation between sentences given that they describe the same event. Each pair is labeled as “entailment”, “neutral”, “contradiction” or “-”, where “-” indicates that an agreement could not be reached.",
            "S2 Citation Count (September 2023)": 51,
            "GitHub Stars": 12,
            "GitHub Topics": [],
            "Text Topics": [
                "Cognitive science",
                "Critical thinking",
                "Logic",
                "Natural language processing",
                "Inference and assumptions",
                "Argumentation",
                "Problem-solving",
                "Reasoning and logic",
                "Scientific method"
            ]
        },
        "Derived from Datasets": [
            "SNLI",
            "social chemestry",
            "ATOMIC"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Rudinger2020ThinkingLA,\n author = {Rachel Rudinger and Vered Shwartz and Jena D. Hwang and Chandra Bhagavatula and Maxwell Forbes and Ronan Le Bras and Noah A. Smith and Yejin Choi},\n booktitle = {Findings},\n pages = {4661-4675},\n title = {Thinking Like a Skeptic: Defeasible Inference in Natural Language},\n year = {2020}\n}\n"
    },
    "fc-sni-detoxifying_lms": {
        "Unique Dataset Identifier": "fc-sni-detoxifying_lms",
        "Dataset Name": "detoxifying_lms",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://aclanthology.org/2021.naacl-main.190/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "Detoxifying Language Models Risks Marginalizing Minority Voices",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2104.06390",
        "Semantic Scholar Corpus ID": 233219395,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 792,
            "Mean Inputs Length": 969.6856,
            "Mean Targets Length": 12.5366,
            "Max Inputs Length": 1527,
            "Max Targets Length": 22,
            "Min Inputs Length": 426,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "jigsaw civil comments",
            "twitter",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Berkeley",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task137_detoxifying-lms_classification_toxicity"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-04-12",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 63,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Xu2021DetoxifyingLM,\n author = {Albert Xu and Eshaan Pathak and Eric Wallace and Suchin Gururangan and Maarten Sap and D. Klein},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {2390-2397},\n title = {Detoxifying Language Models Risks Marginalizing Minority Voices},\n year = {2021}\n}\n"
    },
    "fc-sni-dialogre": {
        "Unique Dataset Identifier": "fc-sni-dialogre",
        "Dataset Name": "dialogre",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://dataset.org/dialogre/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/dialog_re",
        "Paper Title": "Dialogue-Based Relation Extraction",
        "Papers with Code URL": "https://paperswithcode.com/dataset/dialogre",
        "ArXiv URL": "https://arxiv.org/abs/2004.08056",
        "Semantic Scholar Corpus ID": 215814290,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Speaker Identification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 585,
            "Mean Inputs Length": 1984.0308,
            "Mean Targets Length": 8.6803,
            "Max Inputs Length": 4895,
            "Max Targets Length": 36,
            "Min Inputs Length": 380,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "friends tv show"
        ],
        "Model Generated": [],
        "Creators": [
            "Tencent AI Lab",
            "Cornell University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/2004.08056"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task906_dialogre_identify_names"
        ],
        "Inferred Metadata": {
            "HF Dataset": "dialog_re",
            "HF Config": "dialog_re",
            "HF Config License": "Custom",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-04-17",
            "S2 Date": "2020-04-17",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "DialogRE is the first human-annotated dialogue-based relation extraction dataset, containing 1,788 dialogues originating from the complete transcripts of a famous American television situation comedy Friends. The are annotations for all occurrences of 36 possible relation types that exist between an argument pair in a dialogue. DialogRE is available in English and Chinese.",
            "S2 Citation Count (September 2023)": 92,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Education",
                "Personal relationships",
                "Time management",
                "Relationships",
                "Social interactions",
                "Conversation",
                "Daily routine",
                "Communication",
                "General knowledge"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Yu2020DialogueBasedRE,\n author = {Dian Yu and Kai Sun and Claire Cardie and Dong Yu},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Dialogue-Based Relation Extraction},\n volume = {abs/2004.08056},\n year = {2020}\n}\n"
    },
    "fc-sni-diplomacy_detection": {
        "Unique Dataset Identifier": "fc-sni-diplomacy_detection",
        "Dataset Name": "diplomacy_detection",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/diplomacy_detection",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/diplomacy_detection",
        "Paper Title": "It Takes Two to Lie: One to Lie and One to Listen",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/2020.acl-main.353/",
        "Semantic Scholar Corpus ID": 220047262,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Dialogue Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 326,
            "Mean Inputs Length": 1594.1779,
            "Mean Targets Length": 118.9847,
            "Max Inputs Length": 5102,
            "Max Targets Length": 840,
            "Min Inputs Length": 524,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "diplomacy (online game)"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Maryland",
            "Cornell University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/2020.acl-main.353.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1590_diplomacy_text_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "diplomacy_detection",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-07-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 825,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 21,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Strategy in board games",
                "Game strategy",
                "International relations",
                "Strategy in Diplomacy",
                "Diplomacy strategy",
                "Diplomacy",
                "Board games"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Peskov2020ItTT,\n author = {Denis Peskov and Benny Cheng and Ahmed Elgohary and Joe Barrow and Cristian Danescu-Niculescu-Mizil and Jordan L. Boyd-Graber},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {3811-3854},\n title = {It Takes Two to Lie: One to Lie, and One to Listen},\n year = {2020}\n}\n"
    },
    "fc-sni-discofuse": {
        "Unique Dataset Identifier": "fc-sni-discofuse",
        "Dataset Name": "discofuse",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/google-research-datasets/discofuse",
        "GitHub URL": "https://github.com/google-research-datasets/discofuse",
        "Hugging Face URL": "https://huggingface.co/datasets/discofuse",
        "Paper Title": "DiscoFuse: A Large-Scale Dataset for Discourse-Based Sentence Fusion",
        "Papers with Code URL": "https://paperswithcode.com/dataset/discofuse",
        "ArXiv URL": "https://arxiv.org/abs/1902.10526",
        "Semantic Scholar Corpus ID": 67855928,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentence Composition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1189,
            "Mean Inputs Length": 529.4012,
            "Mean Targets Length": 104.5114,
            "Max Inputs Length": 954,
            "Max Targets Length": 234,
            "Min Inputs Length": 202,
            "Min Targets Length": 18,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "sports web articles"
        ],
        "Model Generated": [],
        "Creators": [
            "Tel Aviv University",
            "Google"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 3.0",
                "License URL": "https://github.com/google-research-datasets/discofuse#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task550_discofuse_sentence_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "discofuse",
            "HF Config": "discofuse-sport",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/3.0/",
            "PwC Date": "2019-02-27",
            "S2 Date": "2019-02-27",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "DiscoFuse was created by applying a rule-based splitting method on two corpora -\nsports articles crawled from the Web, and Wikipedia. See the paper for a detailed\ndescription of the dataset generation process and evaluation.\n\nDiscoFuse has two parts with 44,177,443 and 16,642,323 examples sourced from Sports articles and Wikipedia, respectively.\n\nFor each part, a random split is provided to train (98% of the examples), development (1%) and test (1%) sets. In addition, as the original data distribution is highly skewed (see details in the paper), a balanced version for each part is also provided.",
            "S2 Citation Count (September 2023)": 43,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Healthcare and hospitals",
                "Sports",
                "Donation and philanthropy",
                "Language and communication",
                "Linguistics",
                "Writing and composition",
                "Politics",
                "Donation and charity"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Geva2019DiscoFuseAL,\n author = {Mor Geva and Eric Malmi and Idan Szpektor and Jonathan Berant},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {DiscoFuse: A Large-Scale Dataset for Discourse-Based Sentence Fusion},\n volume = {abs/1902.10526},\n year = {2019}\n}\n"
    },
    "fc-sni-disfl_qa": {
        "Unique Dataset Identifier": "fc-sni-disfl_qa",
        "Dataset Name": "disfl_qa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/google-research-datasets/Disfl-QA",
        "GitHub URL": "https://github.com/google-research-datasets/Disfl-QA",
        "Hugging Face URL": "https://huggingface.co/datasets/disfl_qa",
        "Paper Title": "Disfl-QA: A Benchmark Dataset for Understanding Disfluencies in Question Answering",
        "Papers with Code URL": "https://paperswithcode.com/dataset/disfl-qa",
        "ArXiv URL": "https://arxiv.org/abs/2106.04016",
        "Semantic Scholar Corpus ID": 235368330,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Rewriting"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12994,
            "Mean Inputs Length": 391.1028,
            "Mean Targets Length": 58.9616,
            "Max Inputs Length": 852,
            "Max Targets Length": 194,
            "Min Inputs Length": 145,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Google",
            "The University of Texas at Austin",
            "Georgia Institute of Technology"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://github.com/google-research-datasets/Disfl-QA#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1195_disflqa_disfluent_to_fluent_conversion"
        ],
        "Inferred Metadata": {
            "HF Dataset": "disfl_qa",
            "HF Config": "default",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/4.0/",
            "PwC Date": "2021-06-08",
            "S2 Date": "2021-06-08",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "Disfl-QA is a targeted dataset for contextual disfluencies in an information seeking setting, namely question answering over Wikipedia passages. Disfl-QA builds upon the SQuAD-v2 dataset, where each question in the dev set is annotated to add a contextual disfluency using the paragraph as a source of distractors.\n\nThe final dataset consists of ~12k (disfluent question, answer) pairs. Over 90% of the disfluencies are corrections or restarts, making it a much harder test set for disfluency correction. Disfl-QA aims to fill a major gap between speech and NLP research community. We hope the dataset can serve as a benchmark dataset for testing robustness of models against disfluent inputs.",
            "S2 Citation Count (September 2023)": 20,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Sentence structure",
                "Sentence correction",
                "Communication",
                "History",
                "Language processing",
                "Language fluency",
                "Language and communication",
                "Sentence modification",
                "Linguistics"
            ]
        },
        "Derived from Datasets": [
            "SQuADv2"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Gupta2021DisflQAAB,\n author = {Aditya Gupta and Jiacheng Xu and Shyam Upadhyay and Diyi Yang and Manaal Faruqui},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Disfl-QA: A Benchmark Dataset for Understanding Disfluencies in Question Answering},\n volume = {abs/2106.04016},\n year = {2021}\n}\n"
    },
    "fc-sni-doqa": {
        "Unique Dataset Identifier": "fc-sni-doqa",
        "Dataset Name": "doqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "http://www.ixa.eus/node/12931",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/doqa",
        "Paper Title": "DoQA - Accessing Domain-Specific FAQs via Conversational QA",
        "Papers with Code URL": "https://paperswithcode.com/dataset/doqa",
        "ArXiv URL": "https://arxiv.org/abs/2005.01328",
        "Semantic Scholar Corpus ID": 218487043,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1445,
            "Mean Inputs Length": 2170.537,
            "Mean Targets Length": 53.2775,
            "Max Inputs Length": 5395,
            "Max Targets Length": 200,
            "Min Inputs Length": 693,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "movies.stackexchange.com",
            "travel.stackexchange.com",
            "cooking.stackexchange.com"
        ],
        "Model Generated": [],
        "Creators": [
            "University of the Basque Country",
            "Zurich University of Applied Sciences"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "http://www.ixa.eus/node/12931"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1437_doqa_cooking_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "doqa",
            "HF Config": "cooking",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 903,
            "HF Likes (September 2023)": 0,
            "PwC Description": "A dataset with 2,437 dialogues and 10,917 QA pairs. The dialogues are collected from three Stack Exchange sites using the Wizard of Oz method with crowdsourcing.",
            "S2 Citation Count (September 2023)": 45,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Kitchen appliances",
                "Food and ingredients",
                "Culinary arts",
                "Food preparation",
                "Cooking techniques",
                "Culinary techniques",
                "Cooking",
                "Food and beverages"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Campos2020DoQAA,\n author = {Jon Ander Campos and Arantxa Otegi and Aitor Soroa Etxabe and Jan Deriu and Mark Cieliebak and Eneko Agirre},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {DoQA - Accessing Domain-Specific FAQs via Conversational QA},\n volume = {abs/2005.01328},\n year = {2020}\n}\n"
    },
    "fc-sni-dream": {
        "Unique Dataset Identifier": "fc-sni-dream",
        "Dataset Name": "dream",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/nlpdata/dream",
        "GitHub URL": "https://github.com/nlpdata/dream",
        "Hugging Face URL": "https://huggingface.co/datasets/dream",
        "Paper Title": "DREAM: A Challenge Data Set and Models for Dialogue-Based Reading Comprehension",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1902.00164",
        "Semantic Scholar Corpus ID": 59553499,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12927,
            "Mean Inputs Length": 1102.0678,
            "Mean Targets Length": 116.2243,
            "Max Inputs Length": 5592,
            "Max Targets Length": 311,
            "Min Inputs Length": 366,
            "Min Targets Length": 39,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "Cornell University",
            "Tencent AI Lab",
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://github.com/nlpdata/dream/blob/master/license.txt"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task246_dream_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "dream",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-02-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 219,
            "GitHub Stars": 72,
            "GitHub Topics": [
                "dataset",
                "dialogue",
                "machine-reading-comprehension"
            ],
            "Text Topics": [
                "Social interactions",
                "Education",
                "Time management",
                "Decision-making",
                "Transportation",
                "Technology",
                "Geography",
                "Daily routine"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Sun2019DREAMAC,\n author = {Kai Sun and Dian Yu and Jianshu Chen and Dong Yu and Yejin Choi and Claire Cardie},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {217-231},\n title = {DREAM: A Challenge Data Set and Models for Dialogue-Based Reading Comprehension},\n volume = {7},\n year = {2019}\n}\n"
    },
    "fc-sni-dstc3": {
        "Unique Dataset Identifier": "fc-sni-dstc3",
        "Dataset Name": "dstc3",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/NathanDuran/DSTC3-Corpus",
        "GitHub URL": "https://github.com/NathanDuran/DSTC3-Corpus",
        "Hugging Face URL": "",
        "Paper Title": "A Corpus for Modeling User and Language Effects in Argumentation on Online Debating",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1906.11310",
        "Semantic Scholar Corpus ID": 195699380,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Summarization"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4491,
            "Mean Inputs Length": 2733.8753,
            "Mean Targets Length": 139.0134,
            "Max Inputs Length": 8456,
            "Max Targets Length": 194,
            "Min Inputs Length": 1097,
            "Min Targets Length": 94,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "debate.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Cornell University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/write_up.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1499_dstc3_summarization"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-26",
            "GitHub License": "GNU General Public License v3.0",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 18,
            "GitHub Stars": 0,
            "GitHub Topics": [
                "corpus",
                "corpus-data",
                "corpus-processing",
                "corpus-tools",
                "dialogue",
                "dialogues"
            ],
            "Text Topics": [
                "Travel",
                "Contact information for businesses",
                "Food and dining",
                "Location-based suggestions",
                "Technology",
                "Cuisine preferences",
                "Restaurant recommendations",
                "Contact information for venues",
                "Local recommendations"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Durmus2019ACF,\n author = {Esin Durmus and Claire Cardie},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {A Corpus for Modeling User and Language Effects in Argumentation on Online Debating},\n volume = {abs/1906.11310},\n year = {2019}\n}\n"
    },
    "fc-sni-dualrl": {
        "Unique Dataset Identifier": "fc-sni-dualrl",
        "Dataset Name": "dualrl",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/luofuli/DualRL",
        "GitHub URL": "https://github.com/luofuli/DualRL",
        "Hugging Face URL": "",
        "Paper Title": "A Dual Reinforcement Learning Framework for Unsupervised Text Style Transfer",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1905.10060",
        "Semantic Scholar Corpus ID": 165163728,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Style Transfer"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1005,
            "Mean Inputs Length": 380.5861,
            "Mean Targets Length": 45.7562,
            "Max Inputs Length": 644,
            "Max Targets Length": 106,
            "Min Inputs Length": 191,
            "Min Targets Length": 14,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "yelp",
            "yahoo"
        ],
        "Model Generated": [],
        "Creators": [
            "Peking University",
            "WeChat AI",
            "Peng Cheng Laboratory"
        ],
        "Licenses": [
            {
                "License": "Academic Research Purposes Only",
                "License URL": "https://github.com/luofuli/DualRL#dataset"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task927_yelp_negative_to_positive_style_transfer"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-05-24",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 136,
            "GitHub Stars": 260,
            "GitHub Topics": [
                "dual-learning",
                "reinceforcement-learning",
                "text-style-transfer",
                "unsupervised-machine-learning"
            ],
            "Text Topics": [
                "Customer experience",
                "Review conversion",
                "Restaurant reviews",
                "Communication",
                "Sentiment analysis",
                "Food and dining experience",
                "Customer service",
                "Customer satisfaction"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Luo2019ADR,\n author = {Fuli Luo and Peng Li and Jie Zhou and Pengcheng Yang and Baobao Chang and Zhifang Sui and Xu Sun},\n booktitle = {International Joint Conference on Artificial Intelligence},\n journal = {ArXiv},\n title = {A Dual Reinforcement Learning Framework for Unsupervised Text Style Transfer},\n volume = {abs/1905.10060},\n year = {2019}\n}\n"
    },
    "fc-sni-duorc": {
        "Unique Dataset Identifier": "fc-sni-duorc",
        "Dataset Name": "duorc",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/duorc/duorc",
        "GitHub URL": "https://github.com/duorc/duorc",
        "Hugging Face URL": "https://huggingface.co/datasets/duorc",
        "Paper Title": "DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension",
        "Papers with Code URL": "https://paperswithcode.com/dataset/duorc",
        "ArXiv URL": "https://arxiv.org/abs/1804.07927",
        "Semantic Scholar Corpus ID": 5071138,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10624,
            "Mean Inputs Length": 6861.7104,
            "Mean Targets Length": 75.8904,
            "Max Inputs Length": 74965,
            "Max Targets Length": 205,
            "Min Inputs Length": 1047,
            "Min Targets Length": 36,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "imdb.com"
        ],
        "Model Generated": [],
        "Creators": [
            "IBM",
            "Indian Institute of Technology"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/1804.07927"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task182_duorc_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "duorc",
            "HF Config": "SelfRC",
            "HF Config License": "Custom",
            "HF Yaml License": "MIT License",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2018-04-21",
            "S2 Date": "2018-04-01",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 8321,
            "HF Likes (September 2023)": 24,
            "PwC Description": "DuoRC contains 186,089 unique question-answer pairs created from a collection of 7680 pairs of movie plots where each pair in the collection reflects two versions of the same movie.\n\nWhy another RC dataset?\n\nDuoRC pushes the NLP community to address challenges on incorporating knowledge and reasoning in neural architectures for reading comprehension. It poses several interesting challenges such as:\n\n\nDuoRC using parallel plots is especially designed to contain a large number of questions with low lexical overlap between questions and their corresponding passages\nIt requires models to go beyond the content of the given passage itself and incorporate world-knowledge, background knowledge, and common-sense knowledge to arrive at the answer\nIt revolves around narrative passages from movie plots describing complex events and therefore naturally require complex reasoning (e.g. temporal reasoning, entailment, long-distance anaphoras, etc.) across multiple sentences to infer the answer to questions\nSeveral of the questions in DuoRC, while seeming relevant, cannot actually be answered from the given passage. This requires the model to detect the unanswerability of questions. This aspect is important for machines to achieve in industrial settings in particular",
            "S2 Citation Count (September 2023)": 161,
            "GitHub Stars": 15,
            "GitHub Topics": [
                "dataset",
                "nlp-machine-learning",
                "question-answering",
                "reading-comprehension"
            ],
            "Text Topics": [
                "Movies and entertainment",
                "Movies",
                "Literature",
                "Characters",
                "Entertainment",
                "Movie analysis",
                "Movie plot analysis",
                "Character analysis",
                "History"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Saha2018DuoRCTC,\n author = {Amrita Saha and Rahul Aralikatte and Mitesh M. Khapra and Karthik Sankaranarayanan},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1683-1693},\n title = {DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension},\n year = {2018}\n}\n"
    },
    "fc-sni-e_snli": {
        "Unique Dataset Identifier": "fc-sni-e_snli",
        "Dataset Name": "e_snli",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/OanaMariaCamburu/e-SNLI/",
        "GitHub URL": "https://github.com/OanaMariaCamburu/e-SNLI/",
        "Hugging Face URL": "https://huggingface.co/datasets/esnli",
        "Paper Title": "e-SNLI: Natural Language Inference with Natural Language Explanations",
        "Papers with Code URL": "https://paperswithcode.com/dataset/e-snli",
        "ArXiv URL": "https://arxiv.org/abs/1812.01193",
        "Semantic Scholar Corpus ID": 54040953,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 200,
            "Mean Inputs Length": 731.46,
            "Mean Targets Length": 10.77,
            "Max Inputs Length": 1032,
            "Max Targets Length": 21,
            "Min Inputs Length": 507,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced (amt)"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Oxford",
            "University College London",
            "Alan Turing Institute",
            "DeepMind"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://proceedings.neurips.cc/paper_files/paper/2018/file/4c7a167bb329bd92580a99ce422d6fa6-Paper.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task640_esnli_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "esnli",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Custom",
            "PwC License URL": "https://github.com/OanaMariaCamburu/e-SNLI",
            "PwC Date": "",
            "S2 Date": "2018-12-04",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 7246,
            "HF Likes (September 2023)": 14,
            "PwC Description": "e-SNLI is used for various goals, such as obtaining full sentence justifications of a model's decisions, improving universal sentence representations and transferring to out-of-domain NLI datasets.",
            "S2 Citation Count (September 2023)": 393,
            "GitHub Stars": 148,
            "GitHub Topics": [],
            "Text Topics": [
                "Natural language understanding",
                "Reasoning",
                "Education",
                "Critical thinking",
                "Argumentation",
                "Hypothesis testing",
                "Natural language processing",
                "Inference",
                "Logic"
            ]
        },
        "Derived from Datasets": [
            "snli"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Camburu2018eSNLINL,\n author = {Oana-Maria Camburu and Tim Rocktäschel and Thomas Lukasiewicz and Phil Blunsom},\n booktitle = {Neural Information Processing Systems},\n pages = {9560-9572},\n title = {e-SNLI: Natural Language Inference with Natural Language Explanations},\n year = {2018}\n}\n"
    },
    "fc-sni-e2e": {
        "Unique Dataset Identifier": "fc-sni-e2e",
        "Dataset Name": "e2e",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/abs/1706.09254",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/e2e_nlg",
        "Paper Title": "The E2E Dataset: New Challenges For End-to-End Generation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/e2e",
        "ArXiv URL": "https://arxiv.org/abs/1706.09254",
        "Semantic Scholar Corpus ID": 19662556,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Data to Text"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4335,
            "Mean Inputs Length": 601.0489,
            "Mean Targets Length": 110.9119,
            "Max Inputs Length": 1185,
            "Max Targets Length": 290,
            "Min Inputs Length": 324,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Heriot-Watt University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task957_e2e_nlg_text_generation_generate"
        ],
        "Inferred Metadata": {
            "HF Dataset": "e2e_nlg",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/4.0/",
            "PwC Date": "2017-06-28",
            "S2 Date": "2017-06-28",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "End-to-End NLG Challenge (E2E) aims to assess whether recent end-to-end NLG systems can generate more complex output by learning from datasets containing higher lexical richness, syntactic complexity and diverse discourse phenomena.",
            "S2 Citation Count (September 2023)": 319,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Data conversion",
                "Restaurant descriptions",
                "Restaurant reviews",
                "Language processing",
                "Natural language generation",
                "Natural Language Generation",
                "Data processing"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Novikova2017TheED,\n author = {Jekaterina Novikova and Ondrej Dusek and Verena Rieser},\n booktitle = {SIGDIAL Conference},\n journal = {ArXiv},\n title = {The E2E Dataset: New Challenges For End-to-End Generation},\n volume = {abs/1706.09254},\n year = {2017}\n}\n"
    },
    "fc-sni-emea_fr_sk": {
        "Unique Dataset Identifier": "fc-sni-emea_fr_sk",
        "Dataset Name": "emea_fr_sk",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/emea",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/emea",
        "Paper Title": "Parallel Data, Tools and Interfaces in OPUS",
        "Papers with Code URL": "https://paperswithcode.com/dataset/dogc",
        "ArXiv URL": "https://aclanthology.org/L12-1246/",
        "Semantic Scholar Corpus ID": 15453873,
        "Languages": [
            "French",
            "Slovak",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 903,
            "Mean Inputs Length": 393.0166,
            "Mean Targets Length": 75.3056,
            "Max Inputs Length": 1408,
            "Max Targets Length": 492,
            "Min Inputs Length": 114,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "european union",
            "opus software projects",
            "opus movie subtitles",
            "european central bank",
            "moniteur belge/belgisch staatsblad",
            "opensubtitles.org",
            "tehran english-persian parallel corpus",
            "wikisource"
        ],
        "Model Generated": [],
        "Creators": [
            "Uppsala University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://opus.nlpl.eu/EMEA.php"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task762_emea_fr_sk_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "emea",
            "HF Config": "bg-el",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1550,
            "HF Likes (September 2023)": 1,
            "PwC Description": "Intended to provide freely available data sets in various formats together with basic annotation to be useful for applications in computational linguistics, translation studies and cross-linguistic corpus studies.",
            "S2 Citation Count (September 2023)": 1551,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language learning",
                "Medical terminology",
                "Pharmacology",
                "Medical research",
                "Multilingual communication",
                "Medical information",
                "Translation"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Tiedemann2012ParallelDT,\n author = {J. Tiedemann},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2214-2218},\n title = {Parallel Data, Tools and Interfaces in OPUS},\n year = {2012}\n}\n"
    },
    "fc-sni-emo": {
        "Unique Dataset Identifier": "fc-sni-emo",
        "Dataset Name": "emo",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/emo",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/emo",
        "Paper Title": "SemEval-2019 Task 3: EmoContext Contextual Emotion Detection in Text",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/S19-2005/",
        "Semantic Scholar Corpus ID": 184483331,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12955,
            "Mean Inputs Length": 387.7948,
            "Mean Targets Length": 5.0799,
            "Max Inputs Length": 955,
            "Max Targets Length": 15,
            "Min Inputs Length": 178,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "chat with agent"
        ],
        "Model Generated": [],
        "Creators": [
            "Microsoft"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/S19-2005.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task517_emo_classify_emotion_of_dialogue"
        ],
        "Inferred Metadata": {
            "HF Dataset": "emo",
            "HF Config": "emo2019",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 192,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Communication",
                "Text analysis",
                "Time management and scheduling",
                "Emotional intelligence",
                "Emotions",
                "Education and student life",
                "Natural language processing",
                "Sentiment analysis"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chatterjee2019SemEval2019T3,\n author = {Ankush Chatterjee and Kedhar Nath Narahari and Meghana Joshi and Puneet Agrawal},\n booktitle = {International Workshop on Semantic Evaluation},\n pages = {39-48},\n title = {SemEval-2019 Task 3: EmoContext Contextual Emotion Detection in Text},\n year = {2019}\n}\n"
    },
    "fc-sni-emotion": {
        "Unique Dataset Identifier": "fc-sni-emotion",
        "Dataset Name": "emotion",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/dair-ai/emotion_dataset",
        "GitHub URL": "https://github.com/dair-ai/emotion_dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/dair-ai/emotion",
        "Paper Title": "CARER: Contextualized Affect Representations for Emotion Recognition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/emotion",
        "ArXiv URL": "https://aclanthology.org/D18-1404/",
        "Semantic Scholar Corpus ID": 53080764,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6815,
            "Mean Inputs Length": 420.5209,
            "Mean Targets Length": 5.7485,
            "Max Inputs Length": 995,
            "Max Targets Length": 18,
            "Min Inputs Length": 177,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "National Tsing Hua University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://github.com/dair-ai/emotion_dataset#usage"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task512_twitter_emotion_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "dair-ai/emotion",
            "HF Config": "split",
            "HF Config License": "Academic Research Purposes Only",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2018-11-01",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 8250,
            "HF Likes (September 2023)": 115,
            "PwC Description": "CARER is an emotion dataset collected through noisy labels, annotated via distant supervision as in (Go et al., 2009). \n\nThe subset of data provided here corresponds to the six emotions variant described in the paper. The six emotions are anger, fear, joy, love, sadness, and surprise.",
            "S2 Citation Count (September 2023)": 141,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Emotions",
                "Social media",
                "Mental health",
                "Emotion recognition",
                "Emotion classification",
                "Personal experiences",
                "Relationships"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Saravia2018CARERCA,\n author = {Elvis Saravia and Hsien-Chi Toby Liu and Yen-Hao Huang and Junlin Wu and Yi-Shin Chen},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {3687-3697},\n title = {CARER: Contextualized Affect Representations for Emotion Recognition},\n year = {2018}\n}\n"
    },
    "fc-sni-eng_guj_parallel_corpus": {
        "Unique Dataset Identifier": "fc-sni-eng_guj_parallel_corpus",
        "Dataset Name": "eng_guj_parallel_corpus",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/shahparth123/eng_guj_parallel_corpus",
        "GitHub URL": "https://github.com/shahparth123/eng_guj_parallel_corpus",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2002.02758",
        "Semantic Scholar Corpus ID": 204939206,
        "Languages": [
            "Gujarati",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9462,
            "Mean Inputs Length": 417.5161,
            "Mean Targets Length": 74.2935,
            "Max Inputs Length": 857,
            "Max Targets Length": 244,
            "Min Inputs Length": 206,
            "Min Targets Length": 40,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "eu legistlative texts",
            "translated movie subtitiles",
            "european central bank",
            "moniteur belge newspaper",
            "opensubtitles.org",
            "opensubtitles.org",
            "wikisource"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "Uka Tarsadia University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/2002.02758"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task438_eng_guj_parallel_corpus_en_gu_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-02-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 14,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Cultural understanding",
                "Multilingualism",
                "Translation",
                "Cultural diversity",
                "Language learning",
                "Multilingual communication",
                "Animals",
                "Cultural exchange"
            ]
        },
        "Derived from Datasets": [
            "OPUS Collection"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Shah2019NeuralMT,\n author = {Parth Shah and Vishvajit Bakrola},\n booktitle = {2019 Second International Conference on Advanced Computational and Communication Paradigms (ICACCP)},\n journal = {2019 Second International Conference on Advanced Computational and Communication Paradigms (ICACCP)},\n pages = {1-5},\n title = {Neural Machine Translation System of Indic Languages - An Attention based Approach},\n year = {2019}\n}\n"
    },
    "fc-sni-enhanced_wsc": {
        "Unique Dataset Identifier": "fc-sni-enhanced_wsc",
        "Dataset Name": "enhanced_wsc",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/mhany90/perturbed-wsc",
        "GitHub URL": "https://github.com/mhany90/perturbed-wsc",
        "Hugging Face URL": "",
        "Paper Title": "The Sensitivity of Language Models and Humans to Winograd Schema Perturbations",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2005.01348",
        "Semantic Scholar Corpus ID": 218486778,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Coreference Resolution"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1334,
            "Mean Inputs Length": 618.3921,
            "Mean Targets Length": 10.3643,
            "Max Inputs Length": 977,
            "Max Targets Length": 48,
            "Min Inputs Length": 370,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "human",
            "templates"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Copenhagen",
            "University of Oslo",
            "Harvard University",
            "Massachusetts Institute of Technology"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/2005.01348.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task249_enhanced_wsc_pronoun_disambiguation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 24,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Education",
                "Pronouns",
                "Language understanding",
                "Grammar",
                "Reading comprehension",
                "Language comprehension",
                "Language",
                "Language learning",
                "Pronoun reference",
                "Sentence analysis"
            ]
        },
        "Derived from Datasets": [
            "WSC"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Abdou2020TheSO,\n author = {Mostafa Abdou and Vinit Ravishankar and Maria Barrett and Yonatan Belinkov and Desmond Elliott and Anders Søgaard},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {7590-7604},\n title = {The Sensitivity of Language Models and Humans to Winograd Schema Perturbations},\n year = {2020}\n}\n"
    },
    "fc-sni-eqasc": {
        "Unique Dataset Identifier": "fc-sni-eqasc",
        "Dataset Name": "eqasc",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.org/data/eqasc",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/Sandipan1994/eqasc_data",
        "Paper Title": "Learning to Explain: Datasets and Models for Identifying Valid Reasoning Chains in Multihop Question-Answering",
        "Papers with Code URL": "https://paperswithcode.com/dataset/eqasc",
        "ArXiv URL": "https://arxiv.org/abs/2010.03274",
        "Semantic Scholar Corpus ID": 222178328,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1622,
            "Mean Inputs Length": 285.8656,
            "Mean Targets Length": 41.1615,
            "Max Inputs Length": 530,
            "Max Targets Length": 113,
            "Min Inputs Length": 111,
            "Min Targets Length": 13,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "worldtree",
            "ck12.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://allenai.org/data/eqasc"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1580_eqasc-perturbed_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "Sandipan1994/eqasc_data",
            "HF Config": "Sandipan1994--eqasc_data",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-10-07",
            "S2 Date": "2020-10-07",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-12-09",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "This dataset contains 98k 2-hop explanations for questions in the QASC dataset, with annotations indicating if they are valid (~25k) or invalid (~73k) explanations.\n\nThis repository addresses the current lack of training data for distinguish valid multihop explanations from invalid, by providing three new datasets. The main one, eQASC, contains 98k explanation annotations for the multihop question answering dataset QASC, and is the first that annotates multiple candidate explanations for each answer.\n\nThe second dataset, eQASC-perturbed, is constructed by crowd-sourcing perturbations (while preserving their validity) of a subset of explanations in QASC, to test consistency and generalization of explanation prediction models. The third dataset eOBQA is constructed by adding explanation annotations to the OBQA dataset to test generalization of models trained on eQASC.",
            "S2 Citation Count (September 2023)": 52,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Jhamtani2020LearningTE,\n author = {Harsh Jhamtani and Peter Clark},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {137-150},\n title = {Learning to Explain: Datasets and Models for Identifying Valid Reasoning Chains in Multihop Question-Answering},\n year = {2020}\n}\n"
    },
    "fc-sni-equity_evaluation_corpus": {
        "Unique Dataset Identifier": "fc-sni-equity_evaluation_corpus",
        "Dataset Name": "equity_evaluation_corpus",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/peixian/equity_evaluation_corpus",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/peixian/equity_evaluation_corpus",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Gender Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13130,
            "Mean Inputs Length": 320.7618,
            "Mean Targets Length": 5.6011,
            "Max Inputs Length": 507,
            "Max Targets Length": 16,
            "Min Inputs Length": 194,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://saifmohammad.com/WebDocs/EEC/ethics-StarSem-final_with_appendix.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1336_peixian_equity_evaluation_corpus_gender_classifier"
        ],
        "Inferred Metadata": {
            "HF Dataset": "peixian/equity_evaluation_corpus",
            "HF Config": "first_domain",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2021-03-22",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Gender and identity",
                "Gender identification",
                "Language and communication",
                "Linguistics",
                "Gender stereotypes and societal expectations",
                "Language understanding",
                "Language and linguistics",
                "Emotions and gender"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-essential": {
        "Unique Dataset Identifier": "fc-sni-essential",
        "Dataset Name": "essential",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/allenai/essential-terms",
        "GitHub URL": "https://github.com/allenai/essential-terms",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3418,
            "Mean Inputs Length": 1106.5793,
            "Mean Targets Length": 2.5775,
            "Max Inputs Length": 2017,
            "Max Targets Length": 12,
            "Min Inputs Length": 766,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/K17-1010.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task043_essential_terms_answering_incomplete_questions"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Science",
                "Science education",
                "General knowledge",
                "Question answering",
                "Trivia",
                "Masking and information retrieval"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-ethos": {
        "Unique Dataset Identifier": "fc-sni-ethos",
        "Dataset Name": "ethos",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/ethos",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ethos",
        "Paper Title": "A Truncated SVD Framework for Online Hate Speech Detection on the ETHOS Dataset",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ethos",
        "ArXiv URL": "https://arxiv.org/abs/2006.08328",
        "Semantic Scholar Corpus ID": 257654552,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2003,
            "Mean Inputs Length": 360.8652,
            "Mean Targets Length": 6.8462,
            "Max Inputs Length": 3644,
            "Max Targets Length": 18,
            "Min Inputs Length": 123,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "youtube",
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "Aristotle University of Thessaloniki"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://rdcu.be/cEoQn"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1604_ethos_text_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ethos",
            "HF Config": "binary",
            "HF Config License": "",
            "HF Yaml License": "GNU General Public License v3.0",
            "PwC License Name": "GNU General Public License v3.0",
            "PwC License URL": "https://raw.githubusercontent.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset/master/LICENSE",
            "PwC Date": "",
            "S2 Date": "2023-02-11",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2328,
            "HF Likes (September 2023)": 9,
            "PwC Description": "ETHOS is a hate speech detection dataset. It is built from YouTube and Reddit comments validated through a crowdsourcing platform. It has two subsets, one for binary classification and the other for multi-label classification. The former contains 998 comments, while the latter contains fine-grained hate-speech annotations for 433 comments.",
            "S2 Citation Count (September 2023)": 0,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Discrimination",
                "Discrimination and prejudice",
                "Religion",
                "Language and communication",
                "LGBTQ+ rights",
                "Gender equality",
                "Social issues"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Conference{Chhabra2023ATS,\n author = {A. Chhabra and D. Vishwakarma},\n booktitle = {2023 4th International Conference on Innovative Trends in Information Technology (ICITIIT)},\n journal = {2023 4th International Conference on Innovative Trends in Information Technology (ICITIIT)},\n pages = {1-4},\n title = {A Truncated SVD Framework for Online Hate Speech Detection on the ETHOS Dataset},\n year = {2023}\n}\n"
    },
    "fc-sni-eurlex": {
        "Unique Dataset Identifier": "fc-sni-eurlex",
        "Dataset Name": "eurlex",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/eurlex",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/eurlex",
        "Paper Title": "Large-Scale Multi-Label Text Classification on EU Legislation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/eurlex57k",
        "ArXiv URL": "https://arxiv.org/abs/1906.02192",
        "Semantic Scholar Corpus ID": 174802484,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Title Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1298,
            "Mean Inputs Length": 3814.52,
            "Mean Targets Length": 153.0894,
            "Max Inputs Length": 21873,
            "Max Targets Length": 427,
            "Min Inputs Length": 295,
            "Min Targets Length": 46,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "eur-lex portal",
            "eurovoc thesaurus"
        ],
        "Model Generated": [],
        "Creators": [
            "Athens University of Economics and Business"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "http://nlp.cs.aueb.gr/software_and_datasets/EURLEX57K/read_me.txt"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task743_eurlex_summarization"
        ],
        "Inferred Metadata": {
            "HF Dataset": "eurlex",
            "HF Config": "eurlex57k",
            "HF Config License": "CC BY-SA 4.0",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2019-06-05",
            "S2 Date": "2019-06-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 930,
            "HF Likes (September 2023)": 4,
            "PwC Description": "EURLEX57K is a new publicly available legal LMTC dataset, dubbed EURLEX57K, containing 57k English EU legislative documents from the EUR-LEX portal, tagged with ∼4.3k labels (concepts) from the European Vocabulary (EUROVOC).",
            "S2 Citation Count (September 2023)": 141,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Legal acts",
                "French overseas departments",
                "Legal acts and regulations",
                "Legal regulations",
                "European Union regulations",
                "Regulation amendments",
                "European Union legislation",
                "Treaty provisions",
                "European Union directives"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chalkidis2019LargeScaleMT,\n author = {Ilias Chalkidis and Manos Fergadiotis and Prodromos Malakasiotis and Ion Androutsopoulos},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {6314-6322},\n title = {Large-Scale Multi-Label Text Classification on EU Legislation},\n year = {2019}\n}\n"
    },
    "fc-sni-europa_ecdc_tm": {
        "Unique Dataset Identifier": "fc-sni-europa_ecdc_tm",
        "Dataset Name": "europa_ecdc_tm",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/europa_ecdc_tm",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/europa_ecdc_tm",
        "Paper Title": "An overview of the European Union’s highly multilingual parallel corpora",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 207104638,
        "Languages": [
            "Swedish",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4773,
            "Mean Inputs Length": 535.3738,
            "Mean Targets Length": 104.3736,
            "Max Inputs Length": 3818,
            "Max Targets Length": 1530,
            "Min Inputs Length": 245,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://wt-public.emm4u.eu/Resources/ECDC-TM/2012_10_Terms-of-Use_ECDC-TM.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1395_europa_ecdc_tm_en_sv_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "europa_ecdc_tm",
            "HF Config": "en2bg",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2014-12-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1068,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 64,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Education",
                "Health-related topics",
                "Translation",
                "Organization activities",
                "Infectious diseases",
                "Language learning",
                "Microbiology",
                "Organization"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-europarl": {
        "Unique Dataset Identifier": "fc-sni-europarl",
        "Dataset Name": "europarl",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "http://www.statmt.org/europarl/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "Bulgarian",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8622,
            "Mean Inputs Length": 471.0467,
            "Mean Targets Length": 112.7171,
            "Max Inputs Length": 2754,
            "Max Targets Length": 929,
            "Min Inputs Length": 144,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/2005.mtsummit-papers.11.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task271_europarl_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "International relations",
                "European Union",
                "Translation",
                "Bulgarian culture",
                "Multilingual communication",
                "Linguistics",
                "Multilingualism",
                "Language translation"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-evalution": {
        "Unique Dataset Identifier": "fc-sni-evalution",
        "Dataset Name": "evalution",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://aclanthology.org/W15-4208",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "EVALution 1.0: an Evolving Semantic Dataset for Training and Evaluation of Distributional Semantic Models",
        "Papers with Code URL": "https://paperswithcode.com/dataset/evalution",
        "ArXiv URL": "https://aclanthology.org/W15-4208/",
        "Semantic Scholar Corpus ID": 15040286,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Word Relation Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1559,
            "Mean Inputs Length": 904.1758,
            "Mean Targets Length": 7.0282,
            "Max Inputs Length": 1038,
            "Max Targets Length": 21,
            "Min Inputs Length": 818,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "conceptnet",
            "wordnet",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong Polytechnic University",
            "Nara Institute of Science and Technology",
            "Universita di Pisa"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1429_evalution_semantic_relation_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2015-01-01",
            "S2 Date": "2015-07-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "EVALution dataset is evenly distributed among the three classes (hypernyms, co-hyponyms and random) and involves three types of parts of speech (noun, verb, adjective). The full dataset contains a total of 4,263 distinct terms consisting of 2,380 nouns, 958 verbs and 972 adjectives.",
            "S2 Citation Count (September 2023)": 90,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language",
                "Semantics",
                "Semantics and Word Relationships",
                "Word Relationships",
                "Cognitive Science and Word Associations",
                "Linguistics",
                "Word relationships"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Santus2015EVALution1A,\n author = {Enrico Santus and Frances Yung and Alessandro Lenci and Chu-Ren Huang},\n booktitle = {LDL@IJCNLP},\n pages = {64-69},\n title = {EVALution 1.0: an Evolving Semantic Dataset for Training and Evaluation of Distributional Semantic Models},\n year = {2015}\n}\n"
    },
    "fc-sni-event2mind": {
        "Unique Dataset Identifier": "fc-sni-event2mind",
        "Dataset Name": "event2mind",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/event2Mind",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/event2Mind",
        "Paper Title": "Event2Mind: Commonsense Inference on Events, Intents, and Reactions",
        "Papers with Code URL": "https://paperswithcode.com/dataset/event2mind",
        "ArXiv URL": "https://arxiv.org/abs/1805.06939",
        "Semantic Scholar Corpus ID": 29162884,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12917,
            "Mean Inputs Length": 411.5072,
            "Mean Targets Length": 11.5552,
            "Max Inputs Length": 628,
            "Max Targets Length": 115,
            "Min Inputs Length": 280,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wiktionary.org",
            "google syntactic n-grams",
            "undisclosed web",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://maartensap.com/pdfs/rashkin2018event2mind.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1595_event2mind_text_generation_1"
        ],
        "Inferred Metadata": {
            "HF Dataset": "event2Mind",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 555,
            "HF Likes (September 2023)": 0,
            "PwC Description": "Event2Mind is a corpus of 25,000 event phrases covering a diverse range of everyday events and situations.",
            "S2 Citation Count (September 2023)": 159,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Emotional well-being",
                "Personal growth",
                "Psychology",
                "Relationships",
                "Writing",
                "Personal experiences",
                "Emotions and psychology",
                "Emotions"
            ]
        },
        "Derived from Datasets": [
            "ROC Story dataset",
            "Spinn3r corpus"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Rashkin2018Event2MindCI,\n author = {Hannah Rashkin and Maarten Sap and Emily Allaway and Noah A. Smith and Yejin Choi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Event2Mind: Commonsense Inference on Events, Intents, and Reactions},\n volume = {abs/1805.06939},\n year = {2018}\n}\n"
    },
    "fc-sni-facts2story": {
        "Unique Dataset Identifier": "fc-sni-facts2story",
        "Dataset Name": "facts2story",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/eyal-orbach/Facts2Story-data",
        "GitHub URL": "https://github.com/eyal-orbach/Facts2Story-data",
        "Hugging Face URL": "",
        "Paper Title": "Facts2Story: Controlling Text Generation by Key Facts",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2012.04332",
        "Semantic Scholar Corpus ID": 227230484,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Narrative Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13001,
            "Mean Inputs Length": 3022.3868,
            "Mean Targets Length": 2395.3806,
            "Max Inputs Length": 10797,
            "Max Targets Length": 5115,
            "Min Inputs Length": 489,
            "Min Targets Length": 286,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "Bar-Ilan University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://www.aclweb.org/anthology/2020.coling-main.211/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task103_facts2story_long_text_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-12-01",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 11,
            "GitHub Stars": 4,
            "GitHub Topics": [],
            "Text Topics": [
                "Family dynamics and relationships",
                "Family and relationships",
                "Redemption and second chances",
                "Family dynamics",
                "Personal growth and self-discovery",
                "Cultural and social dynamics",
                "Relationships and personal growth",
                "Crime and law enforcement"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Orbach2020Facts2StoryCT,\n author = {Eyal Orbach and Yoav Goldberg},\n booktitle = {International Conference on Computational Linguistics},\n journal = {ArXiv},\n title = {Facts2Story: Controlling Text Generation by Key Facts},\n volume = {abs/2012.04332},\n year = {2020}\n}\n"
    },
    "fc-sni-farstail": {
        "Unique Dataset Identifier": "fc-sni-farstail",
        "Dataset Name": "farstail",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/dml-qom/FarsTail",
        "GitHub URL": "https://github.com/dml-qom/FarsTail",
        "Hugging Face URL": "https://huggingface.co/datasets/PNLPhub/FarsTail",
        "Paper Title": "FarsTail: A Persian Natural Language Inference Dataset",
        "Papers with Code URL": "https://paperswithcode.com/dataset/farstail",
        "ArXiv URL": "https://arxiv.org/abs/2009.08820",
        "Semantic Scholar Corpus ID": 221802461,
        "Languages": [
            "Persian",
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11859,
            "Mean Inputs Length": 864.2617,
            "Mean Targets Length": 1.5935,
            "Max Inputs Length": 1824,
            "Max Targets Length": 11,
            "Min Inputs Length": 438,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "iranian university exams"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Qom"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/dml-qom/FarsTail/blob/master/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task534_farstail_entailment"
        ],
        "Inferred Metadata": {
            "HF Dataset": "PNLPhub/FarsTail",
            "HF Config": "FarsTail",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "https://github.com/dml-qom/FarsTail/blob/master/LICENSE",
            "PwC Date": "2020-09-18",
            "S2 Date": "",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "2023-06-16",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "Natural Language Inference (NLI), also called Textual Entailment, is an important task in NLP with the goal of determining the inference relationship between a premise p and a hypothesis h. It is a three-class problem, where each pair (p, h) is assigned to one of these classes: \"ENTAILMENT\" if the hypothesis can be inferred from the premise, \"CONTRADICTION\" if the hypothesis contradicts the premise, and \"NEUTRAL\" if none of the above holds. There are large datasets such as SNLI, MNLI, and SciTail for NLI in English, but there are few datasets for poor-data languages like Persian. Persian (Farsi) language is a pluricentric language spoken by around 110 million people in countries like Iran, Afghanistan, and Tajikistan. FarsTail is the first relatively large-scale Persian dataset for NLI task. A total of 10,367 samples are generated from a collection of 3,539 multiple-choice questions. The train, validation, and test portions include 7,266, 1,537, and 1,564 instances, respectively.",
            "S2 Citation Count (September 2023)": 19,
            "GitHub Stars": 67,
            "GitHub Topics": [
                "deep-learning",
                "farsi-dataset",
                "natural-language-inference",
                "natural-language-processing",
                "persian-language",
                "textual-entailment"
            ],
            "Text Topics": [
                "Persian language",
                "Cross-lingual entailment",
                "Cross-lingual comprehension",
                "Sentential entailment",
                "Linguistics",
                "Natural language processing",
                "Language understanding",
                "Cross-cultural communication",
                "Language learning",
                "Cross-lingual analysis"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Amirkhani2023FarsTailAP,\n author = {Hossein Amirkhani and Mohammad AzariJafari and Zohreh Pourjafari and Soroush Faridan-Jahromi and Zeinab Kouhkan and Azadeh Amirak},\n booktitle = {Soft Computing - A Fusion of Foundations, Methodologies and Applications},\n journal = {ArXiv},\n title = {FarsTail: A Persian Natural Language Inference Dataset},\n volume = {abs/2009.08820},\n year = {2023}\n}\n"
    },
    "fc-sni-financial_phrasebank": {
        "Unique Dataset Identifier": "fc-sni-financial_phrasebank",
        "Dataset Name": "financial_phrasebank",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/financial_phrasebank",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/financial_phrasebank",
        "Paper Title": "Good debt or bad debt: Detecting semantic orientations in economic texts",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1307.5336",
        "Semantic Scholar Corpus ID": 7700237,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3636,
            "Mean Inputs Length": 501.1463,
            "Mean Targets Length": 8.2181,
            "Max Inputs Length": 952,
            "Max Targets Length": 18,
            "Min Inputs Length": 166,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "lexisnexis database"
        ],
        "Model Generated": [],
        "Creators": [
            "Aalto University School of Business"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/1307.5336"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task843_financial_phrasebank_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "financial_phrasebank",
            "HF Config": "sentences_allagree",
            "HF Config License": "CC BY-NC-SA 3.0",
            "HF Yaml License": "CC BY-NC-SA 3.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2013-07-19",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 200,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Investment",
                "Finance",
                "Stock market",
                "Financial news",
                "Sentiment analysis",
                "Business and economics",
                "Business",
                "News analysis",
                "Financial news analysis"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Malo2013GoodDO,\n author = {P. Malo and Ankur Sinha and P. Korhonen and J. Wallenius and P. Takala},\n booktitle = {J. Assoc. Inf. Sci. Technol.},\n journal = {Journal of the Association for Information Science and Technology},\n title = {Good debt or bad debt: Detecting semantic orientations in economic texts},\n volume = {65},\n year = {2013}\n}\n"
    },
    "fc-sni-flores": {
        "Unique Dataset Identifier": "fc-sni-flores",
        "Dataset Name": "flores",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/flores",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/flores",
        "Paper Title": "The FLORES Evaluation Datasets for Low-Resource Machine Translation: Nepali–English and Sinhala–English",
        "Papers with Code URL": "https://paperswithcode.com/dataset/flores",
        "ArXiv URL": "https://arxiv.org/abs/1902.01382",
        "Semantic Scholar Corpus ID": 59599823,
        "Languages": [
            "Nepali",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4609,
            "Mean Inputs Length": 412.1768,
            "Mean Targets Length": 90.7843,
            "Max Inputs Length": 965,
            "Max Targets Length": 197,
            "Min Inputs Length": 134,
            "Min Targets Length": 35,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Facebook AI Research",
            "Facebook AI Research",
            "Sorbonne Universites",
            "Johns Hopkins University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/facebookresearch/flores/#licenses"
            },
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/facebookresearch/flores/#licenses"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1514_flores_translation_entone"
        ],
        "Inferred Metadata": {
            "HF Dataset": "flores",
            "HF Config": "neen",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://github.com/facebookresearch/flores/blob/master/LICENSE",
            "PwC Date": "2019-11-01",
            "S2 Date": "2019-02-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 914,
            "HF Likes (September 2023)": 2,
            "PwC Description": "FLoRes is a benchmark dataset for machine translation between English and four low resource languages, Nepali, Sinhala, Khmer and Pashto, based on sentences translated from Wikipedia.",
            "S2 Citation Count (September 2023)": 237,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language and linguistics",
                "Sports",
                "Translation",
                "Linguistics",
                "Literature review",
                "Cross-cultural communication",
                "Literature"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Guzmán2019TwoNE,\n author = {Francisco Guzmán and Peng-Jen Chen and Myle Ott and J. Pino and Guillaume Lample and Philipp Koehn and Vishrav Chaudhary and Marc'Aurelio Ranzato},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Two New Evaluation Datasets for Low-Resource Machine Translation: Nepali-English and Sinhala-English},\n volume = {abs/1902.01382},\n year = {2019}\n}\n"
    },
    "fc-sni-freebase_qa": {
        "Unique Dataset Identifier": "fc-sni-freebase_qa",
        "Dataset Name": "freebase_qa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/freebase_qa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/freebase_qa",
        "Paper Title": "FreebaseQA: A New Factoid QA Data Set Matching Trivia-Style Question-Answer Pairs with Freebase",
        "Papers with Code URL": "https://paperswithcode.com/dataset/freebaseqa",
        "ArXiv URL": "https://aclanthology.org/N19-1028/",
        "Semantic Scholar Corpus ID": 174800890,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7762,
            "Mean Inputs Length": 281.3749,
            "Mean Targets Length": 80.9174,
            "Max Inputs Length": 696,
            "Max Targets Length": 359,
            "Min Inputs Length": 122,
            "Min Targets Length": 22,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "York University"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://github.com/kelvin-jiang/FreebaseQA#freebaseqa-v10-a-trivia-type-qa-data-set-over-the-freebase-knowledge-graph"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task897_freebase_qa_topic_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "freebase_qa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 965,
            "HF Likes (September 2023)": 2,
            "PwC Description": "FreebaseQA is a data set for open-domain QA over the Freebase knowledge graph. The question-answer pairs in this data set are collected from various sources, including the TriviaQA data set and other trivia websites (QuizBalls, QuizZone, KnowQuiz), and are matched against Freebase to generate relevant subject-predicate-object triples that were further verified by human annotators. As all questions in FreebaseQA are composed independently for human contestants in various trivia-like competitions, this data set shows richer linguistic variation and complexity than existing QA data sets, making it a good test-bed for emerging KB-QA systems.",
            "S2 Citation Count (September 2023)": 51,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Entertainment",
                "Literature",
                "Music",
                "Geography",
                "Pop culture",
                "Movies",
                "Trivia",
                "Sports",
                "History",
                "General knowledge"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Jiang2019FreebaseQAAN,\n author = {Kelvin Jiang and Dekun Wu and Hui Jiang},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {318-323},\n title = {FreebaseQA: A New Factoid QA Data Set Matching Trivia-Style Question-Answer Pairs with Freebase},\n year = {2019}\n}\n"
    },
    "fc-sni-gap": {
        "Unique Dataset Identifier": "fc-sni-gap",
        "Dataset Name": "gap",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/google-research-datasets/gap-coreference",
        "GitHub URL": "https://github.com/google-research-datasets/gap-coreference",
        "Hugging Face URL": "https://huggingface.co/datasets/gap",
        "Paper Title": "Mind the GAP: A Balanced Corpus of Gendered Ambiguous Pronouns",
        "Papers with Code URL": "https://paperswithcode.com/dataset/gap-coreference-dataset",
        "ArXiv URL": "https://arxiv.org/abs/1810.05201",
        "Semantic Scholar Corpus ID": 52980889,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Coreference Resolution"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8900,
            "Mean Inputs Length": 1244.0898,
            "Mean Targets Length": 2.2002,
            "Max Inputs Length": 2697,
            "Max Targets Length": 17,
            "Min Inputs Length": 440,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/google-research-datasets/gap-coreference#gap-coreference-dataset"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task329_gap_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "gap",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2018-10-11",
            "S2 Date": "2019-06-03",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 604,
            "HF Likes (September 2023)": 2,
            "PwC Description": "GAP is a gender-balanced dataset containing 8,908 coreference-labeled pairs of (ambiguous pronoun, antecedent name), sampled from Wikipedia and released by Google AI Language for the evaluation of coreference resolution in practical applications.",
            "S2 Citation Count (September 2023)": 198,
            "GitHub Stars": 219,
            "GitHub Topics": [],
            "Text Topics": [
                "Language comprehension",
                "Text comprehension",
                "Pronoun reference",
                "Referential understanding",
                "Text analysis"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Webster2019ResolvingGA,\n author = {Kellie Webster and Marta Recasens and Vera Axelrod and Jason Baldridge},\n booktitle = {Proceedings of the First Workshop on Gender Bias in Natural Language Processing},\n journal = {ArXiv},\n title = {Resolving Gendered Ambiguous Pronouns with BERT},\n volume = {abs/1906.01161},\n year = {2019}\n}\n"
    },
    "fc-sni-generated_reviews_enth": {
        "Unique Dataset Identifier": "fc-sni-generated_reviews_enth",
        "Dataset Name": "generated_reviews_enth",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/generated_reviews_enth",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/generated_reviews_enth",
        "Paper Title": "scb-mt-en-th-2020: A Large English-Thai Parallel Corpus",
        "Papers with Code URL": "https://paperswithcode.com/dataset/scb-mt-en-th-2020",
        "ArXiv URL": "https://arxiv.org/abs/2007.03541",
        "Semantic Scholar Corpus ID": 220381366,
        "Languages": [
            "English",
            "Thai"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12980,
            "Mean Inputs Length": 833.9401,
            "Mean Targets Length": 11.074,
            "Max Inputs Length": 1768,
            "Max Targets Length": 21,
            "Min Inputs Length": 246,
            "Min Targets Length": 10,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "taskmaster-1 dataset",
            "the national university of singapore (nus) sms corpus",
            "mozilla common voice dataset",
            "microsoft research paraphrase identification corpus",
            "wikipedia.org",
            "paracrawl",
            "select thai websites",
            "thai government documents"
        ],
        "Model Generated": [
            "Other",
            "CTRL"
        ],
        "Creators": [
            "Vidyasirimedhi Institution of Science and Technology",
            "pyThaiNLP",
            "Chulalongkorn University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": ""
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task929_products_reviews_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "generated_reviews_enth",
            "HF Config": "generated_reviews_enth",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-07-07",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1117,
            "HF Likes (September 2023)": 3,
            "PwC Description": "scb-mt-en-th-2020 is an English-Thai machine translation dataset with over 1 million segment pairs, curated from various sources, namely news, Wikipedia articles, SMS messages, task-based dialogs, web-crawled data and government documents.",
            "S2 Citation Count (September 2023)": 10,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Book reviews",
                "Sentiment Analysis",
                "Product reviews",
                "Natural language processing",
                "Customer satisfaction",
                "Tone analysis",
                "Sentiment analysis",
                "Literature"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lowphansirikul2020ALE,\n author = {Lalita Lowphansirikul and Charin Polpanumas and Attapol T. Rutherford and Sarana Nutanong},\n booktitle = {Language Resources and Evaluation},\n journal = {Language Resources and Evaluation},\n pages = {477 - 499},\n title = {A large English–Thai parallel corpus from the web and machine-generated text},\n volume = {56},\n year = {2020}\n}\n"
    },
    "fc-sni-giga_fren": {
        "Unique Dataset Identifier": "fc-sni-giga_fren",
        "Dataset Name": "giga_fren",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/giga_fren",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/giga_fren",
        "Paper Title": "Parallel Data, Tools and Interfaces in OPUS",
        "Papers with Code URL": "https://paperswithcode.com/dataset/dogc",
        "ArXiv URL": "https://aclanthology.org/L12-1246/",
        "Semantic Scholar Corpus ID": 15453873,
        "Languages": [
            "French",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1988,
            "Mean Inputs Length": 332.5734,
            "Mean Targets Length": 84.4733,
            "Max Inputs Length": 1389,
            "Max Targets Length": 794,
            "Min Inputs Length": 103,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "european union",
            "opus software projects",
            "opus movie subtitles",
            "european central bank",
            "moniteur belge/belgisch staatsblad",
            "opensubtitles.org",
            "tehran english-persian parallel corpus",
            "wikisource"
        ],
        "Model Generated": [],
        "Creators": [
            "Uppsala University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task829_giga_fren_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "giga_fren",
            "HF Config": "en-fr",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "Intended to provide freely available data sets in various formats together with basic annotation to be useful for applications in computational linguistics, translation studies and cross-linguistic corpus studies.",
            "S2 Citation Count (September 2023)": 1551,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Cross-cultural communication",
                "International trade",
                "Medical devices",
                "Access to healthcare",
                "Communication",
                "Language learning",
                "Translation",
                "Politics",
                "Education",
                "Cultural differences"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Tiedemann2012ParallelDT,\n author = {J. Tiedemann},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2214-2218},\n title = {Parallel Data, Tools and Interfaces in OPUS},\n year = {2012}\n}\n"
    },
    "fc-sni-glucose": {
        "Unique Dataset Identifier": "fc-sni-glucose",
        "Dataset Name": "glucose",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/ElementalCognition/glucose/",
        "GitHub URL": "https://github.com/ElementalCognition/glucose/",
        "Hugging Face URL": "https://huggingface.co/datasets/glucose",
        "Paper Title": "GLUCOSE: GeneraLized and COntextualized Story Explanations",
        "Papers with Code URL": "https://paperswithcode.com/dataset/glucose",
        "ArXiv URL": "https://arxiv.org/abs/2009.07758",
        "Semantic Scholar Corpus ID": 221739295,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Cause Effect Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12997,
            "Mean Inputs Length": 1048.856,
            "Mean Targets Length": 71.3669,
            "Max Inputs Length": 1845,
            "Max Targets Length": 149,
            "Min Inputs Length": 546,
            "Min Targets Length": 32,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Elemental Cognition"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/ElementalCognition/glucose/#glucose"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task614_glucose_cause_event_detection"
        ],
        "Inferred Metadata": {
            "HF Dataset": "glucose",
            "HF Config": "glucose",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2020-09-16",
            "S2 Date": "2020-09-16",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 585,
            "HF Likes (September 2023)": 2,
            "PwC Description": "GLUCOSE is a large-scale dataset of implicit commonsense causal knowledge, encoded as causal mini-theories about the world, each grounded in a narrative context. To construct GLUCOSE, we drew on cognitive psychology to identify ten dimensions of causal explanation, focusing on events, states, motivations, and emotions. Each GLUCOSE entry includes a story-specific causal statement paired with an inference rule generalized from the statement.",
            "S2 Citation Count (September 2023)": 83,
            "GitHub Stars": 83,
            "GitHub Topics": [
                "validation-error"
            ],
            "Text Topics": [
                "Education",
                "Social interactions",
                "Reading comprehension",
                "Story analysis",
                "Cause and effect",
                "Health",
                "Cause and effect relationships",
                "Decision-making"
            ]
        },
        "Derived from Datasets": [
            "ROCStories"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Mostafazadeh2020GLUCOSEGA,\n author = {N. Mostafazadeh and Aditya Kalyanpur and Lori Moon and David W. Buchanan and Lauren Berkowitz and Or Biran and Jennifer Chu-Carroll},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {4569-4586},\n title = {GLUCOSE: GeneraLized and COntextualized Story Explanations},\n year = {2020}\n}\n"
    },
    "fc-sni-go_emotions": {
        "Unique Dataset Identifier": "fc-sni-go_emotions",
        "Dataset Name": "go_emotions",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/go_emotions",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/go_emotions",
        "Paper Title": "GoEmotions: A Dataset of Fine-Grained Emotions",
        "Papers with Code URL": "https://paperswithcode.com/dataset/goemotions",
        "ArXiv URL": "https://arxiv.org/abs/2005.00547",
        "Semantic Scholar Corpus ID": 218486942,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 936,
            "Mean Inputs Length": 301.39,
            "Mean Targets Length": 6.8878,
            "Max Inputs Length": 549,
            "Max Targets Length": 19,
            "Min Inputs Length": 133,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University",
            "Google Research",
            "Amazon"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://huggingface.co/datasets/go_emotions#dataset-summary"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task889_goemotions_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "go_emotions",
            "HF Config": "raw",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-05-01",
            "S2 Date": "2020-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "GoEmotions is a corpus of 58k carefully curated comments extracted from Reddit, with human annotations to 27 emotion categories or Neutral.\n\n\nNumber of examples: 58,009.\nNumber of labels: 27 + Neutral.\nMaximum sequence length in training and evaluation datasets: 30.\n\nOn top of the raw data, the dataset also includes a version filtered based on reter-agreement, which contains a train/test/validation split:\n\n\nSize of training dataset: 43,410.\nSize of test dataset: 5,427.\nSize of validation dataset: 5,426.\n\nThe emotion categories are: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise.",
            "S2 Citation Count (September 2023)": 296,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Emotion recognition",
                "Social interactions",
                "Language understanding",
                "Sentiment analysis",
                "Language and communication",
                "Language",
                "Natural language processing",
                "Communication",
                "Emotions",
                "Relationships"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Demszky2020GoEmotionsAD,\n author = {Dorottya Demszky and Dana Movshovitz-Attias and Jeongwoo Ko and Alan S. Cowen and Gaurav Nemade and Sujith Ravi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {4040-4054},\n title = {GoEmotions: A Dataset of Fine-Grained Emotions},\n year = {2020}\n}\n"
    },
    "fc-sni-gooaq": {
        "Unique Dataset Identifier": "fc-sni-gooaq",
        "Dataset Name": "gooaq",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/gooaq",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/gooaq",
        "Paper Title": "GooAQ: Open Question Answering with Diverse Answer Types",
        "Papers with Code URL": "https://paperswithcode.com/dataset/gooaq",
        "ArXiv URL": "https://arxiv.org/abs/2104.08727",
        "Semantic Scholar Corpus ID": 233296036,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 212,
            "Mean Inputs Length": 201.4858,
            "Mean Targets Length": 5.2594,
            "Max Inputs Length": 404,
            "Max Targets Length": 24,
            "Min Inputs Length": 85,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "google search"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "University of Washington",
            "University of Pennsylvania"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/allenai/gooaq/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1656_gooaq_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "gooaq",
            "HF Config": "default",
            "HF Config License": "Apache License 2.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "https://github.com/allenai/gooaq/blob/main/LICENSE",
            "PwC Date": "2021-04-18",
            "S2 Date": "2021-04-18",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 680,
            "HF Likes (September 2023)": 3,
            "PwC Description": "GooAQ is a large-scale dataset with a variety of answer types. This dataset contains over 5 million questions and 3 million answers collected from Google. GooAQ questions are collected semi-automatically from the Google search engine using its autocomplete feature. This results in naturalistic questions of practical interest that are nonetheless short and expressed using simple language. GooAQ answers are mined from Google's responses to the collected questions, specifically from the answer boxes in the search results. This yields a rich space of answer types, containing both textual answers (short and long) as well as more structured ones such as collections.",
            "S2 Citation Count (September 2023)": 28,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Conversion of units",
                "Conversion",
                "Math",
                "Time measurement",
                "Cooking",
                "Mathematics",
                "Unit conversion",
                "Measurement",
                "Units of measurement",
                "Measurement conversion"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Khashabi2021GooAQOQ,\n author = {Daniel Khashabi and Amos Ng and Tushar Khot and Ashish Sabharwal and Hannaneh Hajishirzi and Chris Callison-Burch},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {GooAQ: Open Question Answering with Diverse Answer Types},\n volume = {abs/2104.08727},\n year = {2021}\n}\n"
    },
    "fc-sni-google_wellformed_query": {
        "Unique Dataset Identifier": "fc-sni-google_wellformed_query",
        "Dataset Name": "google_wellformed_query",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/google_wellformed_query",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/google_wellformed_query",
        "Paper Title": "Identifying Well-formed Natural Language Questions",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1808.09419",
        "Semantic Scholar Corpus ID": 52111971,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Understanding"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10708,
            "Mean Inputs Length": 508.0544,
            "Mean Targets Length": 4.0482,
            "Max Inputs Length": 766,
            "Max Targets Length": 14,
            "Min Inputs Length": 359,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikianswers",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/google-research-datasets/query-wellformedness#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task673_google_wellformed_query_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "google_wellformed_query",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-08-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1169,
            "HF Likes (September 2023)": 8,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 40,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Education",
                "Natural language processing",
                "Query classification",
                "Common sense and general facts",
                "Dialog systems",
                "Query formation",
                "Artificial intelligence",
                "Natural Language Processing"
            ]
        },
        "Derived from Datasets": [
            "Paralex dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Faruqui2018IdentifyingWN,\n author = {Manaal Faruqui and Dipanjan Das},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {798-803},\n title = {Identifying Well-formed Natural Language Questions},\n year = {2018}\n}\n"
    },
    "fc-sni-grailqa": {
        "Unique Dataset Identifier": "fc-sni-grailqa",
        "Dataset Name": "grailqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://dki-lab.github.io/GrailQA/",
        "GitHub URL": "https://dki-lab.github.io/GrailQA/",
        "Hugging Face URL": "https://huggingface.co/datasets/grail_qa",
        "Paper Title": "Beyond I.I.D.: Three Levels of Generalization for Question Answering on Knowledge Bases",
        "Papers with Code URL": "https://paperswithcode.com/dataset/grailqa",
        "ArXiv URL": "https://arxiv.org/abs/2011.07743",
        "Semantic Scholar Corpus ID": 226965153,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Rewriting"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6017,
            "Mean Inputs Length": 2276.1256,
            "Mean Targets Length": 69.0392,
            "Max Inputs Length": 5903,
            "Max Targets Length": 390,
            "Min Inputs Length": 895,
            "Min Targets Length": 20,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates",
            "crowdsourced (amt)"
        ],
        "Model Generated": [],
        "Creators": [
            "The Ohio State University",
            "U.S. Army Research Laboratory",
            "Stanford University",
            "UC Santa Barbara",
            "The Ohio State University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://dki-lab.github.io/GrailQA/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task402_grailqa_paraphrase_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "grail_qa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-11-16",
            "S2 Date": "2020-11-16",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 820,
            "HF Likes (September 2023)": 2,
            "PwC Description": "GrailQA is a new large-scale, high-quality dataset for question answering on knowledge bases (KBQA) on Freebase with 64,331 questions annotated with both answers and corresponding logical forms in different syntax (i.e., SPARQL, S-expression, etc.). It can be used to test three levels of generalization in KBQA: i.i.d., compositional, and zero-shot.",
            "S2 Citation Count (September 2023)": 86,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Sports",
                "Information retrieval",
                "General knowledge",
                "Literature",
                "Language and communication",
                "Technology",
                "Linguistics",
                "Question formulation"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Gu2020BeyondIT,\n author = {Yu Gu and Sue E. Kase and M. Vanni and Brian M. Sadler and Percy Liang and Xifeng Yan and Yu Su},\n booktitle = {The Web Conference},\n journal = {Proceedings of the Web Conference 2021},\n title = {Beyond I.I.D.: Three Levels of Generalization for Question Answering on Knowledge Bases},\n year = {2020}\n}\n"
    },
    "fc-sni-gwsd": {
        "Unique Dataset Identifier": "fc-sni-gwsd",
        "Dataset Name": "gwsd",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/yiweiluo/GWStance",
        "GitHub URL": "https://github.com/yiweiluo/GWStance",
        "Hugging Face URL": "",
        "Paper Title": "DeSMOG: Detecting Stance in Media On Global Warming",
        "Papers with Code URL": "https://paperswithcode.com/dataset/desmog",
        "ArXiv URL": "https://arxiv.org/abs/2010.15149",
        "Semantic Scholar Corpus ID": 225103118,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 392,
            "Mean Inputs Length": 769.1301,
            "Mean Targets Length": 7.9413,
            "Max Inputs Length": 1194,
            "Max Targets Length": 19,
            "Min Inputs Length": 489,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "news"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/2020.findings-emnlp.296v2.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task890_gcwd_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-28",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "A dataset of stance-labeled GW sentences.",
            "S2 Citation Count (September 2023)": 35,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Environmental science",
                "Climate change",
                "Human impact on the environment",
                "Global warming"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Luo2020DeSMOGDS,\n author = {Yiwei Luo and Dallas Card and Dan Jurafsky},\n booktitle = {Findings},\n pages = {3296-3315},\n title = {DeSMOG: Detecting Stance in Media On Global Warming},\n year = {2020}\n}\n"
    },
    "fc-sni-hans": {
        "Unique Dataset Identifier": "fc-sni-hans",
        "Dataset Name": "hans",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/abs/1902.01007",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/hans",
        "Paper Title": "Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hans",
        "ArXiv URL": "https://arxiv.org/abs/1902.01007",
        "Semantic Scholar Corpus ID": 59599752,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentence Composition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6001,
            "Mean Inputs Length": 503.0768,
            "Mean Targets Length": 35.4818,
            "Max Inputs Length": 725,
            "Max Targets Length": 53,
            "Min Inputs Length": 332,
            "Min Targets Length": 26,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "Johns Hopkins University",
            "Brown University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1364_hans_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "hans",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-02-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1596,
            "HF Likes (September 2023)": 3,
            "PwC Description": "The HANS (Heuristic Analysis for NLI Systems) dataset which contains many examples where the heuristics fail.",
            "S2 Citation Count (September 2023)": 892,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Grammar",
                "Writing and composition",
                "Language",
                "Language and grammar",
                "Sentence structure",
                "Writing",
                "Communication",
                "Linguistics"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{McCoy2019RightFT,\n author = {R. Thomas McCoy and Ellie Pavlick and Tal Linzen},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {3428-3448},\n title = {Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference},\n year = {2019}\n}\n"
    },
    "fc-sni-haspart_kb": {
        "Unique Dataset Identifier": "fc-sni-haspart_kb",
        "Dataset Name": "haspart_kb",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/abs/2006.07510",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/has_part",
        "Paper Title": "Do Dogs have Whiskers? A New Knowledge Base of hasPart Relations",
        "Papers with Code URL": "https://paperswithcode.com/dataset/haspart-kb",
        "ArXiv URL": "https://arxiv.org/abs/2006.07510",
        "Semantic Scholar Corpus ID": 212414954,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Entity Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6181,
            "Mean Inputs Length": 472.8649,
            "Mean Targets Length": 8.8555,
            "Max Inputs Length": 729,
            "Max Targets Length": 43,
            "Min Inputs Length": 349,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "undisclosed web",
            "arc corpus"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task471_haspart_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "has_part",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-06-12",
            "S2 Date": "2020-06-12",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "This dataset is a new knowledge-base (KB) of hasPart relationships, extracted from a large corpus of generic statements. Complementary to other resources available, it is the first which is all three of: accurate (90% precision), salient (covers relationships a person may mention), and has high coverage of common terms (approximated as within a 10 year old’s vocabulary), as well as having several times more hasPart entries than in the popular ontologies ConceptNet and WordNet. In addition, it contains information about quantifiers, argument modifiers, and links the entities to appropriate concepts in Wikipedia and WordNet.",
            "S2 Citation Count (September 2023)": 18,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Chemistry",
                "Nutrition",
                "Biology",
                "Entity relationships",
                "Anatomy",
                "Meronymy",
                "Semantics",
                "Parts and wholes"
            ]
        },
        "Derived from Datasets": [
            "GenericsKB"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Bhakthavatsalam2020DoDH,\n author = {Sumithra Bhakthavatsalam and Kyle Richardson and Niket Tandon and Peter Clark},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Do Dogs have Whiskers? A New Knowledge Base of hasPart Relations},\n volume = {abs/2006.07510},\n year = {2020}\n}\n"
    },
    "fc-sni-hate_speech_offensive": {
        "Unique Dataset Identifier": "fc-sni-hate_speech_offensive",
        "Dataset Name": "hate_speech_offensive",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/hate_speech_offensive",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/hate_speech_offensive",
        "Paper Title": "Automated Hate Speech Detection and the Problem of Offensive Language",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hate-speech-and-offensive-language",
        "ArXiv URL": "https://arxiv.org/abs/1703.04009",
        "Semantic Scholar Corpus ID": 1733167,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13164,
            "Mean Inputs Length": 569.082,
            "Mean Targets Length": 9.2173,
            "Max Inputs Length": 1225,
            "Max Targets Length": 21,
            "Min Inputs Length": 330,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Cornell University",
            "Hamad Bin Khalifa University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aaai.org/ocs/index.php/ICWSM/ICWSM17/paper/view/15665"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task904_hate_speech_offensive_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "hate_speech_offensive",
            "HF Config": "default",
            "HF Config License": "MIT License",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2017-03-11",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "HSOL is a dataset for hate speech detection. The authors begun with a hate speech lexicon containing words and\nphrases identified by internet users as hate speech, compiled by Hatebase.org. Using the Twitter API they searched\nfor tweets containing terms from the lexicon, resulting in a sample of tweets from 33,458 Twitter users. They extracted\nthe time-line for each user, resulting in a set of 85.4 million tweets. From this corpus they took a random sample of 25k tweets containing terms from the lexicon and had them manually coded by CrowdFlower (CF) workers. Workers were asked to label each tweet as one of three categories: hate speech, offensive but not hate speech, or neither offensive nor hate speech.",
            "S2 Citation Count (September 2023)": 1896,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Social media",
                "Social media analysis",
                "Online harassment",
                "Hate speech and offensive language",
                "Categorization",
                "Online hate speech",
                "Online hate speech detection",
                "Online communication",
                "Categorization of offensive language",
                "Offensive language"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Davidson2017AutomatedHS,\n author = {Thomas Davidson and Dana Warmsley and M. Macy and Ingmar Weber},\n booktitle = {International Conference on Web and Social Media},\n pages = {512-515},\n title = {Automated Hate Speech Detection and the Problem of Offensive Language},\n year = {2017}\n}\n"
    },
    "fc-sni-hateeval": {
        "Unique Dataset Identifier": "fc-sni-hateeval",
        "Dataset Name": "hateeval",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/cicl2018/HateEvalTeam",
        "GitHub URL": "https://github.com/cicl2018/HateEvalTeam",
        "Hugging Face URL": "",
        "Paper Title": "SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 184483123,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11959,
            "Mean Inputs Length": 758.3895,
            "Mean Targets Length": 9.5726,
            "Max Inputs Length": 1430,
            "Max Targets Length": 21,
            "Min Inputs Length": 450,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/cicl2018/HateEvalTeam#hateeval-2019--task-5"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task333_hateeval_classification_hate_en"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 684,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Discrimination and bias analysis",
                "Online hate speech detection",
                "Natural Language Processing",
                "Social media analysis",
                "Hate speech detection",
                "Online hate speech"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Basile2019SemEval2019T5,\n author = {Valerio Basile and C. Bosco and E. Fersini and Debora Nozza and V. Patti and F. M. R. Pardo and Paolo Rosso and M. Sanguinetti},\n booktitle = {International Workshop on Semantic Evaluation},\n pages = {54-63},\n title = {SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter},\n year = {2019}\n}\n"
    },
    "fc-sni-hatexplain": {
        "Unique Dataset Identifier": "fc-sni-hatexplain",
        "Dataset Name": "hatexplain",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/hate-alert/HateXplain",
        "GitHub URL": "https://github.com/hate-alert/HateXplain",
        "Hugging Face URL": "https://huggingface.co/datasets/hatexplain",
        "Paper Title": "HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hatexplain",
        "ArXiv URL": "https://arxiv.org/abs/2012.10289",
        "Semantic Scholar Corpus ID": 229332119,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11030,
            "Mean Inputs Length": 625.9981,
            "Mean Targets Length": 9.2253,
            "Max Inputs Length": 1258,
            "Max Targets Length": 21,
            "Min Inputs Length": 331,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter",
            "gab.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Indian Institute of Technology",
            "Universitat Hamburg"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/2012.10289"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1502_hatexplain_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "hatexplain",
            "HF Config": "plain_text",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-12-18",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1074,
            "HF Likes (September 2023)": 5,
            "PwC Description": "Covers multiple aspects of the issue. Each post in the dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (i.e., hate, offensive or normal), the target community (i.e., the community that has been the victim of hate speech/offensive speech in the post), and the rationales, i.e., the portions of the post on which their labelling decision (as hate, offensive or normal) is based.",
            "S2 Citation Count (September 2023)": 269,
            "GitHub Stars": 156,
            "GitHub Topics": [
                "attention-lstm",
                "bert-fine-tuning",
                "bert-model",
                "bias",
                "detection",
                "explainability",
                "hate-speech",
                "hatespeech",
                "interpretable-deep-learning",
                "lstm",
                "offensive"
            ],
            "Text Topics": [
                "Social media analysis",
                "Text classification",
                "Natural language processing",
                "Online Hate Speech Detection",
                "Natural Language Processing",
                "Social Media Analysis",
                "Online hate speech detection",
                "Online Hate Speech",
                "Online hate speech"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Mathew2020HateXplainAB,\n author = {Binny Mathew and Punyajoy Saha and Seid Muhie Yimam and Chris Biemann and Pawan Goyal and Animesh Mukherjee},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {14867-14875},\n title = {HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection},\n year = {2020}\n}\n"
    },
    "fc-sni-head_qa": {
        "Unique Dataset Identifier": "fc-sni-head_qa",
        "Dataset Name": "head_qa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/head_qa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/head_qa",
        "Paper Title": "HEAD-QA: A Healthcare Dataset for Complex Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/headqa",
        "ArXiv URL": "https://arxiv.org/abs/1906.04701",
        "Semantic Scholar Corpus ID": 184487171,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5128,
            "Mean Inputs Length": 880.8543,
            "Mean Targets Length": 1.5683,
            "Max Inputs Length": 3070,
            "Max Targets Length": 11,
            "Min Inputs Length": 274,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "sanidad.gob.es"
        ],
        "Model Generated": [],
        "Creators": [
            "Universidade da Coruna",
            "CITIC"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/aghie/head-qa#head-qa"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1431_head_qa_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "head_qa",
            "HF Config": "es",
            "HF Config License": "MIT License",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-11",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1333,
            "HF Likes (September 2023)": 4,
            "PwC Description": "HeadQA is a multi-choice question answering testbed to encourage research on complex reasoning. The questions come from exams to access a specialized position in the Spanish healthcare system, and are challenging even for highly specialized humans.",
            "S2 Citation Count (September 2023)": 35,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Chemistry",
                "Surgery",
                "Science",
                "Genetics",
                "Biology",
                "Healthcare",
                "Microbiology",
                "Multiple-choice questions"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Vilares2019HEADQAAH,\n author = {David Vilares and Carlos Gómez-Rodríguez},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {HEAD-QA: A Healthcare Dataset for Complex Reasoning},\n volume = {abs/1906.04701},\n year = {2019}\n}\n"
    },
    "fc-sni-health_fact": {
        "Unique Dataset Identifier": "fc-sni-health_fact",
        "Dataset Name": "health_fact",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/health_fact",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/health_fact",
        "Paper Title": "Explainable Automated Fact-Checking for Public Health Claims",
        "Papers with Code URL": "https://paperswithcode.com/dataset/pubhealth",
        "ArXiv URL": "https://arxiv.org/abs/2010.09926",
        "Semantic Scholar Corpus ID": 224802782,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Fact Verification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 485,
            "Mean Inputs Length": 7882.7856,
            "Mean Targets Length": 1.5588,
            "Max Inputs Length": 28722,
            "Max Targets Length": 11,
            "Min Inputs Length": 957,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "snopes.com",
            "politifact.com",
            "truthorfiction",
            "factcheck",
            "fullfact",
            "ap news",
            "reuters.com",
            "health news reviews (hnr)"
        ],
        "Model Generated": [],
        "Creators": [
            "Imperial College London"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/2010.09926"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1366_healthfact_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "health_fact",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-19",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "PUBHEALTH is a comprehensive dataset for explainable automated fact-checking of public health claims. Each instance in the PUBHEALTH dataset has an associated veracity label (true, false, unproven, mixture). Furthermore each instance in the dataset has an explanation text field. The explanation is a justification for which the claim has been assigned a particular veracity label.",
            "S2 Citation Count (September 2023)": 114,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Education",
                "Text analysis",
                "Argument evaluation",
                "Evidence analysis",
                "Text classification",
                "Reading comprehension",
                "Information retrieval",
                "Natural Language Processing"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Kotonya2020ExplainableAF,\n author = {Neema Kotonya and Francesca Toni},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {7740-7754},\n title = {Explainable Automated Fact-Checking for Public Health Claims},\n year = {2020}\n}\n"
    },
    "fc-sni-help!_need_advice_on_identifying_advice": {
        "Unique Dataset Identifier": "fc-sni-help!_need_advice_on_identifying_advice",
        "Dataset Name": "help!_need_advice_on_identifying_advice",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/venkatasg/Advice-EMNLP2020",
        "GitHub URL": "https://github.com/venkatasg/Advice-EMNLP2020",
        "Hugging Face URL": "",
        "Paper Title": "Help! Need Advice on Identifying Advice",
        "Papers with Code URL": "https://paperswithcode.com/dataset/askparents",
        "ArXiv URL": "https://arxiv.org/abs/2010.02494",
        "Semantic Scholar Corpus ID": 222142461,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11564,
            "Mean Inputs Length": 885.5242,
            "Mean Targets Length": 2.9116,
            "Max Inputs Length": 1891,
            "Max Targets Length": 13,
            "Min Inputs Length": 645,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reddit"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "The University of Texas at Austin",
            "Amazon",
            "McGill University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task115_help_advice_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-06",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "AskParents is a dataset for advice classification extracted from Reddit. In this dataset, posts are annotated for whether they contain advice or not. It contains 8,701 samples for training, 802 for validation and 1,091 for testing.",
            "S2 Citation Count (September 2023)": 7,
            "GitHub Stars": 5,
            "GitHub Topics": [],
            "Text Topics": [
                "Advice",
                "Advice giving",
                "Communication skills",
                "Language learning",
                "Linguistics",
                "Personal development",
                "Language",
                "Advice and guidance",
                "Types of advice"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Govindarajan2020HelpNA,\n author = {Venkata S Govindarajan and Benjamin Chen and Rebecca Warholic and K. Erk and Junyi Jessy Li},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Help! Need Advice on Identifying Advice},\n volume = {abs/2010.02494},\n year = {2020}\n}\n"
    },
    "fc-sni-hind_encorp": {
        "Unique Dataset Identifier": "fc-sni-hind_encorp",
        "Dataset Name": "hind_encorp",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://lindat.mff.cuni.cz/repository/xmlui/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/hind_encorp",
        "Paper Title": "HindEnCorp - Hindi-English and Hindi-only Corpus for Machine Translation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hindencorp",
        "ArXiv URL": "https://aclanthology.org/L14-1643/",
        "Semantic Scholar Corpus ID": 6561801,
        "Languages": [
            "Hindi",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 382,
            "Mean Inputs Length": 804.3613,
            "Mean Targets Length": 182.1728,
            "Max Inputs Length": 5201,
            "Max Targets Length": 3988,
            "Min Inputs Length": 478,
            "Min Targets Length": 31,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "webdunia.com",
            "wikipedia.org",
            "launchpad.net",
            "ted.com",
            "commoncrawl.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Charles University",
            "Masaryk University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 3.0",
                "License URL": "https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0023-625F-0"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1352_hind_encorp_translation_hi_en"
        ],
        "Inferred Metadata": {
            "HF Dataset": "hind_encorp",
            "HF Config": "default",
            "HF Config License": "CC BY-NC-SA 3.0",
            "HF Yaml License": "CC BY-NC-SA 3.0",
            "PwC License Name": "CC BY-NC-SA 3.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-nc-sa/3.0/",
            "PwC Date": "",
            "S2 Date": "2014-05-26",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "A parallel corpus of Hindi and English, and HindMonoCorp, a monolingual corpus of Hindi in their release version 0.5. Both corpora were collected from web sources and preprocessed primarily for the training of statistical machine translation systems. HindEnCorp consists of 274k parallel sentences (3.9 million Hindi and 3.8 million English tokens). HindMonoCorp amounts to 787 million tokens in 44 million sentences.",
            "S2 Citation Count (September 2023)": 129,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "Tides",
            "EMILLE",
            "Indic multi-parallel corpus",
            "Intercorp"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Bojar2014HindEnCorpH,\n author = {Ondrej Bojar and Vojtech Diatka and P. Rychlý and P. Stranák and Vít Suchomel and A. Tamchyna and Daniel Zeman},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {3550-3555},\n title = {HindEnCorp - Hindi-English and Hindi-only Corpus for Machine Translation},\n year = {2014}\n}\n"
    },
    "fc-sni-hindienglish_corpora": {
        "Unique Dataset Identifier": "fc-sni-hindienglish_corpora",
        "Dataset Name": "hindienglish_corpora",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.kaggle.com/aiswaryaramachandran/hindienglish-corpora",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "Hindi",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13054,
            "Mean Inputs Length": 724.4933,
            "Mean Targets Length": 152.1383,
            "Max Inputs Length": 2524,
            "Max Targets Length": 1265,
            "Min Inputs Length": 328,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 3.0",
                "License URL": "https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0023-625F-0"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task424_hindienglish_corpora_hi_en_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language learning",
                "Cultural differences",
                "Cultural exchange",
                "Translation",
                "Cross-cultural communication",
                "Multilingual communication",
                "Literature"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-hippocorpus": {
        "Unique Dataset Identifier": "fc-sni-hippocorpus",
        "Dataset Name": "hippocorpus",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://msropendata.com/datasets/0a83fb6f-a759-4a17-aaa2-fbac84577318",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/hippocorpus",
        "Paper Title": "Recollection versus Imagination: Exploring Human Memory and Cognition via Neural Language Models",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/2020.acl-main.178/",
        "Semantic Scholar Corpus ID": 218498322,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Narrative Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 206,
            "Mean Inputs Length": 2013.4078,
            "Mean Targets Length": 1372.3495,
            "Max Inputs Length": 6455,
            "Max Targets Length": 2710,
            "Min Inputs Length": 758,
            "Min Targets Length": 611,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "original"
        ],
        "Model Generated": [],
        "Creators": [
            "Microsoft Research",
            "University of Washington",
            "AI2",
            "The University of Texas at Austin"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://msropendata-web-api.azurewebsites.net/licenses/f1f352a6-243f-4905-8e00-389edbca9e83/view"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task853_hippocorpus_long_text_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "hippocorpus",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-07-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 862,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 20,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Grief and loss",
                "Family",
                "Vacation",
                "Parenting",
                "Travel",
                "Family and relationships",
                "Moving and starting a new chapter in life",
                "Family dynamics and relationships",
                "Event planning",
                "Family dynamics"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sap2020RecollectionVI,\n author = {Maarten Sap and E. Horvitz and Yejin Choi and Noah A. Smith and J. Pennebaker},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1970-1978},\n title = {Recollection versus Imagination: Exploring Human Memory and Cognition via Neural Language Models},\n year = {2020}\n}\n"
    },
    "fc-sni-hope_edi": {
        "Unique Dataset Identifier": "fc-sni-hope_edi",
        "Dataset Name": "hope_edi",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/hope_edi",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/hope_edi",
        "Paper Title": "HopeEDI: A Multilingual Hope Speech Detection Dataset for Equality, Diversity, and Inclusion",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hopeedi",
        "ArXiv URL": "https://aclanthology.org/2020.peoples-1.5/",
        "Semantic Scholar Corpus ID": 227230585,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7661,
            "Mean Inputs Length": 493.2331,
            "Mean Targets Length": 13.5733,
            "Max Inputs Length": 2252,
            "Max Targets Length": 25,
            "Min Inputs Length": 218,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "youtube"
        ],
        "Model Generated": [],
        "Creators": [
            "Insight SFI Research Centre for Data Analytics",
            "Data Science Institute",
            "National University of Ireland Galway"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/2020.peoples-1.5.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task679_hope_edi_english_text_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "hope_edi",
            "HF Config": "english",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-12-01",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1295,
            "HF Likes (September 2023)": 1,
            "PwC Description": "Over the past few years, systems have been developed to control online content and eliminate abusive, offensive or hate speech content. However, people in power sometimes misuse this form of censorship to obstruct the democratic right of freedom of speech. Therefore, it is imperative that research should take a positive reinforcement approach towards online content that is encouraging, positive and supportive contents. Until now, most studies have focused on solving this problem of negativity in the English language, though the problem is much more than just harmful content. Furthermore, it is multilingual as well. Thus, we have constructed a Hope Speech dataset for Equality, Diversity and Inclusion (HopeEDI) containing user-generated comments from the social media platform YouTube with 28,451, 20,198 and 10,705 comments in English, Tamil and Malayalam, respectively, manually labelled as containing hope speech or not. To our knowledge, this is the first research of its kind to annotate hope speech for equality, diversity and inclusion in a multilingual setting. We determined that the inter-annotator agreement of our dataset using Krippendorff’s alpha. Further, we created several baselines to benchmark the resulting dataset and the results have been expressed using precision, recall and F1-score. The dataset is publicly available for the research community. We hope that this resource will spur further research on encouraging inclusive and responsive speech that reinforces positiveness.",
            "S2 Citation Count (September 2023)": 125,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Equality and inclusion",
                "Social issues",
                "Encouragement",
                "Education",
                "Inclusion and diversity",
                "Social justice",
                "Equality"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Inproceedings{Chakravarthi2020HopeEDIAM,\n author = {Bharathi Raja Chakravarthi},\n booktitle = {Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media},\n title = {HopeEDI: A Multilingual Hope Speech Detection Dataset for Equality, Diversity, and Inclusion},\n year = {2020}\n}\n"
    },
    "fc-sni-hotpotqa": {
        "Unique Dataset Identifier": "fc-sni-hotpotqa",
        "Dataset Name": "hotpotqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/hotpotqa/hotpot",
        "GitHub URL": "https://github.com/hotpotqa/hotpot",
        "Hugging Face URL": "https://huggingface.co/datasets/hotpot_qa",
        "Paper Title": "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hotpotqa",
        "ArXiv URL": "https://arxiv.org/abs/1809.09600",
        "Semantic Scholar Corpus ID": 52822214,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12646,
            "Mean Inputs Length": 372.9559,
            "Mean Targets Length": 14.6051,
            "Max Inputs Length": 1187,
            "Max Targets Length": 534,
            "Min Inputs Length": 126,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University",
            "Stanford University",
            "Montreal Institute of Learning Algorithms (Mila)",
            "Universite de Montreal",
            "CIFAR Senior Fellow",
            "Google"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/hotpotqa/hotpot#license"
            }
        ],
        "License Notes": "Approved for training/fine-tuning only",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task1293_kilt_tasks_hotpotqa_question_answering"
        ],
        "Inferred Metadata": {
            "HF Dataset": "hotpot_qa",
            "HF Config": "distractor",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/4.0/",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-09-25",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 8046,
            "HF Likes (September 2023)": 16,
            "PwC Description": "HotpotQA is a question answering dataset collected on the English Wikipedia, containing about 113K crowd-sourced questions that are constructed to require the introduction paragraphs of two Wikipedia articles to answer. Each question in the dataset comes with the two gold paragraphs, as well as a list of sentences in these paragraphs that crowdworkers identify as supporting facts necessary to answer the question. \n\nA diverse range of reasoning strategies are featured in HotpotQA, including questions involving missing entities in the question, intersection questions (What satisfies property A and property B?), and comparison questions, where two entities are compared by a common attribute, among others. In the few-document distractor setting, the QA models are given ten paragraphs in which the gold paragraphs are guaranteed to be found; in the open-domain fullwiki setting, the models are only given the question and the entire Wikipedia. Models are evaluated on their answer accuracy and explainability, where the former is measured as overlap between the predicted and gold answers with exact match (EM) and unigram F1, and the latter concerns how well the predicted supporting fact sentences match human annotation (Supporting Fact EM/F1). A joint metric is also reported on this dataset, which encourages systems to perform well on both tasks simultaneously.",
            "S2 Citation Count (September 2023)": 1150,
            "GitHub Stars": 343,
            "GitHub Topics": [],
            "Text Topics": [
                "General knowledge",
                "Entertainment",
                "Trivia",
                "Liberal arts education",
                "Choral competitions",
                "Education",
                "Music",
                "Sports",
                "History"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Yang2018HotpotQAAD,\n author = {Zhilin Yang and Peng Qi and Saizheng Zhang and Yoshua Bengio and William W. Cohen and R. Salakhutdinov and Christopher D. Manning},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {2369-2380},\n title = {HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering},\n year = {2018}\n}\n"
    },
    "fc-sni-human_ratings_of_natural_language_generation_outputs": {
        "Unique Dataset Identifier": "fc-sni-human_ratings_of_natural_language_generation_outputs",
        "Dataset Name": "human_ratings_of_natural_language_generation_outputs",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://researchportal.hw.ac.uk/en/datasets/human-ratings-of-natural-language-generation-outputs",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Quality Evaluation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6349,
            "Mean Inputs Length": 579.0608,
            "Mean Targets Length": 1.5672,
            "Max Inputs Length": 1031,
            "Max Targets Length": 11,
            "Min Inputs Length": 317,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://researchportal.hw.ac.uk/en/datasets/human-ratings-of-natural-language-generation-outputs"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1186_nne_hrngo_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Restaurant recommendations",
                "Travel",
                "Evaluation of machine-generated text",
                "Dialogue systems",
                "Natural language generation",
                "Language generation",
                "Linguistics"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-hybridqa": {
        "Unique Dataset Identifier": "fc-sni-hybridqa",
        "Dataset Name": "hybridqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/wenhuchen/HybridQA",
        "GitHub URL": "https://github.com/wenhuchen/HybridQA",
        "Hugging Face URL": "https://huggingface.co/datasets/hybrid_qa",
        "Paper Title": "HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and Textual Data",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hybridqa",
        "ArXiv URL": "https://arxiv.org/abs/2004.07347",
        "Semantic Scholar Corpus ID": 215785913,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12998,
            "Mean Inputs Length": 411.1079,
            "Mean Targets Length": 12.4938,
            "Max Inputs Length": 870,
            "Max Targets Length": 110,
            "Min Inputs Length": 192,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Santa Barbara"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://hybridqa.github.io/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task344_hybridqa_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "hybrid_qa",
            "HF Config": "hybrid_qa",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-15",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 588,
            "HF Likes (September 2023)": 1,
            "PwC Description": "A new large-scale question-answering dataset that requires reasoning on heterogeneous information. Each question is aligned with a Wikipedia table and multiple free-form corpora linked with the entities in the table. The questions are designed to aggregate both tabular information and text information, i.e., lack of either form would render the question unanswerable.",
            "S2 Citation Count (September 2023)": 158,
            "GitHub Stars": 178,
            "GitHub Topics": [],
            "Text Topics": [
                "Geography",
                "Trivia",
                "Cultural heritage",
                "Architecture",
                "Religion",
                "General knowledge",
                "Sports",
                "Education",
                "History",
                "Film and entertainment"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chen2020HybridQAAD,\n author = {Wenhu Chen and Hanwen Zha and Zhiyu Chen and Wenhan Xiong and Hong Wang and W. Wang},\n booktitle = {Findings},\n pages = {1026-1036},\n title = {HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and Textual Data},\n year = {2020}\n}\n"
    },
    "fc-sni-iirc": {
        "Unique Dataset Identifier": "fc-sni-iirc",
        "Dataset Name": "iirc",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.org/data/iirc",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/voidful/IIRC",
        "Paper Title": "IIRC: A Dataset of Incomplete Information Reading Comprehension Questions",
        "Papers with Code URL": "https://paperswithcode.com/dataset/iirc",
        "ArXiv URL": "https://arxiv.org/abs/2011.07127",
        "Semantic Scholar Corpus ID": 226262208,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12926,
            "Mean Inputs Length": 6806.906,
            "Mean Targets Length": 1.5928,
            "Max Inputs Length": 19757,
            "Max Targets Length": 11,
            "Min Inputs Length": 2459,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://allenai.org/data/iirc"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task230_iirc_passage_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "voidful/IIRC",
            "HF Config": "voidful--IIRC",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2023-05-20",
            "HF Downloads (September 2023)": 26,
            "HF Likes (September 2023)": 0,
            "PwC Description": "Contains more than 13K questions over paragraphs from English Wikipedia that provide only partial information to answer them, with the missing information occurring in one or more linked documents. The questions were written by crowd workers who did not have access to any of the linked documents, leading to questions that have little lexical overlap with the contexts where the answers appear.",
            "S2 Citation Count (September 2023)": 27,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "History",
                "Sports",
                "Biography",
                "Language understanding",
                "Passage analysis",
                "Reading comprehension",
                "Historical figures",
                "Education",
                "Critical thinking"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Ferguson2020IIRCAD,\n author = {James Ferguson and Matt Gardner and Tushar Khot and Pradeep Dasigi},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {1137-1147},\n title = {IIRC: A Dataset of Incomplete Information Reading Comprehension Questions},\n year = {2020}\n}\n"
    },
    "fc-sni-imdb": {
        "Unique Dataset Identifier": "fc-sni-imdb",
        "Dataset Name": "imdb",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://ai.stanford.edu/~amaas/data/sentiment/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/imdb",
        "Paper Title": "Learning Word Vectors for Sentiment Analysis",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imdb-movie-reviews",
        "ArXiv URL": "https://aclanthology.org/P11-1015/",
        "Semantic Scholar Corpus ID": 1428702,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12985,
            "Mean Inputs Length": 2231.426,
            "Mean Targets Length": 8.5681,
            "Max Inputs Length": 13776,
            "Max Targets Length": 18,
            "Min Inputs Length": 257,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "imdb.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task284_imdb_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "imdb",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2011-01-01",
            "S2 Date": "2011-06-19",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 229363,
            "HF Likes (September 2023)": 115,
            "PwC Description": "The IMDb Movie Reviews dataset is a binary sentiment analysis dataset consisting of 50,000 reviews from the Internet Movie Database (IMDb) labeled as positive or negative. The dataset contains an even number of positive and negative reviews. Only highly polarizing reviews are considered. A negative review has a score ≤ 4 out of 10, and a positive review has a score ≥ 7 out of 10. No more than 30 reviews are included per movie. The dataset contains additional unlabeled data.",
            "S2 Citation Count (September 2023)": 3941,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Movie reviews",
                "Film appreciation",
                "Pop culture"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Maas2011LearningWV,\n author = {Andrew L. Maas and Raymond E. Daly and Peter T. Pham and Dan Huang and A. Ng and Christopher Potts},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {142-150},\n title = {Learning Word Vectors for Sentiment Analysis},\n year = {2011}\n}\n"
    },
    "fc-sni-imppres": {
        "Unique Dataset Identifier": "fc-sni-imppres",
        "Dataset Name": "imppres",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/imppres",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/imppres",
        "Paper Title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/imppres",
        "ArXiv URL": "https://arxiv.org/abs/2004.03066",
        "Semantic Scholar Corpus ID": 215238941,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentence Composition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 514,
            "Mean Inputs Length": 622.3482,
            "Mean Targets Length": 59.5039,
            "Max Inputs Length": 893,
            "Max Targets Length": 101,
            "Min Inputs Length": 385,
            "Min Targets Length": 38,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/2020.acl-main.768.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1515_imppres_longtextgeneration"
        ],
        "Inferred Metadata": {
            "HF Dataset": "imppres",
            "HF Config": "presupposition_all_n_presupposition",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "CC BY-NC 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-07",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5809,
            "HF Likes (September 2023)": 0,
            "PwC Description": "An IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Inference",
                "Education",
                "Logic and reasoning",
                "Linguistics",
                "Hypothesis generation",
                "Reasoning",
                "General knowledge",
                "Logic"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Jeretic2020AreNL,\n author = {Paloma Jeretic and Alex Warstadt and Suvrat Bhooshan and Adina Williams},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {8690-8705},\n title = {Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition},\n year = {2020}\n}\n"
    },
    "fc-sni-indian_food_101": {
        "Unique Dataset Identifier": "fc-sni-indian_food_101",
        "Dataset Name": "indian_food_101",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.kaggle.com/nehaprabhavalkar/indian-food-101",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 215,
            "Mean Inputs Length": 277.7023,
            "Mean Targets Length": 11.5721,
            "Max Inputs Length": 416,
            "Max Targets Length": 24,
            "Min Inputs Length": 190,
            "Min Targets Length": 10,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://www.kaggle.com/datasets/nehaprabhavalkar/indian-food-101"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1191_food_veg_nonveg"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Food and cuisine",
                "Vegetarianism",
                "Indian Culture",
                "Indian cuisine",
                "Cultural Practices",
                "Food classification",
                "Indian culture",
                "Food",
                "Cultural knowledge",
                "Food and Cuisine"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-indicnlp": {
        "Unique Dataset Identifier": "fc-sni-indicnlp",
        "Dataset Name": "indicnlp",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://indicnlp.ai4bharat.org/papers/arxiv2020_indicnlp_corpus.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages",
        "Papers with Code URL": "https://paperswithcode.com/dataset/indiccorp",
        "ArXiv URL": "https://aclanthology.org/2020.findings-emnlp.445/",
        "Semantic Scholar Corpus ID": 226283984,
        "Languages": [
            "Hindi",
            "English"
        ],
        "Task Categories": [
            "Cause Effect Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 710,
            "Mean Inputs Length": 638.969,
            "Mean Targets Length": 8.607,
            "Max Inputs Length": 951,
            "Max Targets Length": 18,
            "Min Inputs Length": 407,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "online newspaper articles",
            "web search queries",
            "commoncrawl.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Indian Institute of Technology",
            "Microsoft",
            "AI4Bharat"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task938_copa_hi_commonsense_reasoning"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-11-08",
            "S2 Date": "2020-11-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "IndicCorp is a large monolingual corpora with around 9 billion tokens covering 12 of the major Indian languages. It has been developed by discovering and scraping thousands of web sources - primarily news, magazines and books, over a duration of several months.\n\nLanguages covered: Assamese, Bengali, English, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, Telugu\n\nCorpus Format: The corpus is a single large text file containing one sentence per line. The publicly released version is randomly shuffled, untokenized and deduplicated. \n\nDownloads\n\n| Language | # News Articles* | Sentences     | Tokens        | Link     |\n| -------- | ----------------- | ------------- | ------------- | -------- |\n| as       | 0.60M             | 1.39M   |  32.6M  | link |\n| bn       | 3.83M             | 39.9M | 836M  | link |\n| en       | 3.49M             | 54.3M | 1.22B | link |\n| gu       | 2.63M             | 41.1M | 719M  | link |\n| hi       | 4.95M             | 63.1M |  1.86B | link |\n| kn       | 3.76M             | 53.3M | 713M  | link |\n| ml       | 4.75M             | 50.2M |  721M  | link |\n| mr       | 2.31M             | 34.0M | 551M  | link |\n| or       | 0.69M             | 6.94M   | 107M   | link |\n| pa       | 2.64M             | 29.2M |  773M  | link |\n| ta       | 4.41M             |  31.5M   |  582M  | link |\n| te       | 3.98M             | 47.9M   |  674M  | link |\n\n* Excluding articles obtained from the OSCAR corpus",
            "S2 Citation Count (September 2023)": 267,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Cultural understanding",
                "Language processing",
                "Reasoning and logic",
                "Language comprehension",
                "Language and translation",
                "Language learning",
                "Translation",
                "Reasoning"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Kakwani2020iNLPSuiteMC,\n author = {Divyanshu Kakwani and Anoop Kunchukuttan and S. Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n booktitle = {Findings},\n journal = {Findings of the Association for Computational Linguistics: EMNLP 2020},\n title = {iNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages},\n year = {2020}\n}\n"
    },
    "fc-sni-inquisitive": {
        "Unique Dataset Identifier": "fc-sni-inquisitive",
        "Dataset Name": "inquisitive",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/wjko2/INQUISITIVE",
        "GitHub URL": "https://github.com/wjko2/INQUISITIVE",
        "Hugging Face URL": "https://huggingface.co/datasets/inquisitive_qg",
        "Paper Title": "Inquisitive Question Generation for High Level Text Comprehension",
        "Papers with Code URL": "https://paperswithcode.com/dataset/inquisitive",
        "ArXiv URL": "https://arxiv.org/abs/2010.01657",
        "Semantic Scholar Corpus ID": 222133874,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 341,
            "Mean Inputs Length": 614.5161,
            "Mean Targets Length": 43.3196,
            "Max Inputs Length": 1457,
            "Max Targets Length": 155,
            "Min Inputs Length": 193,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wsj",
            "ap news",
            "newsela"
        ],
        "Model Generated": [],
        "Creators": [
            "The University of Texas at Austin"
        ],
        "Licenses": [
            {
                "License": "Request Form",
                "License URL": ""
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task857_inquisitive_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "inquisitive_qg",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 593,
            "HF Likes (September 2023)": 1,
            "PwC Description": "A dataset of ~19K questions that are elicited while a person is reading through a document.",
            "S2 Citation Count (September 2023)": 27,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Government policies",
                "Geography",
                "Travel",
                "Business and entrepreneurship",
                "Politics",
                "Marine biology",
                "Aviation security",
                "Natural disasters",
                "Current events"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Ko2020InquisitiveQG,\n author = {Wei-Jen Ko and Tengyang Chen and Yiyan Huang and Greg Durrett and Junyi Jessy Li},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {6544-6555},\n title = {Inquisitive Question Generation for High Level Text Comprehension},\n year = {2020}\n}\n"
    },
    "fc-sni-jeopardy": {
        "Unique Dataset Identifier": "fc-sni-jeopardy",
        "Dataset Name": "jeopardy",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/jeopardy",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12951,
            "Mean Inputs Length": 533.6436,
            "Mean Targets Length": 11.0534,
            "Max Inputs Length": 906,
            "Max Targets Length": 57,
            "Min Inputs Length": 264,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "jeopardy"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task305_jeopardy_answer_generation_normal"
        ],
        "Inferred Metadata": {
            "HF Dataset": "jeopardy",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 516,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "History",
                "Winter activities",
                "Education",
                "Problem-solving",
                "Entertainment",
                "Word games",
                "Games",
                "Geography"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-jfleg": {
        "Unique Dataset Identifier": "fc-sni-jfleg",
        "Dataset Name": "jfleg",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/jfleg",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/jfleg",
        "Paper Title": "JFLEG: A Fluency Corpus and Benchmark for Grammatical Error Correction",
        "Papers with Code URL": "https://paperswithcode.com/dataset/jfleg",
        "ArXiv URL": "https://arxiv.org/abs/1702.04066",
        "Semantic Scholar Corpus ID": 6922426,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Grammar Error Correction"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1480,
            "Mean Inputs Length": 406.777,
            "Mean Targets Length": 97.0135,
            "Max Inputs Length": 1245,
            "Max Targets Length": 401,
            "Min Inputs Length": 138,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "sentences written by english language learners for the toefl exam"
        ],
        "Model Generated": [],
        "Creators": [
            "Johns Hopkins University",
            "Grammarly"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "https://github.com/keisks/jfleg"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1557_jfleg_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "jfleg",
            "HF Config": "default",
            "HF Config License": "CC BY-NC-SA 4.0",
            "HF Yaml License": "CC BY-NC-SA 4.0",
            "PwC License Name": "CC BY-NC-SA 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-nc-sa/4.0/",
            "PwC Date": "",
            "S2 Date": "2017-02-14",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2710,
            "HF Likes (September 2023)": 28,
            "PwC Description": "JFLEG is for developing and evaluating grammatical error correction (GEC). Unlike other corpora, it represents a broad range of language proficiency levels and uses holistic fluency edits to not only correct grammatical errors but also make the original text more native sounding.",
            "S2 Citation Count (September 2023)": 159,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Communication skills",
                "Transportation",
                "Language correction",
                "Grammar",
                "Grammar correction",
                "Language proficiency",
                "Linguistics",
                "Language learning",
                "Communication",
                "Education"
            ]
        },
        "Derived from Datasets": [
            "GUG corpus"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Tetreault2017JFLEGAF,\n author = {Joel R. Tetreault and Keisuke Sakaguchi and Courtney Napoles},\n booktitle = {Conference of the European Chapter of the Association for Computational Linguistics},\n pages = {229-234},\n title = {JFLEG: A Fluency Corpus and Benchmark for Grammatical Error Correction},\n year = {2017}\n}\n"
    },
    "fc-sni-jigsaw": {
        "Unique Dataset Identifier": "fc-sni-jigsaw",
        "Dataset Name": "jigsaw",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12811,
            "Mean Inputs Length": 714.5723,
            "Mean Targets Length": 8.559,
            "Max Inputs Length": 3080,
            "Max Targets Length": 20,
            "Min Inputs Length": 283,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Google"
        ],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification/overview/faq"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task322_jigsaw_classification_threat"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Social media and online platforms",
                "Social media",
                "Natural language processing",
                "Online safety",
                "Online platforms",
                "Online safety and security",
                "Social media etiquette",
                "Threat detection and classification",
                "Threat detection",
                "Online communication"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-jnlpba_corpus": {
        "Unique Dataset Identifier": "fc-sni-jnlpba_corpus",
        "Dataset Name": "jnlpba_corpus",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/jnlpba",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/jnlpba",
        "Paper Title": "Introduction to the Bio-entity Recognition Task at JNLPBA",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/W04-1213/",
        "Semantic Scholar Corpus ID": 7985741,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2426,
            "Mean Inputs Length": 558.6414,
            "Mean Targets Length": 14.3561,
            "Max Inputs Length": 1214,
            "Max Targets Length": 37,
            "Min Inputs Length": 226,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "pubmed articles"
        ],
        "Model Generated": [],
        "Creators": [
            "Center for Research on Engineering Software Technologies",
            "Japan Science and Technology Agency",
            "University of Tokyo",
            "National Institute of Informatics"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://docs.google.com/viewer?a=v&pid=sites&srcid=Z2VuaWFwcm9qZWN0Lm9yZ3xtYWlufGd4OjU5ZTE1NjY0NjE2OTVlNDY"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1480_gene_extraction_jnlpba_dataset"
        ],
        "Inferred Metadata": {
            "HF Dataset": "jnlpba",
            "HF Config": "jnlpba",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2004-08-28",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 723,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 649,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "DNA repair",
                "Medical research",
                "Protein structure and function",
                "Biochemistry",
                "Molecular biology",
                "Biology",
                "Immunology",
                "Cell biology",
                "Cancer treatment",
                "Genetics"
            ]
        },
        "Derived from Datasets": [
            "Genia dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Collier2004IntroductionTT,\n author = {Nigel Collier and Jin-Dong Kim},\n booktitle = {NLPBA/BioNLP},\n pages = {70-75},\n title = {Introduction to the Bio-entity Recognition Task at JNLPBA},\n year = {2004}\n}\n"
    },
    "fc-sni-kde4": {
        "Unique Dataset Identifier": "fc-sni-kde4",
        "Dataset Name": "kde4",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/kde4",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/kde4",
        "Paper Title": "Parallel Data, Tools and Interfaces in OPUS",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/L12-1246/",
        "Semantic Scholar Corpus ID": 15453873,
        "Languages": [
            "Hindi",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2998,
            "Mean Inputs Length": 596.3949,
            "Mean Targets Length": 40.8849,
            "Max Inputs Length": 1362,
            "Max Targets Length": 327,
            "Min Inputs Length": 430,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "european union",
            "opus software projects",
            "opus movie subtitles",
            "european central bank",
            "moniteur belge/belgisch staatsblad",
            "opensubtitles.org",
            "tehran english-persian parallel corpus",
            "wikisource"
        ],
        "Model Generated": [],
        "Creators": [
            "Uppsala University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task877_kde4_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "kde4",
            "HF Config": "fi-nl",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 4551,
            "HF Likes (September 2023)": 9,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1551,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Cross-cultural communication",
                "Language localization",
                "Linguistics",
                "Localization",
                "Language learning",
                "Language",
                "Language and Linguistics",
                "Language and linguistics"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Tiedemann2012ParallelDT,\n author = {J. Tiedemann},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2214-2218},\n title = {Parallel Data, Tools and Interfaces in OPUS},\n year = {2012}\n}\n"
    },
    "fc-sni-leetcode": {
        "Unique Dataset Identifier": "fc-sni-leetcode",
        "Dataset Name": "leetcode",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://leetcode.com/problems/strong-password-checker/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text to Code"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10335,
            "Mean Inputs Length": 674.5685,
            "Mean Targets Length": 1.9638,
            "Max Inputs Length": 828,
            "Max Targets Length": 12,
            "Min Inputs Length": 560,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Leetcode"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task956_leetcode_420_strong_password_check"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Password requirements",
                "User authentication",
                "Password security",
                "Online privacy",
                "Authentication"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-liar": {
        "Unique Dataset Identifier": "fc-sni-liar",
        "Dataset Name": "liar",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/liar",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/liar",
        "Paper Title": "\"Liar, Liar Pants on Fire\": A New Benchmark Dataset for Fake News Detection",
        "Papers with Code URL": "https://paperswithcode.com/dataset/liar",
        "ArXiv URL": "https://arxiv.org/abs/1705.00648",
        "Semantic Scholar Corpus ID": 10326133,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12994,
            "Mean Inputs Length": 734.1374,
            "Mean Targets Length": 5.0382,
            "Max Inputs Length": 1333,
            "Max Targets Length": 15,
            "Min Inputs Length": 424,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "politifact.com"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Santa Barbara"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/1705.00648"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1187_politifact_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "liar",
            "HF Config": "default",
            "HF Config License": "Unspecified",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2017-05-01",
            "S2 Date": "2017-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1742,
            "HF Likes (September 2023)": 4,
            "PwC Description": "LIAR is a publicly available dataset for fake news detection. A decade-long of 12.8K manually labeled short statements were collected in various contexts from POLITIFACT.COM, which provides detailed analysis report and links to source documents for each case. This dataset can be used for fact-checking research as well. Notably, this new dataset is an order of magnitude larger than previously largest public fake news datasets of similar type. The LIAR dataset4 includes 12.8K human labeled short statements from POLITIFACT.COM’s API, and each statement is evaluated by a POLITIFACT.COM editor for its truthfulness.",
            "S2 Citation Count (September 2023)": 1040,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Natural language processing",
                "Politics",
                "Language understanding",
                "Communication",
                "Public speaking",
                "Language and communication",
                "Media analysis"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Wang2017LiarLP,\n author = {William Yang Wang},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {422-426},\n title = {“Liar, Liar Pants on Fire”: A New Benchmark Dataset for Fake News Detection},\n year = {2017}\n}\n"
    },
    "fc-sni-librispeech_asr,": {
        "Unique Dataset Identifier": "fc-sni-librispeech_asr,",
        "Dataset Name": "librispeech_asr,",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/librispeech_asr",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/librispeech_asr",
        "Paper Title": "Librispeech: An ASR corpus based on public domain audio books",
        "Papers with Code URL": "https://paperswithcode.com/dataset/librispeech",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 2191379,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Fill in The Blank"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 290,
            "Mean Inputs Length": 308.9414,
            "Mean Targets Length": 4.9,
            "Max Inputs Length": 667,
            "Max Targets Length": 18,
            "Min Inputs Length": 67,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "http://www.openslr.org/12"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task963_librispeech_asr_next_word_prediction"
        ],
        "Inferred Metadata": {
            "HF Dataset": "librispeech_asr",
            "HF Config": "all",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/4.0/",
            "PwC Date": "2015-01-01",
            "S2 Date": "2015-04-19",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 14388,
            "HF Likes (September 2023)": 50,
            "PwC Description": "The LibriSpeech corpus is a collection of approximately 1,000 hours of audiobooks that are a part of the LibriVox project. Most of the audiobooks come from the Project Gutenberg. The training data is split into 3 partitions of 100hr, 360hr, and 500hr sets while the dev and test data are split into the ’clean’ and ’other’ categories, respectively, depending upon how well or challenging Automatic Speech Recognition systems would perform against. Each of the dev and test sets is around 5hr in audio length. This corpus also provides the n-gram language models and the corresponding texts excerpted from the Project Gutenberg books, which contain 803M tokens and 977K unique words.",
            "S2 Citation Count (September 2023)": 4137,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Communication",
                "Language processing",
                "Natural language processing",
                "Daily routine",
                "Education",
                "Language understanding",
                "Language",
                "Language learning",
                "Linguistics"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Panayotov2015LibrispeechAA,\n author = {Vassil Panayotov and Guoguo Chen and Daniel Povey and S. Khudanpur},\n booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing},\n journal = {2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n pages = {5206-5210},\n title = {Librispeech: An ASR corpus based on public domain audio books},\n year = {2015}\n}\n"
    },
    "fc-sni-limit": {
        "Unique Dataset Identifier": "fc-sni-limit",
        "Dataset Name": "limit",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/ilmgut/limit_dataset",
        "GitHub URL": "https://github.com/ilmgut/limit_dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/limit",
        "Paper Title": "LiMiT: The Literal Motion in Text Dataset",
        "Papers with Code URL": "https://paperswithcode.com/dataset/limit",
        "ArXiv URL": "https://aclanthology.org/2020.findings-emnlp.88/",
        "Semantic Scholar Corpus ID": 226283877,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Information Extraction"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3984,
            "Mean Inputs Length": 854.6915,
            "Mean Targets Length": 3.0823,
            "Max Inputs Length": 1500,
            "Max Targets Length": 13,
            "Min Inputs Length": 623,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "fiction e-books",
            "online novels"
        ],
        "Model Generated": [],
        "Creators": [
            "IBM"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/ilmgut/limit_dataset/blob/master/LICENSE.md"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1517_limit_classfication"
        ],
        "Inferred Metadata": {
            "HF Dataset": "limit",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 975,
            "HF Likes (September 2023)": 3,
            "PwC Description": "The limit dataset of ~24K sentences that describe literal motion (~14K sentences), and sentences not describing motion or other type of motion (e.g. fictive motion). Senteces were extracted from electronic books categorized as fiction or novels, and a portion from the NetActivity Captions Dataset.",
            "S2 Citation Count (September 2023)": 7,
            "GitHub Stars": 3,
            "GitHub Topics": [],
            "Text Topics": [
                "Language learning",
                "Sentence analysis",
                "Sentence classification",
                "Language understanding",
                "Sentiment analysis",
                "Natural Language Processing",
                "Natural language processing"
            ]
        },
        "Derived from Datasets": [
            "Net Activity Captions dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Manotas2020LiMiTTL,\n author = {Irene Manotas and Ngoc Phuoc An Vo and V. Sheinin},\n booktitle = {Findings},\n pages = {991-1000},\n title = {LiMiT: The Literal Motion in Text Dataset},\n year = {2020}\n}\n"
    },
    "fc-sni-linnaeus_corpus": {
        "Unique Dataset Identifier": "fc-sni-linnaeus_corpus",
        "Dataset Name": "linnaeus_corpus",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/linnaeus",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/linnaeus",
        "Paper Title": "LINNAEUS: A species name identification system for biomedical literature",
        "Papers with Code URL": "https://paperswithcode.com/dataset/linnaeus",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 10197117,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 283,
            "Mean Inputs Length": 565.0247,
            "Mean Targets Length": 13.9329,
            "Max Inputs Length": 1374,
            "Max Targets Length": 32,
            "Min Inputs Length": 219,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-11-85"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1484_gene_extraction_linnaeus_dataset"
        ],
        "Inferred Metadata": {
            "HF Dataset": "linnaeus",
            "HF Config": "linnaeus",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2010-02-11",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 559,
            "HF Likes (September 2023)": 1,
            "PwC Description": "LINNAEUS is a general-purpose dictionary matching software, capable of processing multiple types of document formats in the biomedical domain (MEDLINE, PMC, BMC, OTMI, text, etc.). It can produce multiple types of output (XML, HTML, tab-separated-value file, or save to a database). It also contains methods for acting as a server (including load balancing across several servers), allowing clients to request matching over a network. A package with files for recognizing and identifying species names is available for LINNAEUS, showing 94% recall and 97% precision compared to LINNAEUS-species-corpus.",
            "S2 Citation Count (September 2023)": 333,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Bioinformatics",
                "Medical research",
                "Natural language processing",
                "Genetics",
                "Microbiology",
                "Medicine",
                "Immunology",
                "Molecular biology",
                "Biology"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Gerner2010LINNAEUSAS,\n author = {Martin Gerner and G. Nenadic and C. Bergman},\n booktitle = {BMC Bioinformatics},\n journal = {BMC Bioinformatics},\n pages = {85 - 85},\n title = {LINNAEUS: A species name identification system for biomedical literature},\n volume = {11},\n year = {2010}\n}\n"
    },
    "fc-sni-lj_speec": {
        "Unique Dataset Identifier": "fc-sni-lj_speec",
        "Dataset Name": "lj_speec",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/lj_speech",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/lj_speech",
        "Paper Title": "SOMOS: The Samsung Open MOS Dataset for the Evaluation of Neural Text-to-Speech Synthesis",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ljspeech",
        "ArXiv URL": "https://arxiv.org/abs/2204.03040",
        "Semantic Scholar Corpus ID": 248006221,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Number Conversion"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 985,
            "Mean Inputs Length": 698.3228,
            "Mean Targets Length": 103.7005,
            "Max Inputs Length": 1268,
            "Max Targets Length": 180,
            "Min Inputs Length": 430,
            "Min Targets Length": 20,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "arts and crafts essays",
            "the chronicles of newgate",
            "the fireside chats of franklin delano roosevelt",
            "marion harland's cookery for beginners",
            "the science - history of the universe",
            "vol. 5: biology",
            "the seven wonders of the ancient world",
            "the president's commission report on the JFK assassination"
        ],
        "Model Generated": [],
        "Creators": [
            "Innoetics",
            "Samsung",
            "Mobile Communications Business",
            "Samsung"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://librivox.org/pages/public-domain/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1703_ljspeech_textmodification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "lj_speech",
            "HF Config": "main",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC0 1.0",
            "PwC License URL": "https://librivox.org/pages/public-domain/",
            "PwC Date": "",
            "S2 Date": "2022-04-06",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 920,
            "HF Likes (September 2023)": 8,
            "PwC Description": "This is a public domain speech dataset consisting of 13,100 short audio clips of a single speaker reading passages from 7 non-fiction books. A transcription is provided for each clip. Clips vary in length from 1 to 10 seconds and have a total length of approximately 24 hours. The texts were published between 1884 and 1964, and are in the public domain. The audio was recorded in 2016-17 by the LibriVox project and is also in the public domain.",
            "S2 Citation Count (September 2023)": 9,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Numerical conversion",
                "Language and Linguistics",
                "Language and communication",
                "Historical events",
                "Language processing",
                "Numerical representation",
                "Linguistics",
                "Natural language understanding"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Maniati2022SOMOSTS,\n author = {Georgia Maniati and Alexandra Vioni and Nikolaos Ellinas and Karolos Nikitaras and Konstantinos Klapsas and June Sig Sung and Gunu Jho and Aimilios Chalamandaris and Pirros Tsiakoulis},\n booktitle = {Interspeech},\n pages = {2388-2392},\n title = {SOMOS: The Samsung Open MOS Dataset for the Evaluation of Neural Text-to-Speech Synthesis},\n year = {2022}\n}\n"
    },
    "fc-sni-logic2text": {
        "Unique Dataset Identifier": "fc-sni-logic2text",
        "Dataset Name": "logic2text",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/czyssrs/Logic2Text",
        "GitHub URL": "https://github.com/czyssrs/Logic2Text",
        "Hugging Face URL": "https://huggingface.co/datasets/kasnerz/logic2text",
        "Paper Title": "Logic2Text: High-Fidelity Natural Language Generation from Logical Forms",
        "Papers with Code URL": "https://paperswithcode.com/dataset/logic2text",
        "ArXiv URL": "https://arxiv.org/abs/2004.14579",
        "Semantic Scholar Corpus ID": 216914911,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text to Code"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13018,
            "Mean Inputs Length": 3058.9488,
            "Mean Targets Length": 95.747,
            "Max Inputs Length": 4341,
            "Max Targets Length": 531,
            "Min Inputs Length": 2695,
            "Min Targets Length": 30,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Santa Barbara",
            "Intel AI"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/2020.findings-emnlp.190.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task210_logic2text_structured_text_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "kasnerz/logic2text",
            "HF Config": "default",
            "HF Config License": "MIT License",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-01",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2022-11-28",
            "HF Downloads (September 2023)": 49,
            "HF Likes (September 2023)": 0,
            "PwC Description": "Logic2Text is a large-scale dataset with 10,753 descriptions involving common logic types paired with the underlying logical forms. The logical forms show diversified graph structure of free schema, which poses great challenges on the model's ability to understand the semantics.",
            "S2 Citation Count (September 2023)": 46,
            "GitHub Stars": 60,
            "GitHub Topics": [],
            "Text Topics": [
                "Logic",
                "Logic and reasoning",
                "Table operations",
                "Natural language processing",
                "Data analysis",
                "Logic and operations",
                "Query optimization",
                "Logical operations",
                "Query generation"
            ]
        },
        "Derived from Datasets": [
            "WikiTables"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chen2020Logic2TextHN,\n author = {Zhiyu Chen and Wenhu Chen and Hanwen Zha and Xiyou Zhou and Yunkai Zhang and Sairam Sundaresan and William Yang Wang},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {Logic2Text: High-Fidelity Natural Language Generation from Logical Forms},\n volume = {abs/2004.14579},\n year = {2020}\n}\n"
    },
    "fc-sni-math_qa": {
        "Unique Dataset Identifier": "fc-sni-math_qa",
        "Dataset Name": "math_qa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/math_qa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/math_qa",
        "Paper Title": "MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mathqa",
        "ArXiv URL": "https://arxiv.org/abs/1905.13319",
        "Semantic Scholar Corpus ID": 173188048,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8853,
            "Mean Inputs Length": 732.7629,
            "Mean Targets Length": 1.6023,
            "Max Inputs Length": 1619,
            "Max Targets Length": 11,
            "Min Inputs Length": 319,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "gmat",
            "gre exams"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/N19-1245.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1678_mathqa_answer_selection"
        ],
        "Inferred Metadata": {
            "HF Dataset": "math_qa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Custom",
            "PwC License URL": "https://math-qa.github.io/math-QA/",
            "PwC Date": "",
            "S2 Date": "2019-05-30",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 6948,
            "HF Likes (September 2023)": 34,
            "PwC Description": "MathQA significantly enhances the AQuA dataset with fully-specified operational programs.",
            "S2 Citation Count (September 2023)": 194,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Multiple-choice questions",
                "Math",
                "Mathematics",
                "Logical reasoning",
                "Education",
                "Multiple choice tests",
                "Time management",
                "Problem-solving",
                "Multiple choice"
            ]
        },
        "Derived from Datasets": [
            "AQuA dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Amini2019MathQATI,\n author = {Aida Amini and Saadia Gabriel and Shanchuan Lin and Rik Koncel-Kedziorski and Yejin Choi and Hannaneh Hajishirzi},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {2357-2367},\n title = {MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms},\n year = {2019}\n}\n"
    },
    "fc-sni-mathmatics_dataset": {
        "Unique Dataset Identifier": "fc-sni-mathmatics_dataset",
        "Dataset Name": "mathmatics_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/deepmind/mathematics_dataset",
        "GitHub URL": "https://github.com/deepmind/mathematics_dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/math_dataset",
        "Paper Title": "ANALYSING MATHEMATICAL REASONING ABILITIES OF NEURAL MODELS",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mathematics",
        "ArXiv URL": "https://arxiv.org/abs/1904.01557",
        "Semantic Scholar Corpus ID": 85504763,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Understanding"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8097,
            "Mean Inputs Length": 1024.2946,
            "Mean Targets Length": 9.7926,
            "Max Inputs Length": 1377,
            "Max Targets Length": 21,
            "Min Inputs Length": 811,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "DeepMind"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://openreview.net/pdf?id=H1gR5iR5FX"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task834_mathdataset_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "math_dataset",
            "HF Config": "algebra__linear_1d",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "https://github.com/deepmind/mathematics_dataset/blob/master/LICENSE",
            "PwC Date": "2019-04-02",
            "S2 Date": "2019-04-02",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 26973,
            "HF Likes (September 2023)": 34,
            "PwC Description": "This dataset code generates mathematical question and answer pairs, from a range of question types at roughly school-level difficulty. This is designed to test the mathematical learning and algebraic reasoning skills of learning models.",
            "S2 Citation Count (September 2023)": 256,
            "GitHub Stars": 1643,
            "GitHub Topics": [],
            "Text Topics": [
                "High school curriculum",
                "Mathematics",
                "Problem-solving"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Saxton2019AnalysingMR,\n author = {D. Saxton and Edward Grefenstette and Felix Hill and Pushmeet Kohli},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Analysing Mathematical Reasoning Abilities of Neural Models},\n volume = {abs/1904.01557},\n year = {2019}\n}\n"
    },
    "fc-sni-mathqa": {
        "Unique Dataset Identifier": "fc-sni-mathqa",
        "Dataset Name": "mathqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://math-qa.github.io/math-QA/",
        "GitHub URL": "https://math-qa.github.io/math-QA/",
        "Hugging Face URL": "https://huggingface.co/datasets/math_qa",
        "Paper Title": "MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mathqa",
        "ArXiv URL": "https://arxiv.org/abs/1905.13319",
        "Semantic Scholar Corpus ID": 173188048,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12899,
            "Mean Inputs Length": 765.5987,
            "Mean Targets Length": 1.5831,
            "Max Inputs Length": 1582,
            "Max Targets Length": 11,
            "Min Inputs Length": 272,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "gmat",
            "gre exams"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/N19-1245.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1419_mathqa_gain"
        ],
        "Inferred Metadata": {
            "HF Dataset": "math_qa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Custom",
            "PwC License URL": "https://math-qa.github.io/math-QA/",
            "PwC Date": "",
            "S2 Date": "2019-05-30",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 6948,
            "HF Likes (September 2023)": 34,
            "PwC Description": "MathQA significantly enhances the AQuA dataset with fully-specified operational programs.",
            "S2 Citation Count (September 2023)": 194,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Business",
                "Investment",
                "Mathematics",
                "Problem-solving",
                "Finance",
                "Education",
                "Interest calculation",
                "Percentage calculations"
            ]
        },
        "Derived from Datasets": [
            "AQuA dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Amini2019MathQATI,\n author = {Aida Amini and Saadia Gabriel and Shanchuan Lin and Rik Koncel-Kedziorski and Yejin Choi and Hannaneh Hajishirzi},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {2357-2367},\n title = {MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms},\n year = {2019}\n}\n"
    },
    "fc-sni-matres": {
        "Unique Dataset Identifier": "fc-sni-matres",
        "Dataset Name": "matres",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/CogComp/MATRES",
        "GitHub URL": "https://github.com/CogComp/MATRES",
        "Hugging Face URL": "",
        "Paper Title": "A Multi-Axis Annotation Scheme for Event Temporal Relations",
        "Papers with Code URL": "https://paperswithcode.com/dataset/matres",
        "ArXiv URL": "https://arxiv.org/abs/1804.07828",
        "Semantic Scholar Corpus ID": 5066019,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Misc."
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3905,
            "Mean Inputs Length": 1039.1234,
            "Mean Targets Length": 3.0563,
            "Max Inputs Length": 1949,
            "Max Targets Length": 13,
            "Min Inputs Length": 462,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "University of Illinois Urbana-Champaign",
            "University of Pennsylvania"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/P18-1122.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task383_matres_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2018-04-20",
            "S2 Date": "2018-04-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "This is the Multi-Axis Temporal RElations for Start-points (i.e., MATRES) dataset",
            "S2 Citation Count (September 2023)": 115,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Time perception",
                "Time and tenses",
                "Time and tense",
                "Verb tenses",
                "Language",
                "Grammar",
                "Verbs",
                "Linguistics"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Ning2018AMA,\n author = {Qiang Ning and Hao Wu and D. Roth},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {A Multi-Axis Annotation Scheme for Event Temporal Relations},\n volume = {abs/1804.07828},\n year = {2018}\n}\n"
    },
    "fc-sni-mcscript": {
        "Unique Dataset Identifier": "fc-sni-mcscript",
        "Dataset Name": "mcscript",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "http://www.sfb1102.uni-saarland.de/?page_id=2582",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1803.05223v1",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13004,
            "Mean Inputs Length": 1971.7364,
            "Mean Targets Length": 19.3911,
            "Max Inputs Length": 5232,
            "Max Targets Length": 120,
            "Min Inputs Length": 945,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/1803.05223v1.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task164_mcscript_question_answering_text"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Customer service",
                "Reading comprehension",
                "Test preparation",
                "Question answering",
                "Language understanding",
                "Answer selection",
                "Critical thinking"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": ""
    },
    "fc-sni-mctaco": {
        "Unique Dataset Identifier": "fc-sni-mctaco",
        "Dataset Name": "mctaco",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/CogComp/MCTACO",
        "GitHub URL": "https://github.com/CogComp/MCTACO",
        "Hugging Face URL": "https://huggingface.co/datasets/mc_taco",
        "Paper Title": "“Going on a vacation” takes longer than “Going for a walk”: A Study of Temporal Commonsense Understanding",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mc-taco",
        "ArXiv URL": "https://arxiv.org/abs/1909.03065",
        "Semantic Scholar Corpus ID": 202541184,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 863,
            "Mean Inputs Length": 833.0718,
            "Mean Targets Length": 45.1414,
            "Max Inputs Length": 1253,
            "Max Targets Length": 90,
            "Min Inputs Length": 596,
            "Min Targets Length": 21,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "cnn.com",
            "wsj",
            "nytmes",
            "wikipedia.org",
            "project gutenberg",
            "9/11 reports",
            "textbooks",
            "mctest",
            "anc corpus",
            "masc dataset"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Pennsylvania",
            "AI2",
            "University of Illinois Urbana-Champaign"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/1909.03065"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task003_mctaco_question_generation_event_duration"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mc_taco",
            "HF Config": "plain_text",
            "HF Config License": "Unspecified",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2019-09-06",
            "S2 Date": "2019-09-06",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1739,
            "HF Likes (September 2023)": 0,
            "PwC Description": "MC-TACO is a dataset of 13k question-answer pairs that require temporal commonsense comprehension. The dataset contains five temporal properties, (1) duration (how long an event takes), (2) temporal ordering (typical order of events), (3) typical time (when an event occurs), (4) frequency (how often an event occurs), and (5) stationarity (whether a state is maintained for a very long time or indefinitely).",
            "S2 Citation Count (September 2023)": 130,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "History",
                "Time management",
                "Time measurement",
                "Travel",
                "Daily routine",
                "Science",
                "Geography",
                "General knowledge"
            ]
        },
        "Derived from Datasets": [
            "MultiRC"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zhou2019GoingOA,\n author = {Ben Zhou and Daniel Khashabi and Qiang Ning and D. Roth},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {“Going on a vacation” takes longer than “Going for a walk”: A Study of Temporal Commonsense Understanding},\n volume = {abs/1909.03065},\n year = {2019}\n}\n"
    },
    "fc-sni-md_gender_bias": {
        "Unique Dataset Identifier": "fc-sni-md_gender_bias",
        "Dataset Name": "md_gender_bias",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/md_gender_bias",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/md_gender_bias",
        "Paper Title": "Multi-Dimensional Gender Bias Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/md-gender",
        "ArXiv URL": "https://arxiv.org/abs/2005.00614",
        "Semantic Scholar Corpus ID": 218487627,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentence Perturbation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1992,
            "Mean Inputs Length": 378.5788,
            "Mean Targets Length": 50.3584,
            "Max Inputs Length": 724,
            "Max Targets Length": 140,
            "Min Inputs Length": 190,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "yelp",
            "opensubtitles.org",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Facebook AI Research",
            "Laboratoire Lorrain d’Informatique et Applications (LORIA)"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/2020.emnlp-main.23.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1669_md_gender_bias_text_modification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "md_gender_bias",
            "HF Config": "gendered_words",
            "HF Config License": "MIT License",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3979,
            "HF Likes (September 2023)": 12,
            "PwC Description": "Provides eight automatically annotated large scale datasets with gender information.",
            "S2 Citation Count (September 2023)": 66,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Gender and language",
                "Gender equality",
                "Language and grammar",
                "Language and communication",
                "Daily routine",
                "Gender roles and stereotypes",
                "Sports"
            ]
        },
        "Derived from Datasets": [
            "Funpedia",
            "Wizard of Wikipedia",
            "ConvAI2",
            "ImageChat",
            "LIGHT"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Dinan2020MultiDimensionalGB,\n author = {Emily Dinan and Angela Fan and Ledell Yu Wu and J. Weston and Douwe Kiela and Adina Williams},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {314-331},\n title = {Multi-Dimensional Gender Bias Classification},\n year = {2020}\n}\n"
    },
    "fc-sni-medical_question_pair_dataset": {
        "Unique Dataset Identifier": "fc-sni-medical_question_pair_dataset",
        "Dataset Name": "medical_question_pair_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/curai/medical-question-pair-dataset",
        "GitHub URL": "https://github.com/curai/medical-question-pair-dataset",
        "Hugging Face URL": "https://huggingface.co/datasets/medical_questions_pairs",
        "Paper Title": "Effective Transfer Learning for Identifying Similar Questions: Matching User Questions to COVID-19 FAQs",
        "Papers with Code URL": "https://paperswithcode.com/dataset/medical-question-pairs",
        "ArXiv URL": "https://arxiv.org/abs/2008.13546",
        "Semantic Scholar Corpus ID": 221191709,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Matching"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5953,
            "Mean Inputs Length": 796.6949,
            "Mean Targets Length": 9.1112,
            "Max Inputs Length": 1662,
            "Max Targets Length": 20,
            "Min Inputs Length": 362,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "healthtap.com"
        ],
        "Model Generated": [],
        "Creators": [
            "EightSleep",
            "Stanford University",
            "Curai"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/curai/medical-question-pair-dataset#methodology"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1645_medical_question_pair_dataset_text_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "medical_questions_pairs",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-08-04",
            "S2 Date": "2020-07-06",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 35210,
            "HF Likes (September 2023)": 27,
            "PwC Description": "Medical Question Pairs (MQP) Dataset\nThis repository contains a dataset of 3048 similar and dissimilar medical question pairs hand-generated and labeled by Curai's doctors. The dataset is described in detail in our paper.\n\nMethodology\nWe present our doctors with a list of 1524 patient-asked questions randomly sampled from the publicly available crawl of HealthTap. Each question results in one similar and one different pair through the following instructions provided to the labelers:\n\n\nRewrite the original question in a different way while maintaining the same intent. Restructure the syntax as much as possible and change medical details that would not impact your response.\n e.g. \"I'm a 22-y-o female\" could become \"My 26 year old daughter\"\nCome up with a related but dissimilar question for which the answer to the original question would be WRONG OR IRRELEVANT. Use similar key words.\n\nThe first instruction generates a positive question pair (similar) and the second generates a negative question pair (different). With the above instructions, we intentionally frame the task such that positive question pairs can look very different by superficial metrics, and negative question pairs can conversely look very similar. This ensures that the task is not trivial.\n\nDataset format\nThe dataset is formatted as dr_id, question_1, question_2, label. We used 11 different doctors for this task so dr_id ranges from 1 to 11. The label is 1 if the question pair is similar and 0 otherwise.\n\nDataset statistics\nThe final dataset contains 4567 unique questions. The minimum, maximum, median and average number of tokens in these questions are 4, 81, 20 and 22.675 respectively showing there is reasonable variance in the length of the questions. The shortest question is Are fibroadenomas malignant?\n\nAn off-the-shelf medical entity recognizer finds around 1000 unique medical entities in the questions. Some of the top entity mentions were: physician, pregnancy, pain, lasting weeks, menstruation, emotional state, cancer, visual function, headache, bleeding, fever, sexual intercourse",
            "S2 Citation Count (September 2023)": 41,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Healthcare communication",
                "Classification",
                "Question classification",
                "Medical terminology",
                "Connotation and meaning in medical questions",
                "Connotation analysis",
                "Classification algorithms",
                "Natural language understanding",
                "Natural language processing",
                "Medical knowledge"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{McCreery2020EffectiveTL,\n author = {Clara H. McCreery and Namit Katariya and A. Kannan and Manish Chablani and X. Amatriain},\n booktitle = {Knowledge Discovery and Data Mining},\n journal = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining},\n title = {Effective Transfer Learning for Identifying Similar Questions: Matching User Questions to COVID-19 FAQs},\n year = {2020}\n}\n"
    },
    "fc-sni-menyo20k_mt": {
        "Unique Dataset Identifier": "fc-sni-menyo20k_mt",
        "Dataset Name": "menyo20k_mt",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/menyo20k_mt",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/menyo20k_mt",
        "Paper Title": "The Effect of Domain and Diacritics in Yoruba–English Neural Machine Translation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/menyo-20k",
        "ArXiv URL": "https://arxiv.org/abs/2103.08647",
        "Semantic Scholar Corpus ID": 235829420,
        "Languages": [
            "Yoruba",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7933,
            "Mean Inputs Length": 1321.4198,
            "Mean Targets Length": 102.2632,
            "Max Inputs Length": 3519,
            "Max Targets Length": 1183,
            "Min Inputs Length": 1013,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "jw news",
            "von news",
            "gv news",
            "yoruba proverbs",
            "youtube",
            "ict localisation data",
            "ted.com",
            "out of his mind (book)",
            "bond fm radio",
            "creative commons license texts",
            "ohchr.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Saarland University",
            "Max Planck Institute for Informatics",
            "Masakhane NLP",
            "Alamoja Yoruba & Masakhane NLP",
            "Yobamoodua Cultural Heritage (YMCH)",
            "Defence Space Administration",
            "Nigeria & Masakhane NLP",
            "University of Ibadan",
            "Nigeria & Masakhane NLP",
            "DFKI GmBH",
            "Saarland University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/uds-lsv/menyo-20k_MT/blob/master/menyo_data_collection.pdf"
            },
            {
                "License": "Request Form",
                "License URL": "https://github.com/uds-lsv/menyo-20k_MT/blob/master/menyo_data_collection.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1619_menyo20k-mt_en_yo_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "menyo20k_mt",
            "HF Config": "menyo20k_mt",
            "HF Config License": "Non Commercial",
            "HF Yaml License": "CC BY-NC 4.0",
            "PwC License Name": "CC BY-NC 4.0",
            "PwC License URL": "https://github.com/uds-lsv/menyo-20k_MT/blob/master/LICENSE",
            "PwC Date": "2021-03-15",
            "S2 Date": "2021-03-15",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 556,
            "HF Likes (September 2023)": 1,
            "PwC Description": "MENYO-20k is the first multi-domain parallel corpus with a special focus on clean orthography for Yorùbá--English with standardized train-test splits for benchmarking.",
            "S2 Citation Count (September 2023)": 20,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Adelani2021TheEO,\n author = {David Ifeoluwa Adelani and Dana Ruiter and Jesujoba Oluwadara Alabi and Damilola Adebonojo and Adesina Ayeni and Mofetoluwa Adeyemi and Ayodele Awokoya and C. España-Bonet},\n booktitle = {Machine Translation Summit},\n pages = {61-75},\n title = {The Effect of Domain and Diacritics in Yoruba–English Neural Machine Translation},\n year = {2021}\n}\n"
    },
    "fc-sni-meta_woz": {
        "Unique Dataset Identifier": "fc-sni-meta_woz",
        "Dataset Name": "meta_woz",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/meta_woz",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/meta_woz",
        "Paper Title": "Fast Domain Adaptation for Goal-Oriented Dialogue Using a Hybrid Generative-Retrieval Transformer",
        "Papers with Code URL": "https://paperswithcode.com/dataset/metalwoz",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 216324388,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Dialogue Act Recognition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 440,
            "Mean Inputs Length": 1669.8523,
            "Mean Targets Length": 12.8409,
            "Max Inputs Length": 2458,
            "Max Targets Length": 33,
            "Min Inputs Length": 1221,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://www.microsoft.com/en-us/research/project/metalwoz/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1394_meta_woz_task_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "meta_woz",
            "HF Config": "dialogues",
            "HF Config License": "Microsoft Data Licensing Agreement",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1236,
            "HF Likes (September 2023)": 3,
            "PwC Description": "Collected by leveraging background knowledge from a larger, more highly represented dialogue source.",
            "S2 Citation Count (September 2023)": 11,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Entertainment",
                "Leisure activities",
                "Machine learning",
                "Dialogue systems",
                "Artificial intelligence",
                "Time management",
                "Calendar management",
                "Language understanding",
                "Task classification"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Shalyminov2020FastDA,\n author = {Igor Shalyminov and Alessandro Sordoni and Adam Atkinson and Hannes Schulz},\n booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing},\n journal = {ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n pages = {8039-8043},\n title = {Fast Domain Adaptation for Goal-Oriented Dialogue Using a Hybrid Generative-Retrieval Transformer},\n year = {2020}\n}\n"
    },
    "fc-sni-miam": {
        "Unique Dataset Identifier": "fc-sni-miam",
        "Dataset Name": "miam",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/miam",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/miam",
        "Paper Title": "Code-switched inspired losses for spoken dialog representations",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2108.12465",
        "Semantic Scholar Corpus ID": 237353032,
        "Languages": [
            "French",
            "Spanish",
            "English",
            "German",
            "Italian"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6403,
            "Mean Inputs Length": 300.3075,
            "Mean Targets Length": 7.3259,
            "Max Inputs Length": 1117,
            "Max Targets Length": 17,
            "Min Inputs Length": 123,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "maptask",
            "dihana",
            "callhome spanish",
            "dime",
            "verbmobil",
            "loria",
            "ilisten"
        ],
        "Model Generated": [],
        "Creators": [
            "LTCI",
            "Telecom Paris",
            "Institut Polytechnique de Paris",
            "IBM"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://huggingface.co/datasets/miam#dataset-structure"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task896_miam_language_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "miam",
            "HF Config": "dihana",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-08-27",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1959,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 8,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Travel",
                "Multilingualism",
                "Linguistics",
                "Translation",
                "Communication",
                "Language identification",
                "Multilingual communication",
                "Language learning",
                "Cultural exchange",
                "Cultural diversity"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chapuis2021CodeswitchedIL,\n author = {E. Chapuis and Pierre Colombo and Matthieu Labeau and Chloe Clave},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {8320-8337},\n title = {Code-switched inspired losses for spoken dialog representations},\n year = {2021}\n}\n"
    },
    "fc-sni-missing": {
        "Unique Dataset Identifier": "fc-sni-missing",
        "Dataset Name": "missing",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "missing",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 223,
            "Mean Inputs Length": 2349.1749,
            "Mean Targets Length": 64.7309,
            "Max Inputs Length": 5169,
            "Max Targets Length": 133,
            "Min Inputs Length": 1001,
            "Min Targets Length": 32,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task739_lhoestq_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Pop culture",
                "Music industry",
                "Entertainment",
                "Religion",
                "History",
                "Geography",
                "Music",
                "Education",
                "Comprehension of references"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-mkb": {
        "Unique Dataset Identifier": "fc-sni-mkb",
        "Dataset Name": "mkb",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/mkb",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/mkb",
        "Paper Title": "A Multilingual Parallel Corpora Collection Effort for Indian Languages",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2007.07691",
        "Semantic Scholar Corpus ID": 218973936,
        "Languages": [
            "Hindi",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 304,
            "Mean Inputs Length": 442.3849,
            "Mean Targets Length": 97.3355,
            "Max Inputs Length": 1281,
            "Max Targets Length": 355,
            "Min Inputs Length": 195,
            "Min Targets Length": 22,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "pib.gov.in/indexd.aspx",
            "pmindia.gov.in/en/mann-ki-baat"
        ],
        "Model Generated": [],
        "Creators": [
            "International Institute of Information Technology",
            "Indian Institute of Technology"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/2007.07691"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1654_mkb_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mkb",
            "HF Config": "or-ur",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 11708,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 31,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Translation",
                "Tourism",
                "Religion",
                "History",
                "Language learning",
                "Indian culture",
                "Cross-cultural communication",
                "Travel"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Siripragrada2020AMP,\n author = {Shashank Siripragrada and Jerin Philip and Vinay P. Namboodiri and C. V. Jawahar},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {3743-3751},\n title = {A Multilingual Parallel Corpora Collection Effort for Indian Languages},\n year = {2020}\n}\n"
    },
    "fc-sni-mocha": {
        "Unique Dataset Identifier": "fc-sni-mocha",
        "Dataset Name": "mocha",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/pdf/2010.03636.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/mocha",
        "Paper Title": "MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mocha",
        "ArXiv URL": "https://arxiv.org/abs/2010.03636",
        "Semantic Scholar Corpus ID": 222208714,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10043,
            "Mean Inputs Length": 998.6152,
            "Mean Targets Length": 23.4374,
            "Max Inputs Length": 4927,
            "Max Targets Length": 157,
            "Min Inputs Length": 386,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "project gutenberg",
            "movie scripts",
            "wikipedia.org",
            "stories",
            "spinn3r blogs",
            "crowdsourced"
        ],
        "Model Generated": [
            "OpenAI GPT-2"
        ],
        "Creators": [
            "UC Irvine",
            "The Hebrew University",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task595_mocha_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mocha",
            "HF Config": "default",
            "HF Config License": "CC BY-SA 4.0",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-07",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 933,
            "HF Likes (September 2023)": 0,
            "PwC Description": "Contains 40K human judgement scores on model outputs from 6 diverse question answering datasets and an additional set of minimal pairs for evaluation.",
            "S2 Citation Count (September 2023)": 33,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language understanding",
                "Task-based learning",
                "Contextual analysis",
                "Communication",
                "Reading comprehension",
                "Contextual understanding",
                "Daily routine",
                "Health"
            ]
        },
        "Derived from Datasets": [
            "NarrativeQA",
            "MCScript",
            "CosmosQA",
            "SocialIQA",
            "DROP",
            "Quoref"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chen2020MOCHAAD,\n author = {Anthony Chen and Gabriel Stanovsky and Sameer Singh and Matt Gardner},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {6521-6532},\n title = {MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics},\n year = {2020}\n}\n"
    },
    "fc-sni-movie_rationales": {
        "Unique Dataset Identifier": "fc-sni-movie_rationales",
        "Dataset Name": "movie_rationales",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.tensorflow.org/datasets/catalog/movie_rationales",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/movie_rationales",
        "Paper Title": "ERASER: A Benchmark to Evaluate Rationalized NLP Models",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1911.03429",
        "Semantic Scholar Corpus ID": 207847663,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4045,
            "Mean Inputs Length": 7128.9122,
            "Mean Targets Length": 1.6163,
            "Max Inputs Length": 26909,
            "Max Targets Length": 11,
            "Min Inputs Length": 253,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "wikipedia.org",
            "imdb.com",
            "cnn.com",
            "wsj",
            "nytmes",
            "wikipedia.org",
            "project gutenberg",
            "9/11 reports",
            "textbooks",
            "mctest",
            "conceptnet"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "Northeastern University",
            "Salesforce Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/1911.03429.pdf; https://www.cs.jhu.edu/~jason/papers/zaidan+al.nipsw08.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1361_movierationales_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "movie_rationales",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-11-08",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2532,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 397,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Pop culture",
                "Film analysis",
                "Film reviews",
                "Film and entertainment",
                "Teenagers and partying",
                "Entertainment",
                "Movie review",
                "Film industry",
                "Movie reviews",
                "Sentiment analysis"
            ]
        },
        "Derived from Datasets": [
            "Evidence Inference",
            "BoolQ",
            "Movie Reviews",
            "FEVER",
            "MultiRC",
            "CoS-E",
            "e-SNLI"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{DeYoung2019ERASERAB,\n author = {Jay DeYoung and Sarthak Jain and Nazneen Rajani and Eric P. Lehman and Caiming Xiong and R. Socher and Byron C. Wallace},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {4443-4458},\n title = {ERASER: A Benchmark to Evaluate Rationalized NLP Models},\n year = {2019}\n}\n"
    },
    "fc-sni-mrpc": {
        "Unique Dataset Identifier": "fc-sni-mrpc",
        "Dataset Name": "mrpc",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.microsoft.com/en-us/download/details.aspx?id=52398",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "Automatically Constructing a Corpus of Sentential Paraphrases",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/I05-5002/",
        "Semantic Scholar Corpus ID": 16639476,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Matching"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8087,
            "Mean Inputs Length": 661.4678,
            "Mean Targets Length": 3.2406,
            "Max Inputs Length": 1376,
            "Max Targets Length": 13,
            "Min Inputs Length": 262,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1288_glue_mrpc_paraphrasing"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1202,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Stock market",
                "Finance",
                "Language understanding",
                "Language and communication",
                "News and current events",
                "Paraphrasing",
                "Text similarity",
                "Communication",
                "Linguistics",
                "Government and policies"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Dolan2005AutomaticallyCA,\n author = {W. Dolan and Chris Brockett},\n booktitle = {International Joint Conference on Natural Language Processing},\n title = {Automatically Constructing a Corpus of Sentential Paraphrases},\n year = {2005}\n}\n"
    },
    "fc-sni-mrqa": {
        "Unique Dataset Identifier": "fc-sni-mrqa",
        "Dataset Name": "mrqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/abs/1910.09753",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/mrqa",
        "Paper Title": "MRQA 2019 Shared Task: Evaluating Generalization in Reading Comprehension",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mrqa-2019",
        "ArXiv URL": "https://arxiv.org/abs/1910.09753",
        "Semantic Scholar Corpus ID": 204823992,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9093,
            "Mean Inputs Length": 3194.3271,
            "Mean Targets Length": 13.2474,
            "Max Inputs Length": 13141,
            "Max Targets Length": 282,
            "Min Inputs Length": 294,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced",
            "trivia websites",
            "jeopardy",
            "wikipedia.org",
            "books",
            "undisclosed web",
            "web exams",
            "imdb.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Massachusetts Institute of Technology",
            "Tel Aviv University",
            "Stanford University",
            "University of Washington",
            "NAVER AI Lab",
            "Princeton University",
            "Google",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task469_mrqa_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mrqa",
            "HF Config": "plain_text",
            "HF Config License": "Unspecified",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-10-22",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 789,
            "HF Likes (September 2023)": 7,
            "PwC Description": "The MRQA (Machine Reading for Question Answering) dataset is a dataset for evaluating the generalization capabilities of reading comprehension systems.",
            "S2 Citation Count (September 2023)": 216,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Information retrieval",
                "Sports",
                "History",
                "Education",
                "Language understanding",
                "Biology",
                "Architecture",
                "Genetics",
                "Biography"
            ]
        },
        "Derived from Datasets": [
            "SQuAD",
            "NewsQA",
            "TriviaQA",
            "SearchQA",
            "HotpotQA",
            "Natural Questions",
            "BioASQ",
            "DROP",
            "DuoRC",
            "RACE",
            "RelationExtraction",
            "TextbookQA",
            "BioProcess",
            "ComplexWebQ",
            "MCTest",
            "QAMR",
            "QAST",
            "TREC"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Fisch2019MRQA2S,\n author = {Adam Fisch and Alon Talmor and Robin Jia and Minjoon Seo and Eunsol Choi and Danqi Chen},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {1-13},\n title = {MRQA 2019 Shared Task: Evaluating Generalization in Reading Comprehension},\n year = {2019}\n}\n"
    },
    "fc-sni-ms_marco": {
        "Unique Dataset Identifier": "fc-sni-ms_marco",
        "Dataset Name": "ms_marco",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://microsoft.github.io/msmarco/",
        "GitHub URL": "https://microsoft.github.io/msmarco/",
        "Hugging Face URL": "https://huggingface.co/datasets/ms_marco",
        "Paper Title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ms-marco",
        "ArXiv URL": "https://arxiv.org/abs/1611.09268",
        "Semantic Scholar Corpus ID": 1289517,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1476,
            "Mean Inputs Length": 6029.145,
            "Mean Targets Length": 100.2771,
            "Max Inputs Length": 12156,
            "Max Targets Length": 679,
            "Min Inputs Length": 2093,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "bing search queries",
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://microsoft.github.io/msmarco/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task870_msmarco_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ms_marco",
            "HF Config": "v1.1",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Academic Research Purposes Only",
            "PwC License URL": "https://microsoft.github.io/msmarco/#:~:text=Terms%20and%20Conditions",
            "PwC Date": "2016-01-01",
            "S2 Date": "2016-11-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 8665,
            "HF Likes (September 2023)": 30,
            "PwC Description": "The MS MARCO (Microsoft MAchine Reading Comprehension) is a collection of datasets focused on deep learning in search.\nThe first dataset was a question answering dataset featuring 100,000 real Bing questions and a human generated answer. Over time the collection was extended with a 1,000,000 question dataset, a natural language generation dataset, a passage ranking dataset, keyphrase extraction dataset, crawling dataset, and a conversational search.",
            "S2 Citation Count (September 2023)": 1635,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Government assistance",
                "Time management",
                "Geography",
                "Government assistance programs",
                "Health",
                "Social welfare programs",
                "Food preparation"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Campos2016MSMA,\n author = {Daniel Fernando Campos and Tri Nguyen and Mir Rosenberg and Xia Song and Jianfeng Gao and Saurabh Tiwary and Rangan Majumder and L. Deng and Bhaskar Mitra},\n booktitle = {CoCo@NIPS},\n journal = {ArXiv},\n title = {MS MARCO: A Human Generated MAchine Reading COmprehension Dataset},\n volume = {abs/1611.09268},\n year = {2016}\n}\n"
    },
    "fc-sni-msr_sqa": {
        "Unique Dataset Identifier": "fc-sni-msr_sqa",
        "Dataset Name": "msr_sqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/msr_sqa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/msr_sqa",
        "Paper Title": "Search-based Neural Structured Learning for Sequential Question Answering",
        "Papers with Code URL": "https://paperswithcode.com/dataset/sqa",
        "ArXiv URL": "https://aclanthology.org/P17-1167/",
        "Semantic Scholar Corpus ID": 2623009,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 791,
            "Mean Inputs Length": 2826.6928,
            "Mean Targets Length": 42.5879,
            "Max Inputs Length": 15314,
            "Max Targets Length": 124,
            "Min Inputs Length": 670,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Maryland",
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://msropendata-web-api.azurewebsites.net/licenses/2f933be3-284d-500b-7ea3-2aa2fd0f1bb2/view"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task757_msr_sqa_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "msr_sqa",
            "HF Config": "default",
            "HF Config License": "Microsoft Data Licensing Agreement",
            "HF Yaml License": "Microsoft Data Licensing Agreement",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2017-07-01",
            "S2 Date": "2017-05-08",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 616,
            "HF Likes (September 2023)": 1,
            "PwC Description": "The SQA dataset was created to explore the task of answering sequences of inter-related questions on HTML tables. It has 6,066 sequences with 17,553 questions in total.",
            "S2 Citation Count (September 2023)": 182,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Geography",
                "Sports",
                "American athletes",
                "Data analysis",
                "Trivia",
                "Information retrieval",
                "Table interpretation",
                "Ranking",
                "Reality TV shows"
            ]
        },
        "Derived from Datasets": [
            "WikiTableQuestions"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Iyyer2017SearchbasedNS,\n author = {Mohit Iyyer and Wen-tau Yih and Ming-Wei Chang},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1821-1831},\n title = {Search-based Neural Structured Learning for Sequential Question Answering},\n year = {2017}\n}\n"
    },
    "fc-sni-msr_text_compression": {
        "Unique Dataset Identifier": "fc-sni-msr_text_compression",
        "Dataset Name": "msr_text_compression",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/msr_text_compression",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/msr_text_compression",
        "Paper Title": "Search-based Neural Structured Learning for Sequential Question Answering",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/P17-1167/",
        "Semantic Scholar Corpus ID": 2623009,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentence Compression"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9917,
            "Mean Inputs Length": 584.0086,
            "Mean Targets Length": 128.4365,
            "Max Inputs Length": 1717,
            "Max Targets Length": 483,
            "Min Inputs Length": 122,
            "Min Targets Length": 24,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Maryland",
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://msropendata-web-api.azurewebsites.net/licenses/2f933be3-284d-500b-7ea3-2aa2fd0f1bb2/view"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1340_msr_text_compression_compression"
        ],
        "Inferred Metadata": {
            "HF Dataset": "msr_text_compression",
            "HF Config": "default",
            "HF Config License": "Microsoft Data Licensing Agreement",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2017-05-08",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 581,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 182,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Psychology",
                "Linguistics",
                "Communication",
                "Travel",
                "Politics",
                "Text summarization",
                "Language processing"
            ]
        },
        "Derived from Datasets": [
            "WikiTableQuestions"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Iyyer2017SearchbasedNS,\n author = {Mohit Iyyer and Wen-tau Yih and Ming-Wei Chang},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1821-1831},\n title = {Search-based Neural Structured Learning for Sequential Question Answering},\n year = {2017}\n}\n"
    },
    "fc-sni-multi_woz_v22": {
        "Unique Dataset Identifier": "fc-sni-multi_woz_v22",
        "Dataset Name": "multi_woz_v22",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/multi_woz_v22",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/multi_woz_v22",
        "Paper Title": "Large-Scale Multi-Domain Belief Tracking with Knowledge Sharing",
        "Papers with Code URL": "https://paperswithcode.com/dataset/multiwoz",
        "ArXiv URL": "https://arxiv.org/abs/1807.06517",
        "Semantic Scholar Corpus ID": 49865411,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Speaker Identification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9168,
            "Mean Inputs Length": 2103.8267,
            "Mean Targets Length": 17.7091,
            "Max Inputs Length": 8181,
            "Max Targets Length": 28,
            "Min Inputs Length": 381,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced (amt)"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Cambridge"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://www.aclweb.org/anthology/2020.nlp4convai-1.13.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task638_multi_woz_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "multi_woz_v22",
            "HF Config": "v2.2",
            "HF Config License": "Apache License 2.0",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "MIT License",
            "PwC License URL": "https://github.com/budzianowski/multiwoz",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-07-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 13209,
            "HF Likes (September 2023)": 13,
            "PwC Description": "The Multi-domain Wizard-of-Oz (MultiWOZ) dataset is a large-scale human-human conversational corpus spanning over seven domains, containing 8438 multi-turn dialogues, with each dialogue averaging 14 turns. Different from existing standard datasets like WOZ and DSTC2, which contain less than 10 slots and only a few hundred values, MultiWOZ has 30 (domain, slot) pairs and over 4,500 possible values. The dialogues span seven domains: restaurant, hotel, attraction, taxi, train, hospital and police.",
            "S2 Citation Count (September 2023)": 109,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Travel",
                "Dining options",
                "Communication",
                "Fine dining",
                "Restaurant recommendations",
                "Transportation",
                "Food preferences",
                "Contact information",
                "Accommodation"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Ramadan2018LargeScaleMB,\n author = {Osman Ramadan and Paweł Budzianowski and Milica Gasic},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {432-437},\n title = {Large-Scale Multi-Domain Belief Tracking with Knowledge Sharing},\n year = {2018}\n}\n"
    },
    "fc-sni-multilingual_amazon_reviews": {
        "Unique Dataset Identifier": "fc-sni-multilingual_amazon_reviews",
        "Dataset Name": "multilingual_amazon_reviews",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/amazon_reviews_multi",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/amazon_reviews_multi",
        "Paper Title": "The Multilingual Amazon Reviews Corpus",
        "Papers with Code URL": "https://paperswithcode.com/dataset/amazon-product-data",
        "ArXiv URL": "https://arxiv.org/abs/2010.02573",
        "Semantic Scholar Corpus ID": 222141483,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13163,
            "Mean Inputs Length": 1085.1867,
            "Mean Targets Length": 5.0874,
            "Max Inputs Length": 5293,
            "Max Targets Length": 15,
            "Min Inputs Length": 470,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "amazon.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Amazon",
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://github.com/awslabs/open-data-docs/blob/main/docs/amazon-reviews-ml/license.txt"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1308_amazonreview_category_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "amazon_reviews_multi",
            "HF Config": "all_languages",
            "HF Config License": "Custom",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2016-02-04",
            "S2 Date": "2020-10-06",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 10049,
            "HF Likes (September 2023)": 76,
            "PwC Description": "This dataset contains product reviews and metadata from Amazon, including 142.8 million reviews spanning May 1996 - July 2014.\n\nThis dataset includes reviews (ratings, text, helpfulness votes), product metadata (descriptions, category information, price, brand, and image features), and links (also viewed/also bought graphs).",
            "S2 Citation Count (September 2023)": 86,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Sentiment analysis",
                "Review analysis",
                "Product reviews",
                "Classification",
                "Customer satisfaction",
                "Natural Language Processing",
                "Product Reviews",
                "Product categorization"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Keung2020TheMA,\n author = {Phillip Keung and Y. Lu and György Szarvas and Noah A. Smith},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {4563-4568},\n title = {The Multilingual Amazon Reviews Corpus},\n year = {2020}\n}\n"
    },
    "fc-sni-multilingual_ted": {
        "Unique Dataset Identifier": "fc-sni-multilingual_ted",
        "Dataset Name": "multilingual_ted",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/neulab/word-embeddings-for-nmt",
        "GitHub URL": "https://github.com/neulab/word-embeddings-for-nmt",
        "Hugging Face URL": "",
        "Paper Title": "When and Why Are Pre-trained Word Embeddings Useful for Neural Machine Translation?",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1804.06323",
        "Semantic Scholar Corpus ID": 4929974,
        "Languages": [
            "Galician",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12854,
            "Mean Inputs Length": 373.0227,
            "Mean Targets Length": 88.5631,
            "Max Inputs Length": 1519,
            "Max Targets Length": 555,
            "Min Inputs Length": 104,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "ted.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/N18-2084.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1090_ted_translation_en_gl"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-04-17",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 285,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Translation",
                "Communication",
                "Multilingualism",
                "Linguistics",
                "Language",
                "Cultural exchange",
                "Cultural understanding"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Qi2018WhenAW,\n author = {Ye Qi and Devendra Singh Sachan and Matthieu Felix and Sarguna Padmanabhan and Graham Neubig},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?},\n volume = {abs/1804.06323},\n year = {2018}\n}\n"
    },
    "fc-sni-multinli": {
        "Unique Dataset Identifier": "fc-sni-multinli",
        "Dataset Name": "multinli",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://cims.nyu.edu/~sbowman/multinli/paper.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/multi_nli",
        "Paper Title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
        "Papers with Code URL": "https://paperswithcode.com/dataset/multinli",
        "ArXiv URL": "https://arxiv.org/abs/1704.05426",
        "Semantic Scholar Corpus ID": 3432876,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12861,
            "Mean Inputs Length": 670.6697,
            "Mean Targets Length": 7.9967,
            "Max Inputs Length": 1730,
            "Max Targets Length": 20,
            "Min Inputs Length": 311,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "anc.org"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task197_mnli_domain_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "multi_nli",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Various",
            "PwC License URL": "https://cims.nyu.edu/~sbowman/multinli/paper.pdf",
            "PwC Date": "2018-01-01",
            "S2 Date": "2017-04-18",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 6436,
            "HF Likes (September 2023)": 33,
            "PwC Description": "The Multi-Genre Natural Language Inference (MultiNLI) dataset has 433K sentence pairs. Its size and mode of collection are modeled closely like SNLI. MultiNLI offers ten distinct genres (Face-to-face, Telephone, 9/11, Travel, Letters, Oxford University Press, Slate, Verbatim, Goverment and Fiction) of written and spoken English data. There are matched dev/test sets which are derived from the same sources as those in the training set, and mismatched sets which do not closely resemble any seen at training time.",
            "S2 Citation Count (September 2023)": 3105,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Literature",
                "Journalism",
                "Language",
                "Travel",
                "Politics",
                "Storytelling",
                "Technology",
                "Communication"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Williams2017ABC,\n author = {Adina Williams and Nikita Nangia and Samuel R. Bowman},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {1112-1122},\n title = {A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference},\n year = {2017}\n}\n"
    },
    "fc-sni-mutual": {
        "Unique Dataset Identifier": "fc-sni-mutual",
        "Dataset Name": "mutual",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://aclanthology.org/2020.acl-main.130.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/mutual",
        "Paper Title": "MuTual: A Dataset for Multi-Turn Dialogue Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mutual",
        "ArXiv URL": "https://arxiv.org/abs/2004.04494",
        "Semantic Scholar Corpus ID": 215548215,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Dialogue Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12925,
            "Mean Inputs Length": 1755.3661,
            "Mean Targets Length": 1.5993,
            "Max Inputs Length": 4665,
            "Max Targets Length": 11,
            "Min Inputs Length": 586,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "Zhejiang University",
            "Microsoft Research",
            "Westlake University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task611_mutual_multi_turn_dialogue"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/mutual",
            "HF Config": "metaeval--mutual",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-09",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2023-02-28",
            "HF Downloads (September 2023)": 46,
            "HF Likes (September 2023)": 0,
            "PwC Description": "MuTual is a retrieval-based dataset for multi-turn dialogue reasoning, which is modified from Chinese high school English listening comprehension test data. It tests dialogue reasoning via next utterance prediction.",
            "S2 Citation Count (September 2023)": 101,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Social interactions",
                "Decision-making",
                "Relationships",
                "Conversation analysis",
                "Communication skills",
                "Interpersonal relationships",
                "Social interaction",
                "Education"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Cui2020MuTualAD,\n author = {Leyang Cui and Yu Wu and Shujie Liu and Yue Zhang and Ming Zhou},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {MuTual: A Dataset for Multi-Turn Dialogue Reasoning},\n volume = {abs/2004.04494},\n year = {2020}\n}\n"
    },
    "fc-sni-mwsc": {
        "Unique Dataset Identifier": "fc-sni-mwsc",
        "Dataset Name": "mwsc",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/mwsc",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/mwsc",
        "Paper Title": "The Natural Language Decathlon: Multitask Learning as Question Answering",
        "Papers with Code URL": "https://paperswithcode.com/dataset/decanlp",
        "ArXiv URL": "https://arxiv.org/abs/1806.08730",
        "Semantic Scholar Corpus ID": 49393754,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 202,
            "Mean Inputs Length": 1186.5941,
            "Mean Targets Length": 23.8713,
            "Max Inputs Length": 1652,
            "Max Targets Length": 49,
            "Min Inputs Length": 903,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "rottentomatoes.com",
            "wikipedia.org",
            "cnn.com",
            "dailymail.co.uk",
            "conversations",
            "government speeches",
            "press releases",
            "letters",
            "national commission on terrorist attacks reports",
            "non-fiction books",
            "slate magazine",
            "telephone conversations",
            "travel guides",
            "fiction books",
            "crowdsourced"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "Salesforce Research"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task489_mwsc_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "mwsc",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "Various",
            "PwC License URL": "http://decanlp.com/#what-do-i-need-to-know-about-licensing",
            "PwC Date": "",
            "S2 Date": "2018-06-20",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 979,
            "HF Likes (September 2023)": 0,
            "PwC Description": "Natural Language Decathlon Benchmark (decaNLP) is a challenge that spans ten tasks: question answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, zero-shot relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution. The tasks as cast as question answering over a context.",
            "S2 Citation Count (September 2023)": 550,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Question formation",
                "Language learning",
                "General knowledge",
                "Natural language processing",
                "Language and grammar",
                "Language understanding",
                "Linguistics",
                "Language"
            ]
        },
        "Derived from Datasets": [
            "SQuAD",
            "IWSLT",
            "CNN/DM",
            "MNLI",
            "SST",
            "QA-SRL",
            "QA-ZRE",
            "WOZ",
            "WikiSQL",
            "MWSC"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{McCann2018TheNL,\n author = {Bryan McCann and N. Keskar and Caiming Xiong and R. Socher},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {The Natural Language Decathlon: Multitask Learning as Question Answering},\n volume = {abs/1806.08730},\n year = {2018}\n}\n"
    },
    "fc-sni-narrativeqa": {
        "Unique Dataset Identifier": "fc-sni-narrativeqa",
        "Dataset Name": "narrativeqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/deepmind/narrativeqa",
        "GitHub URL": "https://github.com/deepmind/narrativeqa",
        "Hugging Face URL": "https://huggingface.co/datasets/narrativeqa",
        "Paper Title": "The NarrativeQA Reading Comprehension Challenge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/narrativeqa",
        "ArXiv URL": "https://arxiv.org/abs/1712.07040",
        "Semantic Scholar Corpus ID": 2593903,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3190,
            "Mean Inputs Length": 6439.3219,
            "Mean Targets Length": 47.7476,
            "Max Inputs Length": 16914,
            "Max Targets Length": 165,
            "Min Inputs Length": 1643,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "project gutenberg",
            "undisclosed web",
            "wikipedia.org",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "DeepMind",
            "University of Oxford"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://arxiv.org/abs/1712.07040"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task405_narrativeqa_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "narrativeqa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Apache License 2.0",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "https://github.com/deepmind/narrativeqa",
            "PwC Date": "2017-12-19",
            "S2 Date": "2017-12-19",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 8744,
            "HF Likes (September 2023)": 5,
            "PwC Description": "The NarrativeQA dataset includes a list of documents with Wikipedia summaries, links to full stories, and questions and answers.",
            "S2 Citation Count (September 2023)": 456,
            "GitHub Stars": 419,
            "GitHub Topics": [],
            "Text Topics": [
                "Storytelling",
                "Reading comprehension",
                "Geography",
                "Story comprehension",
                "Character development",
                "Character analysis",
                "Mystery"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Kociský2017TheNR,\n author = {Tomás Kociský and Jonathan Schwarz and Phil Blunsom and Chris Dyer and K. Hermann and Gábor Melis and Edward Grefenstette},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {317-328},\n title = {The NarrativeQA Reading Comprehension Challenge},\n volume = {6},\n year = {2017}\n}\n"
    },
    "fc-sni-ncbi_disease_corpus": {
        "Unique Dataset Identifier": "fc-sni-ncbi_disease_corpus",
        "Dataset Name": "ncbi_disease_corpus",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.ncbi.nlm.nih.gov/research/bionlp/Data/disease/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ncbi_disease",
        "Paper Title": "NCBI disease corpus: A resource for disease name recognition and concept normalization",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ncbi-disease-1",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 234064,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 301,
            "Mean Inputs Length": 719.3156,
            "Mean Targets Length": 11.2359,
            "Max Inputs Length": 1402,
            "Max Targets Length": 38,
            "Min Inputs Length": 451,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://pubmed.ncbi.nlm.nih.gov/24393765/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1448_disease_entity_extraction_ncbi_dataset"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ncbi_disease",
            "HF Config": "ncbi_disease",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2014-01-01",
            "S2 Date": "2014-02-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2731,
            "HF Likes (September 2023)": 18,
            "PwC Description": "The NCBI Disease corpus consists of 793 PubMed abstracts, which are separated into training (593), development (100) and test (100) subsets. The NCBI Disease corpus is annotated with disease mentions, using concept identifiers from either MeSH or OMIM.",
            "S2 Citation Count (September 2023)": 614,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Biology",
                "Disorders and diseases",
                "Medical conditions",
                "Diseases and disorders",
                "Diseases",
                "Disease recognition",
                "Medicine",
                "Dermatology",
                "Health"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Dogan2014NCBIDC,\n author = {R. Dogan and Robert Leaman and Zhiyong Lu},\n booktitle = {Journal of Biomedical Informatics},\n journal = {Journal of biomedical informatics},\n pages = {\n          1-10\n        },\n title = {NCBI disease corpus: A resource for disease name recognition and concept normalization},\n volume = {47},\n year = {2014}\n}\n"
    },
    "fc-sni-news_commentary": {
        "Unique Dataset Identifier": "fc-sni-news_commentary",
        "Dataset Name": "news_commentary",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/news_commentary",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/news_commentary",
        "Paper Title": "Parallel Data, Tools and Interfaces in OPUS",
        "Papers with Code URL": "https://paperswithcode.com/dataset/dogc",
        "ArXiv URL": "https://aclanthology.org/L12-1246/",
        "Semantic Scholar Corpus ID": 15453873,
        "Languages": [
            "Arabic",
            "Russian",
            "Czech",
            "Japanese",
            "French",
            "Spanish",
            "English",
            "German",
            "Portuguese",
            "Italian",
            "Dutch",
            "Zhuang"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4789,
            "Mean Inputs Length": 675.7762,
            "Mean Targets Length": 7.2633,
            "Max Inputs Length": 1920,
            "Max Targets Length": 20,
            "Min Inputs Length": 284,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "european union",
            "opus software projects",
            "opus movie subtitles",
            "european central bank",
            "moniteur belge/belgisch staatsblad",
            "opensubtitles.org",
            "tehran english-persian parallel corpus",
            "wikisource"
        ],
        "Model Generated": [],
        "Creators": [
            "Uppsala University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1370_newscomm_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "news_commentary",
            "HF Config": "ar-cs",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 15660,
            "HF Likes (September 2023)": 18,
            "PwC Description": "Intended to provide freely available data sets in various formats together with basic annotation to be useful for applications in computational linguistics, translation studies and cross-linguistic corpus studies.",
            "S2 Citation Count (September 2023)": 1551,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "News commentary",
                "Language classification",
                "Multilingualism",
                "Current events",
                "Journalism"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Tiedemann2012ParallelDT,\n author = {J. Tiedemann},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2214-2218},\n title = {Parallel Data, Tools and Interfaces in OPUS},\n year = {2012}\n}\n"
    },
    "fc-sni-news_editorials": {
        "Unique Dataset Identifier": "fc-sni-news_editorials",
        "Dataset Name": "news_editorials",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/webis-de/COLING-20",
        "GitHub URL": "https://github.com/webis-de/COLING-20",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Summarization"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 333,
            "Mean Inputs Length": 10198.6847,
            "Mean Targets Length": 185.5015,
            "Max Inputs Length": 22720,
            "Max Targets Length": 629,
            "Min Inputs Length": 3562,
            "Min Targets Length": 23,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/2020.coling-main.470/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task522_news_editorial_summary"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Religion",
                "News analysis",
                "Persuasive writing",
                "Human rights",
                "History",
                "Terrorism",
                "Current events",
                "Journalism",
                "Politics"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-news_headlines_dataset_for_sarcasm_detection": {
        "Unique Dataset Identifier": "fc-sni-news_headlines_dataset_for_sarcasm_detection",
        "Dataset Name": "news_headlines_dataset_for_sarcasm_detection",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/rishabhmisra/News-Headlines-Dataset-For-Sarcasm-Detection",
        "GitHub URL": "https://github.com/rishabhmisra/News-Headlines-Dataset-For-Sarcasm-Detection",
        "Hugging Face URL": "",
        "Paper Title": "Sarcasm detection using news headlines dataset",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1908.07414v2",
        "Semantic Scholar Corpus ID": 256523473,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 992,
            "Mean Inputs Length": 541.1371,
            "Mean Targets Length": 11.7732,
            "Max Inputs Length": 788,
            "Max Targets Length": 23,
            "Min Inputs Length": 358,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "theonion.com",
            "huffpost.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Twitter",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/1908.07414v2.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1488_sarcasmdetection_headline_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-02-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 5,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Sentiment analysis",
                "Language understanding",
                "Natural Language Processing",
                "Linguistics",
                "News classification",
                "Text Classification",
                "Sarcasm detection",
                "Sarcasm Detection",
                "Text classification"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Misra2023SarcasmDU,\n author = {Rishabh Misra and Prahal Arora},\n booktitle = {AI Open},\n journal = {AI Open},\n pages = {13-18},\n title = {Sarcasm detection using news headlines dataset},\n volume = {4},\n year = {2023}\n}\n"
    },
    "fc-sni-nlg_bias": {
        "Unique Dataset Identifier": "fc-sni-nlg_bias",
        "Dataset Name": "nlg_bias",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/ewsheng/nlg-bias",
        "GitHub URL": "https://github.com/ewsheng/nlg-bias",
        "Hugging Face URL": "",
        "Paper Title": "The Woman Worked as a Babysitter: On Biases in Language Generation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1909.01326",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 559,
            "Mean Inputs Length": 728.9767,
            "Mean Targets Length": 9.0751,
            "Max Inputs Length": 980,
            "Max Targets Length": 19,
            "Min Inputs Length": 513,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "University of Southern California",
            "UCLA"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/1909.01326"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task364_regard_social_impact_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language understanding",
                "Psychology",
                "Social perception",
                "Communication skills",
                "Linguistics",
                "Sentiment analysis",
                "Social perception and stereotypes",
                "Psychology and human behavior",
                "Personal identity"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-nlu_asdiv_dataset": {
        "Unique Dataset Identifier": "fc-sni-nlu_asdiv_dataset",
        "Dataset Name": "nlu_asdiv_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/chaochun/nlu-asdiv-dataset",
        "GitHub URL": "https://github.com/chaochun/nlu-asdiv-dataset",
        "Hugging Face URL": "",
        "Paper Title": "A Diverse Corpus for Evaluating and Developing English Math Word Problem Solvers",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2106.15772",
        "Semantic Scholar Corpus ID": 220047831,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1688,
            "Mean Inputs Length": 558.7808,
            "Mean Targets Length": 2.5118,
            "Max Inputs Length": 1164,
            "Max Targets Length": 13,
            "Min Inputs Length": 311,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "Academia Sinica"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/chaochun/nlu-asdiv-dataset"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task861_asdiv_addsub_question_answering"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-07-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 98,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Arithmetic",
                "Halloween",
                "Word problems",
                "Shopping",
                "Problem-solving",
                "Education",
                "Math",
                "Sports"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Miao2020ADC,\n author = {Shen-Yun Miao and Chao-Chun Liang and Keh-Yih Su},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {975-984},\n title = {A Diverse Corpus for Evaluating and Developing English Math Word Problem Solvers},\n year = {2020}\n}\n"
    },
    "fc-sni-numeric_fused_head": {
        "Unique Dataset Identifier": "fc-sni-numeric_fused_head",
        "Dataset Name": "numeric_fused_head",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/yanaiela/num_fh",
        "GitHub URL": "https://github.com/yanaiela/num_fh",
        "Hugging Face URL": "",
        "Paper Title": "Where’s My Head? Definition, Data Set, and Models for Numeric Fused-Head Identification and Resolution",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 166227998,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Coreference Resolution"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13032,
            "Mean Inputs Length": 2181.3509,
            "Mean Targets Length": 10.4079,
            "Max Inputs Length": 9635,
            "Max Targets Length": 34,
            "Min Inputs Length": 1284,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00280/43502/Where-s-My-Head-Definition-Data-Set-and-Models-for"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task304_numeric_fused_head_resolution"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-05-26",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 18,
            "GitHub Stars": 33,
            "GitHub Topics": [
                "dataset",
                "fused-head",
                "machine-learning",
                "missing-elements",
                "nlp"
            ],
            "Text Topics": [
                "Task-based problem solving",
                "Language understanding",
                "Language comprehension",
                "Linguistics",
                "Task-based reasoning",
                "Common sense reasoning",
                "Reference identification",
                "Problem-solving",
                "Critical thinking",
                "Numerical interpretation"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Elazar2019WheresMH,\n author = {Yanai Elazar and Yoav Goldberg},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {519-535},\n title = {Where’s My Head? Definition, Data Set, and Models for Numeric Fused-Head Identification and Resolution},\n volume = {7},\n year = {2019}\n}\n"
    },
    "fc-sni-numersense": {
        "Unique Dataset Identifier": "fc-sni-numersense",
        "Dataset Name": "numersense",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://inklab.usc.edu/NumerSense/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/numer_sense",
        "Paper Title": "Birds have four legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-trained Language Models",
        "Papers with Code URL": "https://paperswithcode.com/dataset/numersense",
        "ArXiv URL": "https://arxiv.org/abs/2005.00683",
        "Semantic Scholar Corpus ID": 218486812,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Fill in The Blank"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11860,
            "Mean Inputs Length": 368.635,
            "Mean Targets Length": 4.3427,
            "Max Inputs Length": 601,
            "Max Targets Length": 15,
            "Min Inputs Length": 194,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "github.com/commonsense/omcs",
            "conceptnet"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/2005.00683"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1359_numer_sense_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "numer_sense",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-02",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1373,
            "HF Likes (September 2023)": 1,
            "PwC Description": "Contains 13.6k masked-word-prediction probes, 10.5k for fine-tuning and 3.1k for testing.",
            "S2 Citation Count (September 2023)": 107,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Animals",
                "Language",
                "Education",
                "Biology",
                "Grammar",
                "Animal reproduction",
                "Health",
                "General knowledge",
                "English language"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lin2020BirdsHF,\n author = {Bill Yuchen Lin and Seyeon Lee and Rahul Khanna and Xiang Ren},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {6862-6868},\n title = {Birds Have Four Legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-trained Language Models},\n year = {2020}\n}\n"
    },
    "fc-sni-nyc": {
        "Unique Dataset Identifier": "fc-sni-nyc",
        "Dataset Name": "nyc",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://nlds.soe.ucsc.edu/source-blending-NLG",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "Learning from Mistakes: Combining Ontologies via Self-Training for Dialogue Generation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.00150",
        "Semantic Scholar Corpus ID": 220379134,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Information Extraction"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12958,
            "Mean Inputs Length": 665.1419,
            "Mean Targets Length": 53.622,
            "Max Inputs Length": 1142,
            "Max Targets Length": 79,
            "Min Inputs Length": 328,
            "Min Targets Length": 35,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Santa Cruz",
            "Amazon"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/2020.sigdial-1.3.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1597_nyc_slot_filling"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-09-30",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 8,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Cuisine",
                "Restaurant description",
                "Restaurant recommendations",
                "Categorization of information",
                "Pricing",
                "Restaurant reviews",
                "Restaurant categorization"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Reed2020LearningFM,\n author = {Lena Reed and Vrindavan Harrison and Shereen Oraby and Dilek Z. Hakkani-Tür and M. Walker},\n booktitle = {SIGDIAL Conferences},\n pages = {21-34},\n title = {Learning from Mistakes: Combining Ontologies via Self-Training for Dialogue Generation},\n year = {2020}\n}\n"
    },
    "fc-sni-odd_man_out": {
        "Unique Dataset Identifier": "fc-sni-odd_man_out",
        "Dataset Name": "odd_man_out",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/gabrielStanovsky/odd-man-out",
        "GitHub URL": "https://github.com/gabrielStanovsky/odd-man-out",
        "Hugging Face URL": "",
        "Paper Title": "Spot the Odd Man Out: Exploring the Associative Power of Lexical Resources",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/D18-1182/",
        "Semantic Scholar Corpus ID": 52205776,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Word Semantics"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12963,
            "Mean Inputs Length": 392.5644,
            "Mean Targets Length": 6.8291,
            "Max Inputs Length": 594,
            "Max Targets Length": 31,
            "Min Inputs Length": 240,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "University of Washington",
            "Reed College"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/gabrielStanovsky/odd-man-out"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task141_odd-man-out_classification_category"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 8,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Stanovsky2018SpotTO,\n author = {Gabriel Stanovsky and Mark Hopkins},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {1533-1542},\n title = {Spot the Odd Man Out: Exploring the Associative Power of Lexical Resources},\n year = {2018}\n}\n"
    },
    "fc-sni-offenseval_dravidian": {
        "Unique Dataset Identifier": "fc-sni-offenseval_dravidian",
        "Dataset Name": "offenseval_dravidian",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/offenseval_dravidian",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/offenseval_dravidian",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "Tamil",
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 676,
            "Mean Inputs Length": 662.8713,
            "Mean Targets Length": 11.8817,
            "Max Inputs Length": 1185,
            "Max Targets Length": 23,
            "Min Inputs Length": 437,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://aclanthology.org/2021.dravidianlangtech-1.46.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1537_tamil_offenseval_dravidian_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "offenseval_dravidian",
            "HF Config": "tamil",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1294,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Cultural sensitivity",
                "Offensive language detection",
                "Language analysis",
                "Language processing",
                "Language evaluation",
                "Offensive content detection"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-ohsumed": {
        "Unique Dataset Identifier": "fc-sni-ohsumed",
        "Dataset Name": "ohsumed",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/ohsumed",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ohsumed",
        "Paper Title": "OHSUMED: An Interactive Retrieval Evaluation and New Large Test Collection for Research",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ohsumed",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 15094383,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Title Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2551,
            "Mean Inputs Length": 2116.6323,
            "Mean Targets Length": 85.2536,
            "Max Inputs Length": 6120,
            "Max Targets Length": 244,
            "Min Inputs Length": 259,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://davis.wpi.edu/xmdv/datasets/ohsumed.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task619_ohsumed_abstract_title_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ohsumed",
            "HF Config": "ohsumed",
            "HF Config License": "CC BY-NC 4.0",
            "HF Yaml License": "CC BY-NC 4.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "1994-08-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 858,
            "HF Likes (September 2023)": 1,
            "PwC Description": "Ohsumed includes medical abstracts from the MeSH categories of the year 1991. In [Joachims, 1997] were used the first 20,000 documents divided in 10,000 for training and 10,000 for testing. The specific task was to categorize the 23 cardiovascular diseases categories. After selecting the such category subset, the unique abstract number becomes 13,929 (6,286 for training and 7,643 for testing). As current computers can easily manage larger number of documents we make available all 34,389 cardiovascular diseases abstracts out of 50,216 medical abstracts contained in the year 1991.",
            "S2 Citation Count (September 2023)": 925,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Medical research",
                "Biology",
                "Cardiology",
                "Emergency medicine",
                "Medical imaging",
                "Orthopedics",
                "Medicine",
                "Neurology",
                "Physiology"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Hersh1994OHSUMEDAI,\n author = {W. Hersh and C. Buckley and T. J. Leone and D. Hickam},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n pages = {192-201},\n title = {OHSUMED: an interactive retrieval evaluation and new large test collection for research},\n year = {1994}\n}\n"
    },
    "fc-sni-olid": {
        "Unique Dataset Identifier": "fc-sni-olid",
        "Dataset Name": "olid",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/abs/1902.09666",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/christinacdl/OLID_Offensive",
        "Paper Title": "Kungfupanda at SemEval-2020 Task 12: BERT-Based Multi-Task Learning for Offensive Language Detection",
        "Papers with Code URL": "https://paperswithcode.com/dataset/olid",
        "ArXiv URL": "https://arxiv.org/abs/1902.09666",
        "Semantic Scholar Corpus ID": 216562642,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12090,
            "Mean Inputs Length": 755.6003,
            "Mean Targets Length": 6.5663,
            "Max Inputs Length": 1482,
            "Max Targets Length": 19,
            "Min Inputs Length": 486,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Center for Artificial Intelligence Research (CAiRE)",
            "The Hong Kong University of Science and Technology"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task286_olid_offense_judgment"
        ],
        "Inferred Metadata": {
            "HF Dataset": "christinacdl/OLID_Offensive",
            "HF Config": "christinacdl--OLID_Offensive",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2019-01-01",
            "S2 Date": "2020-04-28",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2023-06-26",
            "HF Downloads (September 2023)": 90,
            "HF Likes (September 2023)": 0,
            "PwC Description": "The OLID is a hierarchical dataset to identify the type and the target of offensive texts in social media. The dataset is collected on Twitter and publicly available. There are 14,100 tweets in total, in which 13,240 are in the training set, and 860 are in the test set. For each tweet, there are three levels of labels: (A) Offensive/Not-Offensive, (B) Targeted-Insult/Untargeted, (C) Individual/Group/Other. The relationship between them is hierarchical. If a tweet is offensive, it can have a target or no target. If it is offensive to a specific target, the target can be an individual, a group, or some other objects. This dataset is used in the OffensEval-2019 competition in SemEval-2019.",
            "S2 Citation Count (September 2023)": 19,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Social media",
                "Online content moderation",
                "Offensive language detection",
                "Offensive Language Detection",
                "Online etiquette",
                "Social media analysis",
                "Natural language processing",
                "Social Media Analysis",
                "Offensive language",
                "Natural Language Processing"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Dai2020KungfupandaAS,\n author = {Wenliang Dai and Tiezheng Yu and Zihan Liu and Pascale Fung},\n booktitle = {International Workshop on Semantic Evaluation},\n pages = {2060-2066},\n title = {Kungfupanda at SemEval-2020 Task 12: BERT-Based Multi-TaskLearning for Offensive Language Detection},\n year = {2020}\n}\n"
    },
    "fc-sni-ollie": {
        "Unique Dataset Identifier": "fc-sni-ollie",
        "Dataset Name": "ollie",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/ollie",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ollie",
        "Paper Title": "Open Language Learning for Information Extraction",
        "Papers with Code URL": "https://paperswithcode.com/dataset/carb",
        "ArXiv URL": "https://aclanthology.org/D12-1048/",
        "Semantic Scholar Corpus ID": 74065,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Information Extraction"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12878,
            "Mean Inputs Length": 611.3558,
            "Mean Targets Length": 10.382,
            "Max Inputs Length": 1357,
            "Max Targets Length": 38,
            "Min Inputs Length": 256,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://raw.githubusercontent.com/knowitall/ollie/master/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task676_ollie_relationship_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ollie",
            "HF Config": "ollie_lemmagrep",
            "HF Config License": "Custom",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2019-11-01",
            "S2 Date": "2012-07-12",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 701,
            "HF Likes (September 2023)": 0,
            "PwC Description": "CaRB [Bhardwaj et al., 2019] is developed by re-annotating the dev and test splits of OIE2016 via crowd-sourcing. Besides improving annotation quality, CaRB also provides a new matching scorer. CaRB scorer uses token level match and it matches relation with relation, arguments with arguments.\n\nSource: https://arxiv.org/pdf/2205.11725.pdf (section 3.1)",
            "S2 Citation Count (September 2023)": 789,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Emotions and feelings",
                "Perception and observation",
                "Religion",
                "Language understanding",
                "History",
                "Education",
                "Linguistics",
                "Text analysis",
                "Language and communication"
            ]
        },
        "Derived from Datasets": [
            "ClueWeb09 Dataset"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Mausam2012OpenLL,\n author = {Mausam and Michael Schmitz and S. Soderland and Robert Bart and Oren Etzioni},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {523-534},\n title = {Open Language Learning for Information Extraction},\n year = {2012}\n}\n"
    },
    "fc-sni-open_pi": {
        "Unique Dataset Identifier": "fc-sni-open_pi",
        "Dataset Name": "open_pi",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.org/data/openpi",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "A Dataset for Tracking Entities in Open Domain Procedural Text",
        "Papers with Code URL": "https://paperswithcode.com/dataset/open-pi",
        "ArXiv URL": "https://arxiv.org/abs/2011.08092",
        "Semantic Scholar Corpus ID": 226262266,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1551,
            "Mean Inputs Length": 945.3024,
            "Mean Targets Length": 18.6235,
            "Max Inputs Length": 2150,
            "Max Targets Length": 31,
            "Min Inputs Length": 442,
            "Min Targets Length": 15,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikihow.com"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://allenai.org/data/openpi"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1630_openpi_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-10-31",
            "S2 Date": "2020-10-31",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "Open PI is the first dataset for tracking state changes in procedural text from arbitrary domains by using an unrestricted (open) vocabulary. The dataset comprises 29,928 state changes over 4,050 sentences from 810 procedural real-world paragraphs from WikiHow.com.\nThe state tracking task assumes new formulation in which just the text is provided, from which a set of state changes (entity, attribute, before, after) is generated for each step, where the entity, attribute, and values must all be predicted from an open vocabulary.",
            "S2 Citation Count (September 2023)": 32,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Interior design",
                "Text classification",
                "Content categorization",
                "Language understanding",
                "Food and cooking",
                "Categorization",
                "Home improvement",
                "Natural language processing",
                "Reading comprehension",
                "Gardening"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Tandon2020ADF,\n author = {Niket Tandon and Keisuke Sakaguchi and Bhavana Dalvi and Dheeraj Rajagopal and Peter Clark and Michal Guerquin and Kyle Richardson and E. Hovy},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {A Dataset for Tracking Entities in Open Domain Procedural Text},\n volume = {abs/2011.08092},\n year = {2020}\n}\n"
    },
    "fc-sni-opensubtitles": {
        "Unique Dataset Identifier": "fc-sni-opensubtitles",
        "Dataset Name": "opensubtitles",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://opus.nlpl.eu/OpenSubtitles.php",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/open_subtitles",
        "Paper Title": "OpenSubtitles2016: Extracting Large Parallel Corpora from Movie and TV Subtitles",
        "Papers with Code URL": "https://paperswithcode.com/dataset/opensubtitles",
        "ArXiv URL": "https://aclanthology.org/L16-1147/",
        "Semantic Scholar Corpus ID": 29180066,
        "Languages": [
            "Hindi",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11621,
            "Mean Inputs Length": 302.819,
            "Mean Targets Length": 31.3251,
            "Max Inputs Length": 806,
            "Max Targets Length": 297,
            "Min Inputs Length": 169,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "opensubtitles.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Oslo",
            "University of Helsinki"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://opus.nlpl.eu/OpenSubtitles.php"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1323_open_subtitles_hi_en_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "open_subtitles",
            "HF Config": "bs-eo",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2016-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1920,
            "HF Likes (September 2023)": 23,
            "PwC Description": "OpenSubtitles is collection of multilingual parallel corpora. The dataset is compiled from a large database of movie and TV subtitles and includes a total of 1689 bitexts spanning 2.6 billion sentences across 60 languages.",
            "S2 Citation Count (September 2023)": 681,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language proficiency",
                "Communication",
                "Language and communication",
                "Employment",
                "Cultural understanding",
                "Daily routine",
                "Cultural differences",
                "Language learning",
                "Translation",
                "Cultural exchange"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Lison2016OpenSubtitles2016EL,\n author = {Pierre Lison and J. Tiedemann},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {923-929},\n title = {OpenSubtitles2016: Extracting Large Parallel Corpora from Movie and TV Subtitles},\n year = {2016}\n}\n"
    },
    "fc-sni-opp_115": {
        "Unique Dataset Identifier": "fc-sni-opp_115",
        "Dataset Name": "opp_115",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.usableprivacy.org/data",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1337,
            "Mean Inputs Length": 1045.2117,
            "Mean Targets Length": 24.104,
            "Max Inputs Length": 1464,
            "Max Targets Length": 40,
            "Min Inputs Length": 741,
            "Min Targets Length": 13,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://www.usableprivacy.org/data"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task682_online_privacy_policy_text_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Online advertising",
                "Data protection",
                "User information collection",
                "Data privacy",
                "User information",
                "Data sharing with third-party companies",
                "Privacy policies"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-opus_100": {
        "Unique Dataset Identifier": "fc-sni-opus_100",
        "Dataset Name": "opus_100",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/EdinburghNLP/opus-100-corpus",
        "GitHub URL": "https://github.com/EdinburghNLP/opus-100-corpus",
        "Hugging Face URL": "https://huggingface.co/datasets/opus100",
        "Paper Title": "Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/opus-100",
        "ArXiv URL": "https://arxiv.org/abs/2004.11867",
        "Semantic Scholar Corpus ID": 216144650,
        "Languages": [
            "Gujarati",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 375,
            "Mean Inputs Length": 672.9787,
            "Mean Targets Length": 105.9013,
            "Max Inputs Length": 1644,
            "Max Targets Length": 420,
            "Min Inputs Length": 407,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "eu legistlative texts",
            "translated movie subtitiles",
            "european central bank",
            "moniteur belge newspaper",
            "opensubtitles.org",
            "opensubtitles.org",
            "wikisource"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Edinburgh",
            "University of Amsterdam",
            "University of Zurich"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/2004.11867"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1350_opus100_translation_en_gu"
        ],
        "Inferred Metadata": {
            "HF Dataset": "opus100",
            "HF Config": "af-en",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-24",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 197356,
            "HF Likes (September 2023)": 46,
            "PwC Description": "A novel multilingual dataset with 100 languages.",
            "S2 Citation Count (September 2023)": 236,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Translation",
                "Language learning",
                "Linguistics",
                "Cultural exchange"
            ]
        },
        "Derived from Datasets": [
            "OPUS Collection"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Zhang2020ImprovingMM,\n author = {Biao Zhang and P. Williams and Ivan Titov and Rico Sennrich},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation},\n volume = {abs/2004.11867},\n year = {2020}\n}\n"
    },
    "fc-sni-opus_books": {
        "Unique Dataset Identifier": "fc-sni-opus_books",
        "Dataset Name": "opus_books",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://opus.nlpl.eu/Books.php",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/opus_books",
        "Paper Title": "Parallel Data, Tools and Interfaces in OPUS",
        "Papers with Code URL": "https://paperswithcode.com/dataset/dogc",
        "ArXiv URL": "https://aclanthology.org/L12-1246/",
        "Semantic Scholar Corpus ID": 15453873,
        "Languages": [
            "Portuguese",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2775,
            "Mean Inputs Length": 678.3405,
            "Mean Targets Length": 104.3715,
            "Max Inputs Length": 2412,
            "Max Targets Length": 938,
            "Min Inputs Length": 413,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "european union",
            "opus software projects",
            "opus movie subtitles",
            "european central bank",
            "moniteur belge/belgisch staatsblad",
            "opensubtitles.org",
            "tehran english-persian parallel corpus",
            "wikisource"
        ],
        "Model Generated": [],
        "Creators": [
            "Uppsala University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://opus.nlpl.eu/Books.php"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1647_opus_books_en-pt_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "opus_books",
            "HF Config": "ca-de",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 23853,
            "HF Likes (September 2023)": 13,
            "PwC Description": "Intended to provide freely available data sets in various formats together with basic annotation to be useful for applications in computational linguistics, translation studies and cross-linguistic corpus studies.",
            "S2 Citation Count (September 2023)": 1551,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Tiedemann2012ParallelDT,\n author = {J. Tiedemann},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2214-2218},\n title = {Parallel Data, Tools and Interfaces in OPUS},\n year = {2012}\n}\n"
    },
    "fc-sni-opus_paracrawl": {
        "Unique Dataset Identifier": "fc-sni-opus_paracrawl",
        "Dataset Name": "opus_paracrawl",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/opus_paracrawl",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/opus_paracrawl",
        "Paper Title": "ParaCrawl: Web-Scale Acquisition of Parallel Corpora",
        "Papers with Code URL": "https://paperswithcode.com/dataset/paracrawl",
        "ArXiv URL": "https://aclanthology.org/2020.acl-main.417/",
        "Semantic Scholar Corpus ID": 219165306,
        "Languages": [
            "Somali",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11942,
            "Mean Inputs Length": 655.4599,
            "Mean Targets Length": 191.2265,
            "Max Inputs Length": 2474,
            "Max Targets Length": 996,
            "Min Inputs Length": 159,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Edinburgh",
            "University of Alicante",
            "Johns Hopkins University",
            "TAUS",
            "Omniscien Technologies"
        ],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://paracrawl.eu/index.php"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task446_opus_paracrawl_en_so_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "opus_paracrawl",
            "HF Config": "el-en",
            "HF Config License": "",
            "HF Yaml License": "CC0 1.0",
            "PwC License Name": "CC0 1.0",
            "PwC License URL": "https://creativecommons.org/share-your-work/public-domain/cc0/",
            "PwC Date": "2020-07-01",
            "S2 Date": "2020-07-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2769,
            "HF Likes (September 2023)": 5,
            "PwC Description": "ParaCrawl v.7.1 is a parallel dataset with 41 language pairs primarily aligned with English (39 out of 41) and mined using the parallel-data-crawling tool Bitextor which includes downloading documents, preprocessing and normalization, aligning documents and segments, and filtering noisy data via Bicleaner. ParaCrawl focuses on European languages, but also includes 9 lower-resource, non-European language pairs in v7.1.",
            "S2 Citation Count (September 2023)": 141,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Sports",
                "History",
                "Linguistics",
                "Language learning",
                "Cultural exchange",
                "Religion",
                "Language",
                "Cultural understanding"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Bañón2020ParaCrawlWA,\n author = {Marta Bañón and Pinzhen Chen and B. Haddow and Kenneth Heafield and Hieu D. Hoang and Miquel Esplà-GomisF and Mikel ForcadaF and Amir Kamran and Faheem Kirefu and Philipp Koehn and Sergio Ortiz-Rojas and Leopoldo PlaF and Gema Ramírez-Sánchez and Elsa Sarrı́asF and Marek Střelec and Brian Thompson and W. Waites and Dion WigginsN and Jaume Zaragoza},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {4555-4567},\n title = {ParaCrawl: Web-Scale Acquisition of Parallel Corpora},\n year = {2020}\n}\n"
    },
    "fc-sni-opus_ted_talks": {
        "Unique Dataset Identifier": "fc-sni-opus_ted_talks",
        "Dataset Name": "opus_ted_talks",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/opus_tedtalks",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/opus_tedtalks",
        "Paper Title": "Parallel Data, Tools and Interfaces in OPUS",
        "Papers with Code URL": "https://paperswithcode.com/dataset/dogc",
        "ArXiv URL": "https://aclanthology.org/L12-1246/",
        "Semantic Scholar Corpus ID": 15453873,
        "Languages": [
            "Croatian",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12812,
            "Mean Inputs Length": 1098.5478,
            "Mean Targets Length": 79.9475,
            "Max Inputs Length": 2106,
            "Max Targets Length": 699,
            "Min Inputs Length": 787,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "european union",
            "opus software projects",
            "opus movie subtitles",
            "european central bank",
            "moniteur belge/belgisch staatsblad",
            "opensubtitles.org",
            "tehran english-persian parallel corpus",
            "wikisource"
        ],
        "Model Generated": [],
        "Creators": [
            "Uppsala University"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 3.0",
                "License URL": "https://opus.nlpl.eu/TedTalks.php"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1365_opustedtalks_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "opus_tedtalks",
            "HF Config": "en-hr",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 542,
            "HF Likes (September 2023)": 0,
            "PwC Description": "Intended to provide freely available data sets in various formats together with basic annotation to be useful for applications in computational linguistics, translation studies and cross-linguistic corpus studies.",
            "S2 Citation Count (September 2023)": 1551,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Tiedemann2012ParallelDT,\n author = {J. Tiedemann},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2214-2218},\n title = {Parallel Data, Tools and Interfaces in OPUS},\n year = {2012}\n}\n"
    },
    "fc-sni-opus_xhosanavy": {
        "Unique Dataset Identifier": "fc-sni-opus_xhosanavy",
        "Dataset Name": "opus_xhosanavy",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/opus_xhosanavy",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/opus_xhosanavy",
        "Paper Title": "Parallel Data, Tools and Interfaces in OPUS",
        "Papers with Code URL": "https://paperswithcode.com/dataset/dogc",
        "ArXiv URL": "https://aclanthology.org/L12-1246/",
        "Semantic Scholar Corpus ID": 15453873,
        "Languages": [
            "Xhosa",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11253,
            "Mean Inputs Length": 445.6965,
            "Mean Targets Length": 100.1784,
            "Max Inputs Length": 1491,
            "Max Targets Length": 896,
            "Min Inputs Length": 171,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "european union",
            "opus software projects",
            "opus movie subtitles",
            "european central bank",
            "moniteur belge/belgisch staatsblad",
            "opensubtitles.org",
            "tehran english-persian parallel corpus",
            "wikisource"
        ],
        "Model Generated": [],
        "Creators": [
            "Uppsala University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task872_opus_xhosanavy_translation_eng_xhosa"
        ],
        "Inferred Metadata": {
            "HF Dataset": "opus_xhosanavy",
            "HF Config": "en-xh",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2012-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 550,
            "HF Likes (September 2023)": 3,
            "PwC Description": "Intended to provide freely available data sets in various formats together with basic annotation to be useful for applications in computational linguistics, translation studies and cross-linguistic corpus studies.",
            "S2 Citation Count (September 2023)": 1551,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Grammar",
                "Physics",
                "Linguistics",
                "Cultural understanding",
                "Geography",
                "Engineering",
                "History"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Tiedemann2012ParallelDT,\n author = {J. Tiedemann},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {2214-2218},\n title = {Parallel Data, Tools and Interfaces in OPUS},\n year = {2012}\n}\n"
    },
    "fc-sni-overruling": {
        "Unique Dataset Identifier": "fc-sni-overruling",
        "Dataset Name": "overruling",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/reglab/casehold",
        "GitHub URL": "https://github.com/reglab/casehold",
        "Hugging Face URL": "https://huggingface.co/datasets/casehold/casehold",
        "Paper Title": "When does pretraining help?: assessing self-supervised learning for law and the CaseHOLD dataset of 53,000+ legal holdings",
        "Papers with Code URL": "https://paperswithcode.com/dataset/overruling",
        "ArXiv URL": "https://arxiv.org/abs/2104.08671",
        "Semantic Scholar Corpus ID": 233296302,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4731,
            "Mean Inputs Length": 769.0913,
            "Mean Targets Length": 12.4936,
            "Max Inputs Length": 1883,
            "Max Targets Length": 24,
            "Min Inputs Length": 435,
            "Min Targets Length": 10,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "harvard caselaw project",
            "casetext company"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/2104.08671"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task274_overruling_legal_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "casehold/casehold",
            "HF Config": "all",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2021-04-18",
            "S2 Date": "2021-04-18",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "2023-03-27",
            "HF Downloads (September 2023)": 383,
            "HF Likes (September 2023)": 4,
            "PwC Description": "The Overruling dataset is a law dataset corresponding to the task of determining when a sentence is overruling a prior decision. This is a binary classification task, where positive examples are overruling sentences and negative examples are non-overruling sentences extracted from legal opinions. In law, an overruling sentence is a statement that nullifies a previous case decision as a precedent, by a constitutionally valid statute or a decision by the same or higher ranking court which establishes a different rule on the point of law involved. The Overruling dataset consists of 2,400 sentences.\n\nTo read more about the dataset, please see our paper or our blogpost.",
            "S2 Citation Count (September 2023)": 94,
            "GitHub Stars": 58,
            "GitHub Topics": [],
            "Text Topics": [
                "Judicial decision-making",
                "Law",
                "Legal terminology",
                "Legal precedent",
                "Constitutional validity"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zheng2021WhenDP,\n author = {Lucia Zheng and Neel Guha and Brandon R. Anderson and Peter Henderson and Daniel E. Ho},\n booktitle = {International Conference on Artificial Intelligence and Law},\n journal = {Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law},\n title = {When does pretraining help?: assessing self-supervised learning for law and the CaseHOLD dataset of 53,000+ legal holdings},\n year = {2021}\n}\n"
    },
    "fc-sni-paper_reviews_data_set": {
        "Unique Dataset Identifier": "fc-sni-paper_reviews_data_set",
        "Dataset Name": "paper_reviews_data_set",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://archive.ics.uci.edu/ml/datasets/Paper+Reviews",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "Spanish",
            "English"
        ],
        "Task Categories": [
            "Paper Review"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 309,
            "Mean Inputs Length": 4734.3204,
            "Mean Targets Length": 6.657,
            "Max Inputs Length": 13723,
            "Max Targets Length": 16,
            "Min Inputs Length": 358,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://archive.ics.uci.edu/dataset/410/paper+reviews"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task264_paper_reviews_accept_or_reject_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Bilingualism",
                "Language analysis",
                "Paper review",
                "Natural Language Processing",
                "Bilingual evaluation",
                "Decision making",
                "Decision-making",
                "Paper reviewing",
                "Paper reviews"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-para_nmt": {
        "Unique Dataset Identifier": "fc-sni-para_nmt",
        "Dataset Name": "para_nmt",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.cs.cmu.edu/~jwieting/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "ParaNMT-50M: Pushing the Limits of Paraphrastic Sentence Embeddings with Millions of Machine Translations",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 5003931,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Paraphrase Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13105,
            "Mean Inputs Length": 432.8425,
            "Mean Targets Length": 66.592,
            "Max Inputs Length": 989,
            "Max Targets Length": 396,
            "Min Inputs Length": 217,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University",
            "Toyota Technological Institute at Chicago"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task177_para-nmt_paraphrasing"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2017-11-15",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 279,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Wieting2017PushingTL,\n author = {J. Wieting and Kevin Gimpel},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Pushing the Limits of Paraphrastic Sentence Embeddings with Millions of Machine Translations},\n volume = {abs/1711.05732},\n year = {2017}\n}\n"
    },
    "fc-sni-para_pat": {
        "Unique Dataset Identifier": "fc-sni-para_pat",
        "Dataset Name": "para_pat",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/para_pat",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/para_pat",
        "Paper Title": "ParaPat: The Multi-Million Sentences Parallel Corpus of Patents Abstracts",
        "Papers with Code URL": "https://paperswithcode.com/dataset/parapat",
        "ArXiv URL": "https://aclanthology.org/2020.lrec-1.465/",
        "Semantic Scholar Corpus ID": 218973735,
        "Languages": [
            "Spanish",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11547,
            "Mean Inputs Length": 441.1678,
            "Mean Targets Length": 135.3549,
            "Max Inputs Length": 25226,
            "Max Targets Length": 12677,
            "Min Inputs Length": 48,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "patents.google.com"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "University of Sheffield",
            "TransPerfect Translations"
        ],
        "Licenses": [
            {
                "License": "GNU General Public License v3.0",
                "License URL": "https://github.com/soares-f/parapat"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task840_para_pdt_en_es_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "para_pat",
            "HF Config": "el-en",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5372,
            "HF Likes (September 2023)": 8,
            "PwC Description": "A parallel corpus from the open access Google Patents dataset in 74 language pairs, comprising more than 68 million sentences and 800 million tokens. Sentences were automatically aligned using the Hunalign algorithm for the largest 22 language pairs, while the others were abstract (i.e. paragraph) aligned.",
            "S2 Citation Count (September 2023)": 3,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Engineering",
                "Telecommunications",
                "Chemistry",
                "Communication",
                "Technical instructions",
                "Manufacturing processes",
                "Technology",
                "Translation",
                "Language learning"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Soares2020ParaPatTM,\n author = {Felipe Soares and Mark Stevenson and Diego Bartolomé and A. Zaretskaya},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {3769-3774},\n title = {ParaPat: The Multi-Million Sentences Parallel Corpus of Patents Abstracts},\n year = {2020}\n}\n"
    },
    "fc-sni-parsinlu": {
        "Unique Dataset Identifier": "fc-sni-parsinlu",
        "Dataset Name": "parsinlu",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/persiannlp/parsinlu",
        "GitHub URL": "https://github.com/persiannlp/parsinlu",
        "Hugging Face URL": "https://huggingface.co/datasets/persiannlp/parsinlu_translation_en_fa",
        "Paper Title": "ParsiNLU: A Suite of Language Understanding Challenges for Persian",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2012.06154",
        "Semantic Scholar Corpus ID": 228375016,
        "Languages": [
            "Arabic",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12925,
            "Mean Inputs Length": 292.6597,
            "Mean Targets Length": 61.571,
            "Max Inputs Length": 3886,
            "Max Targets Length": 6418,
            "Min Inputs Length": 101,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "search-engine(google) auto-complete",
            "web exams",
            "web exams",
            "digikala.com",
            "tiwall.com",
            "github.com/miras-tech/mirastext",
            "jon.dehdari.org/corpora",
            "wikipedia.org",
            "wikipedia.org",
            "javabkoo.com",
            "quora",
            "quran",
            "github.com/christos-c/bible-corpus",
            "opus",
            "globalvoices.org"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "Google",
            "George Washington University",
            "UC Irvine",
            "University of Pittsburgh",
            "TaskRabbit",
            "Arizona State University",
            "UC Santa Cruz",
            "University of Southern California",
            "IMRSV Data Labs",
            "EPFL",
            "University of Chicago",
            "University of Maryland",
            "Rutgers University",
            "University of Pennsylvania",
            "Expedia Inc.",
            "University of Houston",
            "Indiana University Bloomington",
            "Microsoft"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00419/107835/ParsiNLU-A-Suite-of-Language-Understanding"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task650_opus100_ar_en_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "persiannlp/parsinlu_translation_en_fa",
            "HF Config": "parsinlu-repo",
            "HF Config License": "CC BY-NC-SA 4.0",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-12-11",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2021-03-22",
            "HF Downloads (September 2023)": 187,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 24,
            "GitHub Stars": 113,
            "GitHub Topics": [
                "farsi",
                "machine-translation",
                "mt5-models",
                "natural-language-inference",
                "natural-language-processing",
                "persian",
                "persian-language",
                "query-paraphrasing",
                "reading-comprehension",
                "sentiment-analysis",
                "sentiment-analysis-dataset",
                "textual-entailment"
            ],
            "Text Topics": [
                "Language and communication",
                "Cultural differences",
                "Arabic language",
                "Cultural understanding",
                "Communication",
                "Cultural exchange",
                "Translation",
                "Daily routine",
                "Multilingual communication"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Khashabi2020ParsiNLUAS,\n author = {Daniel Khashabi and Arman Cohan and Siamak Shakeri and Pedram Hosseini and Pouya Pezeshkpour and Malihe Alikhani and Moin Aminnaseri and Marzieh Bitaab and Faeze Brahman and Sarik Ghazarian and Mozhdeh Gheini and Arman Kabiri and Rabeeh Karimi Mahabadi and Omid Memarrast and Ahmadreza Mosallanezhad and Erfan Noury and Shahab Raji and Mohammad Sadegh Rasooli and Sepideh Sadeghi and Erfan Sadeqi Azer and Niloofar Safi Samghabadi and Mahsa Shafaei and Saber Sheybani and Ali Tazarv and Yadollah Yaghoobzadeh},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {1147-1162},\n title = {ParsiNLU: A Suite of Language Understanding Challenges for Persian},\n volume = {9},\n year = {2020}\n}\n"
    },
    "fc-sni-pasinlu": {
        "Unique Dataset Identifier": "fc-sni-pasinlu",
        "Dataset Name": "pasinlu",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/persiannlp/parsinlu",
        "GitHub URL": "https://github.com/persiannlp/parsinlu",
        "Hugging Face URL": "https://huggingface.co/datasets/persiannlp/parsinlu_translation_en_fa",
        "Paper Title": "ParsiNLU: A Suite of Language Understanding Challenges for Persian",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2012.06154",
        "Semantic Scholar Corpus ID": 228375016,
        "Languages": [
            "Persian",
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5374,
            "Mean Inputs Length": 763.0916,
            "Mean Targets Length": 10.6556,
            "Max Inputs Length": 1915,
            "Max Targets Length": 23,
            "Min Inputs Length": 325,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "search-engine(google) auto-complete",
            "web exams",
            "web exams",
            "digikala.com",
            "tiwall.com",
            "github.com/miras-tech/mirastext",
            "jon.dehdari.org/corpora",
            "wikipedia.org",
            "wikipedia.org",
            "javabkoo.com",
            "quora",
            "quran",
            "github.com/christos-c/bible-corpus",
            "opus",
            "globalvoices.org"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "Google",
            "George Washington University",
            "UC Irvine",
            "University of Pittsburgh",
            "TaskRabbit",
            "Arizona State University",
            "UC Santa Cruz",
            "University of Southern California",
            "IMRSV Data Labs",
            "EPFL",
            "University of Chicago",
            "University of Maryland",
            "Rutgers University",
            "University of Pennsylvania",
            "Expedia Inc.",
            "University of Houston",
            "Indiana University Bloomington",
            "Microsoft"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task463_parsinlu_entailment_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "persiannlp/parsinlu_translation_en_fa",
            "HF Config": "parsinlu-repo",
            "HF Config License": "CC BY-NC-SA 4.0",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-12-11",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2021-03-22",
            "HF Downloads (September 2023)": 187,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 24,
            "GitHub Stars": 113,
            "GitHub Topics": [
                "farsi",
                "machine-translation",
                "mt5-models",
                "natural-language-inference",
                "natural-language-processing",
                "persian",
                "persian-language",
                "query-paraphrasing",
                "reading-comprehension",
                "sentiment-analysis",
                "sentiment-analysis-dataset",
                "textual-entailment"
            ],
            "Text Topics": [
                "Textual entailment",
                "Persian language",
                "Natural language processing",
                "Persian language comprehension",
                "Linguistics",
                "Persian language understanding",
                "Logic",
                "Language processing",
                "Logical reasoning",
                "Logic and reasoning"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Khashabi2020ParsiNLUAS,\n author = {Daniel Khashabi and Arman Cohan and Siamak Shakeri and Pedram Hosseini and Pouya Pezeshkpour and Malihe Alikhani and Moin Aminnaseri and Marzieh Bitaab and Faeze Brahman and Sarik Ghazarian and Mozhdeh Gheini and Arman Kabiri and Rabeeh Karimi Mahabadi and Omid Memarrast and Ahmadreza Mosallanezhad and Erfan Noury and Shahab Raji and Mohammad Sadegh Rasooli and Sepideh Sadeghi and Erfan Sadeqi Azer and Niloofar Safi Samghabadi and Mahsa Shafaei and Saber Sheybani and Ali Tazarv and Yadollah Yaghoobzadeh},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {1147-1162},\n title = {ParsiNLU: A Suite of Language Understanding Challenges for Persian},\n volume = {9},\n year = {2020}\n}\n"
    },
    "fc-sni-paws": {
        "Unique Dataset Identifier": "fc-sni-paws",
        "Dataset Name": "paws",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/abs/1904.01130",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/paws-x",
        "Paper Title": "PAWS: Paraphrase Adversaries from Word Scrambling",
        "Papers with Code URL": "https://paperswithcode.com/dataset/paws",
        "ArXiv URL": "https://arxiv.org/abs/1904.01130",
        "Semantic Scholar Corpus ID": 91184042,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Matching"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12997,
            "Mean Inputs Length": 794.7494,
            "Mean Targets Length": 12.8323,
            "Max Inputs Length": 1434,
            "Max Targets Length": 24,
            "Min Inputs Length": 356,
            "Min Targets Length": 10,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "quora",
            "wikipedia.org"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://github.com/google-research-datasets/paws/blob/master/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task400_paws_paraphrase_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "paws-x",
            "HF Config": "en",
            "HF Config License": "All Uses-Attribution",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Custom",
            "PwC License URL": "https://github.com/google-research-datasets/paws",
            "PwC Date": "2019-04-01",
            "S2 Date": "2019-04-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 9105,
            "HF Likes (September 2023)": 16,
            "PwC Description": "Paraphrase Adversaries from Word Scrambling (PAWS) is a dataset contains 108,463 human-labeled and 656k noisily labeled pairs that feature the importance of modeling structure, context, and word order information for the problem of paraphrase identification. The dataset has two subsets, one based on Wikipedia and the other one based on the Quora Question Pairs (QQP) dataset.",
            "S2 Citation Count (September 2023)": 367,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Textual Similarity",
                "Language",
                "Natural language understanding",
                "Paraphrasing",
                "Language processing",
                "Linguistics",
                "Natural Language Processing",
                "Textual similarity",
                "Language understanding"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zhang2019PAWSPA,\n author = {Yuan Zhang and Jason Baldridge and Luheng He},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {PAWS: Paraphrase Adversaries from Word Scrambling},\n volume = {abs/1904.01130},\n year = {2019}\n}\n"
    },
    "fc-sni-paws_x": {
        "Unique Dataset Identifier": "fc-sni-paws_x",
        "Dataset Name": "paws_x",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/paws-x",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/paws-x",
        "Paper Title": "PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/paws-x",
        "ArXiv URL": "https://arxiv.org/abs/1908.11828",
        "Semantic Scholar Corpus ID": 201698093,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Paraphrase Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 527,
            "Mean Inputs Length": 514.8425,
            "Mean Targets Length": 114.0152,
            "Max Inputs Length": 1030,
            "Max Targets Length": 212,
            "Min Inputs Length": 178,
            "Min Targets Length": 37,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "quora"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://github.com/google-research-datasets/paws/blob/master/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task770_pawsx_english_text_modification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "paws-x",
            "HF Config": "en",
            "HF Config License": "All Uses-Attribution",
            "HF Yaml License": "",
            "PwC License Name": "Custom",
            "PwC License URL": "https://github.com/google-research-datasets/paws/blob/master/LICENSE",
            "PwC Date": "2019-08-30",
            "S2 Date": "2019-08-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 9105,
            "HF Likes (September 2023)": 16,
            "PwC Description": "PAWS-X contains 23,659 human translated PAWS evaluation pairs and 296,406 machine translated training pairs in six typologically distinct languages: French, Spanish, German, Chinese, Japanese, and Korean. All translated pairs are sourced from examples in PAWS-Wiki.",
            "S2 Citation Count (September 2023)": 233,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Translation",
                "History",
                "Linguistics",
                "Paraphrasing",
                "Sentence structure",
                "Language proficiency",
                "Geography"
            ]
        },
        "Derived from Datasets": [
            "PAWS dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Yang2019PAWSXAC,\n author = {Yinfei Yang and Y. Zhang and Chris Tar and Jason Baldridge},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {3685-3690},\n title = {PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification},\n year = {2019}\n}\n"
    },
    "fc-sni-pec": {
        "Unique Dataset Identifier": "fc-sni-pec",
        "Dataset Name": "pec",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/pec",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/pec",
        "Paper Title": "Towards Persona-Based Empathetic Conversational Models",
        "Papers with Code URL": "https://paperswithcode.com/dataset/pec",
        "ArXiv URL": "https://arxiv.org/abs/2004.12316",
        "Semantic Scholar Corpus ID": 216562921,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 158,
            "Mean Inputs Length": 589.8861,
            "Mean Targets Length": 8.5949,
            "Max Inputs Length": 1293,
            "Max Targets Length": 18,
            "Min Inputs Length": 206,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "Alibaba-NTU Singapore Joint Research Institute",
            "Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly",
            "Nanyang Technological University",
            "Alibaba Group"
        ],
        "Licenses": [
            {
                "License": "GNU General Public License v3.0",
                "License URL": "https://www.aclweb.org/anthology/2020.emnlp-main.531/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task819_pec_sentiment_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pec",
            "HF Config": "all",
            "HF Config License": "",
            "HF Yaml License": "GNU General Public License v3.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-26",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1081,
            "HF Likes (September 2023)": 3,
            "PwC Description": "A novel large-scale multi-domain dataset for persona-based empathetic conversations.",
            "S2 Citation Count (September 2023)": 63,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Relationships",
                "Health",
                "Emotional intelligence",
                "Personal experiences",
                "Sentiment analysis",
                "Emotions",
                "Appearance",
                "Natural language processing",
                "Emotional well-being",
                "Mental health"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Zhong2020TowardsPE,\n author = {Peixiang Zhong and Yan Lindsay Sun and Yong Liu and Chen Zhang and Hao Wang and Zaiqing Nie and Chun Miao},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {6556-6566},\n title = {Towards Persona-Based Empathetic Conversational Models},\n year = {2020}\n}\n"
    },
    "fc-sni-peer_read": {
        "Unique Dataset Identifier": "fc-sni-peer_read",
        "Dataset Name": "peer_read",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/peer_read",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/peer_read",
        "Paper Title": "A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP Applications",
        "Papers with Code URL": "https://paperswithcode.com/dataset/peerread",
        "ArXiv URL": "https://arxiv.org/abs/1804.09635",
        "Semantic Scholar Corpus ID": 13746581,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Title Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6042,
            "Mean Inputs Length": 2164.8328,
            "Mean Targets Length": 66.6028,
            "Max Inputs Length": 39124,
            "Max Targets Length": 183,
            "Min Inputs Length": 160,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "academic paper reviews"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University",
            "AI2",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/1804.09635"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1540_parsed_pdfs_summarization"
        ],
        "Inferred Metadata": {
            "HF Dataset": "peer_read",
            "HF Config": "parsed_pdfs",
            "HF Config License": "CC0 1.0",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "https://github.com/allenai/PeerRead#readme",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-04-25",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1185,
            "HF Likes (September 2023)": 2,
            "PwC Description": "PearRead is a dataset of scientific peer reviews. The dataset consists of over 14K paper drafts and the corresponding accept/reject decisions in top-tier venues including ACL, NIPS and ICLR, as well as over 10K textual peer reviews written by experts for a subset of the papers.",
            "S2 Citation Count (September 2023)": 129,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Artificial Intelligence",
                "Information retrieval",
                "Neural Networks",
                "Artificial intelligence",
                "Machine Learning",
                "Machine learning",
                "Natural language processing"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Kang2018ADO,\n author = {Dongyeop Kang and Waleed Ammar and Bhavana Dalvi and Madeleine van Zuylen and Sebastian Kohlmeier and E. Hovy and Roy Schwartz},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP Applications},\n volume = {abs/1804.09635},\n year = {2018}\n}\n"
    },
    "fc-sni-penn_treebank": {
        "Unique Dataset Identifier": "fc-sni-penn_treebank",
        "Dataset Name": "penn_treebank",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://catalog.ldc.upenn.edu/LDC99T42",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Part-of-Speech Tagging"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12936,
            "Mean Inputs Length": 2481.8127,
            "Mean Targets Length": 3.5691,
            "Max Inputs Length": 4057,
            "Max Targets Length": 14,
            "Min Inputs Length": 2065,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://www.ldc.upenn.edu/language-resources/data/obtaining"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1167_penn_treebank_coarse_pos_tagging"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Natural Language Processing",
                "Language analysis",
                "Language processing",
                "Part-of-speech tagging",
                "Linguistics",
                "Natural language understanding",
                "Grammar analysis"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-persent": {
        "Unique Dataset Identifier": "fc-sni-persent",
        "Dataset Name": "persent",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/MHDBST/PerSenT",
        "GitHub URL": "https://github.com/MHDBST/PerSenT",
        "Hugging Face URL": "https://huggingface.co/datasets/per_sent",
        "Paper Title": "Author's Sentiment Prediction",
        "Papers with Code URL": "https://paperswithcode.com/dataset/persent",
        "ArXiv URL": "https://arxiv.org/abs/2011.06128",
        "Semantic Scholar Corpus ID": 226307003,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Title Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6823,
            "Mean Inputs Length": 3749.3758,
            "Mean Targets Length": 61.5899,
            "Max Inputs Length": 50324,
            "Max Targets Length": 195,
            "Min Inputs Length": 252,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "blogs",
            "newswire",
            "editorials",
            "undisclosed web",
            "discussion forums"
        ],
        "Model Generated": [],
        "Creators": [
            "Stony Brook University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/2011.06128"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task418_persent_title_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "per_sent",
            "HF Config": "default",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-12",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 697,
            "HF Likes (September 2023)": 0,
            "PwC Description": "PerSenT is a dataset of crowd-sourced annotations of the sentiment expressed by the authors towards the main entities in news articles. The dataset also includes paragraph-level sentiment annotations to provide more fine-grained supervision for the task.",
            "S2 Citation Count (September 2023)": 11,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "International relations",
                "News",
                "Current events",
                "News and current events",
                "Sports",
                "Government",
                "Technology",
                "Document summarization"
            ]
        },
        "Derived from Datasets": [
            "MPQA",
            "TAC 2014 KBP Challenge dataset",
            "Media Rank"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Bastan2020AuthorsSP,\n author = {Mohaddeseh Bastan and Mahnaz Koupaee and Youngseo Son and Richard Sicoli and Niranjan Balasubramanian},\n booktitle = {International Conference on Computational Linguistics},\n pages = {604-615},\n title = {Author’s Sentiment Prediction},\n year = {2020}\n}\n"
    },
    "fc-sni-persianqa": {
        "Unique Dataset Identifier": "fc-sni-persianqa",
        "Dataset Name": "persianqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/sajjjadayobi/PersianQA",
        "GitHub URL": "https://github.com/sajjjadayobi/PersianQA",
        "Hugging Face URL": "https://huggingface.co/datasets/SajjadAyoubi/persian_qa",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "Persian",
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2019,
            "Mean Inputs Length": 2073.0847,
            "Mean Targets Length": 36.9559,
            "Max Inputs Length": 4359,
            "Max Targets Length": 92,
            "Min Inputs Length": 744,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/sajjjadayobi/PersianQA"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task394_persianqa_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "SajjadAyoubi/persian_qa",
            "HF Config": "persian_qa",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "GNU General Public License v3.0",
            "Github Date": "",
            "HF Date": "2021-04-17",
            "HF Downloads (September 2023)": 800,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 166,
            "GitHub Topics": [
                "dataset",
                "farsi",
                "natural-language-processing",
                "nlp",
                "persian-language",
                "persian-nlp",
                "question-answering",
                "reading-comprehension",
                "squad"
            ],
            "Text Topics": [
                "Persian language",
                "Economics",
                "Education",
                "Geography",
                "Reading comprehension",
                "History",
                "Biology",
                "Persian language and literature",
                "Biography",
                "Astronomy"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-personachat": {
        "Unique Dataset Identifier": "fc-sni-personachat",
        "Dataset Name": "personachat",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/bavard/personachat_truecased",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/bavard/personachat_truecased",
        "Paper Title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1801.07243",
        "Semantic Scholar Corpus ID": 6869582,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Dialogue Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13015,
            "Mean Inputs Length": 1422.8224,
            "Mean Targets Length": 50.0554,
            "Max Inputs Length": 3503,
            "Max Targets Length": 105,
            "Min Inputs Length": 452,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Montreal Institute of Learning Algorithms (Mila)",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/1801.07243.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1729_personachat_generate_next"
        ],
        "Inferred Metadata": {
            "HF Dataset": "bavard/personachat_truecased",
            "HF Config": "full",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-01-22",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2021-04-22",
            "HF Downloads (September 2023)": 1419,
            "HF Likes (September 2023)": 20,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 1030,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Personal interests and hobbies",
                "Daily routine",
                "Food",
                "Personal preferences",
                "Culture",
                "Hobbies",
                "Travel",
                "Music",
                "Personal interests",
                "Hobbies and interests"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Zhang2018PersonalizingDA,\n author = {Saizheng Zhang and Emily Dinan and Jack Urbanek and Arthur Szlam and Douwe Kiela and J. Weston},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Personalizing Dialogue Agents: I have a dog, do you have pets too?},\n volume = {abs/1801.07243},\n year = {2018}\n}\n"
    },
    "fc-sni-perspectrum": {
        "Unique Dataset Identifier": "fc-sni-perspectrum",
        "Dataset Name": "perspectrum",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/CogComp/perspectrum/",
        "GitHub URL": "https://github.com/CogComp/perspectrum/",
        "Hugging Face URL": "",
        "Paper Title": "Seeing Things from a Different Angle:Discovering Diverse Perspectives about Claims",
        "Papers with Code URL": "https://paperswithcode.com/dataset/perspectrum",
        "ArXiv URL": "https://aclanthology.org/N19-1053/",
        "Semantic Scholar Corpus ID": 85556928,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12935,
            "Mean Inputs Length": 598.0805,
            "Mean Targets Length": 8.5612,
            "Max Inputs Length": 1114,
            "Max Targets Length": 19,
            "Min Inputs Length": 318,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "idebate.org",
            "debatewise.org",
            "procon.org",
            "crowdsourced",
            "web search queries"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Pennsylvania"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "http://cogcomp.org/page/publication_view/870"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task738_perspectrum_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-08",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "Perspectrum is a dataset of claims, perspectives and evidence, making use of online debate websites to create the initial data collection, and augmenting it using search engines in order to expand and diversify the dataset. Crowd-sourcing was used to filter out noise and ensure high-quality data. The dataset contains 1k claims, accompanied with pools of 10k and 8k perspective sentences and evidence paragraphs, respectively.",
            "S2 Citation Count (September 2023)": 79,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Communication",
                "Education",
                "International relations",
                "Ethics",
                "Persuasion",
                "Health",
                "Argumentation",
                "Music",
                "Politics"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Chen2019SeeingTF,\n author = {Sihao Chen and Daniel Khashabi and Wenpeng Yin and Chris Callison-Burch and D. Roth},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {542-557},\n title = {Seeing Things from a Different Angle:Discovering Diverse Perspectives about Claims},\n year = {2019}\n}\n"
    },
    "fc-sni-pib": {
        "Unique Dataset Identifier": "fc-sni-pib",
        "Dataset Name": "pib",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/pib",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/pib",
        "Paper Title": "A Multilingual Parallel Corpora Collection Effort for Indian Languages",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2007.07691",
        "Semantic Scholar Corpus ID": 218973936,
        "Languages": [
            "Tamil",
            "Malayalam",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2946,
            "Mean Inputs Length": 563.7685,
            "Mean Targets Length": 126.4956,
            "Max Inputs Length": 1611,
            "Max Targets Length": 654,
            "Min Inputs Length": 179,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "pib.gov.in/indexd.aspx",
            "pmindia.gov.in/en/mann-ki-baat"
        ],
        "Model Generated": [],
        "Creators": [
            "International Institute of Information Technology - Hyderabad",
            "Indian Institute of Technology - Kanpur"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "http://preon.iiit.ac.in/~jerin/bhasha/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1000_pib_translation_tamil_malayalam"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pib",
            "HF Config": "or-ur",
            "HF Config License": "CC BY-SA 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 14524,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 31,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Cultural differences",
                "Language and communication",
                "Language learning",
                "Language and linguistics",
                "Cultural exchange",
                "Translation",
                "Linguistics",
                "Language translation"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Siripragrada2020AMP,\n author = {Shashank Siripragrada and Jerin Philip and Vinay P. Namboodiri and C. V. Jawahar},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {3743-3751},\n title = {A Multilingual Parallel Corpora Collection Effort for Indian Languages},\n year = {2020}\n}\n"
    },
    "fc-sni-pico": {
        "Unique Dataset Identifier": "fc-sni-pico",
        "Dataset Name": "pico",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/Markus-Zlabinger/pico-annotation",
        "GitHub URL": "https://github.com/Markus-Zlabinger/pico-annotation",
        "Hugging Face URL": "https://huggingface.co/datasets/bigbio/pico_extraction",
        "Paper Title": "Effective Crowd-Annotation of Participants, Interventions, and Outcomes in the Text of Clinical Trial Reports",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/2020.findings-emnlp.274/",
        "Semantic Scholar Corpus ID": 226283554,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Information Extraction"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 875,
            "Mean Inputs Length": 936.1897,
            "Mean Targets Length": 17.2217,
            "Max Inputs Length": 1762,
            "Max Targets Length": 125,
            "Min Inputs Length": 628,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "biomed articles",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "TU Wien"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/2020.findings-emnlp.274/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task179_participant_extraction"
        ],
        "Inferred Metadata": {
            "HF Dataset": "bigbio/pico_extraction",
            "HF Config": "pico_extraction_source",
            "HF Config License": "Unspecified",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-11-13",
            "HF Downloads (September 2023)": 53,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 5,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Clinical trials",
                "Breast cancer treatment",
                "Autism research",
                "Medical studies",
                "Treatment testing",
                "Research methodology",
                "Bone loss",
                "Participant demographics",
                "Study participants",
                "Participant characteristics"
            ]
        },
        "Derived from Datasets": [
            "EBM-NLP corpus (Nye et al 2018)"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zlabinger2020EffectiveCO,\n author = {Markus Zlabinger and M. Sabou and Sebastian Hofstätter and A. Hanbury},\n booktitle = {Findings},\n pages = {3064-3074},\n title = {Effective Crowd-Annotation of Participants, Interventions, and Outcomes in the Text of Clinical Trial Reports},\n year = {2020}\n}\n"
    },
    "fc-sni-poem_sentiment": {
        "Unique Dataset Identifier": "fc-sni-poem_sentiment",
        "Dataset Name": "poem_sentiment",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/poem_sentiment",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/poem_sentiment",
        "Paper Title": "Investigating Societal Biases in a Poetry Composition System",
        "Papers with Code URL": "https://paperswithcode.com/dataset/gutenberg-poem-dataset",
        "ArXiv URL": "https://arxiv.org/abs/2011.02686",
        "Semantic Scholar Corpus ID": 226254460,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 578,
            "Mean Inputs Length": 260.2578,
            "Mean Targets Length": 8.6453,
            "Max Inputs Length": 440,
            "Max Targets Length": 18,
            "Min Inputs Length": 135,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "project gutenberg"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Southern California",
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://github.com/google-research-datasets/poem-sentiment/blob/master/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task833_poem_sentiment_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "poem_sentiment",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-11-05",
            "S2 Date": "2020-11-05",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3292,
            "HF Likes (September 2023)": 8,
            "PwC Description": "Gutenberg Poem Dataset is used for the next verse prediction component.",
            "S2 Citation Count (September 2023)": 28,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Emotions",
                "Sentiment analysis",
                "Language processing",
                "Poetry",
                "Language understanding",
                "Literature",
                "Natural language processing",
                "Emotion recognition",
                "Poetry analysis"
            ]
        },
        "Derived from Datasets": [
            "Gutenberg Poem Dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sheng2020InvestigatingSB,\n author = {Emily Sheng and David C. Uthus},\n booktitle = {GEBNLP},\n journal = {ArXiv},\n title = {Investigating Societal Biases in a Poetry Composition System},\n volume = {abs/2011.02686},\n year = {2020}\n}\n"
    },
    "fc-sni-points_of_correspondence": {
        "Unique Dataset Identifier": "fc-sni-points_of_correspondence",
        "Dataset Name": "points_of_correspondence",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/ucfnlp/points-of-correspondence",
        "GitHub URL": "https://github.com/ucfnlp/points-of-correspondence",
        "Hugging Face URL": "",
        "Paper Title": "Understanding Points of Correspondence between Sentences for Abstractive Summarization",
        "Papers with Code URL": "https://paperswithcode.com/dataset/poc",
        "ArXiv URL": "https://arxiv.org/abs/2006.05621",
        "Semantic Scholar Corpus ID": 219559167,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Overlap Extraction"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2925,
            "Mean Inputs Length": 1205.8957,
            "Mean Targets Length": 66.6304,
            "Max Inputs Length": 2297,
            "Max Targets Length": 348,
            "Min Inputs Length": 526,
            "Min Targets Length": 14,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "cnn.com",
            "dailymail.co.uk"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Central Florida",
            "Adobe Research"
        ],
        "Licenses": [
            {
                "License": "BSD 3-Clause License",
                "License URL": "https://github.com/ucfnlp/points-of-correspondence/blob/master/LICENSE.md"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task281_points_of_correspondence"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-06-10",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "A dataset containing the documents, source and fusion sentences, and human annotations of points of correspondence between sentences. The dataset bridges the gap between coreference resolution and summarization.",
            "S2 Citation Count (September 2023)": 23,
            "GitHub Stars": 20,
            "GitHub Topics": [],
            "Text Topics": [
                "Politics",
                "Language understanding",
                "Linguistics",
                "Noun phrases",
                "International relations",
                "Identity",
                "Noun phrase identification",
                "Sentence comprehension"
            ]
        },
        "Derived from Datasets": [
            "CNN/DailyMail corpus"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lebanoff2020UnderstandingPO,\n author = {Logan Lebanoff and John Muchovej and Franck Dernoncourt and Doo Soon Kim and Lidan Wang and Walter Chang and Fei Liu},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Understanding Points of Correspondence between Sentences for Abstractive Summarization},\n volume = {abs/2006.05621},\n year = {2020}\n}\n"
    },
    "fc-sni-poki": {
        "Unique Dataset Identifier": "fc-sni-poki",
        "Dataset Name": "poki",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/whipson/PoKi-Poems-by-Kids",
        "GitHub URL": "https://github.com/whipson/PoKi-Poems-by-Kids",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "https://paperswithcode.com/dataset/poki",
        "ArXiv URL": "https://arxiv.org/abs/2004.06188",
        "Semantic Scholar Corpus ID": 215754852,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Poem Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12873,
            "Mean Inputs Length": 694.6762,
            "Mean Targets Length": 253.9666,
            "Max Inputs Length": 4128,
            "Max Targets Length": 13818,
            "Min Inputs Length": 415,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "poems written by children in grades 1 to 12",
            "hosted by scholastic corporation."
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://github.com/whipson/PoKi-Poems-by-Kids"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1711_poki_text_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "PoKi is a corpus of 61,330 poems written by children from grades 1 to 12. PoKi is especially useful in studying child language because it comes with information about the age of the child authors (their grade).",
            "S2 Citation Count (September 2023)": 4,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Sports",
                "Creative writing",
                "Daily routine",
                "Nature",
                "Imagination",
                "Animals",
                "Children's literature",
                "Imagination and creativity",
                "Children's activities",
                "Poetry"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hipson2020PoKiAL,\n author = {Will E. Hipson and Saif M. Mohammad},\n booktitle = {International Conference on Language Resources and Evaluation},\n journal = {ArXiv},\n title = {PoKi: A Large Dataset of Poems by Children},\n volume = {abs/2004.06188},\n year = {2020}\n}\n"
    },
    "fc-sni-poleval2019_mt": {
        "Unique Dataset Identifier": "fc-sni-poleval2019_mt",
        "Dataset Name": "poleval2019_mt",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/poleval2019_mt",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/poleval2019_mt",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "Polish",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1867,
            "Mean Inputs Length": 258.4971,
            "Mean Targets Length": 44.1516,
            "Max Inputs Length": 671,
            "Max Targets Length": 193,
            "Min Inputs Length": 97,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "http://2019.poleval.pl/index.php/tasks/task4"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task830_poleval2019_mt_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "poleval2019_mt",
            "HF Config": "ru-pl",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1299,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Math",
                "General knowledge",
                "Translation",
                "Cultural differences",
                "Linguistics",
                "Communication",
                "Language learning"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-prepositional_paraprasing": {
        "Unique Dataset Identifier": "fc-sni-prepositional_paraprasing",
        "Dataset Name": "prepositional_paraprasing",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.cse.iitb.ac.in/~girishp/nc-dataset/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "Treat us like the sequences we are: Prepositional Paraphrasing of Noun Compounds using LSTM",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 51914360,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Preposition Prediction"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1866,
            "Mean Inputs Length": 479.1806,
            "Mean Targets Length": 3.1388,
            "Max Inputs Length": 663,
            "Max Targets Length": 15,
            "Min Inputs Length": 368,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Indian Institute of Technology Bombay",
            "TCS Research Tata Consultancy Services"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://www.cse.iitb.ac.in/~girishp/nc-dataset/register.php?resource=LREC-2018-NC-FN"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task585_preposition_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-08-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 8,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Word meaning",
                "Prepositions and their usage",
                "Language understanding",
                "Language learning",
                "Word association",
                "Prepositions",
                "Language and grammar",
                "Word association and meaning",
                "Grammar",
                "Preposition prediction"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Ponkiya2018TreatUL,\n author = {Girishkumar Ponkiya and Kevin Patel and P. Bhattacharyya and Girish Keshav Palshikar},\n booktitle = {International Conference on Computational Linguistics},\n pages = {1827-1836},\n title = {Treat us like the sequences we are: Prepositional Paraphrasing of Noun Compounds using LSTM},\n year = {2018}\n}\n"
    },
    "fc-sni-propara": {
        "Unique Dataset Identifier": "fc-sni-propara",
        "Dataset Name": "propara",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/abs/1805.06975",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "Tracking State Changes in Procedural Text: A Challenge Dataset and Models for Process Paragraph Comprehension",
        "Papers with Code URL": "https://paperswithcode.com/dataset/propara",
        "ArXiv URL": "https://arxiv.org/abs/1805.06975",
        "Semantic Scholar Corpus ID": 5019682,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Named Entity Recognition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 392,
            "Mean Inputs Length": 1074.8827,
            "Mean Targets Length": 41.2959,
            "Max Inputs Length": 2179,
            "Max Targets Length": 99,
            "Min Inputs Length": 512,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "Rensselaer Polytechnic Institute"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://allenai.org/data/propara"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1566_propara_structured_text_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2018-05-17",
            "S2 Date": "2018-05-17",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "The ProPara dataset is designed to train and test comprehension of simple paragraphs describing processes (e.g., photosynthesis), designed for the task of predicting, tracking, and answering questions about how entities change during the process.\n\nProPara aims to promote the research in natural language understanding in the context of procedural text. This requires identifying the actions described in the paragraph and tracking state changes happening to the entities involved. The comprehension task is treated as that of predicting, tracking, and answering questions about how entities change during the procedure. The dataset contains 488 paragraphs and 3,300 sentences. Each paragraph is richly annotated with the existence and locations of all the main entities (the “participants”) at every time step (sentence) throughout the procedure (~81,000 annotations).\n\nProPara paragraphs are natural (authored by crowdsourcing) rather than synthetic (e.g., in bAbI). Workers were given a prompt (e.g., “What happens during photosynthesis?”) and then asked to author a series of sentences describing the sequence of events in the procedure. From these sentences, participant entities and their existence and locations were identified. The goal of the challenge is to predict the existence and location of each participant, based on sentences in the paragraph.",
            "S2 Citation Count (September 2023)": 103,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language understanding",
                "Geology",
                "Biology",
                "Linguistics",
                "Botany",
                "Science",
                "Chemistry"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Dalvi2018TrackingSC,\n author = {Bhavana Dalvi and Lifu Huang and Niket Tandon and Wen-tau Yih and Peter Clark},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {1595-1604},\n title = {Tracking State Changes in Procedural Text: a Challenge Dataset and Models for Process Paragraph Comprehension},\n year = {2018}\n}\n"
    },
    "fc-sni-prost": {
        "Unique Dataset Identifier": "fc-sni-prost",
        "Dataset Name": "prost",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/corypaik/prost",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/corypaik/prost",
        "Paper Title": "PROST: Physical Reasoning about Objects through Space and Time",
        "Papers with Code URL": "https://paperswithcode.com/dataset/prost",
        "ArXiv URL": "https://arxiv.org/abs/2106.03634",
        "Semantic Scholar Corpus ID": 235358436,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 212,
            "Mean Inputs Length": 390.0519,
            "Mean Targets Length": 52.6887,
            "Max Inputs Length": 974,
            "Max Targets Length": 68,
            "Min Inputs Length": 144,
            "Min Targets Length": 32,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Colorado Boulder"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/2106.03634"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task859_prost_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "corypaik/prost",
            "HF Config": "default",
            "HF Config License": "Apache License 2.0",
            "HF Yaml License": "",
            "PwC License Name": "Apache License 2.0",
            "PwC License URL": "https://github.com/nala-cub/prost/blob/main/LICENSE",
            "PwC Date": "2021-06-07",
            "S2 Date": "2021-06-07",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2021-05-30",
            "HF Downloads (September 2023)": 1074,
            "HF Likes (September 2023)": 1,
            "PwC Description": "The PROST (Physical Reasoning about Objects Through Space and Time) dataset contains 18,736 multiple-choice questions made from 14 manually curated templates, covering 10 physical reasoning concepts. All questions are designed to probe both causal and masked language models in a zero-shot setting.",
            "S2 Citation Count (September 2023)": 22,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Problem-solving",
                "Physical activities",
                "Object stacking",
                "Physical coordination",
                "Geometry",
                "Physical tasks",
                "Fine motor skills"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Aroca-Ouellette2021PROSTPR,\n author = {Stephane T Aroca-Ouellette and Cory Paik and A. Roncone and Katharina Kann},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {PROST: Physical Reasoning about Objects through Space and Time},\n volume = {abs/2106.03634},\n year = {2021}\n}\n"
    },
    "fc-sni-proto_qa": {
        "Unique Dataset Identifier": "fc-sni-proto_qa",
        "Dataset Name": "proto_qa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/proto_qa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/proto_qa",
        "Paper Title": "ProtoQA: A Question Answering Dataset for Prototypical Common-Sense Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/protoqa",
        "ArXiv URL": "https://arxiv.org/abs/2005.00771",
        "Semantic Scholar Corpus ID": 218487363,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10110,
            "Mean Inputs Length": 369.6875,
            "Mean Targets Length": 8.5769,
            "Max Inputs Length": 588,
            "Max Targets Length": 31,
            "Min Inputs Length": 210,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "family feud"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Massachusetts Amherst"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://github.com/iesl/protoqa-data/blob/master/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task820_protoqa_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "proto_qa",
            "HF Config": "proto_qa",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-02",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 992,
            "HF Likes (September 2023)": 1,
            "PwC Description": "ProtoQA is a question answering dataset for training and evaluating common sense reasoning capabilities of artificial intelligence systems in such prototypical situations. The training set is gathered from an existing set of questions played in a long-running international game show FAMILY- FEUD. The hidden evaluation set is created by gathering answers for each question from 100 crowd-workers.",
            "S2 Citation Count (September 2023)": 37,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Geography",
                "Daily routine",
                "Health",
                "Beach activities",
                "Culture",
                "Trivia",
                "General knowledge",
                "Entertainment",
                "Travel",
                "Sun protection"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Boratko2020ProtoQAAQ,\n author = {Michael Boratko and Xiang Lorraine Li and Rajarshi Das and Timothy J. O'Gorman and Daniel Le and A. McCallum},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {ProtoQA: A Question Answering Dataset for Prototypical Common-Sense Reasoning},\n volume = {abs/2005.00771},\n year = {2020}\n}\n"
    },
    "fc-sni-pubmed_qa": {
        "Unique Dataset Identifier": "fc-sni-pubmed_qa",
        "Dataset Name": "pubmed_qa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/pubmed_qa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/pubmed_qa",
        "Paper Title": "PubMedQA: A Dataset for Biomedical Research Question Answering",
        "Papers with Code URL": "https://paperswithcode.com/dataset/pubmedqa",
        "ArXiv URL": "https://arxiv.org/abs/1909.06146",
        "Semantic Scholar Corpus ID": 202572622,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13001,
            "Mean Inputs Length": 3746.2033,
            "Mean Targets Length": 114.8489,
            "Max Inputs Length": 9767,
            "Max Targets Length": 282,
            "Min Inputs Length": 718,
            "Min Targets Length": 29,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "pubmed"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Pittsburgh",
            "Carnegie Mellon University",
            "Google"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/1909.06146"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task845_pubmedqa_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pubmed_qa",
            "HF Config": "pqa_labeled",
            "HF Config License": "MIT License",
            "HF Yaml License": "MIT License",
            "PwC License Name": "Custom",
            "PwC License URL": "https://pubmedqa.github.io/",
            "PwC Date": "2019-09-13",
            "S2 Date": "2019-09-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 12176,
            "HF Likes (September 2023)": 56,
            "PwC Description": "The task of PubMedQA is to answer research questions with yes/no/maybe (e.g.: Do preoperative statins reduce atrial fibrillation after coronary artery bypass grafting?) using the corresponding abstracts.\n\nPubMedQA has 1k expert labeled, 61.2k unlabeled and 211.3k artificially generated QA instances.",
            "S2 Citation Count (September 2023)": 193,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Genetics",
                "Medical research",
                "Research methods",
                "Cardiology",
                "Biology",
                "Medicine",
                "Medicine/Health",
                "Immunology",
                "Health",
                "Cancer research"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Jin2019PubMedQAAD,\n author = {Qiao Jin and Bhuwan Dhingra and Zhengping Liu and William W. Cohen and Xinghua Lu},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {2567-2577},\n title = {PubMedQA: A Dataset for Biomedical Research Question Answering},\n year = {2019}\n}\n"
    },
    "fc-sni-qa_srl": {
        "Unique Dataset Identifier": "fc-sni-qa_srl",
        "Dataset Name": "qa_srl",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/huggingface/datasets/tree/master/datasets/qa_srl",
        "GitHub URL": "https://github.com/huggingface/datasets/tree/master/datasets/qa_srl",
        "Hugging Face URL": "https://huggingface.co/datasets/qa_srl",
        "Paper Title": "Question-Answer Driven Semantic Role Labeling: Using Natural Language to Annotate Natural Language",
        "Papers with Code URL": "https://paperswithcode.com/dataset/qa-srl",
        "ArXiv URL": "https://aclanthology.org/D15-1076/",
        "Semantic Scholar Corpus ID": 1848109,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 659,
            "Mean Inputs Length": 1198.1608,
            "Mean Targets Length": 25.7208,
            "Max Inputs Length": 1816,
            "Max Targets Length": 45,
            "Min Inputs Length": 796,
            "Min Targets Length": 10,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "newswire",
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/D15-1076.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1519_qa_srl_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "qa_srl",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2015-01-01",
            "S2 Date": "2015-09-01",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1188,
            "HF Likes (September 2023)": 1,
            "PwC Description": "QA-SRL was proposed as an open schema for semantic roles, in which the relation between an argument and a predicate is expressed as a natural-language question containing the predicate (“Where was someone educated?”) whose answer is the argument (“Princeton”). The authors collected about 19,000 question-answer pairs from 3,200 sentences.",
            "S2 Citation Count (September 2023)": 191,
            "GitHub Stars": 17058,
            "GitHub Topics": [
                "computer-vision",
                "datasets",
                "deep-learning",
                "hacktoberfest",
                "machine-learning",
                "natural-language-processing",
                "nlp",
                "numpy",
                "pandas",
                "pytorch",
                "speech",
                "tensorflow"
            ],
            "Text Topics": [
                "Sentence structure",
                "Communication",
                "Interrogative sentences",
                "Language and grammar",
                "Linguistics",
                "Language learning",
                "Question formation"
            ]
        },
        "Derived from Datasets": [
            "PropBank"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{He2015QuestionAnswerDS,\n author = {Luheng He and M. Lewis and Luke Zettlemoyer},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {643-653},\n title = {Question-Answer Driven Semantic Role Labeling: Using Natural Language to Annotate Natural Language},\n year = {2015}\n}\n"
    },
    "fc-sni-qanta": {
        "Unique Dataset Identifier": "fc-sni-qanta",
        "Dataset Name": "qanta",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://people.cs.umass.edu/~miyyer/qblearn/index.html",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/qanta",
        "Paper Title": "Quizbowl: The Case for Incremental Question Answering",
        "Papers with Code URL": "https://paperswithcode.com/dataset/quizbowl",
        "ArXiv URL": "https://arxiv.org/abs/1904.04792",
        "Semantic Scholar Corpus ID": 104292014,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13079,
            "Mean Inputs Length": 1598.5,
            "Mean Targets Length": 9.9782,
            "Max Inputs Length": 3319,
            "Max Targets Length": 24,
            "Min Inputs Length": 374,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "quizdb.org",
            "protobowl.com"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Maryland",
            "University of Massachusetts Amherst",
            "New York University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task521_trivia_question_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "qanta",
            "HF Config": "mode=full,char_skip=25",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-04-09",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1259,
            "HF Likes (September 2023)": 3,
            "PwC Description": "Consists of multiple sentences whose clues are arranged by difficulty (from obscure to obvious) and uniquely identify a well-known entity such as those found on Wikipedia.",
            "S2 Citation Count (September 2023)": 28,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Education",
                "General knowledge",
                "Science",
                "Categorization",
                "Literature",
                "Quiz",
                "Social sciences",
                "Fine Arts",
                "Trivia",
                "History"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Rodriguez2019QuizbowlTC,\n author = {Pedro Rodriguez and Shi Feng and Mohit Iyyer and He He and Jordan L. Boyd-Graber},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Quizbowl: The Case for Incremental Question Answering},\n volume = {abs/1904.04792},\n year = {2019}\n}\n"
    },
    "fc-sni-qasc": {
        "Unique Dataset Identifier": "fc-sni-qasc",
        "Dataset Name": "qasc",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.org/data/qasc",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/qasc",
        "Paper Title": "QASC: A Dataset for Question Answering via Sentence Composition",
        "Papers with Code URL": "https://paperswithcode.com/dataset/qasc",
        "ArXiv URL": "https://arxiv.org/abs/1910.11473",
        "Semantic Scholar Corpus ID": 204915921,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Keyword Tagging"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1806,
            "Mean Inputs Length": 512.3965,
            "Mean Targets Length": 19.5365,
            "Max Inputs Length": 746,
            "Max Targets Length": 81,
            "Min Inputs Length": 348,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "ck12.org"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "University of Arizona"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://github.com/allenai/qasc"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task036_qasc_topic_word_to_generate_related_fact"
        ],
        "Inferred Metadata": {
            "HF Dataset": "qasc",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2019-10-25",
            "S2 Date": "2019-10-25",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5201,
            "HF Likes (September 2023)": 5,
            "PwC Description": "QASC is a question-answering dataset with a focus on sentence composition. It consists of 9,980 8-way multiple-choice questions about grade school science (8,134 train, 926 dev, 920 test), and comes with a corpus of 17M sentences.",
            "S2 Citation Count (September 2023)": 199,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Animal behavior",
                "Chemistry",
                "Science",
                "Biology",
                "Health",
                "Environmental science",
                "Environmental conservation",
                "Geography",
                "Geology"
            ]
        },
        "Derived from Datasets": [
            "WorldTree corpus"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Khot2019QASCAD,\n author = {Tushar Khot and Peter Clark and Michal Guerquin and Peter Alexander Jansen and Ashish Sabharwal},\n booktitle = {AAAI Conference on Artificial Intelligence},\n journal = {ArXiv},\n title = {QASC: A Dataset for Question Answering via Sentence Composition},\n volume = {abs/1910.11473},\n year = {2019}\n}\n"
    },
    "fc-sni-qasper": {
        "Unique Dataset Identifier": "fc-sni-qasper",
        "Dataset Name": "qasper",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.org/project/qasper/home",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/allenai/qasper",
        "Paper Title": "A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers",
        "Papers with Code URL": "https://paperswithcode.com/dataset/qasper",
        "ArXiv URL": "https://arxiv.org/abs/2105.03011",
        "Semantic Scholar Corpus ID": 234093776,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5362,
            "Mean Inputs Length": 1180.3553,
            "Mean Targets Length": 90.0668,
            "Max Inputs Length": 12433,
            "Max Targets Length": 1632,
            "Min Inputs Length": 214,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semantic scholar articles"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://allenai.org/data/qasper"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task460_qasper_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "allenai/qasper",
            "HF Config": "qasper",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/4.0/",
            "PwC Date": "2021-05-07",
            "S2 Date": "2021-05-07",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 831,
            "HF Likes (September 2023)": 28,
            "PwC Description": "QASPER is a dataset for question answering on scientific research papers. It consists of 5,049 questions over 1,585 Natural Language Processing papers. Each question is written by an NLP practitioner who read only the title and abstract of the corresponding paper, and the question seeks information present in the full text. The questions are then answered by a separate set of NLP practitioners who also provide supporting evidence to answers.",
            "S2 Citation Count (September 2023)": 69,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Linguistics",
                "Machine learning",
                "Academic research",
                "Text summarization",
                "Machine Learning",
                "Text Summarization",
                "Social Media Analysis"
            ]
        },
        "Derived from Datasets": [
            "S2ORC"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Dasigi2021ADO,\n author = {Pradeep Dasigi and Kyle Lo and Iz Beltagy and Arman Cohan and Noah A. Smith and Matt Gardner},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers},\n volume = {abs/2105.03011},\n year = {2021}\n}\n"
    },
    "fc-sni-qed": {
        "Unique Dataset Identifier": "fc-sni-qed",
        "Dataset Name": "qed",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/google-research-datasets/QED",
        "GitHub URL": "https://github.com/google-research-datasets/QED",
        "Hugging Face URL": "https://huggingface.co/datasets/qed",
        "Paper Title": "QED: A Framework and Dataset for Explanations in Question Answering",
        "Papers with Code URL": "https://paperswithcode.com/dataset/qed",
        "ArXiv URL": "https://arxiv.org/abs/2009.06354",
        "Semantic Scholar Corpus ID": 221655495,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 400,
            "Mean Inputs Length": 1499.675,
            "Mean Targets Length": 6.2825,
            "Max Inputs Length": 7521,
            "Max Targets Length": 25,
            "Min Inputs Length": 300,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "google search",
            "wikipedia.org",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University",
            "Google Research",
            "The University of Texas at Austin"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://research.google/pubs/pub47761/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task768_qed_text_span_selection"
        ],
        "Inferred Metadata": {
            "HF Dataset": "qed",
            "HF Config": "qed",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-09-08",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1121,
            "HF Likes (September 2023)": 2,
            "PwC Description": "QED is a linguistically principled framework for explanations in question answering. Given a question and a passage, QED represents an explanation of the answer as a combination of discrete, human-interpretable steps:\nsentence selection := identification of a sentence implying an answer to the question\nreferential equality := identification of noun phrases in the question and the answer sentence that refer to the same thing\npredicate entailment := confirmation that the predicate in the sentence entails the predicate in the question once referential equalities are abstracted away.\nThe QED dataset is an expert-annotated dataset of QED explanations build upon a subset of the Google Natural Questions dataset.",
            "S2 Citation Count (September 2023)": 45,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "History",
                "Sports",
                "Language understanding",
                "Reading comprehension",
                "Information retrieval",
                "General knowledge",
                "Legal cases"
            ]
        },
        "Derived from Datasets": [
            "Natural Questions dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lamm2020QEDAF,\n author = {Matthew Lamm and J. Palomaki and Chris Alberti and D. Andor and Eunsol Choi and Livio Baldini Soares and Michael Collins},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {790-806},\n title = {QED: A Framework and Dataset for Explanations in Question Answering},\n volume = {9},\n year = {2020}\n}\n"
    },
    "fc-sni-qed_amara": {
        "Unique Dataset Identifier": "fc-sni-qed_amara",
        "Dataset Name": "qed_amara",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/qed_amara",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/qed_amara",
        "Paper Title": "The AMARA Corpus: Building Parallel Language Resources for the Educational Domain",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/L14-1675/",
        "Semantic Scholar Corpus ID": 18357046,
        "Languages": [
            "French",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12816,
            "Mean Inputs Length": 376.9269,
            "Mean Targets Length": 77.0841,
            "Max Inputs Length": 2049,
            "Max Targets Length": 926,
            "Min Inputs Length": 79,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "amara.org",
            "khanacademy.org",
            "coursera.org",
            "udacity.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Qatar Computing Research Institute"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://opus.nlpl.eu/QED.php"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1689_qed_amara_translation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "qed_amara",
            "HF Config": "ar-ko",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1542,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 102,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Linguistics",
                "Daily routine",
                "Cultural differences",
                "Translation",
                "Cultural understanding",
                "Language learning",
                "Multilingualism"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Abdelali2014TheAC,\n author = {Ahmed Abdelali and Francisco Guzmán and Hassan Sajjad and S. Vogel},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {1856-1862},\n title = {The AMARA Corpus: Building Parallel Language Resources for the Educational Domain},\n year = {2014}\n}\n"
    },
    "fc-sni-qqp": {
        "Unique Dataset Identifier": "fc-sni-qqp",
        "Dataset Name": "qqp",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://gluebenchmark.com/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/SetFit/qqp",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Matching"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13161,
            "Mean Inputs Length": 479.9114,
            "Mean Targets Length": 2.9489,
            "Max Inputs Length": 1066,
            "Max Targets Length": 13,
            "Min Inputs Length": 192,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://openreview.net/pdf?id=rJ4km2R5t7"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1287_glue_qqp_paraphrasing"
        ],
        "Inferred Metadata": {
            "HF Dataset": "SetFit/qqp",
            "HF Config": "SetFit--qqp",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-02-28",
            "HF Downloads (September 2023)": 1479,
            "HF Likes (September 2023)": 4,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language and communication",
                "Online security",
                "Physics",
                "Technology",
                "Internet",
                "Password recovery",
                "Education",
                "Social media",
                "Music",
                "Entertainment"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-quail": {
        "Unique Dataset Identifier": "fc-sni-quail",
        "Dataset Name": "quail",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/quail",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/quail",
        "Paper Title": "Getting Closer to AI Complete Question Answering: A Set of Prerequisite Real Tasks",
        "Papers with Code URL": "https://paperswithcode.com/dataset/quail",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 213474484,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1010,
            "Mean Inputs Length": 3512.6733,
            "Mean Targets Length": 45.3089,
            "Max Inputs Length": 6863,
            "Max Targets Length": 141,
            "Min Inputs Length": 1606,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "University of Massachusetts Lowell"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "https://github.com/text-machine-lab/quail/blob/master/LICENSE.md"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task886_quail_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "quail",
            "HF Config": "quail",
            "HF Config License": "",
            "HF Yaml License": "CC BY-NC-SA 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-03",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5174,
            "HF Likes (September 2023)": 1,
            "PwC Description": "A new kind of question-answering dataset that combines commonsense, text-based, and unanswerable questions, balanced for different genres and reasoning types. Reasoning type annotation for 9 types of reasoning: temporal, causality, factoid, coreference, character properties, their belief states, subsequent entity states, event durations, and unanswerable. Genres: CC license fiction, Voice of America news, blogs, user stories from Quora 800 texts, 18 questions for each (~14K questions).",
            "S2 Citation Count (September 2023)": 76,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Psychology",
                "Character analysis",
                "Daily routine",
                "Personal growth and self-improvement",
                "Politics",
                "Geography",
                "Literature"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Rogers2020GettingCT,\n author = {Anna Rogers and Olga Kovaleva and Matthew Downey and Anna Rumshisky},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {8722-8731},\n title = {Getting Closer to AI Complete Question Answering: A Set of Prerequisite Real Tasks},\n year = {2020}\n}\n"
    },
    "fc-sni-quarel": {
        "Unique Dataset Identifier": "fc-sni-quarel",
        "Dataset Name": "quarel",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.org/data/quarel",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/quarel",
        "Paper Title": "Getting Closer to AI Complete Question Answering: A Set of Prerequisite Real Tasks",
        "Papers with Code URL": "https://paperswithcode.com/dataset/quarel",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 213474484,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1584,
            "Mean Inputs Length": 661.5486,
            "Mean Targets Length": 11.2677,
            "Max Inputs Length": 1529,
            "Max Targets Length": 71,
            "Min Inputs Length": 315,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "University of Massachusetts Lowell"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://allenai.org/data/quarel"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task1378_quarel_correct_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "quarel",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2018-11-20",
            "S2 Date": "2020-04-03",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3707,
            "HF Likes (September 2023)": 2,
            "PwC Description": "QuaRel is a crowdsourced dataset of 2771 multiple-choice story questions, including their logical forms.",
            "S2 Citation Count (September 2023)": 76,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Mechanics",
                "Physical appearance",
                "General knowledge",
                "Fitness",
                "Sports",
                "Language understanding",
                "Gym",
                "Physics",
                "Reading comprehension",
                "Sentence analysis"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Rogers2020GettingCT,\n author = {Anna Rogers and Olga Kovaleva and Matthew Downey and Anna Rumshisky},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {8722-8731},\n title = {Getting Closer to AI Complete Question Answering: A Set of Prerequisite Real Tasks},\n year = {2020}\n}\n"
    },
    "fc-sni-quartz": {
        "Unique Dataset Identifier": "fc-sni-quartz",
        "Dataset Name": "quartz",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.org/data/quartz",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/quartz",
        "Paper Title": "QUARTZ: An Open-Domain Dataset of Qualitative Relationship Questions",
        "Papers with Code URL": "https://paperswithcode.com/dataset/quartz",
        "ArXiv URL": "https://arxiv.org/abs/1909.03553",
        "Semantic Scholar Corpus ID": 202539540,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5408,
            "Mean Inputs Length": 745.0673,
            "Mean Targets Length": 9.0425,
            "Max Inputs Length": 1592,
            "Max Targets Length": 108,
            "Min Inputs Length": 294,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://allenai.org/data/quartz"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task1731_quartz_question_answering"
        ],
        "Inferred Metadata": {
            "HF Dataset": "quartz",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2019-09-08",
            "S2 Date": "2019-09-08",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 4972,
            "HF Likes (September 2023)": 3,
            "PwC Description": "QuaRTz is a crowdsourced dataset of 3864 multiple-choice questions about open domain qualitative relationships. Each question is paired with one of 405 different background sentences (sometimes short paragraphs).\n\nThe QuaRTz dataset V1 contains 3864 questions about open domain qualitative relationships. Each question is paired with one of 405 different background sentences (sometimes short paragraphs).\n\nThe dataset is split into train (2696), dev (384) and test (784). A background sentence will only appear in a single split.\n\nEach line in a dataset file is a question specified as a json object, e.g., (with extra whitespace for readability).",
            "S2 Citation Count (September 2023)": 74,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Water scarcity",
                "Education",
                "Climate change",
                "Population growth",
                "Reading comprehension",
                "Thermodynamics",
                "Geography",
                "Physics",
                "Chemistry",
                "Science"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Tafjord2019QuaRTzAO,\n author = {Oyvind Tafjord and Matt Gardner and Kevin Lin and Peter Clark},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {QuaRTz: An Open-Domain Dataset of Qualitative Relationship Questions},\n volume = {abs/1909.03553},\n year = {2019}\n}\n"
    },
    "fc-sni-question_&_answer_zre": {
        "Unique Dataset Identifier": "fc-sni-question_&_answer_zre",
        "Dataset Name": "question_&_answer_zre",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "http://nlp.cs.washington.edu/zeroshot/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "Zero-Shot Relation Extraction via Reading Comprehension",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1706.04115",
        "Semantic Scholar Corpus ID": 793385,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10332,
            "Mean Inputs Length": 830.6158,
            "Mean Targets Length": 45.4787,
            "Max Inputs Length": 3482,
            "Max Targets Length": 124,
            "Min Inputs Length": 397,
            "Min Targets Length": 20,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "wikidata",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "http://nlp.cs.washington.edu/zeroshot/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1325_qa_zre_question_generation_on_subject_relation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2017-06-13",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 437,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Education",
                "Geography",
                "Entertainment",
                "Biography",
                "General knowledge",
                "Sports",
                "Military",
                "History"
            ]
        },
        "Derived from Datasets": [
            "Wikireading dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Levy2017ZeroShotRE,\n author = {Omer Levy and Minjoon Seo and Eunsol Choi and Luke Zettlemoyer},\n booktitle = {Conference on Computational Natural Language Learning},\n journal = {ArXiv},\n title = {Zero-Shot Relation Extraction via Reading Comprehension},\n volume = {abs/1706.04115},\n year = {2017}\n}\n"
    },
    "fc-sni-quoref": {
        "Unique Dataset Identifier": "fc-sni-quoref",
        "Dataset Name": "quoref",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://paperswithcode.com/dataset/quoref",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/quoref",
        "Paper Title": "Quoref: A Reading Comprehension Dataset with Questions Requiring Coreferential Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/quoref",
        "ArXiv URL": "https://arxiv.org/abs/1908.05803",
        "Semantic Scholar Corpus ID": 201058596,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 8476,
            "Mean Inputs Length": 4061.6717,
            "Mean Targets Length": 80.8539,
            "Max Inputs Length": 11832,
            "Max Targets Length": 277,
            "Min Inputs Length": 1047,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://allenai.org/data/quoref"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task001_quoref_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "quoref",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/4.0/",
            "PwC Date": "2019-08-16",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 4439,
            "HF Likes (September 2023)": 1,
            "PwC Description": "Quoref is a QA dataset which tests the coreferential reasoning capability of reading comprehension systems. In this span-selection benchmark containing 24K questions over 4.7K paragraphs from Wikipedia, a system must resolve hard coreferences before selecting the appropriate span(s) in the paragraphs for answering questions.",
            "S2 Citation Count (September 2023)": 136,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Comprehension of references",
                "Literature",
                "Information retrieval",
                "Geography",
                "Comprehension of references in a passage",
                "Comprehension",
                "Reading comprehension"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Dasigi2019QuorefAR,\n author = {Pradeep Dasigi and Nelson F. Liu and Ana Marasović and Noah A. Smith and Matt Gardner},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Quoref: A Reading Comprehension Dataset with Questions Requiring Coreferential Reasoning},\n volume = {abs/1908.05803},\n year = {2019}\n}\n"
    },
    "fc-sni-race": {
        "Unique Dataset Identifier": "fc-sni-race",
        "Dataset Name": "race",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.cs.cmu.edu/~glai1/data/race/#:~:text=notes",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/race",
        "Paper Title": "RACE: Large-scale ReAding Comprehension Dataset From Examinations",
        "Papers with Code URL": "https://paperswithcode.com/dataset/race",
        "ArXiv URL": "https://arxiv.org/abs/1704.04683",
        "Semantic Scholar Corpus ID": 6826032,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12993,
            "Mean Inputs Length": 4028.052,
            "Mean Targets Length": 1.5766,
            "Max Inputs Length": 11809,
            "Max Targets Length": 11,
            "Min Inputs Length": 848,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "web exams"
        ],
        "Model Generated": [],
        "Creators": [
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://www.cs.cmu.edu/~glai1/data/race/#:~:text=notes"
            }
        ],
        "License Notes": "Non-commercial",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task309_race_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "race",
            "HF Config": "all",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Academic Research Purposes Only",
            "PwC License URL": "https://www.cs.cmu.edu/~glai1/data/race/#:~:text=notes",
            "PwC Date": "2017-01-01",
            "S2 Date": "2017-04-15",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 24087,
            "HF Likes (September 2023)": 20,
            "PwC Description": "The ReAding Comprehension dataset from Examinations (RACE) dataset is a machine reading comprehension dataset consisting of 27,933 passages and 97,867 questions from English exams, targeting Chinese students aged 12-18. RACE consists of two subsets, RACE-M and RACE-H, from middle school and high school exams, respectively. RACE-M has 28,293 questions and RACE-H has 69,574. Each question is associated with 4 candidate answers, one of which is correct. The data generation process of RACE differs from most machine reading comprehension datasets - instead of generating questions and answers by heuristics or crowd-sourcing, questions in RACE are specifically designed for testing human reading skills, and are created by domain experts.",
            "S2 Citation Count (September 2023)": 927,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language learning",
                "Reading comprehension",
                "Multiple choice questions",
                "Test-taking strategies",
                "Test taking strategies",
                "Language proficiency",
                "Critical thinking",
                "Test preparation"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lai2017RACELR,\n author = {Guokun Lai and Qizhe Xie and Hanxiao Liu and Yiming Yang and E. Hovy},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {RACE: Large-scale ReAding Comprehension Dataset From Examinations},\n volume = {abs/1704.04683},\n year = {2017}\n}\n"
    },
    "fc-sni-recipe_nlg": {
        "Unique Dataset Identifier": "fc-sni-recipe_nlg",
        "Dataset Name": "recipe_nlg",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/recipe_nlg",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/recipe_nlg",
        "Paper Title": "RecipeNLG: A Cooking Recipes Dataset for Semi-Structured Text Generation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/recipenlg",
        "ArXiv URL": "https://aclanthology.org/2020.inlg-1.4/",
        "Semantic Scholar Corpus ID": 227216980,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Title Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13069,
            "Mean Inputs Length": 1487.1775,
            "Mean Targets Length": 24.2947,
            "Max Inputs Length": 7807,
            "Max Targets Length": 106,
            "Min Inputs Length": 241,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "cooking websites"
        ],
        "Model Generated": [],
        "Creators": [
            "Poznan University of Technology"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://recipenlg.cs.put.poznan.pl/dataset"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task569_recipe_nlg_text_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "recipe_nlg",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2020-12-15",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 639,
            "HF Likes (September 2023)": 18,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 21,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Food and cuisine",
                "Culinary techniques",
                "Recipe creation",
                "Cooking and recipes",
                "Food and ingredients",
                "Culinary arts",
                "Cooking techniques",
                "Meal planning"
            ]
        },
        "Derived from Datasets": [
            "Recipe1M"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Bień2020RecipeNLGAC,\n author = {Michał Bień and Michał Gilski and M. Maciejewska and Wojciech Taisner and Dawid Wisniewski and Agnieszka Lawrynowicz},\n booktitle = {International Conference on Natural Language Generation},\n pages = {22-28},\n title = {RecipeNLG: A Cooking Recipes Dataset for Semi-Structured Text Generation},\n year = {2020}\n}\n"
    },
    "fc-sni-reddit_tifu_dataset": {
        "Unique Dataset Identifier": "fc-sni-reddit_tifu_dataset",
        "Dataset Name": "reddit_tifu_dataset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://aclanthology.org/N19-1260.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/reddit_tifu",
        "Paper Title": "Abstractive Summarization of Reddit Posts with Multi-level Memory Networks",
        "Papers with Code URL": "https://paperswithcode.com/dataset/reddit-tifu",
        "ArXiv URL": "https://arxiv.org/abs/1811.00783",
        "Semantic Scholar Corpus ID": 53295957,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Title Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12988,
            "Mean Inputs Length": 2772.5219,
            "Mean Targets Length": 46.3928,
            "Max Inputs Length": 25242,
            "Max Targets Length": 262,
            "Min Inputs Length": 263,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "Seoul National University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/N19-1260.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task510_reddit_tifu_title_summarization"
        ],
        "Inferred Metadata": {
            "HF Dataset": "reddit_tifu",
            "HF Config": "short",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2018-11-02",
            "S2 Date": "2018-11-02",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 973,
            "HF Likes (September 2023)": 4,
            "PwC Description": "Reddit TIFU dataset is a newly collected Reddit dataset, where TIFU denotes the name of /r/tifu subbreddit.\nThere are 122,933 text-summary pairs in total.",
            "S2 Citation Count (September 2023)": 130,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Communication",
                "Humor",
                "Daily routine",
                "Relationships",
                "Humorous anecdotes",
                "Social media",
                "Social interactions",
                "Daily life"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Kim2018AbstractiveSO,\n author = {Byeongchang Kim and Hyunwoo Kim and Gunhee Kim},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Abstractive Summarization of Reddit Posts with Multi-level Memory Networks},\n volume = {abs/1811.00783},\n year = {2018}\n}\n"
    },
    "fc-sni-refresd": {
        "Unique Dataset Identifier": "fc-sni-refresd",
        "Dataset Name": "refresd",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://raw.githubusercontent.com/Elbria/xling-SemDiv/master/REFreSD/REFreSD_rationale",
        "GitHub URL": "https://github.com/Elbria/xling-SemDiv/tree/master",
        "Hugging Face URL": "https://huggingface.co/datasets/refresd",
        "Paper Title": "Detecting Fine-Grained Cross-Lingual Semantic Divergences without Supervision by Learning to Rank",
        "Papers with Code URL": "https://paperswithcode.com/dataset/refresd",
        "ArXiv URL": "https://arxiv.org/abs/2010.03662",
        "Semantic Scholar Corpus ID": 222208706,
        "Languages": [
            "French",
            "English"
        ],
        "Task Categories": [
            "Text Matching"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 784,
            "Mean Inputs Length": 840.4668,
            "Mean Targets Length": 1.5281,
            "Max Inputs Length": 1671,
            "Max Targets Length": 11,
            "Min Inputs Length": 285,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "University of Maryland"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task643_refresd_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "refresd",
            "HF Config": "default",
            "HF Config License": "MIT License",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-07",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 574,
            "HF Likes (September 2023)": 0,
            "PwC Description": "Consists of English-French sentence-pairs annotated with semantic divergence classes and token-level rationales.",
            "S2 Citation Count (September 2023)": 14,
            "GitHub Stars": 6,
            "GitHub Topics": [
                "bertology",
                "corpus-filtering",
                "cross-lingual-similarity",
                "learning-to-rank",
                "multilingual-bert",
                "parallel-data",
                "semantic-divergences",
                "synthetic-supervision"
            ],
            "Text Topics": [
                "Anthropology",
                "Translation",
                "Language processing",
                "Language learning",
                "Cultural differences",
                "Literature",
                "History"
            ]
        },
        "Derived from Datasets": [
            "Wikimatrix dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Briakou2020DetectingFC,\n author = {Eleftheria Briakou and Marine Carpuat},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {1563-1580},\n title = {Detecting Fine-Grained Cross-Lingual Semantic Divergences without Supervision by Learning to Rank},\n year = {2020}\n}\n"
    },
    "fc-sni-ro_sts_parallel": {
        "Unique Dataset Identifier": "fc-sni-ro_sts_parallel",
        "Dataset Name": "ro_sts_parallel",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/ro_sts_parallel",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ro_sts_parallel",
        "Paper Title": "LiRo: Benchmark and leaderboard for Romanian language tasks",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 237259105,
        "Languages": [
            "Romanian",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 11908,
            "Mean Inputs Length": 391.5789,
            "Mean Targets Length": 63.4257,
            "Max Inputs Length": 1117,
            "Max Targets Length": 248,
            "Min Inputs Length": 154,
            "Min Targets Length": 15,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/dumitrescustefan/RO-STS"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1435_ro_sts_parallel_language_translation_ro_to_en"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ro_sts_parallel",
            "HF Config": "ro_sts_parallel",
            "HF Config License": "CC BY-SA 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 537,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 13,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language learning",
                "Politics",
                "Cultural differences",
                "Legal proceedings",
                "Translation",
                "Finance",
                "Culinary arts",
                "Sports",
                "Food and cooking",
                "Cultural understanding"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Dumitrescu2021LiRoBA,\n author = {S. Dumitrescu and Petru Rebeja and Beáta Lőrincz and Mihaela Găman and M. Ilie and Andrei Pruteanu and Adriana Stan and Luciana Morogan and Traian Rebedea and Sebastian Ruder},\n booktitle = {NeurIPS Datasets and Benchmarks},\n title = {LiRo: Benchmark and leaderboard for Romanian language tasks},\n year = {2021}\n}\n"
    },
    "fc-sni-roc_stories": {
        "Unique Dataset Identifier": "fc-sni-roc_stories",
        "Dataset Name": "roc_stories",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://cs.rochester.edu/nlp/rocstories/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Fill in The Blank"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3869,
            "Mean Inputs Length": 895.7896,
            "Mean Targets Length": 1.6095,
            "Max Inputs Length": 1500,
            "Max Targets Length": 11,
            "Min Inputs Length": 463,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://cs.rochester.edu/nlp/rocstories/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task296_storycloze_correct_end_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Reading comprehension",
                "Language comprehension",
                "Language understanding",
                "Coherence in writing",
                "Daily routine",
                "Natural language processing",
                "Decision-making"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-rocstories": {
        "Unique Dataset Identifier": "fc-sni-rocstories",
        "Dataset Name": "rocstories",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/pdf/1604.01696.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories",
        "Papers with Code URL": "https://paperswithcode.com/dataset/rocstories",
        "ArXiv URL": "https://arxiv.org/abs/1604.01696",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Fill in The Blank"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13024,
            "Mean Inputs Length": 1045.932,
            "Mean Targets Length": 1.6166,
            "Max Inputs Length": 1792,
            "Max Targets Length": 11,
            "Min Inputs Length": 572,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Rochester",
            "United States Naval Academy",
            "Microsoft Research",
            "Virginia Tech",
            "The Institute for Human & Machine Cognition"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task213_rocstories_correct_ending_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2016-01-01",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "ROCStories is a collection of commonsense short stories. The corpus consists of 100,000 five-sentence stories. Each story logically follows everyday topics created by Amazon Mechanical Turk workers. These stories contain a variety of commonsense causal and temporal relations between everyday events. Writers also develop an additional 3,742 Story Cloze Test stories which contain a four-sentence-long body and two candidate endings. The endings were collected by asking Mechanical Turk workers to write both a right ending and a wrong ending after eliminating original endings of given short stories. Both endings were required to make logical sense and include at least one character from the main story line. The published ROCStories dataset is constructed with ROCStories as a training set that includes 98,162 stories that exclude candidate wrong endings, an evaluation set, and a test set, which have the same structure (1 body + 2 candidate endings) and a size of 1,871.",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Creative storytelling",
                "Writing",
                "Creative writing",
                "Creative thinking",
                "Critical thinking"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": ""
    },
    "fc-sni-root09": {
        "Unique Dataset Identifier": "fc-sni-root09",
        "Dataset Name": "root09",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/abs/1603.08702",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "Path-based vs. Distributional Information in Recognizing Lexical Semantic Relations",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1603.08702",
        "Semantic Scholar Corpus ID": 207754,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Word Relation Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6302,
            "Mean Inputs Length": 523.1717,
            "Mean Targets Length": 6.0065,
            "Max Inputs Length": 690,
            "Max Targets Length": 16,
            "Min Inputs Length": 425,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Bar-Ilan University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1505_root09_semantic_relation_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2016-08-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 30,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Word relationships",
                "Semantics",
                "Language and Linguistics",
                "Language",
                "Education and Teaching Methods",
                "Language and semantics",
                "Word Relationships",
                "Semantics and Word Relationships",
                "Language analysis",
                "Linguistics"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Shwartz2016PathbasedVD,\n author = {Vered Shwartz and Ido Dagan},\n booktitle = {CogALex@COLING},\n pages = {24-29},\n title = {Path-based vs. Distributional Information in Recognizing Lexical Semantic Relations},\n year = {2016}\n}\n"
    },
    "fc-sni-ropes": {
        "Unique Dataset Identifier": "fc-sni-ropes",
        "Dataset Name": "ropes",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://paperswithcode.com/dataset/ropes",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/ropes",
        "Paper Title": "Reasoning Over Paragraph Effects in Situations",
        "Papers with Code URL": "https://paperswithcode.com/dataset/ropes",
        "ArXiv URL": "https://arxiv.org/abs/1908.05852",
        "Semantic Scholar Corpus ID": 201058633,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Narrative Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1053,
            "Mean Inputs Length": 2546.2697,
            "Mean Targets Length": 307.5385,
            "Max Inputs Length": 7248,
            "Max Targets Length": 894,
            "Min Inputs Length": 1096,
            "Min Targets Length": 93,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "books",
            "wikipedia.org",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://allenai.org/data/ropes"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task059_ropes_story_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "ropes",
            "HF Config": "plain_text",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/4.0/",
            "PwC Date": "2019-08-16",
            "S2 Date": "2019-08-16",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5332,
            "HF Likes (September 2023)": 9,
            "PwC Description": "ROPES is a QA dataset which tests a system's ability to apply knowledge from a passage of text to a new situation. A system is presented a background passage containing a causal or qualitative relation(s), a novel situation that uses this background, and questions that require reasoning about effects of the relationships in the back-ground passage in the context of the situation.",
            "S2 Citation Count (September 2023)": 92,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Animal behavior",
                "Chemistry",
                "Health",
                "Science",
                "Decision-making",
                "Education",
                "Biology"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lin2019ReasoningOP,\n author = {Kevin Lin and Oyvind Tafjord and Peter Clark and Matt Gardner},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {58-62},\n title = {Reasoning Over Paragraph Effects in Situations},\n year = {2019}\n}\n"
    },
    "fc-sni-rotten_tomatoe": {
        "Unique Dataset Identifier": "fc-sni-rotten_tomatoe",
        "Dataset Name": "rotten_tomatoe",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/rotten_tomatoes",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/rotten_tomatoes",
        "Paper Title": "Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales",
        "Papers with Code URL": "https://paperswithcode.com/dataset/mr",
        "ArXiv URL": "https://arxiv.org/abs/cs/0506075",
        "Semantic Scholar Corpus ID": 3264224,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1014,
            "Mean Inputs Length": 379.9438,
            "Mean Targets Length": 8.5533,
            "Max Inputs Length": 804,
            "Max Targets Length": 18,
            "Min Inputs Length": 115,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "rottentomatoes.com"
        ],
        "Model Generated": [],
        "Creators": [
            "Cornell University",
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/cs/0506075.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task888_reviews_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "rotten_tomatoes",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2004-01-01",
            "S2 Date": "2005-06-17",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 58503,
            "HF Likes (September 2023)": 26,
            "PwC Description": "MR Movie Reviews is a dataset for use in sentiment-analysis experiments. Available are collections of movie-review documents labeled with respect to their overall sentiment polarity (positive or negative) or subjective rating (e.g., \"two and a half stars\") and sentences labeled with respect to their subjectivity status (subjective or objective) or polarity.",
            "S2 Citation Count (September 2023)": 2633,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Movie reviews",
                "Character development",
                "Film criticism",
                "Film analysis",
                "Sentiment analysis",
                "Recommendations",
                "Genre classification",
                "Natural language processing",
                "Critical thinking",
                "Entertainment"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Pang2005SeeingSE,\n author = {B. Pang and Lillian Lee},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {115-124},\n title = {Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales},\n year = {2005}\n}\n"
    },
    "fc-sni-rtgender": {
        "Unique Dataset Identifier": "fc-sni-rtgender",
        "Dataset Name": "rtgender",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/peixian/rtGender",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/peixian/rtGender",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9963,
            "Mean Inputs Length": 718.7126,
            "Mean Targets Length": 8.0959,
            "Max Inputs Length": 1577,
            "Max Targets Length": 18,
            "Min Inputs Length": 314,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://nlp.stanford.edu/robvoigt/rtgender/rtgender.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task823_peixian-rtgender_sentiment_analysis"
        ],
        "Inferred Metadata": {
            "HF Dataset": "peixian/rtGender",
            "HF Config": "annotations",
            "HF Config License": "Academic Research Purposes Only",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2021-03-22",
            "HF Downloads (September 2023)": 286,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-ruletaker": {
        "Unique Dataset Identifier": "fc-sni-ruletaker",
        "Dataset Name": "ruletaker",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.org/data/ruletaker",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/ruletaker",
        "Paper Title": "Transformers as Soft Reasoners over Language",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2002.05867",
        "Semantic Scholar Corpus ID": 211126663,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Fact Verification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 600,
            "Mean Inputs Length": 1233.2083,
            "Mean Targets Length": 5.0783,
            "Max Inputs Length": 2632,
            "Max Targets Length": 15,
            "Min Inputs Length": 612,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://allenai.org/data/ruletaker"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task966_ruletaker_fact_checking_based_on_given_context"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/ruletaker",
            "HF Config": "tasksource--ruletaker",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-02-14",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2023-05-23",
            "HF Downloads (September 2023)": 44,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 202,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Logical reasoning",
                "Text comprehension",
                "Fact-checking",
                "Fact checking",
                "General knowledge",
                "Inference",
                "Reading comprehension"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Clark2020TransformersAS,\n author = {Peter Clark and Oyvind Tafjord and Kyle Richardson},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {3882-3890},\n title = {Transformers as Soft Reasoners over Language},\n year = {2020}\n}\n"
    },
    "fc-sni-sarcasm_in_twitter": {
        "Unique Dataset Identifier": "fc-sni-sarcasm_in_twitter",
        "Dataset Name": "sarcasm_in_twitter",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.kaggle.com/c/gse002",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 248,
            "Mean Inputs Length": 578.0927,
            "Mean Targets Length": 11.6331,
            "Max Inputs Length": 824,
            "Max Targets Length": 23,
            "Min Inputs Length": 346,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1489_sarcasmdetection_tweet_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Social media and online interactions",
                "Social media",
                "Sarcasm and irony",
                "Sentiment analysis",
                "Social Media Analysis",
                "Social media analysis",
                "Language and communication",
                "Sentiment Analysis",
                "Natural Language Processing"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-sbic": {
        "Unique Dataset Identifier": "fc-sni-sbic",
        "Dataset Name": "sbic",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/social_bias_frames",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/social_bias_frames",
        "Paper Title": "Social Bias Frames: Reasoning about Social and Power Implications of Language",
        "Papers with Code URL": "https://paperswithcode.com/dataset/sbic",
        "ArXiv URL": "https://arxiv.org/abs/1911.03891",
        "Semantic Scholar Corpus ID": 207853290,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Toxicity Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3394,
            "Mean Inputs Length": 670.8757,
            "Mean Targets Length": 3.0545,
            "Max Inputs Length": 1079,
            "Max Targets Length": 13,
            "Min Inputs Length": 425,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reddit",
            "twitter",
            "gab.com",
            "stormfront.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "AI2",
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/2020.acl-main.486.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task607_sbic_intentional_offense_binary_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "social_bias_frames",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-11-10",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 719,
            "HF Likes (September 2023)": 8,
            "PwC Description": "To support large-scale modelling and evaluation with 150k structured annotations of social media posts, covering over 34k implications about a thousand demographic groups.",
            "S2 Citation Count (September 2023)": 281,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Text classification",
                "Social media analysis",
                "Online etiquette",
                "Offensive language detection",
                "Online behavior",
                "Online content moderation",
                "Online communication",
                "Offensive language",
                "Social media"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Sap2019SocialBF,\n author = {Maarten Sap and Saadia Gabriel and Lianhui Qin and Dan Jurafsky and Noah A. Smith and Yejin Choi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Social Bias Frames: Reasoning about Social and Power Implications of Language},\n volume = {abs/1911.03891},\n year = {2019}\n}\n"
    },
    "fc-sni-scan": {
        "Unique Dataset Identifier": "fc-sni-scan",
        "Dataset Name": "scan",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/brendenlake/SCAN",
        "GitHub URL": "https://github.com/brendenlake/SCAN",
        "Hugging Face URL": "https://huggingface.co/datasets/scan",
        "Paper Title": "Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks",
        "Papers with Code URL": "https://paperswithcode.com/dataset/scan",
        "ArXiv URL": "https://arxiv.org/abs/1711.00350",
        "Semantic Scholar Corpus ID": 46761158,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text to Code"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12985,
            "Mean Inputs Length": 1422.2782,
            "Mean Targets Length": 143.3557,
            "Max Inputs Length": 2270,
            "Max Targets Length": 479,
            "Min Inputs Length": 1219,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "custom model/code generated"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "New York University",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "BSD 3-Clause License",
                "License URL": "https://github.com/brendenlake/SCAN/blob/master/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task126_scan_structured_text_generation_command_action_all"
        ],
        "Inferred Metadata": {
            "HF Dataset": "scan",
            "HF Config": "simple",
            "HF Config License": "",
            "HF Yaml License": "BSD 3-Clause License",
            "PwC License Name": "BSD 3-Clause License",
            "PwC License URL": "https://github.com/brendenlake/SCAN/blob/master/LICENSE",
            "PwC Date": "",
            "S2 Date": "2017-10-31",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 6855,
            "HF Likes (September 2023)": 2,
            "PwC Description": "SCAN is a dataset for grounded navigation which consists of a set of simple compositional navigation commands paired with the corresponding action sequences.",
            "S2 Citation Count (September 2023)": 583,
            "GitHub Stars": 160,
            "GitHub Topics": [],
            "Text Topics": [
                "Task-oriented dialogue systems",
                "Agent navigation",
                "Navigation and spatial awareness",
                "Natural language processing",
                "Instruction execution",
                "Task execution",
                "Command execution"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Lake2017GeneralizationWS,\n author = {B. Lake and Marco Baroni},\n booktitle = {International Conference on Machine Learning},\n pages = {2879-2888},\n title = {Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks},\n year = {2017}\n}\n"
    },
    "fc-sni-schema_guided_dstc8": {
        "Unique Dataset Identifier": "fc-sni-schema_guided_dstc8",
        "Dataset Name": "schema_guided_dstc8",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/schema_guided_dstc8",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/schema_guided_dstc8",
        "Paper Title": "Schema-Guided Dialogue State Tracking Task at DSTC8",
        "Papers with Code URL": "https://paperswithcode.com/dataset/sgd",
        "ArXiv URL": "https://arxiv.org/abs/2002.01359",
        "Semantic Scholar Corpus ID": 211020805,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Dialogue Act Recognition"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4583,
            "Mean Inputs Length": 352.3901,
            "Mean Targets Length": 3.0836,
            "Max Inputs Length": 717,
            "Max Targets Length": 13,
            "Min Inputs Length": 187,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "Google Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/google-research-datasets/dstc8-schema-guided-dialogue/blob/master/LICENSE.txt"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task879_schema_guided_dstc8_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "schema_guided_dstc8",
            "HF Config": "dialogues",
            "HF Config License": "CC BY-SA 4.0",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://github.com/google-research-datasets/dstc8-schema-guided-dialogue",
            "PwC Date": "",
            "S2 Date": "2020-02-02",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5338,
            "HF Likes (September 2023)": 6,
            "PwC Description": "The Schema-Guided Dialogue (SGD) dataset consists of over 20k annotated multi-domain, task-oriented conversations between a human and a virtual assistant. These conversations involve interactions with services and APIs spanning 20 domains, ranging from banks and events to media, calendar, travel, and weather. For most of these domains, the dataset contains multiple different APIs, many of which have overlapping functionalities but different interfaces, which reflects common real-world scenarios. The wide range of available annotations can be used for intent prediction, slot filling, dialogue state tracking, policy imitation learning, language generation, user simulation learning, among other tasks in large-scale virtual assistants. Besides these, the dataset has unseen domains and services in the evaluation set to quantify the performance in zero-shot or few shot settings.",
            "S2 Citation Count (September 2023)": 37,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Natural language processing",
                "Customer service",
                "Restaurant reservations",
                "Conversational AI",
                "Virtual assistants",
                "Food and dining",
                "Communication",
                "Conversation analysis"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Rastogi2020SchemaGuidedDS,\n author = {Abhinav Rastogi and Xiaoxue Zang and Srinivas Sunkara and Raghav Gupta and Pranav Khaitan},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Schema-Guided Dialogue State Tracking Task at DSTC8},\n volume = {abs/2002.01359},\n year = {2020}\n}\n"
    },
    "fc-sni-scifact": {
        "Unique Dataset Identifier": "fc-sni-scifact",
        "Dataset Name": "scifact",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/scifact",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/scifact",
        "Paper Title": "Fact or Fiction: Verifying Scientific Claims",
        "Papers with Code URL": "https://paperswithcode.com/dataset/scifact",
        "ArXiv URL": "https://arxiv.org/abs/2004.14974",
        "Semantic Scholar Corpus ID": 216867133,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Title Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10017,
            "Mean Inputs Length": 2881.5981,
            "Mean Targets Length": 98.3826,
            "Max Inputs Length": 13830,
            "Max Targets Length": 308,
            "Min Inputs Length": 322,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "semantic scholar articles"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 2.0",
                "License URL": "https://github.com/allenai/scifact/blob/master/LICENSE.md"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1586_scifact_title_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "scifact",
            "HF Config": "corpus",
            "HF Config License": "",
            "HF Yaml License": "CC BY-NC 2.0",
            "PwC License Name": "CC BY-NC 2.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-nc/2.0/",
            "PwC Date": "2020-04-30",
            "S2 Date": "2020-04-30",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1262,
            "HF Likes (September 2023)": 4,
            "PwC Description": "SciFact is a dataset of 1.4K expert-written claims, paired with evidence-containing abstracts annotated with veracity labels and rationales.",
            "S2 Citation Count (September 2023)": 223,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Brain development",
                "Molecular biology",
                "Biology",
                "Immunology",
                "Medical research",
                "Neuroscience",
                "Cell biology"
            ]
        },
        "Derived from Datasets": [
            "S2ORC"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Wadden2020FactOF,\n author = {David Wadden and Kyle Lo and Lucy Lu Wang and Shanchuan Lin and Madeleine van Zuylen and Arman Cohan and Hannaneh Hajishirzi},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Fact or Fiction: Verifying Scientific Claims},\n volume = {abs/2004.14974},\n year = {2020}\n}\n"
    },
    "fc-sni-sciq": {
        "Unique Dataset Identifier": "fc-sni-sciq",
        "Dataset Name": "sciq",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/sciq",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sciq",
        "Paper Title": "Crowdsourcing Multiple Choice Science Questions",
        "Papers with Code URL": "https://paperswithcode.com/dataset/sciq",
        "ArXiv URL": "https://arxiv.org/abs/1707.06209",
        "Semantic Scholar Corpus ID": 1553193,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12892,
            "Mean Inputs Length": 274.2274,
            "Mean Targets Length": 11.6275,
            "Max Inputs Length": 760,
            "Max Targets Length": 67,
            "Min Inputs Length": 79,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "creative commons license textbooks"
        ],
        "Model Generated": [],
        "Creators": [
            "University College London",
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 3.0",
                "License URL": "https://www.semanticscholar.org/reader/932a5de79d8a8ebb75ea0c43493450fd9922e738"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task591_sciq_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sciq",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY-NC 3.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2017-07-19",
            "S2 Date": "2017-07-19",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 59289,
            "HF Likes (September 2023)": 56,
            "PwC Description": "The SciQ dataset contains 13,679 crowdsourced science exam questions about Physics, Chemistry and Biology, among others. The questions are in multiple-choice format with 4 answer options each. For the majority of the questions, an additional paragraph with supporting evidence for the correct answer is provided.",
            "S2 Citation Count (September 2023)": 142,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Evolution",
                "Science",
                "Chemistry",
                "Biology",
                "History of Science",
                "Botany",
                "Anatomy",
                "Physics",
                "Health",
                "Medicine"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Welbl2017CrowdsourcingMC,\n author = {Johannes Welbl and Nelson F. Liu and Matt Gardner},\n booktitle = {NUT@EMNLP},\n journal = {ArXiv},\n title = {Crowdsourcing Multiple Choice Science Questions},\n volume = {abs/1707.06209},\n year = {2017}\n}\n"
    },
    "fc-sni-scitail": {
        "Unique Dataset Identifier": "fc-sni-scitail",
        "Dataset Name": "scitail",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "http://data.allenai.org.s3.amazonaws.com/downloads/SciTailV1.1.zip",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/scitail",
        "Paper Title": "SciTaiL: A Textual Entailment Dataset from Science Question Answering",
        "Papers with Code URL": "https://paperswithcode.com/dataset/scitail",
        "ArXiv URL": "https://arxiv.org/abs/1809.05726",
        "Semantic Scholar Corpus ID": 24462950,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6165,
            "Mean Inputs Length": 373.3111,
            "Mean Targets Length": 73.4989,
            "Max Inputs Length": 937,
            "Max Targets Length": 237,
            "Min Inputs Length": 137,
            "Min Targets Length": 21,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "IBM",
            "University of Illinois Urbana-Champaign",
            "Tulane University"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://allenai.org/data/scitail"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1552_scitail_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "scitail",
            "HF Config": "snli_format",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-04-27",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5317,
            "HF Likes (September 2023)": 4,
            "PwC Description": "The SciTail dataset is an entailment dataset created from multiple-choice science exams and web sentences. Each question and the correct answer choice are converted into an assertive statement to form the hypothesis. We use information retrieval to obtain relevant text from a large text corpus of web sentences, and use these sentences as a premise P. We crowdsource the annotation of such premise-hypothesis pair as supports (entails) or not (neutral), in order to create the SciTail dataset. The dataset contains 27,026 examples with 10,101 examples with entails label and 16,925 examples with neutral label.",
            "S2 Citation Count (September 2023)": 363,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "General knowledge",
                "Reproduction",
                "Chemistry",
                "Microbiology",
                "Astronomy",
                "Geology",
                "Biology",
                "Physics",
                "Earth Science"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Khot2018SciTaiLAT,\n author = {Tushar Khot and Ashish Sabharwal and Peter Clark},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {5189-5197},\n title = {SciTaiL: A Textual Entailment Dataset from Science Question Answering},\n year = {2018}\n}\n"
    },
    "fc-sni-scitailv1.1": {
        "Unique Dataset Identifier": "fc-sni-scitailv1.1",
        "Dataset Name": "scitailv1.1",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "http://data.allenai.org/scitail",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/scitail",
        "Paper Title": "SciTaiL: A Textual Entailment Dataset from Science Question Answering",
        "Papers with Code URL": "https://paperswithcode.com/dataset/scitail",
        "ArXiv URL": "https://arxiv.org/abs/1809.05726",
        "Semantic Scholar Corpus ID": 24462950,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 10059,
            "Mean Inputs Length": 856.0919,
            "Mean Targets Length": 7.5586,
            "Max Inputs Length": 1614,
            "Max Targets Length": 17,
            "Min Inputs Length": 480,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "IBM",
            "University of Illinois Urbana-Champaign",
            "Tulane University"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://allenai.org/data/scitail"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1529_scitail1.1_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "scitail",
            "HF Config": "snli_format",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-04-27",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 5317,
            "HF Likes (September 2023)": 4,
            "PwC Description": "The SciTail dataset is an entailment dataset created from multiple-choice science exams and web sentences. Each question and the correct answer choice are converted into an assertive statement to form the hypothesis. We use information retrieval to obtain relevant text from a large text corpus of web sentences, and use these sentences as a premise P. We crowdsource the annotation of such premise-hypothesis pair as supports (entails) or not (neutral), in order to create the SciTail dataset. The dataset contains 27,026 examples with 10,101 examples with entails label and 16,925 examples with neutral label.",
            "S2 Citation Count (September 2023)": 363,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Khot2018SciTaiLAT,\n author = {Tushar Khot and Ashish Sabharwal and Peter Clark},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {5189-5197},\n title = {SciTaiL: A Textual Entailment Dataset from Science Question Answering},\n year = {2018}\n}\n"
    },
    "fc-sni-scitldr": {
        "Unique Dataset Identifier": "fc-sni-scitldr",
        "Dataset Name": "scitldr",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/allenai/scitldr",
        "GitHub URL": "https://github.com/allenai/scitldr",
        "Hugging Face URL": "https://huggingface.co/datasets/allenai/scitldr",
        "Paper Title": "TLDR: Extreme Summarization of Scientific Documents",
        "Papers with Code URL": "https://paperswithcode.com/dataset/scitldr",
        "ArXiv URL": "https://arxiv.org/abs/2004.15011",
        "Semantic Scholar Corpus ID": 216867622,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Summarization"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6392,
            "Mean Inputs Length": 2349.1472,
            "Mean Targets Length": 136.7932,
            "Max Inputs Length": 6293,
            "Max Targets Length": 667,
            "Min Inputs Length": 403,
            "Min Targets Length": 18,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "openreview.net"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/2004.15011"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task668_extreme_abstract_summarization"
        ],
        "Inferred Metadata": {
            "HF Dataset": "allenai/scitldr",
            "HF Config": "Abstract",
            "HF Config License": "Apache License 2.0",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-30",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 2760,
            "HF Likes (September 2023)": 13,
            "PwC Description": "A new multi-target dataset of 5.4K TLDRs over 3.2K papers. SciTLDR contains both author-written and expert-derived TLDRs, where the latter are collected using a novel annotation protocol that produces high-quality summaries while minimizing annotation burden.",
            "S2 Citation Count (September 2023)": 117,
            "GitHub Stars": 726,
            "GitHub Topics": [],
            "Text Topics": [
                "Deep learning",
                "Machine learning",
                "Artificial intelligence",
                "Artificial Intelligence",
                "Deep Learning",
                "Machine Learning",
                "Reinforcement Learning",
                "Neural Networks"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Cachola2020TLDRES,\n author = {Isabel Cachola and Kyle Lo and Arman Cohan and Daniel S. Weld},\n booktitle = {Findings},\n journal = {ArXiv},\n title = {TLDR: Extreme Summarization of Scientific Documents},\n volume = {abs/2004.15011},\n year = {2020}\n}\n"
    },
    "fc-sni-scruples": {
        "Unique Dataset Identifier": "fc-sni-scruples",
        "Dataset Name": "scruples",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.org/data/scruples",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/metaeval/scruples",
        "Paper Title": "Scruples: A Corpus of Community Ethical Judgments on 32, 000 Real-Life Anecdotes",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 221186813,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Ethics Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12067,
            "Mean Inputs Length": 477.6589,
            "Mean Targets Length": 1.5598,
            "Max Inputs Length": 899,
            "Max Targets Length": 11,
            "Min Inputs Length": 265,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/allenai/scruples#data"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task106_scruples_ethical_judgment"
        ],
        "Inferred Metadata": {
            "HF Dataset": "metaeval/scruples",
            "HF Config": "metaeval--scruples",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-08-20",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2023-02-03",
            "HF Downloads (September 2023)": 50,
            "HF Likes (September 2023)": 1,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 63,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Personal relationships",
                "Communication",
                "Parenting",
                "Decision-making",
                "Friendship",
                "Moral values",
                "Ethics",
                "Relationships",
                "Moral philosophy"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Lourie2020ScruplesAC,\n author = {Nicholas Lourie and Ronan Le Bras and Yejin Choi},\n booktitle = {AAAI Conference on Artificial Intelligence},\n journal = {ArXiv},\n title = {Scruples: A Corpus of Community Ethical Judgments on 32, 000 Real-Life Anecdotes},\n volume = {abs/2008.09094},\n year = {2020}\n}\n"
    },
    "fc-sni-semantic_parser_localizer": {
        "Unique Dataset Identifier": "fc-sni-semantic_parser_localizer",
        "Dataset Name": "semantic_parser_localizer",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/stanford-oval/SPL",
        "GitHub URL": "https://github.com/stanford-oval/SPL",
        "Hugging Face URL": "",
        "Paper Title": "Localizing Open-Ontology QA Semantic Parsers in a Day Using Machine Translation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.05106",
        "Semantic Scholar Corpus ID": 222290782,
        "Languages": [
            "German",
            "English"
        ],
        "Task Categories": [
            "Translation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 724,
            "Mean Inputs Length": 1246.5359,
            "Mean Targets Length": 52.2486,
            "Max Inputs Length": 1494,
            "Max Targets Length": 112,
            "Min Inputs Length": 1067,
            "Min Targets Length": 21,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "yelp",
            "hyatt.com",
            "linkedin",
            "imdb.com",
            "goodreads.com",
            "last.fm"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/2020.emnlp-main.481/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task117_spl_translation_en_de"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-10",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 16,
            "GitHub Stars": 5,
            "GitHub Topics": [],
            "Text Topics": [
                "Translation",
                "Restaurants",
                "Language learning"
            ]
        },
        "Derived from Datasets": [
            "Schema2QA dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Moradshahi2020LocalizingQS,\n author = {M. Moradshahi and Giovanni Campagna and Sina J. Semnani and Silei Xu and M. Lam},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {5970-5983},\n title = {Localizing Q&A Semantic Parsers for Any Language in a Day},\n year = {2020}\n}\n"
    },
    "fc-sni-semeval_2018_task1": {
        "Unique Dataset Identifier": "fc-sni-semeval_2018_task1",
        "Dataset Name": "semeval_2018_task1",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://aclanthology.org/S18-1001/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sem_eval_2018_task_1",
        "Paper Title": "SemEval-2018 Task 1: Affect in Tweets",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/S18-1001/",
        "Semantic Scholar Corpus ID": 4941467,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5224,
            "Mean Inputs Length": 425.1283,
            "Mean Targets Length": 7.2954,
            "Max Inputs Length": 694,
            "Max Targets Length": 19,
            "Min Inputs Length": 186,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "National Research Council Canada",
            "The University of Waikato",
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://competitions.codalab.org/competitions/17751#learn_the_details-terms_and_conditions"
            },
            {
                "License": "Custom",
                "License URL": "https://competitions.codalab.org/competitions/17751#learn_the_details-terms_and_conditions"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task397_semeval_2018_task1_tweet_anger_detection"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sem_eval_2018_task_1",
            "HF Config": "subtask5.english",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-06-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3106,
            "HF Likes (September 2023)": 9,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 539,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Social media",
                "Emotions",
                "Sentiment analysis",
                "Media bias",
                "Emotional analysis",
                "Political discourse",
                "Communication"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Mohammad2018SemEval2018T1,\n author = {Saif M. Mohammad and Felipe Bravo-Marquez and Mohammad Salameh and S. Kiritchenko},\n booktitle = {International Workshop on Semantic Evaluation},\n pages = {1-17},\n title = {SemEval-2018 Task 1: Affect in Tweets},\n year = {2018}\n}\n"
    },
    "fc-sni-semeval_2018_task3": {
        "Unique Dataset Identifier": "fc-sni-semeval_2018_task3",
        "Dataset Name": "semeval_2018_task3",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://aclanthology.org/S18-1005.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "SemEval-2018 Task 3: Irony Detection in English Tweets",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/S18-1005/",
        "Semantic Scholar Corpus ID": 44145664,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Irony Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3691,
            "Mean Inputs Length": 652.9339,
            "Mean Targets Length": 4.9309,
            "Max Inputs Length": 1485,
            "Max Targets Length": 16,
            "Min Inputs Length": 453,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter"
        ],
        "Model Generated": [],
        "Creators": [
            "Ghent University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://competitions.codalab.org/competitions/17468#learn_the_details-terms_and_conditions"
            },
            {
                "License": "Unspecified",
                "License URL": "https://competitions.codalab.org/competitions/17468#learn_the_details-terms_and_conditions"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task386_semeval_2018_task3_irony_detection"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-06-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 229,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Social Media Analysis",
                "Social media",
                "Social media analysis",
                "Irony",
                "Language and communication",
                "Natural Language Processing",
                "Irony detection",
                "Irony Detection",
                "Humor and irony",
                "Linguistics"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hee2018SemEval2018T3,\n author = {Cynthia Van Hee and Els Lefever and Veronique Hoste},\n booktitle = {International Workshop on Semantic Evaluation},\n pages = {39-50},\n title = {SemEval-2018 Task 3: Irony Detection in English Tweets},\n year = {2018}\n}\n"
    },
    "fc-sni-semeval_2019_task_10": {
        "Unique Dataset Identifier": "fc-sni-semeval_2019_task_10",
        "Dataset Name": "semeval_2019_task_10",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://aclanthology.org/S19-2153.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "SemEval 2019 Task 10: Math Question Answering",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/S19-2153/",
        "Semantic Scholar Corpus ID": 184482945,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1379,
            "Mean Inputs Length": 1158.7868,
            "Mean Targets Length": 1.6715,
            "Max Inputs Length": 1918,
            "Max Targets Length": 11,
            "Min Inputs Length": 810,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "sat exams"
        ],
        "Model Generated": [],
        "Creators": [
            "Reed College",
            "AI2",
            "University of Washington"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://github.com/allenai/semeval-2019-task-10#terms-and-conditions"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task104_semeval_2019_task10_closed_vocabulary_mathematical_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 23,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Mathematics",
                "Problem-solving",
                "Logical reasoning",
                "Education"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Hopkins2019SemEval2019T1,\n author = {Mark Hopkins and Ronan Le Bras and Cristian Petrescu-Prahova and Gabriel Stanovsky and Hannaneh Hajishirzi and Rik Koncel-Kedziorski},\n booktitle = {International Workshop on Semantic Evaluation},\n pages = {893-899},\n title = {SemEval-2019 Task 10: Math Question Answering},\n year = {2019}\n}\n"
    },
    "fc-sni-semeval_2020_task_7": {
        "Unique Dataset Identifier": "fc-sni-semeval_2020_task_7",
        "Dataset Name": "semeval_2020_task_7",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.cs.rochester.edu/u/nhossain/humicroedit.html",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "“President Vows to Cut Hair”: Dataset and Analysis of Creative Text Editing for Humorous Headlines",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1906.00274",
        "Semantic Scholar Corpus ID": 173990506,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13106,
            "Mean Inputs Length": 573.0698,
            "Mean Targets Length": 7.6476,
            "Max Inputs Length": 864,
            "Max Targets Length": 19,
            "Min Inputs Length": 367,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "reddit"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Rochester",
            "Microsoft"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://competitions.codalab.org/competitions/20970#learn_the_details-terms_and_conditions"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task495_semeval_headline_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 73,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language and Linguistics",
                "News headlines",
                "Language processing",
                "News and media",
                "Humor",
                "Language and linguistics",
                "Humor and Entertainment",
                "Humor classification",
                "Language editing",
                "News and Media"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hossain2019PresidentVT,\n author = {Nabil Hossain and John Krumm and Michael Gamon},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {“President Vows to Cut  Hair”: Dataset and Analysis of Creative Text Editing for Humorous Headlines},\n volume = {abs/1906.00274},\n year = {2019}\n}\n"
    },
    "fc-sni-semeval_2020_task4": {
        "Unique Dataset Identifier": "fc-sni-semeval_2020_task4",
        "Dataset Name": "semeval_2020_task4",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/abs/2007.00236",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "SemEval-2020 Task 4: Commonsense Validation and Explanation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/2020.semeval-1.39/",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Commonsense Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12121,
            "Mean Inputs Length": 466.9714,
            "Mean Targets Length": 6.0952,
            "Max Inputs Length": 810,
            "Max Targets Length": 16,
            "Min Inputs Length": 296,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Zhejiang University",
            "Westlake University",
            "Singapore University of Technology and Design",
            "Sun Yat-Sen University",
            "Queen’s University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://competitions.codalab.org/competitions/21080#learn_the_details-terms_and_conditions"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task291_semeval_2020_task4_commonsense_validation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Critical thinking",
                "Natural language processing",
                "Common sense knowledge",
                "Common sense reasoning",
                "Reasoning",
                "Reasoning and logic",
                "Language understanding",
                "Decision-making",
                "Cooking"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": ""
    },
    "fc-sni-sentence_compression": {
        "Unique Dataset Identifier": "fc-sni-sentence_compression",
        "Dataset Name": "sentence_compression",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/google-research-datasets/sentence-compression",
        "GitHub URL": "https://github.com/google-research-datasets/sentence-compression",
        "Hugging Face URL": "https://huggingface.co/datasets/embedding-data/sentence-compression",
        "Paper Title": "Overcoming the Lack of Parallel Data in Sentence Compression",
        "Papers with Code URL": "https://paperswithcode.com/dataset/sentence-compression",
        "ArXiv URL": "https://aclanthology.org/D13-1155/",
        "Semantic Scholar Corpus ID": 9751546,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Matching"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1971,
            "Mean Inputs Length": 694.3349,
            "Mean Targets Length": 4.1147,
            "Max Inputs Length": 1846,
            "Max Targets Length": 15,
            "Min Inputs Length": 302,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "Google"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://github.com/google-research-datasets/sentence-compression"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1354_sent_comp_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "embedding-data/sentence-compression",
            "HF Config": "embedding-data--sentence-compression",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Custom",
            "PwC License URL": "https://github.com/google-research-datasets/sentence-compression",
            "PwC Date": "",
            "S2 Date": "2013-10-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-07-07",
            "HF Downloads (September 2023)": 575,
            "HF Likes (September 2023)": 9,
            "PwC Description": "Sentence Compression is a dataset where the syntactic trees of the compressions are subtrees of their uncompressed counterparts, and hence where supervised systems which require a structural alignment between the input and output can be successfully trained.",
            "S2 Citation Count (September 2023)": 152,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "News",
                "Language understanding",
                "Text classification",
                "News analysis",
                "Sports",
                "Natural Language Processing",
                "News article analysis"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Filippova2013OvercomingTL,\n author = {Katja Filippova and Y. Altun},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {1481-1491},\n title = {Overcoming the Lack of Parallel Data in Sentence Compression},\n year = {2013}\n}\n"
    },
    "fc-sni-senteval": {
        "Unique Dataset Identifier": "fc-sni-senteval",
        "Dataset Name": "senteval",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/facebookresearch/SentEval/tree/main/data/probing",
        "GitHub URL": "https://github.com/facebookresearch/SentEval/tree/main/data/probing",
        "Hugging Face URL": "",
        "Paper Title": "What you can cram into a single vector: Probing sentence embeddings for linguistic properties",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1803.05449",
        "Semantic Scholar Corpus ID": 24461982,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Linguistic Probing"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12890,
            "Mean Inputs Length": 509.8387,
            "Mean Targets Length": 9.1213,
            "Max Inputs Length": 803,
            "Max Targets Length": 19,
            "Min Inputs Length": 332,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "rottentomatoes.com",
            "amazon.com",
            "imdb.com",
            "crowdsourced",
            "flickr"
        ],
        "Model Generated": [],
        "Creators": [
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/1803.05449"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task428_senteval_inversion"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-05-03",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 688,
            "GitHub Stars": 1969,
            "GitHub Topics": [],
            "Text Topics": [
                "Language processing",
                "Language and linguistics",
                "Grammar and syntax",
                "Grammar",
                "Language analysis",
                "Logic and reasoning",
                "Sentence structure",
                "Linguistics"
            ]
        },
        "Derived from Datasets": [
            "Movie Reviews (Pang and Lee 2005)",
            "product reviews (Hu and Liu, 2004)",
            "Movie reviews (Pang and Lee 2005)",
            "MPQA",
            "TREC",
            "SST",
            "MRPC",
            "SICK",
            "COCO",
            "SNLI"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Conneau2018WhatYC,\n author = {Alexis Conneau and Germán Kruszewski and Guillaume Lample and Loïc Barrault and Marco Baroni},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {2126-2136},\n title = {What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties},\n year = {2018}\n}\n"
    },
    "fc-sni-sherliic": {
        "Unique Dataset Identifier": "fc-sni-sherliic",
        "Dataset Name": "sherliic",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "http://cistern.cis.lmu.de/SherLIiC/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/sherliic",
        "Paper Title": "SherLIiC: A Typed Event-Focused Lexical Inference Benchmark for Evaluating Natural Language Inference",
        "Papers with Code URL": "https://paperswithcode.com/dataset/sherliic",
        "ArXiv URL": "https://arxiv.org/abs/1906.01393",
        "Semantic Scholar Corpus ID": 174797858,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4717,
            "Mean Inputs Length": 482.0513,
            "Mean Targets Length": 3.0095,
            "Max Inputs Length": 800,
            "Max Targets Length": 13,
            "Min Inputs Length": 276,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "freebase",
            "crowdsourced",
            "undisclosed web"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "LMU Munich"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "http://cistern.cis.lmu.de/SherLIiC/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task970_sherliic_causal_relationship"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/sherliic",
            "HF Config": "tasksource--sherliic",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/4.0/",
            "PwC Date": "2019-06-04",
            "S2 Date": "2019-06-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2023-05-25",
            "HF Downloads (September 2023)": 49,
            "HF Likes (September 2023)": 0,
            "PwC Description": "SherLIiC is a testbed for lexical inference in context (LIiC), consisting of 3985 manually annotated inference rule candidates (InfCands), accompanied by (i) ~960k unlabeled InfCands, and (ii) ~190k typed textual relations between Freebase entities extracted from the large entity-linked corpus ClueWeb09. Each InfCand consists of one of these relations, expressed as a lemmatized dependency path, and two argument placeholders, each linked to one or more Freebase types.",
            "S2 Citation Count (September 2023)": 14,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language understanding",
                "Textual entailment",
                "Natural language processing",
                "Logic and reasoning",
                "NLP (Natural Language Processing)",
                "Logic",
                "Textual Entailment",
                "Linguistics",
                "Natural Language Processing"
            ]
        },
        "Derived from Datasets": [
            "ClueWeb09"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Schmitt2019SherLIiCAT,\n author = {Martin Schmitt and Hinrich Schütze},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {902-914},\n title = {SherLIiC: A Typed Event-Focused Lexical Inference Benchmark for Evaluating Natural Language Inference},\n year = {2019}\n}\n"
    },
    "fc-sni-sick": {
        "Unique Dataset Identifier": "fc-sni-sick",
        "Dataset Name": "sick",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/sick",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/sick",
        "Paper Title": "A SICK cure for the evaluation of compositional distributional semantic models",
        "Papers with Code URL": "https://paperswithcode.com/dataset/sick",
        "ArXiv URL": "https://aclanthology.org/L14-1314/",
        "Semantic Scholar Corpus ID": 762228,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Textual Entailment"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3594,
            "Mean Inputs Length": 649.0086,
            "Mean Targets Length": 1.574,
            "Max Inputs Length": 1058,
            "Max Targets Length": 11,
            "Min Inputs Length": 400,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flickr",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Trento",
            "Fondazione Bruno Kessler"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 3.0",
                "License URL": "https://marcobaroni.org/composes/sick.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1612_sick_label_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "sick",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY-NC-SA 3.0",
            "PwC License Name": "CC BY-NC-SA 3.0",
            "PwC License URL": "http://marcobaroni.org/composes/sick.html#:~:text=Creative%20Commons%20Attribution-NonCommercial-ShareAlike%20license",
            "PwC Date": "2014-01-01",
            "S2 Date": "2014-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3224,
            "HF Likes (September 2023)": 5,
            "PwC Description": "The Sentences Involving Compositional Knowledge (SICK) dataset is a dataset for compositional distributional semantics. It includes a large number of sentence pairs that are rich in the lexical, syntactic and semantic phenomena. Each pair of sentences is annotated in two dimensions: relatedness and entailment. The relatedness score ranges from 1 to 5, and Pearson’s r is used for evaluation; the entailment relation is categorical, consisting of entailment, contradiction, and neutral. There are 4439 pairs in the train split, 495 in the trial split used for development and 4906 in the test split. The sentence pairs are generated from image and video caption datasets before being paired up using some algorithm.",
            "S2 Citation Count (September 2023)": 684,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Text classification",
                "Sentiment analysis",
                "Natural language processing",
                "Textual Entailment",
                "Sentiment Analysis",
                "Natural Language Processing",
                "Language understanding",
                "Linguistics",
                "Sentence classification"
            ]
        },
        "Derived from Datasets": [
            "MRPC",
            "MSR-Video Descriptions dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Marelli2014ASC,\n author = {M. Marelli and S. Menini and Marco Baroni and L. Bentivogli and R. Bernardi and Roberto Zamparelli},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {216-223},\n title = {A SICK cure for the evaluation of compositional distributional semantic models},\n year = {2014}\n}\n"
    },
    "fc-sni-smcalflow": {
        "Unique Dataset Identifier": "fc-sni-smcalflow",
        "Dataset Name": "smcalflow",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00333",
        "GitHub URL": "https://github.com/microsoft/task_oriented_dialogue_as_dataflow_synthesis",
        "Hugging Face URL": "https://huggingface.co/datasets/iohadrubin/smcalflow",
        "Paper Title": "Task-Oriented Dialogue as Dataflow Synthesis",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2009.11423",
        "Semantic Scholar Corpus ID": 221822514,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Speaker Identification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7572,
            "Mean Inputs Length": 561.5281,
            "Mean Targets Length": 4.8469,
            "Max Inputs Length": 933,
            "Max Targets Length": 15,
            "Min Inputs Length": 392,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "original"
        ],
        "Model Generated": [],
        "Creators": [
            "Microsoft Semantic Machines"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/microsoft/task_oriented_dialogue_as_dataflow_synthesis"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1599_smcalflow_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "iohadrubin/smcalflow",
            "HF Config": "smcalflow",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-09-01",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2022-01-01",
            "HF Downloads (September 2023)": 567,
            "HF Likes (September 2023)": 2,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 106,
            "GitHub Stars": 289,
            "GitHub Topics": [],
            "Text Topics": [
                "Natural language processing",
                "Event retrieval",
                "Conversation",
                "Language understanding",
                "Scheduling events",
                "Checking the schedule",
                "Retrieving event information",
                "Human-computer interaction",
                "Event information retrieval"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Andreas2020TaskOrientedDA,\n author = {Jacob Andreas and J. Bufe and David Burkett and Charles C. Chen and Joshua Clausman and J. Crawford and Kate Crim and Jordan DeLoach and Leah Dorner and Jason Eisner and Hao Fang and Alan Guo and David Leo Wright Hall and K. Hayes and Kellie Hill and Diana Ho and Wendy Iwaszuk and Smriti Jha and D. Klein and Jayant Krishnamurthy and Theo Lanman and P. Liang and C. H. Lin and Ilya Lintsbakh and Andy McGovern and Aleksandr Nisnevich and Adam Pauls and Dmitrij Petters and Brent Read and D. Roth and Subhro Roy and Jesse Rusak and B. Short and Div Slomin and B. Snyder and Stephon Striplin and Yu Su and Zachary Tellman and Sam Thomson and A. Vorobev and Izabela Witoszko and Jason Wolfe and A. Wray and Yuchen Zhang and Alexander Zotov},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {556-571},\n title = {Task-Oriented Dialogue as Dataflow Synthesis},\n volume = {8},\n year = {2020}\n}\n"
    },
    "fc-sni-sms_spam_collection_v.1": {
        "Unique Dataset Identifier": "fc-sni-sms_spam_collection_v.1",
        "Dataset Name": "sms_spam_collection_v.1",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.dt.fee.unicamp.br/~tiago/smsspamcollection/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Spam Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2093,
            "Mean Inputs Length": 622.9422,
            "Mean Targets Length": 3.785,
            "Max Inputs Length": 1105,
            "Max Targets Length": 14,
            "Min Inputs Length": 390,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task109_smsspamcollection_spamsmsdetection"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Communication",
                "Spam detection",
                "Text message classification",
                "Natural language processing",
                "Text messaging",
                "Text classification",
                "Spam filtering"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-social_iqa": {
        "Unique Dataset Identifier": "fc-sni-social_iqa",
        "Dataset Name": "social_iqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://leaderboard.allenai.org/socialiqa/submissions/get-started",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/social_i_qa",
        "Paper Title": " Social IQa: Commonsense Reasoning about Social Interactions ",
        "Papers with Code URL": "https://paperswithcode.com/dataset/social-iqa",
        "ArXiv URL": "https://arxiv.org/abs/1904.09728",
        "Semantic Scholar Corpus ID": 128296356,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Understanding"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 9681,
            "Mean Inputs Length": 659.125,
            "Mean Targets Length": 4.941,
            "Max Inputs Length": 1090,
            "Max Targets Length": 15,
            "Min Inputs Length": 378,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced (amt)"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "Paul G. Allen School of Computer Science & Engineering"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://www.semanticscholar.org/paper/Social-IQA%3A-Commonsense-Reasoning-about-Social-Sap-Rashkin/421cb75cc91e8e5683d41ee6a918121aedf6d24d"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task384_socialiqa_question_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "social_i_qa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2019-04-22",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 36880,
            "HF Likes (September 2023)": 4,
            "PwC Description": "Social Interaction QA (SIQA) is a question-answering benchmark for testing social commonsense intelligence. Contrary to many prior benchmarks that focus on physical or taxonomic knowledge, Social IQa focuses on reasoning about people’s actions and their social implications. For example, given an action like \"Jesse saw a concert\" and a question like \"Why did Jesse do this?\", humans can easily infer that Jesse wanted \"to see their favorite performer\" or \"to enjoy the music\", and not \"to see what's happening inside\" or \"to see if it works\". The actions in Social IQa span a wide variety of social situations, and answer candidates contain both human-curated answers and adversarially-filtered machine-generated candidates. Social IQa contains over 37,000 QA pairs for evaluating models’ abilities to reason about the social implications of everyday events and situations.",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Contextual understanding",
                "Dialog analysis",
                "Communication",
                "Social situations",
                "Commonsense reasoning",
                "Language understanding",
                "Social interactions",
                "Contextual reasoning"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": ""
    },
    "fc-sni-splash": {
        "Unique Dataset Identifier": "fc-sni-splash",
        "Dataset Name": "splash",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/pdf/2005.02539.pdf",
        "GitHub URL": "https://github.com/MSR-LIT/Splash",
        "Hugging Face URL": "",
        "Paper Title": "Speak to your Parser: Interactive Text-to-SQL with Natural Language Feedback",
        "Papers with Code URL": "https://paperswithcode.com/dataset/splash",
        "ArXiv URL": "https://arxiv.org/abs/2005.02539",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text to Code"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4214,
            "Mean Inputs Length": 2753.1728,
            "Mean Targets Length": 120.3828,
            "Max Inputs Length": 4432,
            "Max Targets Length": 523,
            "Min Inputs Length": 2362,
            "Min Targets Length": 20,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [
            "University of Maryland",
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/MSR-LIT/Splash"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task076_splash_correcting_sql_mistake"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "A dataset of utterances, incorrect SQL interpretations and the corresponding natural language feedback.",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Database management",
                "SQL query optimization",
                "Troubleshooting SQL queries",
                "SQL query correction",
                "Error handling in SQL queries",
                "Data retrieval and sorting",
                "Data retrieval and filtering",
                "Data analysis",
                "SQL query troubleshooting"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-spolin": {
        "Unique Dataset Identifier": "fc-sni-spolin",
        "Dataset Name": "spolin",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://justin-cho.com/spolin",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/wise-east/spolin",
        "Paper Title": "Grounding Conversations with Improvised Dialogues",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2004.09544",
        "Semantic Scholar Corpus ID": 216036372,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Dialogue Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12737,
            "Mean Inputs Length": 1057.9772,
            "Mean Targets Length": 78.4687,
            "Max Inputs Length": 1712,
            "Max Targets Length": 472,
            "Min Inputs Length": 784,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "spontaneanation podcast"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://justin-cho.com/spolin#License"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task360_spolin_yesand_response_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wise-east/spolin",
            "HF Config": "wise-east--spolin",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-20",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-06-08",
            "HF Downloads (September 2023)": 101,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 21,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Communication and dialogue",
                "Communication",
                "Collaborative storytelling",
                "Collaborative problem-solving",
                "Collaboration",
                "Creative thinking",
                "Communication skills"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Cho2020GroundingCW,\n author = {Hyundong Justin Cho and Jonathan May},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {2398-2413},\n title = {Grounding Conversations with Improvised Dialogues},\n year = {2020}\n}\n"
    },
    "fc-sni-sqac": {
        "Unique Dataset Identifier": "fc-sni-sqac",
        "Dataset Name": "sqac",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/BSC-TeMU/SQAC",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/BSC-TeMU/SQAC",
        "Paper Title": "MarIA: Spanish Language Models",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2107.07253",
        "Semantic Scholar Corpus ID": 252847802,
        "Languages": [
            "Spanish",
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13113,
            "Mean Inputs Length": 2694.0258,
            "Mean Targets Length": 47.8129,
            "Max Inputs Length": 17840,
            "Max Targets Length": 399,
            "Min Inputs Length": 450,
            "Min Targets Length": 10,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "encyclopedic articles",
            "wikinews"
        ],
        "Model Generated": [],
        "Creators": [
            "Barcelona Supercomputing Center"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 3.0",
                "License URL": "https://huggingface.co/datasets/BSC-LT/SQAC"
            },
            {
                "License": "CC BY 2.5",
                "License URL": "https://huggingface.co/datasets/BSC-LT/SQAC"
            },
            {
                "License": "CC BY 4.0",
                "License URL": "https://huggingface.co/datasets/BSC-LT/SQAC"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1334_sqac_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "BSC-TeMU/SQAC",
            "HF Config": "SQAC",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-07-15",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2021-08-10",
            "HF Downloads (September 2023)": 515,
            "HF Likes (September 2023)": 5,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 49,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Japanese culture",
                "War",
                "Politics",
                "Cultural understanding",
                "History",
                "Language learning",
                "Geography",
                "Translation",
                "Religion",
                "Culture"
            ]
        },
        "Derived from Datasets": [
            "Spanish section of the AnCora corpus"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Gutiérrez-Fandiño2021MarIASL,\n author = {Asier Gutiérrez-Fandiño and Jordi Armengol-Estap'e and Marc Pàmies and Joan Llop-Palao and Joaquín Silveira-Ocampo and C. Carrino and Carme Armentano-Oller and C. R. Penagos and Aitor Gonzalez-Agirre and Marta Villegas},\n booktitle = {Proces. del Leng. Natural},\n journal = {Proces. del Leng. Natural},\n pages = {39-60},\n title = {MarIA: Spanish Language Models},\n volume = {68},\n year = {2021}\n}\n"
    },
    "fc-sni-squad_1.1": {
        "Unique Dataset Identifier": "fc-sni-squad_1.1",
        "Dataset Name": "squad_1.1",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://rajpurkar.github.io/SQuAD-explorer/",
        "GitHub URL": "https://rajpurkar.github.io/SQuAD-explorer/",
        "Hugging Face URL": "https://huggingface.co/datasets/squad",
        "Paper Title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text",
        "Papers with Code URL": "https://paperswithcode.com/dataset/squad",
        "ArXiv URL": "https://arxiv.org/abs/1606.05250",
        "Semantic Scholar Corpus ID": 11816014,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12925,
            "Mean Inputs Length": 1973.5984,
            "Mean Targets Length": 59.0622,
            "Max Inputs Length": 6510,
            "Max Targets Length": 256,
            "Min Inputs Length": 623,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://rajpurkar.github.io/SQuAD-explorer/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task074_squad1.1_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "squad",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/4.0/",
            "PwC Date": "2016-01-01",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 153870,
            "HF Likes (September 2023)": 128,
            "PwC Description": "The Stanford Question Answering Dataset (SQuAD) is a collection of question-answer pairs derived from Wikipedia articles. In SQuAD, the correct answers of questions can be any sequence of tokens in the given text. Because the questions and answers are produced by humans through crowdsourcing, it is more diverse than some other question-answering datasets. SQuAD 1.1 contains 107,785 question-answer pairs on 536 articles. SQuAD2.0 (open-domain SQuAD, SQuAD-Open), the latest version, combines the 100,000 questions in SQuAD1.1 with over 50,000 un-answerable questions written adversarially by crowdworkers in forms that are similar to the answerable ones.",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Rajpurkar2016SQuAD1Q,\n author = {Pranav Rajpurkar and Jian Zhang and Konstantin Lopyrev and Percy Liang},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {2383-2392},\n title = {SQuAD: 100,000+ Questions for Machine Comprehension of Text},\n year = {2016}\n}\n"
    },
    "fc-sni-squad2.0": {
        "Unique Dataset Identifier": "fc-sni-squad2.0",
        "Dataset Name": "squad2.0",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/pdf/1806.03822.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/squad_v2",
        "Paper Title": "Know What You Don’t Know: Unanswerable Questions for SQuAD",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1806.03822",
        "Semantic Scholar Corpus ID": 47018994,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12994,
            "Mean Inputs Length": 2241.8296,
            "Mean Targets Length": 56.0459,
            "Max Inputs Length": 7048,
            "Max Targets Length": 178,
            "Min Inputs Length": 912,
            "Min Targets Length": 11,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced (daemo)"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://rajpurkar.github.io/SQuAD-explorer/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task348_squad2.0_unanswerable_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 8690810,
            "HF Likes (September 2023)": 65,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Rajpurkar2018KnowWY,\n author = {Pranav Rajpurkar and Robin Jia and Percy Liang},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Know What You Don’t Know: Unanswerable Questions for SQuAD},\n volume = {abs/1806.03822},\n year = {2018}\n}\n"
    },
    "fc-sni-starcon": {
        "Unique Dataset Identifier": "fc-sni-starcon",
        "Dataset Name": "starcon",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://aclanthology.org/2020.emnlp-main.4/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/starcon",
        "Paper Title": "Unsupervised stance detection for arguments from consequences",
        "Papers with Code URL": "",
        "ArXiv URL": "https://aclanthology.org/2020.emnlp-main.4/",
        "Semantic Scholar Corpus ID": 226262286,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Stance Detection"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3014,
            "Mean Inputs Length": 425.4038,
            "Mean Targets Length": 7.99,
            "Max Inputs Length": 772,
            "Max Targets Length": 18,
            "Min Inputs Length": 229,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "debatepedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Mannheim"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task209_stancedetection_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/starcon",
            "HF Config": "tasksource--starcon",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2023-05-14",
            "HF Downloads (September 2023)": 56,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 17,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Artificial intelligence",
                "Technology",
                "Energy production",
                "Environmental issues",
                "Government policies and corruption",
                "Infrastructure development",
                "International relations"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Kobbe2020UnsupervisedSD,\n author = {J. Kobbe and Ioana Hulpus and H. Stuckenschmidt},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {50-60},\n title = {Unsupervised Stance Detection for Arguments from Consequences},\n year = {2020}\n}\n"
    },
    "fc-sni-stereoset": {
        "Unique Dataset Identifier": "fc-sni-stereoset",
        "Dataset Name": "stereoset",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://stereoset.mit.edu",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/stereoset",
        "Paper Title": "StereoSet: Measuring stereotypical bias in pretrained language models",
        "Papers with Code URL": "https://paperswithcode.com/dataset/stereoset",
        "ArXiv URL": "https://arxiv.org/abs/2004.09456",
        "Semantic Scholar Corpus ID": 215828184,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Fill in The Blank"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2034,
            "Mean Inputs Length": 464.1234,
            "Mean Targets Length": 7.267,
            "Max Inputs Length": 778,
            "Max Targets Length": 22,
            "Min Inputs Length": 325,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikidata",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Massachusetts Institute of Technology",
            "Intel AI",
            "Facebook AI Research",
            "McGill University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/2004.09456.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task277_stereoset_sentence_generation_stereotype"
        ],
        "Inferred Metadata": {
            "HF Dataset": "stereoset",
            "HF Config": "intersentence",
            "HF Config License": "CC BY-SA 4.0",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://github.com/moinnadeem/StereoSet/blob/master/LICENSE.md",
            "PwC Date": "",
            "S2 Date": "2020-04-20",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1588,
            "HF Likes (September 2023)": 7,
            "PwC Description": "A large-scale natural dataset in English to measure stereotypical biases in four domains: gender, profession, race, and religion.",
            "S2 Citation Count (September 2023)": 414,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Social issues",
                "Cultural stereotypes",
                "Cultural beliefs",
                "Social psychology",
                "Stereotypes",
                "Prejudice and discrimination",
                "Language and communication"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Nadeem2020StereoSetMS,\n author = {Moin Nadeem and Anna Bethke and Siva Reddy},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {5356-5371},\n title = {StereoSet: Measuring stereotypical bias in pretrained language models},\n year = {2020}\n}\n"
    },
    "fc-sni-storycommonsense": {
        "Unique Dataset Identifier": "fc-sni-storycommonsense",
        "Dataset Name": "storycommonsense",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://uwnlp.github.io/storycommonsense/",
        "GitHub URL": "https://uwnlp.github.io/storycommonsense/",
        "Hugging Face URL": "",
        "Paper Title": "Modeling Naive Psychology of Characters in Simple Commonsense Stories",
        "Papers with Code URL": "https://paperswithcode.com/dataset/story-commonsense",
        "ArXiv URL": "https://arxiv.org/abs/1805.06533",
        "Semantic Scholar Corpus ID": 21689288,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Information Extraction"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12961,
            "Mean Inputs Length": 730.5488,
            "Mean Targets Length": 16.6641,
            "Max Inputs Length": 1399,
            "Max Targets Length": 80,
            "Min Inputs Length": 329,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "AI2",
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://uwnlp.github.io/storycommonsense/data/rashkin2018modeling.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task292_storycommonsense_character_text_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2018-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "Story Commonsense is a new large-scale dataset with rich low-level annotations and establishes baseline performance on several new tasks, suggesting avenues for future research.",
            "S2 Citation Count (September 2023)": 81,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Story analysis",
                "Language understanding",
                "Comprehension",
                "Text comprehension",
                "Character analysis",
                "Character identification",
                "Text analysis"
            ]
        },
        "Derived from Datasets": [
            "StoryCloze"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Rashkin2018ModelingNP,\n author = {Hannah Rashkin and Antoine Bosselut and Maarten Sap and Kevin Knight and Yejin Choi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Modeling Naive Psychology of Characters in Simple Commonsense Stories},\n volume = {abs/1805.06533},\n year = {2018}\n}\n"
    },
    "fc-sni-strategyqa": {
        "Unique Dataset Identifier": "fc-sni-strategyqa",
        "Dataset Name": "strategyqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/eladsegal/strategyqa",
        "GitHub URL": "https://github.com/eladsegal/strategyqa",
        "Hugging Face URL": "https://huggingface.co/datasets/wics/strategy-qa",
        "Paper Title": "Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies",
        "Papers with Code URL": "https://paperswithcode.com/dataset/strategyqa",
        "ArXiv URL": "https://arxiv.org/abs/2101.02235",
        "Semantic Scholar Corpus ID": 230799347,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4698,
            "Mean Inputs Length": 1385.5739,
            "Mean Targets Length": 58.2863,
            "Max Inputs Length": 1819,
            "Max Targets Length": 165,
            "Min Inputs Length": 1141,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Tel Aviv University",
            "AI2",
            "University of Pennsylvania"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/2101.02235"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task167_strategyqa_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wics/strategy-qa",
            "HF Config": "strategyQA",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2021-01-06",
            "S2 Date": "2021-01-06",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2023-05-10",
            "HF Downloads (September 2023)": 8039,
            "HF Likes (September 2023)": 1,
            "PwC Description": "StrategyQA is a question answering benchmark where the required reasoning steps are implicit in the question, and should be inferred using a strategy.\nIt includes 2,780 examples, each consisting of a strategy question, its decomposition, and evidence paragraphs.\nQuestions in StrategyQA are short, topic-diverse, and cover a wide range of strategies.",
            "S2 Citation Count (September 2023)": 194,
            "GitHub Stars": 39,
            "GitHub Topics": [
                "dataset",
                "open-domain-qa",
                "question-answering"
            ],
            "Text Topics": [
                "Entertainment",
                "Animal behavior",
                "Food and cooking",
                "Sports",
                "Geography",
                "History",
                "Trivia",
                "General knowledge"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Geva2021DidAU,\n author = {Mor Geva and Daniel Khashabi and Elad Segal and Tushar Khot and D. Roth and Jonathan Berant},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {346-361},\n title = {Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies},\n volume = {9},\n year = {2021}\n}\n"
    },
    "fc-sni-sts_b": {
        "Unique Dataset Identifier": "fc-sni-sts_b",
        "Dataset Name": "sts_b",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://dl.fbaipublicfiles.com/glue/data/STS-B.zip",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/pietrolesci/glue_diagnostics",
        "Paper Title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
        "Papers with Code URL": "https://paperswithcode.com/dataset/glue",
        "ArXiv URL": "https://arxiv.org/abs/1708.00055",
        "Semantic Scholar Corpus ID": 5034059,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Matching"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6024,
            "Mean Inputs Length": 820.577,
            "Mean Targets Length": 1.5684,
            "Max Inputs Length": 1497,
            "Max Targets Length": 11,
            "Min Inputs Length": 589,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "flickr"
        ],
        "Model Generated": [
            "Google Translate"
        ],
        "Creators": [
            "New York University",
            "Paul G. Allen School of Computer Science & Engineering",
            "DeepMind"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://dl.fbaipublicfiles.com/glue/data/STS-B.zip"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1347_glue_sts-b_similarity_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pietrolesci/glue_diagnostics",
            "HF Config": "pietrolesci--glue_diagnostics",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Various",
            "PwC License URL": "https://gluebenchmark.com/faq",
            "PwC Date": "2019-01-01",
            "S2 Date": "2018-04-20",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-04-21",
            "HF Downloads (September 2023)": 52,
            "HF Likes (September 2023)": 0,
            "PwC Description": "General Language Understanding Evaluation (GLUE) benchmark is a collection of nine natural language understanding tasks, including single-sentence tasks CoLA and SST-2, similarity and paraphrasing tasks MRPC, STS-B and QQP, and natural language inference tasks MNLI, QNLI, RTE and WNLI.",
            "S2 Citation Count (September 2023)": 4367,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [
            "SNLI"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Wang2018GLUEAM,\n author = {Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},\n booktitle = {BlackboxNLP@EMNLP},\n pages = {353-355},\n title = {GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n year = {2018}\n}\n"
    },
    "fc-sni-subjqa": {
        "Unique Dataset Identifier": "fc-sni-subjqa",
        "Dataset Name": "subjqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/megagonlabs/SubjQA",
        "GitHub URL": "https://github.com/megagonlabs/SubjQA",
        "Hugging Face URL": "https://huggingface.co/datasets/subjqa",
        "Paper Title": "SubjQA: A Dataset for Subjectivity and Review Comprehension",
        "Papers with Code URL": "https://paperswithcode.com/dataset/subjqa",
        "ArXiv URL": "https://arxiv.org/abs/2004.14283",
        "Semantic Scholar Corpus ID": 216642239,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1319,
            "Mean Inputs Length": 2418.2077,
            "Mean Targets Length": 40.5201,
            "Max Inputs Length": 18626,
            "Max Targets Length": 293,
            "Min Inputs Length": 613,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "tripadvisor",
            "yelp",
            "amazon.com"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Copenhagen",
            "Megagon Labs",
            "Aalborg University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/megagonlabs/SubjQA"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task144_subjqa_question_answering"
        ],
        "Inferred Metadata": {
            "HF Dataset": "subjqa",
            "HF Config": "books",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-04-29",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 6035,
            "HF Likes (September 2023)": 6,
            "PwC Description": "SubjQA is a question answering dataset that focuses on subjective (as opposed to factual) questions and answers. The dataset consists of roughly 10,000 questions over reviews from 6 different domains: books, movies, grocery, electronics, TripAdvisor (i.e. hotels), and restaurants. Each question is paired with a review and a span is highlighted as the answer to the question (with some questions having no answer). Moreover, both questions and answer spans are assigned a subjectivity label by annotators. Questions such as \"How much does this product weigh?\" is a factual question (i.e., low subjectivity), while \"Is this easy to use?\" is a subjective question (i.e., high subjectivity).",
            "S2 Citation Count (September 2023)": 26,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Book review",
                "Accommodation",
                "Movie review",
                "Travel",
                "Food",
                "Food and beverages",
                "Technology",
                "Entertainment"
            ]
        },
        "Derived from Datasets": [
            "Wang et al. 2010",
            "McAuley and Yang 2016"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Bjerva2020SubjQAAD,\n author = {Johannes Bjerva and Nikita Bhutani and Behzad Golshan and W. Tan and Isabelle Augenstein},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {5480-5494},\n title = {SubjQA: A Dataset for Subjectivity and Review Comprehension},\n year = {2020}\n}\n"
    },
    "fc-sni-svamp": {
        "Unique Dataset Identifier": "fc-sni-svamp",
        "Dataset Name": "svamp",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/arkilpatel/SVAMP",
        "GitHub URL": "https://github.com/arkilpatel/SVAMP",
        "Hugging Face URL": "",
        "Paper Title": "Are NLP Models really able to Solve Simple Math Word Problems?",
        "Papers with Code URL": "https://paperswithcode.com/dataset/svamp",
        "ArXiv URL": "https://arxiv.org/abs/2103.07191",
        "Semantic Scholar Corpus ID": 232223322,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1039,
            "Mean Inputs Length": 570.3022,
            "Mean Targets Length": 2.2166,
            "Max Inputs Length": 1123,
            "Max Targets Length": 16,
            "Min Inputs Length": 303,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/arkilpatel/SVAMP"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task751_svamp_subtraction_question_answering"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "MIT License",
            "PwC License URL": "",
            "PwC Date": "2021-03-12",
            "S2 Date": "2021-03-11",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "A challenge set for elementary-level Math Word Problems (MWP). An MWP consists of a short Natural Language narrative that describes a state of the world and poses a question about some unknown quantities.\n\nThe examples in SVAMP test a model across different aspects of solving MWPs: 1) Is the model question sensitive? 2) Does the model have robust reasoning ability? 3) Is it invariant to structural alterations?",
            "S2 Citation Count (September 2023)": 195,
            "GitHub Stars": 87,
            "GitHub Topics": [],
            "Text Topics": [
                "Logic",
                "Measurement",
                "Daily routine",
                "Math",
                "Arithmetic",
                "Comparison",
                "Problem-solving",
                "Education"
            ]
        },
        "Derived from Datasets": [
            "ASDiv-A dataset (Miao et al 2020)"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Patel2021AreNM,\n author = {Arkil Patel and S. Bhattamishra and Navin Goyal},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {2080-2094},\n title = {Are NLP Models really able to Solve Simple Math Word Problems?},\n year = {2021}\n}\n"
    },
    "fc-sni-swag": {
        "Unique Dataset Identifier": "fc-sni-swag",
        "Dataset Name": "swag",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/rowanz/swagaf/tree/master/data",
        "GitHub URL": "https://github.com/rowanz/swagaf/tree/master/data",
        "Hugging Face URL": "https://huggingface.co/datasets/swag",
        "Paper Title": "SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference",
        "Papers with Code URL": "https://paperswithcode.com/dataset/svamp",
        "ArXiv URL": "https://arxiv.org/abs/1808.05326",
        "Semantic Scholar Corpus ID": 52019251,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Fill in The Blank"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13095,
            "Mean Inputs Length": 387.332,
            "Mean Targets Length": 45.8082,
            "Max Inputs Length": 880,
            "Max Targets Length": 135,
            "Min Inputs Length": 161,
            "Min Targets Length": 9,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "youtube",
            "movies"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/1808.05326"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task453_swag_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "swag",
            "HF Config": "full",
            "HF Config License": "Unspecified",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "MIT License",
            "PwC License URL": "",
            "PwC Date": "2021-03-12",
            "S2 Date": "2018-08-16",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 8167,
            "HF Likes (September 2023)": 10,
            "PwC Description": "A challenge set for elementary-level Math Word Problems (MWP). An MWP consists of a short Natural Language narrative that describes a state of the world and poses a question about some unknown quantities.\n\nThe examples in SVAMP test a model across different aspects of solving MWPs: 1) Is the model question sensitive? 2) Does the model have robust reasoning ability? 3) Is it invariant to structural alterations?",
            "S2 Citation Count (September 2023)": 583,
            "GitHub Stars": 179,
            "GitHub Topics": [
                "emnlp-2018",
                "grounded-language-learning",
                "natural-language-inference",
                "natural-language-processing"
            ],
            "Text Topics": [
                "Safety equipment",
                "Safety precautions",
                "Water sports",
                "Communication",
                "Clothing and fashion",
                "Outdoor activities",
                "Social interaction",
                "Daily routine",
                "Sports",
                "Adventure"
            ]
        },
        "Derived from Datasets": [
            "ActivityNet Captions dataset",
            "Large Scale Movie Description Challenge (LSMDC) dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zellers2018SWAGAL,\n author = {Rowan Zellers and Yonatan Bisk and Roy Schwartz and Yejin Choi},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {93-104},\n title = {SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference},\n year = {2018}\n}\n"
    },
    "fc-sni-tecla": {
        "Unique Dataset Identifier": "fc-sni-tecla",
        "Dataset Name": "tecla",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/BSC-TeMU/tecla",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/BSC-TeMU/tecla",
        "Paper Title": "Are Multilingual Models the Best Choice for Moderately Under-resourced Languages? A Comprehensive Assessment for Catalan",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2107.07903",
        "Semantic Scholar Corpus ID": 236034103,
        "Languages": [
            "Catalan",
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1890,
            "Mean Inputs Length": 4983.6265,
            "Mean Targets Length": 8.3958,
            "Max Inputs Length": 16509,
            "Max Targets Length": 24,
            "Min Inputs Length": 963,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "acn.cat",
            "wikipedia.org",
            "opus dogc corpus",
            "catalan open subtitles",
            "cawac corpus",
            "catalan government crawling"
        ],
        "Model Generated": [],
        "Creators": [
            "Barcelona Supercomputing Center"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-ND 4.0",
                "License URL": "https://huggingface.co/datasets/BSC-LT/tecla#source-data"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1588_tecla_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "BSC-TeMU/tecla",
            "HF Config": "tecla",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-07-16",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2021-08-30",
            "HF Downloads (September 2023)": 450,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 23,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Politics",
                "Culture",
                "Language and Linguistics",
                "Tourism",
                "Text Classification",
                "Catalan Culture and Society",
                "Catalan language and culture",
                "Government"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Armengol-Estap'e2021AreMM,\n author = {Jordi Armengol-Estap'e and C. Carrino and Carlos Rodríguez-Penagos and Ona de Gibert Bonet and Carme Armentano-Oller and Aitor Gonzalez-Agirre and Maite Melero and Marta Villegas},\n booktitle = {Findings},\n pages = {4933-4946},\n title = {Are Multilingual Models the Best Choice for Moderately Under-resourced Languages? A Comprehensive Assessment for Catalan},\n year = {2021}\n}\n"
    },
    "fc-sni-tellmewhy": {
        "Unique Dataset Identifier": "fc-sni-tellmewhy",
        "Dataset Name": "tellmewhy",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/StonyBrookNLP/tellmewhy",
        "GitHub URL": "https://github.com/StonyBrookNLP/tellmewhy",
        "Hugging Face URL": "https://huggingface.co/datasets/StonyBrookNLP/tellmewhy",
        "Paper Title": "TellMeWhy: A Dataset for Answering Why-Questions in Narratives",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2106.06132",
        "Semantic Scholar Corpus ID": 235417184,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Answerability Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6942,
            "Mean Inputs Length": 836.9784,
            "Mean Targets Length": 11.7515,
            "Max Inputs Length": 1463,
            "Max Targets Length": 24,
            "Min Inputs Length": 423,
            "Min Targets Length": 10,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Stony Brook University",
            "US Naval Academy",
            "The University of Texas at Austin",
            "Stony Brook University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/StonyBrookNLP/tellmewhy#building-the-dataset"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task290_tellmewhy_question_answerability"
        ],
        "Inferred Metadata": {
            "HF Dataset": "StonyBrookNLP/tellmewhy",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-06-11",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-09-21",
            "HF Downloads (September 2023)": 75,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 19,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Question evaluation",
                "Reading comprehension",
                "Story analysis",
                "Question answering"
            ]
        },
        "Derived from Datasets": [
            "ROCStories"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Lal2021TellMeWhyAD,\n author = {Yash Kumar Lal and Nathanael Chambers and R. Mooney and Niranjan Balasubramanian},\n booktitle = {Findings},\n pages = {596-610},\n title = {TellMeWhy: A Dataset for Answering Why-Questions in Narratives},\n year = {2021}\n}\n"
    },
    "fc-sni-timetravel": {
        "Unique Dataset Identifier": "fc-sni-timetravel",
        "Dataset Name": "timetravel",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/qkaren/Counterfactual-StoryRW",
        "GitHub URL": "https://github.com/qkaren/Counterfactual-StoryRW",
        "Hugging Face URL": "https://huggingface.co/datasets/wza/TimeTravel",
        "Paper Title": "Counterfactual Story Reasoning and Generation",
        "Papers with Code URL": "https://paperswithcode.com/dataset/timetravel",
        "ArXiv URL": "https://arxiv.org/abs/1909.04076",
        "Semantic Scholar Corpus ID": 202542404,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Coherence Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12834,
            "Mean Inputs Length": 1215.5474,
            "Mean Targets Length": 8.5796,
            "Max Inputs Length": 1967,
            "Max Targets Length": 18,
            "Min Inputs Length": 698,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/1909.04076"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task065_timetravel_consistent_sentence_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wza/TimeTravel",
            "HF Config": "supervised_large",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-09-09",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2022-04-27",
            "HF Downloads (September 2023)": 33,
            "HF Likes (September 2023)": 0,
            "PwC Description": "TimeTravel contains 29,849 counterfactual rewritings, each with the original story, a counterfactual event, and human-generated revision of the original story compatible with the counterfactual event.",
            "S2 Citation Count (September 2023)": 92,
            "GitHub Stars": 97,
            "GitHub Topics": [],
            "Text Topics": [
                "Critical thinking",
                "Reading comprehension",
                "Short stories",
                "Storytelling",
                "Short story analysis",
                "Logical reasoning",
                "Language proficiency",
                "Narrative structure"
            ]
        },
        "Derived from Datasets": [
            "ROCStories corpus"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Qin2019CounterfactualSR,\n author = {Lianhui Qin and Antoine Bosselut and Ari Holtzman and Chandra Bhagavatula and Elizabeth Clark and Yejin Choi},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {5042-5052},\n title = {Counterfactual Story Reasoning and Generation},\n year = {2019}\n}\n"
    },
    "fc-sni-tom_qa": {
        "Unique Dataset Identifier": "fc-sni-tom_qa",
        "Dataset Name": "tom_qa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/kayburns/tom-qa-dataset",
        "GitHub URL": "https://github.com/kayburns/tom-qa-dataset",
        "Hugging Face URL": "",
        "Paper Title": "Evaluating Theory of Mind in Question Answering",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tom-qa",
        "ArXiv URL": "https://arxiv.org/abs/1808.09352",
        "Semantic Scholar Corpus ID": 52115700,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12956,
            "Mean Inputs Length": 974.7401,
            "Mean Targets Length": 12.8045,
            "Max Inputs Length": 1476,
            "Max Targets Length": 30,
            "Min Inputs Length": 609,
            "Min Targets Length": 7,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "templates"
        ],
        "Model Generated": [
            "templates"
        ],
        "Creators": [
            "DeepMind",
            "UC Berkeley",
            "Princeton University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/1808.09352"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task151_tomqa_find_location_easy_clean"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2018-08-28",
            "S2 Date": "2018-08-28",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "The data consists of a set of 3 task types and 4 question types, creating 12 total scenarios. The tasks are grouped into stories, which are denoted by the numbering at the start of each line.",
            "S2 Citation Count (September 2023)": 47,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Storytelling",
                "Belief and reality",
                "Perception and cognition",
                "Critical thinking",
                "Story analysis",
                "Reading comprehension",
                "Perception and truth",
                "Cognitive dissonance"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Nematzadeh2018EvaluatingTO,\n author = {Aida Nematzadeh and Kaylee Burns and Erin Grant and A. Gopnik and T. Griffiths},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Evaluating Theory of Mind in Question Answering},\n volume = {abs/1808.09352},\n year = {2018}\n}\n"
    },
    "fc-sni-torque": {
        "Unique Dataset Identifier": "fc-sni-torque",
        "Dataset Name": "torque",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allennlp.org/torque.html",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "TORQUE: A Reading Comprehension Dataset of Temporal Ordering Questions",
        "Papers with Code URL": "https://paperswithcode.com/dataset/torque",
        "ArXiv URL": "https://arxiv.org/abs/2005.00242",
        "Semantic Scholar Corpus ID": 218470560,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Information Extraction"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4544,
            "Mean Inputs Length": 1125.3332,
            "Mean Targets Length": 6.6017,
            "Max Inputs Length": 2085,
            "Max Targets Length": 22,
            "Min Inputs Length": 627,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "abc",
            "cnn.com",
            "pri",
            "voa",
            "ap news",
            "nytmes",
            "wsj",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2",
            "Hooray Data Co.",
            "University of Southern California",
            "University of Pennsylvania"
        ],
        "Licenses": [
            {
                "License": "Apache License 2.0",
                "License URL": "https://github.com/qiangning/TORQUE-dataset/blob/main/LICENSE"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task388_torque_token_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "Torque is an English reading comprehension benchmark built on 3.2k news snippets with 21k human-generated questions querying temporal relationships.",
            "S2 Citation Count (September 2023)": 70,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Reading Comprehension",
                "Reading comprehension",
                "Language processing",
                "Language understanding",
                "Event identification",
                "Education",
                "Text analysis",
                "Critical thinking",
                "Language learning",
                "Language and Linguistics"
            ]
        },
        "Derived from Datasets": [
            "TempEval3"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Ning2020TORQUEAR,\n author = {Qiang Ning and Hao Wu and Rujun Han and Nanyun Peng and Matt Gardner and D. Roth},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {1158-1172},\n title = {TORQUE: A Reading Comprehension Dataset of Temporal Ordering Questions},\n year = {2020}\n}\n"
    },
    "fc-sni-trianglecopa": {
        "Unique Dataset Identifier": "fc-sni-trianglecopa",
        "Dataset Name": "trianglecopa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/asgordon/TriangleCOPA",
        "GitHub URL": "https://github.com/asgordon/TriangleCOPA",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 208,
            "Mean Inputs Length": 653.6587,
            "Mean Targets Length": 31.6346,
            "Max Inputs Length": 1006,
            "Max Targets Length": 70,
            "Min Inputs Length": 402,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/asgordon/TriangleCOPA"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1665_trainglecopa_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Problem-solving",
                "Language and communication",
                "Mathematics",
                "Geometry",
                "Storytelling and narrative",
                "Reasoning",
                "Logic"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-triviaqa": {
        "Unique Dataset Identifier": "fc-sni-triviaqa",
        "Dataset Name": "triviaqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/abs/1705.03551",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/trivia_qa",
        "Paper Title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
        "Papers with Code URL": "https://paperswithcode.com/dataset/triviaqa",
        "ArXiv URL": "https://arxiv.org/abs/1705.03551",
        "Semantic Scholar Corpus ID": 26501419,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 233,
            "Mean Inputs Length": 331.073,
            "Mean Targets Length": 9.9399,
            "Max Inputs Length": 766,
            "Max Targets Length": 31,
            "Min Inputs Length": 131,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "undisclosed web"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/1705.03551"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1564_triviaqa_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "trivia_qa",
            "HF Config": "rc",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Unspecified",
            "PwC License URL": "http://nlp.cs.washington.edu/triviaqa/#:~:text=copyright",
            "PwC Date": "2017-01-01",
            "S2 Date": "2017-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 93735,
            "HF Likes (September 2023)": 23,
            "PwC Description": "TriviaQA is a realistic text-based question answering dataset which includes 950K question-answer pairs from 662K documents collected from Wikipedia and the web. This dataset is more challenging than standard QA benchmark datasets such as Stanford Question Answering Dataset (SQuAD), as the answers for a question may not be directly obtained by span prediction and the context is very long. TriviaQA dataset consists of both human-verified and machine-generated QA subsets.",
            "S2 Citation Count (September 2023)": 1045,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Sports",
                "History",
                "Religion",
                "General knowledge",
                "Music",
                "Geography",
                "Entertainment",
                "Pop culture"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Joshi2017TriviaQAAL,\n author = {Mandar Joshi and Eunsol Choi and Daniel S. Weld and Luke Zettlemoyer},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension},\n volume = {abs/1705.03551},\n year = {2017}\n}\n"
    },
    "fc-sni-turk": {
        "Unique Dataset Identifier": "fc-sni-turk",
        "Dataset Name": "turk",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/turk",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/turk",
        "Paper Title": "Optimizing Statistical Machine Translation for Text Simplification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/turkcorpus",
        "ArXiv URL": "https://aclanthology.org/Q16-1029/",
        "Semantic Scholar Corpus ID": 2177849,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Simplification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4872,
            "Mean Inputs Length": 549.8754,
            "Mean Targets Length": 110.0378,
            "Max Inputs Length": 1580,
            "Max Targets Length": 494,
            "Min Inputs Length": 206,
            "Min Targets Length": 23,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Pennsylvania",
            "Johns Hopkins University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task934_turk_simplification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "turk",
            "HF Config": "simplification",
            "HF Config License": "GNU General Public License v3.0",
            "HF Yaml License": "GNU General Public License v3.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2016-01-01",
            "S2 Date": "2016-07-27",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1313,
            "HF Likes (September 2023)": 3,
            "PwC Description": "TurkCorpus, a dataset with 2,359 original sentences from English Wikipedia, each with 8 manual reference simplifications.\nThe dataset is divided into two subsets: 2,000 sentences for validation and 359 for testing of sentence simplification models.",
            "S2 Citation Count (September 2023)": 450,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "History",
                "Cultural heritage",
                "Linguistics",
                "Sports",
                "Paraphrasing",
                "Lexical paraphrasing",
                "Language processing",
                "Translation",
                "Geography"
            ]
        },
        "Derived from Datasets": [
            "Parallel Wikipedia Simplification (PWKP) corpus (Zhu et al., 2010)"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Xu2016OptimizingSM,\n author = {W. Xu and Courtney Napoles and Ellie Pavlick and Quan Ze Chen and Chris Callison-Burch},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {401-415},\n title = {Optimizing Statistical Machine Translation for Text Simplification},\n volume = {4},\n year = {2016}\n}\n"
    },
    "fc-sni-tweetqa": {
        "Unique Dataset Identifier": "fc-sni-tweetqa",
        "Dataset Name": "tweetqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://tweetqa.github.io/",
        "GitHub URL": "https://tweetqa.github.io/",
        "Hugging Face URL": "https://huggingface.co/datasets/tweet_qa",
        "Paper Title": "TWEETQA: A Social Media Focused Question Answering Dataset",
        "Papers with Code URL": "https://paperswithcode.com/dataset/tweetqa",
        "ArXiv URL": "https://arxiv.org/abs/1907.06292",
        "Semantic Scholar Corpus ID": 196174735,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13030,
            "Mean Inputs Length": 645.3955,
            "Mean Targets Length": 15.1576,
            "Max Inputs Length": 1188,
            "Max Targets Length": 68,
            "Min Inputs Length": 266,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "twitter",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "UC Santa Barbara",
            "IBM"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://tweetqa.github.io/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task239_tweetqa_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tweet_qa",
            "HF Config": "default",
            "HF Config License": "CC BY-SA 4.0",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2019-07-14",
            "S2 Date": "2019-07-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 704,
            "HF Likes (September 2023)": 2,
            "PwC Description": "With social media becoming increasingly popular on which lots of news and real-time events are reported, developing automated question answering systems is critical to the effectiveness of many applications that rely on real-time knowledge. While previous question answering (QA) datasets have concentrated on formal text like news and Wikipedia, the first large-scale dataset for QA over social media data is presented. To make sure the tweets are meaningful and contain interesting information, tweets used by journalists to write news articles are gathered. Then human annotators are asked to write questions and answers upon these tweets. Unlike other QA datasets like SQuAD in which the answers are extractive, the answer are allowed to be abstractive. The task requires model to read a short tweet and a question and outputs a text phrase (does not need to be in the tweet) as the answer.",
            "S2 Citation Count (September 2023)": 56,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Current events",
                "Celebrity culture",
                "Sports",
                "Television shows",
                "Politics",
                "Social media",
                "Education",
                "Support and empathy"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Xiong2019TWEETQAAS,\n author = {Wenhan Xiong and Jiawei Wu and Hong Wang and Vivek Kulkarni and Mo Yu and Shiyu Chang and Xiaoxiao Guo and William Yang Wang},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {TWEETQA: A Social Media Focused Question Answering Dataset},\n volume = {abs/1907.06292},\n year = {2019}\n}\n"
    },
    "fc-sni-universal_dependencies___english_dependency_treebank": {
        "Unique Dataset Identifier": "fc-sni-universal_dependencies___english_dependency_treebank",
        "Dataset Name": "universal_dependencies___english_dependency_treebank",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/UniversalDependencies/UD_English-EWT",
        "GitHub URL": "https://github.com/UniversalDependencies/UD_English-EWT",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Part-of-Speech Tagging"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12034,
            "Mean Inputs Length": 3261.2946,
            "Mean Targets Length": 4.2246,
            "Max Inputs Length": 4586,
            "Max Targets Length": 15,
            "Min Inputs Length": 2867,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/UniversalDependencies/UD_English-EWT#licensecopyright"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task583_udeps_eng_coarse_pos_tagging"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "CC BY-SA 4.0",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": 185,
            "GitHub Topics": [],
            "Text Topics": [
                "Grammar",
                "Grammar analysis",
                "Language learning",
                "Linguistics",
                "Parts-of-speech tagging",
                "Natural language processing",
                "Natural Language Processing",
                "Language processing"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-viquiquad": {
        "Unique Dataset Identifier": "fc-sni-viquiquad",
        "Dataset Name": "viquiquad",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/BSC-TeMU/viquiquad",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/BSC-TeMU/viquiquad",
        "Paper Title": "Are Multilingual Models the Best Choice for Moderately Under-resourced Languages? A Comprehensive Assessment for Catalan",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2107.07903",
        "Semantic Scholar Corpus ID": 236034103,
        "Languages": [
            "Catalan",
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4921,
            "Mean Inputs Length": 2075.4806,
            "Mean Targets Length": 45.3392,
            "Max Inputs Length": 5392,
            "Max Targets Length": 134,
            "Min Inputs Length": 811,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "acn.cat",
            "wikipedia.org",
            "opus dogc corpus",
            "catalan open subtitles",
            "cawac corpus",
            "catalan government crawling"
        ],
        "Model Generated": [],
        "Creators": [
            "Barcelona Supercomputing Center"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 3.0",
                "License URL": "https://huggingface.co/datasets/BSC-LT/viquiquad#introduction"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task836_viquiquad_question_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "BSC-TeMU/viquiquad",
            "HF Config": "ViquiQuAD",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2021-07-16",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2021-08-30",
            "HF Downloads (September 2023)": 450,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 23,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language learning",
                "History",
                "Language and linguistics",
                "Cultural heritage",
                "Catalan language and culture",
                "Language and literature",
                "Geography"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Armengol-Estap'e2021AreMM,\n author = {Jordi Armengol-Estap'e and C. Carrino and Carlos Rodríguez-Penagos and Ona de Gibert Bonet and Carme Armentano-Oller and Aitor Gonzalez-Agirre and Maite Melero and Marta Villegas},\n booktitle = {Findings},\n pages = {4933-4946},\n title = {Are Multilingual Models the Best Choice for Moderately Under-resourced Languages? A Comprehensive Assessment for Catalan},\n year = {2021}\n}\n"
    },
    "fc-sni-web_nlg": {
        "Unique Dataset Identifier": "fc-sni-web_nlg",
        "Dataset Name": "web_nlg",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/web_nlg",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/web_nlg",
        "Paper Title": "Creating Training Corpora for NLG Micro-Planners",
        "Papers with Code URL": "https://paperswithcode.com/dataset/webnlg",
        "ArXiv URL": "https://aclanthology.org/P17-1017/",
        "Semantic Scholar Corpus ID": 6702871,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Data to Text"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12984,
            "Mean Inputs Length": 636.8509,
            "Mean Targets Length": 117.0679,
            "Max Inputs Length": 1957,
            "Max Targets Length": 444,
            "Min Inputs Length": 272,
            "Min Targets Length": 21,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "dbpedia",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "CNRS",
            "University of Edinburgh"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC-SA 4.0",
                "License URL": "https://gitlab.com/shimorina/webnlg-dataset/-/tree/master/#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1728_web_nlg_data_to_text"
        ],
        "Inferred Metadata": {
            "HF Dataset": "web_nlg",
            "HF Config": "webnlg_challenge_2017",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "CC BY-NC-SA 4.0",
            "PwC License URL": "https://gitlab.com/shimorina/webnlg-dataset",
            "PwC Date": "2017-01-01",
            "S2 Date": "2017-08-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 4897,
            "HF Likes (September 2023)": 10,
            "PwC Description": "The WebNLG corpus comprises of sets of triplets describing facts (entities and relations between them) and the corresponding facts in form of natural language text. The corpus contains sets with up to 7 triplets each along with one or more reference texts for each set. The test set is split into two parts: seen, containing inputs created for entities and relations belonging to DBpedia categories that were seen in the training data, and unseen, containing inputs extracted for entities and relations belonging to 5 unseen categories.\n\nInitially, the dataset was used for the WebNLG natural language generation challenge which consists of mapping the sets of triplets to text, including referring expression generation, aggregation, lexicalization, surface realization, and sentence segmentation.\nThe corpus is also used for a reverse task of triplets extraction.\n\nVersioning history of the dataset can be found here.",
            "S2 Citation Count (September 2023)": 285,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Translation",
                "Literature",
                "Geography",
                "Language",
                "Natural language processing",
                "Language understanding",
                "Sports",
                "Knowledge representation"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Gardent2017CreatingTC,\n author = {Claire Gardent and Anastasia Shimorina and Shashi Narayan and Laura Perez-Beltrachini},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {179-188},\n title = {Creating Training Corpora for NLG Micro-Planners},\n year = {2017}\n}\n"
    },
    "fc-sni-web_questions": {
        "Unique Dataset Identifier": "fc-sni-web_questions",
        "Dataset Name": "web_questions",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://nlp.stanford.edu/software/sempre/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/web_questions",
        "Paper Title": "Semantic Parsing on Freebase from Question-Answer Pairs",
        "Papers with Code URL": "https://paperswithcode.com/dataset/webquestions",
        "ArXiv URL": "https://aclanthology.org/D13-1160/",
        "Semantic Scholar Corpus ID": 6401679,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 7483,
            "Mean Inputs Length": 251.2351,
            "Mean Targets Length": 16.4149,
            "Max Inputs Length": 544,
            "Max Targets Length": 474,
            "Min Inputs Length": 119,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "Stanford University"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://nlp.stanford.edu/software/sempre/"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task1412_web_questions_question_answering"
        ],
        "Inferred Metadata": {
            "HF Dataset": "web_questions",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2013-01-01",
            "S2 Date": "2013-10-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 20984,
            "HF Likes (September 2023)": 9,
            "PwC Description": "The WebQuestions dataset is a question answering dataset using Freebase as the knowledge base and contains 6,642 question-answer pairs. It was created by crawling questions through the Google Suggest API, and then obtaining answers using Amazon Mechanical Turk. The original split uses 3,778 examples for training and 2,032 for testing. All answers are defined as Freebase entities.\n\nExample questions (answers) in the dataset include “Where did Edgar Allan Poe died?” (baltimore) or “What degrees did Barack Obama get?” (bachelor_of_arts, juris_doctor).",
            "S2 Citation Count (September 2023)": 1594,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Entertainment",
                "Trivia",
                "World War II",
                "Religion",
                "Politics",
                "General knowledge",
                "Travel"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Berant2013SemanticPO,\n author = {Jonathan Berant and A. Chou and Roy Frostig and Percy Liang},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {1533-1544},\n title = {Semantic Parsing on Freebase from Question-Answer Pairs},\n year = {2013}\n}\n"
    },
    "fc-sni-wiki_auto": {
        "Unique Dataset Identifier": "fc-sni-wiki_auto",
        "Dataset Name": "wiki_auto",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/chaojiang06/wiki-auto",
        "GitHub URL": "https://github.com/chaojiang06/wiki-auto",
        "Hugging Face URL": "https://huggingface.co/datasets/wiki_auto",
        "Paper Title": "Neural CRF Model for Sentence Alignment in Text Simplification",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2005.02324",
        "Semantic Scholar Corpus ID": 216557637,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Simplification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3549,
            "Mean Inputs Length": 810.4897,
            "Mean Targets Length": 108.1953,
            "Max Inputs Length": 1848,
            "Max Targets Length": 456,
            "Min Inputs Length": 394,
            "Min Targets Length": 26,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "newsela"
        ],
        "Model Generated": [],
        "Creators": [
            "The Ohio State University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/chaojiang06/wiki-auto#instructions"
            },
            {
                "License": "Request Form",
                "License URL": "https://github.com/chaojiang06/wiki-auto#instructions"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task933_wiki_auto_style_transfer"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wiki_auto",
            "HF Config": "auto",
            "HF Config License": "CC BY-SA 3.0",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1770,
            "HF Likes (September 2023)": 6,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 93,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language",
                "Geography",
                "Communication",
                "Language simplification",
                "Simplification",
                "Sports",
                "Linguistics",
                "Translation",
                "Simplification of language",
                "History"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Jiang2020NeuralCM,\n author = {Chao Jiang and Mounica Maddela and Wuwei Lan and Yang Zhong and W. Xu},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Neural CRF Model for Sentence Alignment in Text Simplification},\n volume = {abs/2005.02324},\n year = {2020}\n}\n"
    },
    "fc-sni-wiki_auto_all_data": {
        "Unique Dataset Identifier": "fc-sni-wiki_auto_all_data",
        "Dataset Name": "wiki_auto_all_data",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.dropbox.com/sh/ohqaw41v48c7e5p/aadb6_qwcwghvscqg121ck9ma?dl=0",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Keyword Tagging"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3936,
            "Mean Inputs Length": 420.0899,
            "Mean Targets Length": 14.6928,
            "Max Inputs Length": 992,
            "Max Targets Length": 62,
            "Min Inputs Length": 177,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/chaojiang06/wiki-auto#instructions"
            },
            {
                "License": "Request Form",
                "License URL": "https://github.com/chaojiang06/wiki-auto#instructions"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task645_summarization"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Communication",
                "Sports",
                "Geography",
                "Travel",
                "Medical procedures",
                "Biography",
                "Education",
                "Music",
                "Mental health"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-wiki_hop": {
        "Unique Dataset Identifier": "fc-sni-wiki_hop",
        "Dataset Name": "wiki_hop",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://paperswithcode.com/dataset/wikihop",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/wiki_hop",
        "Paper Title": "Neural Text Generation from Structured Data with Application to the Biography Domain",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wikihop",
        "ArXiv URL": "https://arxiv.org/abs/1603.07771",
        "Semantic Scholar Corpus ID": 1238927,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13007,
            "Mean Inputs Length": 12765.5325,
            "Mean Targets Length": 12.6659,
            "Max Inputs Length": 79656,
            "Max Targets Length": 58,
            "Min Inputs Length": 736,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "EPFL",
            "Facebook AI Research"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 3.0",
                "License URL": "http://qangaroo.cs.ucl.ac.uk/"
            }
        ],
        "License Notes": "Approved for training/fine-tuning only",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task1296_wiki_hop_question_answering"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wiki_hop",
            "HF Config": "original",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "http://qangaroo.cs.ucl.ac.uk/",
            "PwC Date": "2017-01-01",
            "S2 Date": "2016-03-24",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 4841,
            "HF Likes (September 2023)": 1,
            "PwC Description": "WikiHop is a multi-hop question-answering dataset. The query of WikiHop is constructed with entities and relations from WikiData, while supporting documents are from WikiReading. A bipartite graph connecting entities and documents is first built and the answer for each query is located by traversal on this graph. Candidates that are type-consistent with the answer and share the same relation in query with the answer are included, resulting in a set of candidates. Thus, WikiHop is a multi-choice style reading comprehension data set. There are totally about 43K samples in training set, 5K samples in development set and 2.5K samples in test set. The test set is not provided. The task is to predict the correct answer given a query and multiple supporting documents.\n\nThe dataset includes a masked variant, where all candidates and their mentions in the supporting documents are replaced by random but consistent placeholder tokens.",
            "S2 Citation Count (September 2023)": 427,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Culture",
                "Biography",
                "Geography",
                "Figure skating",
                "Canadian culture",
                "Sports",
                "Education",
                "History",
                "Travel",
                "General knowledge"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Lebret2016NeuralTG,\n author = {R. Lebret and David Grangier and Michael Auli},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {1203-1213},\n title = {Neural Text Generation from Structured Data with Application to the Biography Domain},\n year = {2016}\n}\n"
    },
    "fc-sni-wiki_movies": {
        "Unique Dataset Identifier": "fc-sni-wiki_movies",
        "Dataset Name": "wiki_movies",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/wiki_movies",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/wiki_movies",
        "Paper Title": "Key-Value Memory Networks for Directly Reading Documents",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wikimovies",
        "ArXiv URL": "https://arxiv.org/abs/1606.03126",
        "Semantic Scholar Corpus ID": 2711679,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12906,
            "Mean Inputs Length": 343.1832,
            "Mean Targets Length": 33.4141,
            "Max Inputs Length": 1151,
            "Max Targets Length": 801,
            "Min Inputs Length": 199,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "open movie database",
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "Facebook AI Research",
            "Carnegie Mellon University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/pdf/1606.03126.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task615_moviesqa_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wiki_movies",
            "HF Config": "default",
            "HF Config License": "CC0 1.0",
            "HF Yaml License": "CC BY 3.0",
            "PwC License Name": "Unspecified",
            "PwC License URL": "",
            "PwC Date": "2016-06-09",
            "S2 Date": "2016-06-09",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 593,
            "HF Likes (September 2023)": 1,
            "PwC Description": "WikiMovies is a dataset for question answering for movies content. It contains ~100k questions in the movie domain, and was designed to be answerable by using either a perfect KB (based on OMDb),",
            "S2 Citation Count (September 2023)": 806,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Film analysis",
                "Filmography",
                "Open movie database",
                "Movie trivia",
                "Open-domain question answering",
                "Movies",
                "Entertainment",
                "Film industry",
                "Movie genres",
                "Film genres"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Miller2016KeyValueMN,\n author = {Alexander H. Miller and Adam Fisch and Jesse Dodge and Amir-Hossein Karimi and Antoine Bordes and J. Weston},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Key-Value Memory Networks for Directly Reading Documents},\n volume = {abs/1606.03126},\n year = {2016}\n}\n"
    },
    "fc-sni-wiki_qa": {
        "Unique Dataset Identifier": "fc-sni-wiki_qa",
        "Dataset Name": "wiki_qa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/wiki_qa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/wiki_qa",
        "Paper Title": "WikiQA: A Challenge Dataset for Open-Domain Question Answering",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wikiqa",
        "ArXiv URL": "https://aclanthology.org/D15-1237/",
        "Semantic Scholar Corpus ID": 1373518,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Answer Verification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 4289,
            "Mean Inputs Length": 534.2087,
            "Mean Targets Length": 3.0492,
            "Max Inputs Length": 1693,
            "Max Targets Length": 13,
            "Min Inputs Length": 198,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "bing search queries",
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "Georgia Institute of Technology",
            "Microsoft Research"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://www.microsoft.com/en-us/download/details.aspx?id=52419"
            }
        ],
        "License Notes": "Denied - no commercial use",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task1294_wiki_qa_answer_verification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wiki_qa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "Custom",
            "PwC License URL": "https://www.microsoft.com/en-us/download/details.aspx?id=52419",
            "PwC Date": "2015-01-01",
            "S2 Date": "2015-09-21",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 18380,
            "HF Likes (September 2023)": 14,
            "PwC Description": "The WikiQA corpus is a publicly available set of question and sentence pairs, collected and annotated for research on open-domain question answering. In order to reflect the true information need of general users, Bing query logs were used as the question source. Each question is linked to a Wikipedia page that potentially has the answer. Because the summary section of a Wikipedia page provides the basic and usually most important information about the topic, sentences in this section were used as the candidate answers. The corpus includes 3,047 questions and 29,258 sentences, where 1,473 sentences were labeled as answer sentences to their corresponding questions.",
            "S2 Citation Count (September 2023)": 761,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Physics",
                "Biography",
                "Geography",
                "Education",
                "Music",
                "Science",
                "Trivia",
                "History"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Yang2015WikiQAAC,\n author = {Yi Yang and Wen-tau Yih and Christopher Meek},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {2013-2018},\n title = {WikiQA: A Challenge Dataset for Open-Domain Question Answering},\n year = {2015}\n}\n"
    },
    "fc-sni-wikitext": {
        "Unique Dataset Identifier": "fc-sni-wikitext",
        "Dataset Name": "wikitext",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://blog.salesforceairesearch.com/the-wikitext-long-term-dependency-language-modeling-dataset/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/wikitext",
        "Paper Title": "Pointer Sentinel Mixture Models",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wikitext-2",
        "ArXiv URL": "https://arxiv.org/abs/1609.07843",
        "Semantic Scholar Corpus ID": 16299141,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Title Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 170,
            "Mean Inputs Length": 3480.0059,
            "Mean Targets Length": 16.4765,
            "Max Inputs Length": 18974,
            "Max Targets Length": 41,
            "Min Inputs Length": 261,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "MetaMind - A Salesforce Company"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 3.0",
                "License URL": "https://blog.salesforceairesearch.com/the-wikitext-long-term-dependency-language-modeling-dataset/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task602_wikitext-103_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wikitext",
            "HF Config": "wikitext-103-v1",
            "HF Config License": "CC BY-SA 4.0",
            "HF Yaml License": "CC BY-SA 3.0",
            "PwC License Name": "CC BY-SA 3.0",
            "PwC License URL": "https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/",
            "PwC Date": "2016-09-26",
            "S2 Date": "2016-09-26",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 1028094,
            "HF Likes (September 2023)": 174,
            "PwC Description": "The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia. The dataset is available under the Creative Commons Attribution-ShareAlike License.\n\nCompared to the preprocessed version of Penn Treebank (PTB), WikiText-2 is over 2 times larger and WikiText-103 is over 110 times larger. The WikiText dataset also features a far larger vocabulary and retains the original case, punctuation and numbers - all of which are removed in PTB. As it is composed of full articles, the dataset is well suited for models that can take advantage of long term dependencies.",
            "S2 Citation Count (September 2023)": 1490,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": []
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Merity2016PointerSM,\n author = {Stephen Merity and Caiming Xiong and James Bradbury and R. Socher},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Pointer Sentinel Mixture Models},\n volume = {abs/1609.07843},\n year = {2016}\n}\n"
    },
    "fc-sni-wino_bias": {
        "Unique Dataset Identifier": "fc-sni-wino_bias",
        "Dataset Name": "wino_bias",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/viewer/?dataset=wino_bias",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/viewer/?dataset=wino_bias",
        "Paper Title": "Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods",
        "Papers with Code URL": "https://paperswithcode.com/dataset/winobias",
        "ArXiv URL": "https://arxiv.org/abs/1804.06876",
        "Semantic Scholar Corpus ID": 4952494,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Coreference Resolution"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 804,
            "Mean Inputs Length": 753.1965,
            "Mean Targets Length": 17.7488,
            "Max Inputs Length": 1017,
            "Max Targets Length": 31,
            "Min Inputs Length": 565,
            "Min Targets Length": 12,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "UCLA",
            "University of Virginia",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/1804.06876"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1664_winobias_text_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wino_bias",
            "HF Config": "type1_pro",
            "HF Config License": "MIT License",
            "HF Yaml License": "MIT License",
            "PwC License Name": "MIT License",
            "PwC License URL": "https://github.com/uclanlp/corefBias/blob/master/LICENSE",
            "PwC Date": "2018-01-01",
            "S2 Date": "2018-04-18",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "WinoBias contains 3,160 sentences, split equally for development and test, created by researchers familiar with the project. Sentences were created to follow two prototypical templates but annotators were encouraged to come up with scenarios where entities could be interacting in plausible ways. Templates were selected to be challenging and designed to cover cases requiring semantics and syntax separately.",
            "S2 Citation Count (September 2023)": 555,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Natural language processing",
                "Coreference Resolution",
                "Language understanding",
                "Coreference resolution",
                "Linguistics",
                "Natural language understanding",
                "Natural Language Processing",
                "Text analysis",
                "Language analysis"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zhao2018GenderBI,\n author = {Jieyu Zhao and Tianlu Wang and Mark Yatskar and Vicente Ordonez and Kai-Wei Chang},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {15-20},\n title = {Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods},\n year = {2018}\n}\n"
    },
    "fc-sni-winograd_wsc": {
        "Unique Dataset Identifier": "fc-sni-winograd_wsc",
        "Dataset Name": "winograd_wsc",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/winograd_wsc",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/winograd_wsc",
        "Paper Title": "The Winograd Schema Challenge",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wsc",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": 15710851,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Information Extraction"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 227,
            "Mean Inputs Length": 544.9604,
            "Mean Targets Length": 5.9339,
            "Max Inputs Length": 809,
            "Max Targets Length": 20,
            "Min Inputs Length": 368,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task646_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "winograd_wsc",
            "HF Config": "wsc285",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "CC BY 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by/4.0/",
            "PwC Date": "2012-01-01",
            "S2 Date": "2011-03-20",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3264,
            "HF Likes (September 2023)": 5,
            "PwC Description": "The Winograd Schema Challenge was introduced both as an alternative to the Turing Test and as a test of a system’s ability to do commonsense reasoning. A Winograd schema is a pair of sentences differing in one or two words with a highly ambiguous pronoun, resolved differently in the two sentences, that appears to require commonsense knowledge to be resolved correctly. The examples were designed to be easily solvable by humans but difficult for machines, in principle requiring a deep understanding of the content of the text and the situation it describes.\n\nThe original Winograd Schema Challenge dataset consisted of 100 Winograd schemas constructed manually by AI experts. As of 2020 there are 285 examples available; however, the last 12 examples were only added recently. To ensure consistency with earlier models, several authors often prefer to report the performance on the first 273 examples only. These datasets are usually referred to as WSC285 and WSC273, respectively.",
            "S2 Citation Count (September 2023)": 1000,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language learning",
                "Linguistics",
                "Language",
                "Pronoun identification",
                "Communication",
                "Language analysis",
                "Language understanding",
                "Grammar",
                "Pronouns",
                "Education"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": "@Article{Levesque2011TheWS,\n author = {H. Levesque and E. Davis and L. Morgenstern},\n booktitle = {AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning},\n title = {The Winograd Schema Challenge},\n year = {2011}\n}\n"
    },
    "fc-sni-winomt": {
        "Unique Dataset Identifier": "fc-sni-winomt",
        "Dataset Name": "winomt",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/gabrielStanovsky/mt_gender",
        "GitHub URL": "https://github.com/gabrielStanovsky/mt_gender",
        "Hugging Face URL": "",
        "Paper Title": "Evaluating Gender Bias in Machine Translation",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/1906.00591",
        "Semantic Scholar Corpus ID": 173991101,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Gender Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3172,
            "Mean Inputs Length": 556.4023,
            "Mean Targets Length": 5.558,
            "Max Inputs Length": 805,
            "Max Targets Length": 16,
            "Min Inputs Length": 370,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "grammar-based"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Washington",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/gabrielStanovsky/mt_gender#evaluating-gender-bias-in-machine-translation"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task340_winomt_classification_gender_pro"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2019-06-03",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 255,
            "GitHub Stars": 42,
            "GitHub Topics": [],
            "Text Topics": [
                "Natural language processing",
                "Language and Linguistics",
                "Language understanding",
                "Gender identification",
                "Cultural context",
                "Professions",
                "Equality and inclusivity"
            ]
        },
        "Derived from Datasets": [
            "Winogender",
            "WinoBias"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Stanovsky2019EvaluatingGB,\n author = {Gabriel Stanovsky and Noah A. Smith and Luke Zettlemoyer},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Evaluating Gender Bias in Machine Translation},\n volume = {abs/1906.00591},\n year = {2019}\n}\n"
    },
    "fc-sni-winowhy": {
        "Unique Dataset Identifier": "fc-sni-winowhy",
        "Dataset Name": "winowhy",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/HKUST-KnowComp/WinoWhy",
        "GitHub URL": "https://github.com/HKUST-KnowComp/WinoWhy",
        "Hugging Face URL": "https://huggingface.co/datasets/tasksource/winowhy",
        "Paper Title": "WinoWhy: A Deep Diagnosis of Essential Commonsense Knowledge for Answering Winograd Schema Challenge",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2005.05763",
        "Semantic Scholar Corpus ID": 218595822,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Coreference Resolution"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 5741,
            "Mean Inputs Length": 1576.1416,
            "Mean Targets Length": 6.4808,
            "Max Inputs Length": 2254,
            "Max Targets Length": 17,
            "Min Inputs Length": 1199,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "winograd schema challenge dataset",
            "conceptnet",
            "crowdsourced"
        ],
        "Model Generated": [],
        "Creators": [
            "The Hong Kong University of Science and Technology"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/2005.05763"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task133_winowhy_reason_plausibility_detection"
        ],
        "Inferred Metadata": {
            "HF Dataset": "tasksource/winowhy",
            "HF Config": "tasksource--winowhy",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-12",
            "GitHub License": "MIT License",
            "Github Date": "",
            "HF Date": "2023-05-25",
            "HF Downloads (September 2023)": 46,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 35,
            "GitHub Stars": 16,
            "GitHub Topics": [],
            "Text Topics": [
                "Pronoun coreference",
                "Reasoning and inference",
                "Language comprehension",
                "Natural language processing",
                "Coreference resolution",
                "Reasoning and justification",
                "Language understanding",
                "Reasoning"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Zhang2020WinoWhyAD,\n author = {Hongming Zhang and Xinran Zhao and Yangqiu Song},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {5736-5745},\n title = {WinoWhy: A Deep Diagnosis of Essential Commonsense Knowledge for Answering Winograd Schema Challenge},\n year = {2020}\n}\n"
    },
    "fc-sni-wiqa": {
        "Unique Dataset Identifier": "fc-sni-wiqa",
        "Dataset Name": "wiqa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://allenai.org/data/wiqa",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/wiqa",
        "Paper Title": "WIQA: A dataset for “What if...” reasoning over procedural text",
        "Papers with Code URL": "https://paperswithcode.com/dataset/wiqa",
        "ArXiv URL": "https://arxiv.org/abs/1909.04739",
        "Semantic Scholar Corpus ID": 202558452,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentence Ordering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1198,
            "Mean Inputs Length": 1146.3548,
            "Mean Targets Length": 3.1553,
            "Max Inputs Length": 2374,
            "Max Targets Length": 15,
            "Min Inputs Length": 571,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "propara"
        ],
        "Model Generated": [],
        "Creators": [
            "AI2"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/D19-1629.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "task1548_wiqa_binary_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "wiqa",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2019-09-10",
            "S2 Date": "2019-09-01",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 3807,
            "HF Likes (September 2023)": 2,
            "PwC Description": "The WIQA dataset V1 has 39705 questions containing a perturbation and a possible effect in the context of a paragraph. The dataset is split into 29808 train questions, 6894 dev questions and 3003 test questions.",
            "S2 Citation Count (September 2023)": 74,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Order and sequence",
                "Language understanding",
                "Task analysis",
                "Task: Answering questions",
                "Critical thinking",
                "Process analysis",
                "Task completion"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Tandon2019WIQAAD,\n author = {Niket Tandon and Bhavana Dalvi and Keisuke Sakaguchi and Antoine Bosselut and Peter Clark},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {WIQA: A dataset for “What if...” reasoning over procedural text},\n volume = {abs/1909.04739},\n year = {2019}\n}\n"
    },
    "fc-sni-wordnet": {
        "Unique Dataset Identifier": "fc-sni-wordnet",
        "Dataset Name": "wordnet",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://wordnet.princeton.edu/",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Word Semantics"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 6784,
            "Mean Inputs Length": 199.6293,
            "Mean Targets Length": 9.5588,
            "Max Inputs Length": 369,
            "Max Targets Length": 29,
            "Min Inputs Length": 104,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://wordnet.princeton.edu/license-and-commercial-use"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1508_wordnet_antonyms"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language and linguistics",
                "Vocabulary and word usage",
                "Vocabulary",
                "Opposites and Antonyms",
                "Linguistics",
                "Opposites and Contradictions",
                "Language",
                "Language and Linguistics",
                "Vocabulary and Word Usage"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-wsc_fiexed": {
        "Unique Dataset Identifier": "fc-sni-wsc_fiexed",
        "Dataset Name": "wsc_fiexed",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/super_glue",
        "GitHub URL": "https://github.com/google-research-datasets/boolean-questions",
        "Hugging Face URL": "https://huggingface.co/datasets/super_glue",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Coreference Resolution"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1302,
            "Mean Inputs Length": 597.5906,
            "Mean Targets Length": 5.1121,
            "Max Inputs Length": 1283,
            "Max Targets Length": 15,
            "Min Inputs Length": 314,
            "Min Targets Length": 4,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY-SA 3.0",
                "License URL": "https://github.com/google-research-datasets/boolean-questions#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1390_wscfixed_coreference"
        ],
        "Inferred Metadata": {
            "HF Dataset": "SetFit/wsc_fixed",
            "HF Config": "SetFit--wsc_fixed",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 199405,
            "HF Likes (September 2023)": 111,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Reading comprehension",
                "Language comprehension",
                "Pronoun reference",
                "Context analysis",
                "Contextual analysis",
                "Pronoun resolution",
                "Language understanding"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-wsc; enhanced_wsc": {
        "Unique Dataset Identifier": "fc-sni-wsc; enhanced_wsc",
        "Dataset Name": "wsc; enhanced_wsc",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/winograd_wsc; https://github.com/mhany90/perturbed-wsc",
        "GitHub URL": "https://huggingface.co/datasets/winograd_wsc; https://github.com/mhany90/perturbed-wsc",
        "Hugging Face URL": "https://huggingface.co/datasets/winograd_wsc; https://github.com/mhany90/perturbed-wsc",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentence Perturbation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2298,
            "Mean Inputs Length": 1145.6227,
            "Mean Targets Length": 95.8499,
            "Max Inputs Length": 1682,
            "Max Targets Length": 215,
            "Min Inputs Length": 874,
            "Min Targets Length": 38,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task275_enhanced_wsc_paraphrase_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "winograd_wsc",
            "HF Config": "wsc285",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Sports",
                "Social interaction",
                "Friendship",
                "Language learning",
                "Language",
                "Transportation",
                "Communication",
                "Grammar",
                "Travel"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-x_csr": {
        "Unique Dataset Identifier": "fc-sni-x_csr",
        "Dataset Name": "x_csr",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://inklab.usc.edu/XCSR/xcsr_datasets",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/xcsr",
        "Paper Title": "Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/x-csqa",
        "ArXiv URL": "https://arxiv.org/abs/2106.06937",
        "Semantic Scholar Corpus ID": 235421949,
        "Languages": [
            "Vietnamese",
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1993,
            "Mean Inputs Length": 613.6919,
            "Mean Targets Length": 1.5494,
            "Max Inputs Length": 1098,
            "Max Targets Length": 11,
            "Min Inputs Length": 322,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/2106.06937"
            },
            {
                "License": "Request Form",
                "License URL": "https://arxiv.org/abs/2106.06937"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1130_xcsr_vi_commonsense_mc_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "xcsr",
            "HF Config": "X-CSQA-en",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2021-06-13",
            "S2 Date": "2021-06-13",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 8617,
            "HF Likes (September 2023)": 3,
            "PwC Description": "X-CSQA is a multilingual dataset for Commonsense reasoning research, based on CSQA.",
            "S2 Citation Count (September 2023)": 24,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language learning",
                "Vietnamese language",
                "Multiple choice questions",
                "Language proficiency",
                "Cultural norms and etiquette",
                "Common sense reasoning",
                "Multiple choice question answering"
            ]
        },
        "Derived from Datasets": [
            "OMCS corpus"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Lin2021CommonSB,\n author = {Bill Yuchen Lin and Seyeon Lee and Xiaoyang Qiao and Xiang Ren},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning},\n volume = {abs/2106.06937},\n year = {2021}\n}\n"
    },
    "fc-sni-xcopa": {
        "Unique Dataset Identifier": "fc-sni-xcopa",
        "Dataset Name": "xcopa",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/cambridgeltl/xcopa",
        "GitHub URL": "https://github.com/cambridgeltl/xcopa",
        "Hugging Face URL": "https://huggingface.co/datasets/xcopa",
        "Paper Title": "XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/xcopa",
        "ArXiv URL": "https://arxiv.org/abs/2005.00333",
        "Semantic Scholar Corpus ID": 218470125,
        "Languages": [
            "Haitian",
            "English"
        ],
        "Task Categories": [
            "Cause Effect Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1221,
            "Mean Inputs Length": 553.6781,
            "Mean Targets Length": 1.5242,
            "Max Inputs Length": 776,
            "Max Targets Length": 11,
            "Min Inputs Length": 374,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "human"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Cambridge",
            "University of Mannheim"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://github.com/cambridgeltl/xcopa/blob/master/LICENSE.md"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1168_xcopa_commonsense_reasoning_ht"
        ],
        "Inferred Metadata": {
            "HF Dataset": "xcopa",
            "HF Config": "et",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-05-01",
            "GitHub License": "CC BY 4.0",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 16014,
            "HF Likes (September 2023)": 5,
            "PwC Description": "The Cross-lingual Choice of Plausible Alternatives (XCOPA) dataset is a benchmark to evaluate the ability of machine learning models to transfer commonsense reasoning across languages. The dataset is the translation and reannotation of the English COPA (Roemmele et al. 2011) and covers 11 languages from 11 families and several areas around the globe. The dataset is challenging as it requires both the command of world knowledge and the ability to generalise to new languages.",
            "S2 Citation Count (September 2023)": 128,
            "GitHub Stars": 79,
            "GitHub Topics": [],
            "Text Topics": [
                "Cause and effect reasoning",
                "Plausibility reasoning",
                "Language learning",
                "Language comprehension",
                "Reasoning and logic",
                "Critical thinking",
                "Cultural understanding",
                "Cultural knowledge"
            ]
        },
        "Derived from Datasets": [
            "COPA dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Ponti2020XCOPAAM,\n author = {E. Ponti and Goran Glavavs and Olga Majewska and Qianchu Liu and Ivan Vulic and A. Korhonen},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {2362-2376},\n title = {XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning},\n year = {2020}\n}\n"
    },
    "fc-sni-xcsr": {
        "Unique Dataset Identifier": "fc-sni-xcsr",
        "Dataset Name": "xcsr",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://inklab.usc.edu/XCSR/",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/xcsr",
        "Paper Title": "Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning",
        "Papers with Code URL": "https://paperswithcode.com/dataset/x-csqa",
        "ArXiv URL": "https://arxiv.org/abs/2106.06937",
        "Semantic Scholar Corpus ID": 235421949,
        "Languages": [
            "French",
            "English"
        ],
        "Task Categories": [
            "Sentence Perturbation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12965,
            "Mean Inputs Length": 589.1705,
            "Mean Targets Length": 64.5686,
            "Max Inputs Length": 897,
            "Max Targets Length": 123,
            "Min Inputs Length": 351,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "crowdsourced"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "University of Southern California"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://arxiv.org/abs/2106.06937"
            },
            {
                "License": "Request Form",
                "License URL": "https://arxiv.org/abs/2106.06937"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task406_mickey_fr_sentence_perturbation_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "xcsr",
            "HF Config": "X-CSQA-en",
            "HF Config License": "",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2021-06-13",
            "S2 Date": "2021-06-13",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 8617,
            "HF Likes (September 2023)": 3,
            "PwC Description": "X-CSQA is a multilingual dataset for Commonsense reasoning research, based on CSQA.",
            "S2 Citation Count (September 2023)": 24,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Semantics",
                "Language processing",
                "Translation",
                "Language learning",
                "Sentence transformation",
                "French culture",
                "Semantics and syntax",
                "Syntax"
            ]
        },
        "Derived from Datasets": [
            "OMCS corpus"
        ],
        "Human Annotation": "No",
        "Bibtex": "@Article{Lin2021CommonSB,\n author = {Bill Yuchen Lin and Seyeon Lee and Xiaoyang Qiao and Xiang Ren},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning},\n volume = {abs/2106.06937},\n year = {2021}\n}\n"
    },
    "fc-sni-xl_wic": {
        "Unique Dataset Identifier": "fc-sni-xl_wic",
        "Dataset Name": "xl_wic",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/pasinit/xlwic",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/pasinit/xlwic",
        "Paper Title": "XL-WiC: A Multilingual Benchmark\nfor Evaluating Semantic Contextualization",
        "Papers with Code URL": "https://paperswithcode.com/dataset/xl-wic",
        "ArXiv URL": "https://arxiv.org/abs/2010.06478",
        "Semantic Scholar Corpus ID": 222310469,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Word Semantics"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 268,
            "Mean Inputs Length": 560.1381,
            "Mean Targets Length": 5.9701,
            "Max Inputs Length": 912,
            "Max Targets Length": 16,
            "Min Inputs Length": 334,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wiktionary.org",
            "wordnet",
            "verbnet"
        ],
        "Model Generated": [],
        "Creators": [
            "University of Helsinki",
            "Sapienza University of Rome",
            "Cardiff University",
            "Tehran Institute for Advanced Studies"
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://pilehvar.github.io/xlwic/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task625_xlwic_true_or_false_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "pasinit/xlwic",
            "HF Config": "xlwic_en_bg",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-13",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2021-06-02",
            "HF Downloads (September 2023)": 1011,
            "HF Likes (September 2023)": 3,
            "PwC Description": "A large multilingual benchmark, XL-WiC, featuring gold standards in 12 new languages from varied language families and with different degrees of resource availability, opening room for evaluation scenarios such as zero-shot cross-lingual transfer.",
            "S2 Citation Count (September 2023)": 37,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Language comprehension",
                "Language and semantics",
                "Critical thinking",
                "Word meaning and usage",
                "Language",
                "Linguistics",
                "Word meaning"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Raganato2020XLWiCAM,\n author = {Alessandro Raganato and Tommaso Pasini and José Camacho-Collados and Mohammad Taher Pilehvar},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {XL-WiC: A Multilingual Benchmark for Evaluating Semantic Contextualization},\n volume = {abs/2010.06478},\n year = {2020}\n}\n"
    },
    "fc-sni-xlsum": {
        "Unique Dataset Identifier": "fc-sni-xlsum",
        "Dataset Name": "xlsum",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://arxiv.org/abs/2106.13822",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/GEM/xlsum",
        "Paper Title": "XL-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages",
        "Papers with Code URL": "https://paperswithcode.com/dataset/xl-sum",
        "ArXiv URL": "https://arxiv.org/abs/2106.13822",
        "Semantic Scholar Corpus ID": 235658519,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Title Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 12296,
            "Mean Inputs Length": 4912.0654,
            "Mean Targets Length": 53.2639,
            "Max Inputs Length": 46049,
            "Max Targets Length": 98,
            "Min Inputs Length": 397,
            "Min Targets Length": 16,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "bbc"
        ],
        "Model Generated": [],
        "Creators": [
            "Bangladesh University of Engineering and Technology",
            "University of Rochester",
            "Monash University",
            "Swinburne University of Technology"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1356_xlsum_title_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "GEM/xlsum",
            "HF Config": "oromo",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "Non Commercial",
            "PwC License URL": "https://github.com/csebuetnlp/xl-sum#license",
            "PwC Date": "2021-06-25",
            "S2 Date": "2021-06-25",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2021-11-24",
            "HF Downloads (September 2023)": 11826,
            "HF Likes (September 2023)": 3,
            "PwC Description": "XL-Sum is a comprehensive and diverse dataset for abstractive summarization comprising 1 million professionally annotated article-summary pairs from BBC, extracted using a set of carefully designed heuristics. The dataset covers 44 languages ranging from low to high-resource, for many of which no public dataset is currently available. XL-Sum is highly abstractive, concise, and of high quality, as indicated by human and intrinsic evaluation.",
            "S2 Citation Count (September 2023)": 119,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Legal challenges and implications",
                "Education",
                "Politics",
                "Local news",
                "News and current events",
                "Legal issues",
                "Travel",
                "Transportation"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Hasan2021XLSumLM,\n author = {Tahmid Hasan and Abhik Bhattacharjee and Md Saiful Islam and Kazi Samin Mubasshir and Yuan-Fang Li and Yong-Bin Kang and M. Rahman and Rifat Shahriyar},\n booktitle = {Findings},\n pages = {4693-4703},\n title = {XL-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages},\n year = {2021}\n}\n"
    },
    "fc-sni-xquad": {
        "Unique Dataset Identifier": "fc-sni-xquad",
        "Dataset Name": "xquad",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/viewer/?dataset=xquad",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/viewer/?dataset=xquad",
        "Paper Title": "On the Cross-lingual Transferability of Monolingual Representations",
        "Papers with Code URL": "https://paperswithcode.com/dataset/xquad",
        "ArXiv URL": "https://arxiv.org/abs/1910.11856",
        "Semantic Scholar Corpus ID": 204901567,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Answering"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2339,
            "Mean Inputs Length": 1714.0825,
            "Mean Targets Length": 19.4352,
            "Max Inputs Length": 6860,
            "Max Targets Length": 156,
            "Min Inputs Length": 400,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org"
        ],
        "Model Generated": [],
        "Creators": [
            "HiTZ Center",
            "University of the Basque Country",
            "DeepMind"
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/deepmind/xquad#license"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1608_xquad_en_answer_generation"
        ],
        "Inferred Metadata": {
            "HF Dataset": "xquad",
            "HF Config": "xquad.ar",
            "HF Config License": "",
            "HF Yaml License": "CC BY-SA 4.0",
            "PwC License Name": "CC BY-SA 4.0",
            "PwC License URL": "https://creativecommons.org/licenses/by-sa/4.0/legalcode",
            "PwC Date": "2019-10-25",
            "S2 Date": "2019-10-25",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "XQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering performance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set of SQuAD v1.1 (Rajpurkar et al., 2016) together with their professional translations into ten languages: Spanish, German, Greek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, and Hindi. Consequently, the dataset is entirely parallel across 11 languages.",
            "S2 Citation Count (September 2023)": 502,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "History",
                "Education",
                "Chemistry",
                "Biography",
                "Geography",
                "Sports",
                "Environmental science"
            ]
        },
        "Derived from Datasets": [
            "Squad"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Artetxe2019OnTC,\n author = {Mikel Artetxe and Sebastian Ruder and Dani Yogatama},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {4623-4637},\n title = {On the Cross-lingual Transferability of Monolingual Representations},\n year = {2019}\n}\n"
    },
    "fc-sni-yahoo_answers_topics": {
        "Unique Dataset Identifier": "fc-sni-yahoo_answers_topics",
        "Dataset Name": "yahoo_answers_topics",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/yahoo_answers_topics",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/yahoo_answers_topics",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 1998,
            "Mean Inputs Length": 513.9189,
            "Mean Targets Length": 1.5,
            "Max Inputs Length": 748,
            "Max Targets Length": 11,
            "Min Inputs Length": 349,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "ag news",
            "amazon.com",
            "dbpedia",
            "sogou news",
            "yahoo! answers",
            "yahoo review"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://drive.google.com/drive/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M?resourcekey=0-TLwzfR2O-D2aPitmn5o9VQ"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1592_yahoo_answers_topics_classfication"
        ],
        "Inferred Metadata": {
            "HF Dataset": "yahoo_answers_topics",
            "HF Config": "yahoo_answers_topics",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 10376,
            "HF Likes (September 2023)": 26,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Sports",
                "Education & Reference",
                "Science & Mathematics",
                "Computers & Internet",
                "Society & Culture",
                "Technology",
                "Family & Relationships",
                "Business & Finance",
                "Entertainment & Music"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-yelp_polarity": {
        "Unique Dataset Identifier": "fc-sni-yelp_polarity",
        "Dataset Name": "yelp_polarity",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://proceedings.neurips.cc/paper/2015/file/250cf8b51c773f3f8dc8b4be867a9a02-Paper.pdf",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/yelp_polarity",
        "Paper Title": "Character-level Convolutional Networks for Text Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/yelp-review-polarity",
        "ArXiv URL": "https://arxiv.org/abs/1509.01626",
        "Semantic Scholar Corpus ID": 368182,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13121,
            "Mean Inputs Length": 1452.7735,
            "Mean Targets Length": 8.5733,
            "Max Inputs Length": 10827,
            "Max Targets Length": 18,
            "Min Inputs Length": 221,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web",
            "amazon.com",
            "yelp",
            "sogou news",
            "dbpedia",
            "yahoo! answers",
            "ag news"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": null
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task475_yelp_polarity_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "yelp_polarity",
            "HF Config": "plain_text",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2015-09-04",
            "S2 Date": "2015-09-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 4000,
            "HF Likes (September 2023)": 5,
            "PwC Description": "The Yelp Reviews Polarity dataset is obtained from the Yelp Dataset Challenge in 2015 (1,569,264 samples that have review text).\n\nThe polarity label is constructed by considering stars 1 and 2 negative, and 3 and 4 positive.\n\nThe polarity dataset has 280,000 training samples and 19,000 test samples in each polarity.",
            "S2 Citation Count (September 2023)": 4622,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Food and dining",
                "Food and dining experience",
                "Customer reviews",
                "Natural language processing",
                "Food",
                "Restaurant experience",
                "Restaurant reviews",
                "Sentiment analysis",
                "Customer service"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Zhang2015CharacterlevelCN,\n author = {Xiang Zhang and J. Zhao and Yann LeCun},\n booktitle = {Neural Information Processing Systems},\n pages = {649-657},\n title = {Character-level Convolutional Networks for Text Classification},\n year = {2015}\n}\n"
    },
    "fc-sni-yelp_restaurant_review": {
        "Unique Dataset Identifier": "fc-sni-yelp_restaurant_review",
        "Dataset Name": "yelp_restaurant_review",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.yelp.com/dataset",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 2032,
            "Mean Inputs Length": 1695.3342,
            "Mean Targets Length": 8.5876,
            "Max Inputs Length": 7044,
            "Max Targets Length": 18,
            "Min Inputs Length": 223,
            "Min Targets Length": 8,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "yelp"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://s3-media3.fl.yelpcdn.com/assets/srv0/engineering_pages/bea5c1e92bf3/assets/vendor/yelp-dataset-agreement.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task746_yelp_restaurant_review_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "",
            "HF Downloads (September 2023)": "",
            "HF Likes (September 2023)": "",
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Customer service",
                "Food quality",
                "Customer experience",
                "Restaurant reviews",
                "Takeout experience",
                "West coast",
                "Work-related issues",
                "Dining out",
                "Plumbing services"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-yelp_review_full": {
        "Unique Dataset Identifier": "fc-sni-yelp_review_full",
        "Dataset Name": "yelp_review_full",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://www.yelp.com/dataset",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/yelp_review_full",
        "Paper Title": "Character-level Convolutional Networks for Text Classification",
        "Papers with Code URL": "https://paperswithcode.com/dataset/yelp-review-polarity",
        "ArXiv URL": "https://arxiv.org/abs/1509.01626",
        "Semantic Scholar Corpus ID": 368182,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Sentiment Analysis"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13043,
            "Mean Inputs Length": 1465.9354,
            "Mean Targets Length": 7.3583,
            "Max Inputs Length": 9143,
            "Max Targets Length": 17,
            "Min Inputs Length": 120,
            "Min Targets Length": 6,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "undisclosed web",
            "amazon.com",
            "yelp",
            "sogou news",
            "dbpedia",
            "yahoo! answers",
            "ag news"
        ],
        "Model Generated": [],
        "Creators": [
            "New York University"
        ],
        "Licenses": [
            {
                "License": "Custom",
                "License URL": "https://s3-media3.fl.yelpcdn.com/assets/srv0/engineering_pages/bea5c1e92bf3/assets/vendor/yelp-dataset-agreement.pdf"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1292_yelp_review_full_text_categorization"
        ],
        "Inferred Metadata": {
            "HF Dataset": "yelp_review_full",
            "HF Config": "yelp_review_full",
            "HF Config License": "Custom",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "2015-09-04",
            "S2 Date": "2015-09-04",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 24020,
            "HF Likes (September 2023)": 27,
            "PwC Description": "The Yelp Reviews Polarity dataset is obtained from the Yelp Dataset Challenge in 2015 (1,569,264 samples that have review text).\n\nThe polarity label is constructed by considering stars 1 and 2 negative, and 3 and 4 positive.\n\nThe polarity dataset has 280,000 training samples and 19,000 test samples in each polarity.",
            "S2 Citation Count (September 2023)": 4622,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Food and dining experience",
                "Pricing and value for money",
                "Customer experience",
                "Customer satisfaction",
                "Travel",
                "Restaurant review",
                "Restaurant reviews",
                "Customer service",
                "Food and drink",
                "Restaurant experience"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "No",
        "Bibtex": "@Article{Zhang2015CharacterlevelCN,\n author = {Xiang Zhang and J. Zhao and Yann LeCun},\n booktitle = {Neural Information Processing Systems},\n pages = {649-657},\n title = {Character-level Convolutional Networks for Text Classification},\n year = {2015}\n}\n"
    },
    "fc-sni-yoruba_bbc_topics": {
        "Unique Dataset Identifier": "fc-sni-yoruba_bbc_topics",
        "Dataset Name": "yoruba_bbc_topics",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/yoruba_bbc_topics",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/yoruba_bbc_topics",
        "Paper Title": "Transfer Learning and Distant Supervision for Multilingual Transformer Models: A Study on African Languages",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2010.03179",
        "Semantic Scholar Corpus ID": 222178270,
        "Languages": [
            "Yoruba",
            "English"
        ],
        "Task Categories": [
            "Text Classification"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 3800,
            "Mean Inputs Length": 400.5334,
            "Mean Targets Length": 8.6026,
            "Max Inputs Length": 633,
            "Max Targets Length": 23,
            "Min Inputs Length": 229,
            "Min Targets Length": 5,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "voa",
            "sadilar",
            "globalvoices.org",
            "bbc"
        ],
        "Model Generated": [
            "Other"
        ],
        "Creators": [
            "Saarland University",
            "DFKI GmBH",
            "Nuhu Bamalli Polytechnic"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://aclanthology.org/2020.emnlp-main.204/"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task612_yorubabbc_classification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "yoruba_bbc_topics",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "Unspecified",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-10-07",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 566,
            "HF Likes (September 2023)": 0,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 53,
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Cultural awareness",
                "Language processing",
                "Nigerian politics",
                "African politics",
                "Politics",
                "African culture",
                "African news",
                "Language and culture",
                "African current affairs",
                "News classification"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Hedderich2020TransferLA,\n author = {Michael A. Hedderich and David Ifeoluwa Adelani and D. Zhu and Jesujoba Oluwadara Alabi and Udia Markus and D. Klakow},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {2580-2591},\n title = {Transfer Learning and Distant Supervision for Multilingual Transformer Models: A Study on African Languages},\n year = {2020}\n}\n"
    },
    "fc-sni-youtube_caption_corrections": {
        "Unique Dataset Identifier": "fc-sni-youtube_caption_corrections",
        "Dataset Name": "youtube_caption_corrections",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://huggingface.co/datasets/youtube_caption_corrections",
        "GitHub URL": "",
        "Hugging Face URL": "https://huggingface.co/datasets/youtube_caption_corrections",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "",
        "Semantic Scholar Corpus ID": "",
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Grammar Error Correction"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 13083,
            "Mean Inputs Length": 2652.883,
            "Mean Targets Length": 830.7034,
            "Max Inputs Length": 5606,
            "Max Targets Length": 1026,
            "Min Inputs Length": 1034,
            "Min Targets Length": 176,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "youtube"
        ],
        "Model Generated": [],
        "Creators": [],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/2dot71mily/youtube_captions_corrections"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task1415_youtube_caption_corrections_grammar_correction"
        ],
        "Inferred Metadata": {
            "HF Dataset": "youtube_caption_corrections",
            "HF Config": "default",
            "HF Config License": "MIT License",
            "HF Yaml License": "MIT License",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "",
            "GitHub License": "",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 540,
            "HF Likes (September 2023)": 3,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": "",
            "GitHub Stars": "",
            "GitHub Topics": [],
            "Text Topics": [
                "Speech-to-text technology",
                "Education",
                "Mathematics",
                "Language and grammar",
                "Linguistics",
                "Language learning",
                "Language processing",
                "Education and learning",
                "Grammar"
            ]
        },
        "Human Annotation": "No",
        "Derived from Datasets": [],
        "Bibtex": ""
    },
    "fc-sni-zest": {
        "Unique Dataset Identifier": "fc-sni-zest",
        "Dataset Name": "zest",
        "Collection": "Flan Collection (Super-NaturalInstructions)",
        "Collection URL": "https://github.com/google-research/FLAN/tree/main/flan/v2",
        "Dataset URL": "https://github.com/allenai/zest",
        "GitHub URL": "https://github.com/allenai/zest",
        "Hugging Face URL": "https://huggingface.co/datasets/zest",
        "Paper Title": "Learning from Task Descriptions",
        "Papers with Code URL": "https://paperswithcode.com/dataset/zest",
        "ArXiv URL": "https://arxiv.org/abs/2011.08115",
        "Semantic Scholar Corpus ID": 226262281,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Question Generation"
        ],
        "Format": [
            "Zero-shot",
            "Few-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 291,
            "Mean Inputs Length": 1300.7216,
            "Mean Targets Length": 56.622,
            "Max Inputs Length": 1497,
            "Max Targets Length": 89,
            "Min Inputs Length": 1125,
            "Min Targets Length": 35,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "wikipedia.org",
            "whitehouse.gov",
            "nps.gov"
        ],
        "Model Generated": [],
        "Creators": [
            "Brigham Young University",
            "AI2"
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://allenai.org/data/zest"
            }
        ],
        "License Notes": "",
        "License Verified By": "",
        "Dataset Filter IDs": [
            "task120_zest_text_modification"
        ],
        "Inferred Metadata": {
            "HF Dataset": "zest",
            "HF Config": "default",
            "HF Config License": "",
            "HF Yaml License": "CC BY 4.0",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2020-11-01",
            "GitHub License": "Apache License 2.0",
            "Github Date": "",
            "HF Date": "2022-01-25",
            "HF Downloads (September 2023)": 946,
            "HF Likes (September 2023)": 1,
            "PwC Description": "A new English language dataset structured for task-oriented evaluation on unseen tasks.",
            "S2 Citation Count (September 2023)": 62,
            "GitHub Stars": 16,
            "GitHub Topics": [],
            "Text Topics": [
                "Animals",
                "Dog breeds",
                "Outdoor activities",
                "Geography",
                "Dogs",
                "Travel",
                "History",
                "Politics",
                "National Parks"
            ]
        },
        "Derived from Datasets": [],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Weller2020LearningFT,\n author = {Orion Weller and Nicholas Lourie and Matt Gardner and Matthew E. Peters},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Learning from Task Descriptions},\n volume = {abs/2011.08115},\n year = {2020}\n}\n"
    }
}