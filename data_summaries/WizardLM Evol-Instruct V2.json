{
    "wizardlm-evol_instruct2": {
        "Unique Dataset Identifier": "wizardlm-evol_instruct2",
        "Dataset Name": "evol_instruct2",
        "Collection": "WizardLM Evol-Instruct V2",
        "Collection URL": "https://github.com/nlpxucan/evol-instruct",
        "Dataset URL": "https://github.com/nlpxucan/evol-instruct",
        "GitHub URL": "https://github.com/nlpxucan/WizardLM",
        "Hugging Face URL": "https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k",
        "Paper Title": "",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2304.12244",
        "Semantic Scholar Corpus ID": 258298159,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Brainstorming",
            "Creative Writing",
            "Creativity",
            "Timeline Memory Resolution Question Answering",
            "Code Modification Question Answering",
            "Code Generation",
            "Narrative Generation",
            "Multiple Choice Question Answering",
            "Mathematical Equation Generation",
            "Motivational Dialogue Generation",
            "Open-Domain Natural Language Understanding (NLU)",
            "Open-Domain Question Answering"
        ],
        "Format": [
            "Zero-shot"
        ],
        "Text Metrics": {
            "Num Dialogs": 143000,
            "Mean Inputs Length": 602.854,
            "Mean Targets Length": 1704.9492,
            "Max Inputs Length": 22564,
            "Max Targets Length": 129267,
            "Min Inputs Length": 0,
            "Min Targets Length": 0,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [
            "OpenAI GPT-3",
            "OpenAI ChatGPT"
        ],
        "Model Generated": [
            "OpenAI GPT-3",
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "Microsoft",
            "Peking University"
        ],
        "Licenses": [
            {
                "License": "Academic Research Purposes Only",
                "License URL": "https://github.com/nlpxucan/WizardLM#disclaimer"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2304.12244"
            }
        ],
        "License Notes": "Github repo clearly states academic research purpose only under 'Disclaimer'",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "evol_instruct_v2"
        ],
        "Inferred Metadata": {
            "HF Dataset": "WizardLM/WizardLM_evol_instruct_V2_196k",
            "HF Config": "WizardLM--WizardLM_evol_instruct_V2_196k",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-04-24",
            "GitHub License": "",
            "Text Topics": [
                "Data analysis",
                "Environmental sustainability",
                "Mathematics",
                "Natural Language Processing (NLP)",
                "Programming",
                "Computer vision",
                "Data visualization",
                "Philosophy",
                "Culinary arts",
                "Coding"
            ],
            "Github Date": "",
            "HF Date": "2023-06-15",
            "HF Downloads (September 2023)": 1178,
            "HF Likes (September 2023)": 125,
            "PwC Description": "",
            "S2 Citation Count (September 2023)": 55,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "Alpaca instructions dataset"
        ],
        "Human Annotation": "Yes",
        "Bibtex": "@Article{Xu2023WizardLMEL,\n author = {Can Xu and Qingfeng Sun and Kai Zheng and Xiubo Geng and Pu Zhao and Jiazhan Feng and Chongyang Tao and Daxin Jiang},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {WizardLM: Empowering Large Language Models to Follow Complex Instructions},\n volume = {abs/2304.12244},\n year = {2023}\n}\n"
    }
}