{
    "hc3_zh-baike": {
        "Unique Dataset Identifier": "hc3_zh-baike",
        "Dataset Name": "hc3_zh_web_baike",
        "Collection": "HC3 (Chinese)",
        "Collection URL": "https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese",
        "Dataset URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection",
        "GitHub URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection",
        "Hugging Face URL": "https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese",
        "Paper Title": "How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hc3",
        "ArXiv URL": "https://arxiv.org/abs/2301.07597",
        "Semantic Scholar Corpus ID": 255998637,
        "Languages": [
            "Mandarin Chinese"
        ],
        "Task Categories": [
            "Question Answering",
            "Response Ranking",
            "Data Analysis",
            "Open-form Text Generation",
            "Creativity"
        ],
        "Format": [
            "Response Ranking"
        ],
        "Text Metrics": {
            "Num Dialogs": 4617,
            "Mean Inputs Length": 29.7795,
            "Mean Targets Length": 175.8234,
            "Max Inputs Length": 53,
            "Max Targets Length": 2605,
            "Min Inputs Length": 25,
            "Min Targets Length": 17,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 3,
            "Mean Dialog Turns": 2.9998
        },
        "Text Sources": [
            "crowdsourced",
            "web exams",
            "wikipedia.org",
            "iclinic.com",
            "healthcaremagic.com",
            "financial news",
            "financial blogs"
        ],
        "Model Generated": [
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "Shanghai University of Finance and Economics",
            "Harbin Institute of Technology",
            "Beijing Language and Culture University",
            "Xidian University",
            "Queen’s University",
            "Wind Information Co."
        ],
        "Licenses": [
            {
                "License": "CC BY-SA 4.0",
                "License URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection#dataset-copyright"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2301.07597"
            }
        ],
        "License Notes": "Provides human and ChatGPT responses for different domains and languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "baike"
        ],
        "Inferred Metadata": {
            "HF Dataset": "Hello-SimpleAI/HC3-Chinese",
            "HF Config": "all",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-01-18",
            "GitHub License": "",
            "Text Topics": [
                "Telecommunications",
                "Computer Science",
                "Information Science",
                "Computer hardware",
                "Information technology",
                "Information Technology",
                "Programming",
                "Wireless communication",
                "Networking",
                "Mathematics"
            ],
            "Github Date": "",
            "HF Date": "2023-01-18",
            "HF Downloads (September 2023)": 517,
            "HF Likes (September 2023)": 93,
            "PwC Description": "The HC3 (Human ChatGPT Comparison Corpus) dataset consists of nearly 40K questions and their corresponding human/ChatGPT answers. The motivation for this dataset was to study ChatGPT's answers in contrast to human's answers. The questions range from a wide variety of domains, including open-domain, financial, medical, legal, and psychological areas.",
            "S2 Citation Count (September 2023)": 121,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "ELI5 dataset",
            "WikiQA dataset",
            "Wikipedia",
            "Medical Dialog dataset",
            "FiQA dataset",
            "WebTextQA dataset",
            "BaikeQA dataset",
            "BaiduBake",
            "NLPCC-DBQA dataset",
            "Chinese Psychological Exams",
            "LegalQA dataset",
            "FinanceZhidao dataset"
        ],
        "Human Annotation": "Yes"
    },
    "hc3_zh-open_qa": {
        "Unique Dataset Identifier": "hc3_zh-open_qa",
        "Dataset Name": "hc3_zh_open_qa",
        "Collection": "HC3 (Chinese)",
        "Collection URL": "https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese",
        "Dataset URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection",
        "GitHub URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection",
        "Hugging Face URL": "https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese",
        "Paper Title": "How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hc3",
        "ArXiv URL": "https://arxiv.org/abs/2301.07597",
        "Semantic Scholar Corpus ID": 255998637,
        "Languages": [
            "Mandarin Chinese"
        ],
        "Task Categories": [
            "Question Answering",
            "Response Ranking",
            "Data Analysis",
            "Open-form Text Generation",
            "Creativity"
        ],
        "Format": [
            "Response Ranking"
        ],
        "Text Metrics": {
            "Num Dialogs": 3293,
            "Mean Inputs Length": 38.7145,
            "Mean Targets Length": 202.4499,
            "Max Inputs Length": 965,
            "Max Targets Length": 2003,
            "Min Inputs Length": 6,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 3,
            "Mean Dialog Turns": 2.9991
        },
        "Text Sources": [
            "crowdsourced",
            "web exams",
            "wikipedia.org",
            "iclinic.com",
            "healthcaremagic.com",
            "financial news",
            "financial blogs"
        ],
        "Model Generated": [
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "Shanghai University of Finance and Economics",
            "Harbin Institute of Technology",
            "Beijing Language and Culture University",
            "Xidian University",
            "Queen’s University",
            "Wind Information Co."
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection#dataset-copyright"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2301.07597"
            }
        ],
        "License Notes": "Provides human and ChatGPT responses for different domains and languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "open_qa"
        ],
        "Inferred Metadata": {
            "HF Dataset": "Hello-SimpleAI/HC3-Chinese",
            "HF Config": "all",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-01-18",
            "GitHub License": "",
            "Text Topics": [
                "Translation",
                "Gaming",
                "Daily routine",
                "Gaming skills and strategies",
                "Geography",
                "Film analysis",
                "Sports",
                "Celebrity endorsements",
                "Popular trends",
                "Board games and competitive gaming"
            ],
            "Github Date": "",
            "HF Date": "2023-01-18",
            "HF Downloads (September 2023)": 517,
            "HF Likes (September 2023)": 93,
            "PwC Description": "The HC3 (Human ChatGPT Comparison Corpus) dataset consists of nearly 40K questions and their corresponding human/ChatGPT answers. The motivation for this dataset was to study ChatGPT's answers in contrast to human's answers. The questions range from a wide variety of domains, including open-domain, financial, medical, legal, and psychological areas.",
            "S2 Citation Count (September 2023)": 121,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "ELI5 dataset",
            "WikiQA dataset",
            "Wikipedia",
            "Medical Dialog dataset",
            "FiQA dataset",
            "WebTextQA dataset",
            "BaikeQA dataset",
            "BaiduBake",
            "NLPCC-DBQA dataset",
            "Chinese Psychological Exams",
            "LegalQA dataset",
            "FinanceZhidao dataset"
        ],
        "Human Annotation": "Yes"
    },
    "hc3_zh-finance": {
        "Unique Dataset Identifier": "hc3_zh-finance",
        "Dataset Name": "hc3_zh_finance",
        "Collection": "HC3 (Chinese)",
        "Collection URL": "https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese",
        "Dataset URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection",
        "GitHub URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection",
        "Hugging Face URL": "https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese",
        "Paper Title": "How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hc3",
        "ArXiv URL": "https://arxiv.org/abs/2301.07597",
        "Semantic Scholar Corpus ID": 255998637,
        "Languages": [
            "Mandarin Chinese"
        ],
        "Task Categories": [
            "Question Answering",
            "Response Ranking",
            "Data Analysis",
            "Open-form Text Generation",
            "Creativity"
        ],
        "Format": [
            "Response Ranking"
        ],
        "Text Metrics": {
            "Num Dialogs": 689,
            "Mean Inputs Length": 18.1176,
            "Mean Targets Length": 153.7972,
            "Max Inputs Length": 133,
            "Max Targets Length": 1085,
            "Min Inputs Length": 2,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 3,
            "Mean Dialog Turns": 2.9826
        },
        "Text Sources": [
            "crowdsourced",
            "web exams",
            "wikipedia.org",
            "iclinic.com",
            "healthcaremagic.com",
            "financial news",
            "financial blogs"
        ],
        "Model Generated": [
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "Shanghai University of Finance and Economics",
            "Harbin Institute of Technology",
            "Beijing Language and Culture University",
            "Xidian University",
            "Queen’s University",
            "Wind Information Co."
        ],
        "Licenses": [
            {
                "License": "CC BY 4.0",
                "License URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection#dataset-copyright"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2301.07597"
            }
        ],
        "License Notes": "Provides human and ChatGPT responses for different domains and languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "finance"
        ],
        "Inferred Metadata": {
            "HF Dataset": "Hello-SimpleAI/HC3-Chinese",
            "HF Config": "all",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-01-18",
            "GitHub License": "",
            "Text Topics": [
                "Personal finance",
                "Banking services",
                "Loan application process",
                "Personal finance and loans",
                "Loan application process and requirements",
                "Customer support",
                "Credit card management",
                "Mobile banking",
                "Customer service",
                "Online banking"
            ],
            "Github Date": "",
            "HF Date": "2023-01-18",
            "HF Downloads (September 2023)": 517,
            "HF Likes (September 2023)": 93,
            "PwC Description": "The HC3 (Human ChatGPT Comparison Corpus) dataset consists of nearly 40K questions and their corresponding human/ChatGPT answers. The motivation for this dataset was to study ChatGPT's answers in contrast to human's answers. The questions range from a wide variety of domains, including open-domain, financial, medical, legal, and psychological areas.",
            "S2 Citation Count (September 2023)": 121,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "ELI5 dataset",
            "WikiQA dataset",
            "Wikipedia",
            "Medical Dialog dataset",
            "FiQA dataset",
            "WebTextQA dataset",
            "BaikeQA dataset",
            "BaiduBake",
            "NLPCC-DBQA dataset",
            "Chinese Psychological Exams",
            "LegalQA dataset",
            "FinanceZhidao dataset"
        ],
        "Human Annotation": "Yes"
    },
    "hc3_zh-legalqa": {
        "Unique Dataset Identifier": "hc3_zh-legalqa",
        "Dataset Name": "hc3_zh_legalqa",
        "Collection": "HC3 (Chinese)",
        "Collection URL": "https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese",
        "Dataset URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection",
        "GitHub URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection",
        "Hugging Face URL": "https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese",
        "Paper Title": "How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hc3",
        "ArXiv URL": "https://arxiv.org/abs/2301.07597",
        "Semantic Scholar Corpus ID": 255998637,
        "Languages": [
            "Mandarin Chinese"
        ],
        "Task Categories": [
            "Question Answering",
            "Response Ranking",
            "Data Analysis",
            "Open-form Text Generation",
            "Creativity"
        ],
        "Format": [
            "Response Ranking"
        ],
        "Text Metrics": {
            "Num Dialogs": 372,
            "Mean Inputs Length": 59.078,
            "Mean Targets Length": 144.3239,
            "Max Inputs Length": 100,
            "Max Targets Length": 1605,
            "Min Inputs Length": 11,
            "Min Targets Length": 5,
            "Min Dialog Turns": 3,
            "Max Dialog Turns": 3,
            "Mean Dialog Turns": 3.0
        },
        "Text Sources": [
            "crowdsourced",
            "web exams",
            "wikipedia.org",
            "iclinic.com",
            "healthcaremagic.com",
            "financial news",
            "financial blogs"
        ],
        "Model Generated": [
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "Shanghai University of Finance and Economics",
            "Harbin Institute of Technology",
            "Beijing Language and Culture University",
            "Xidian University",
            "Queen’s University",
            "Wind Information Co."
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection#dataset-copyright"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2301.07597"
            }
        ],
        "License Notes": "Provides human and ChatGPT responses for different domains and languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "law"
        ],
        "Inferred Metadata": {
            "HF Dataset": "Hello-SimpleAI/HC3-Chinese",
            "HF Config": "all",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-01-18",
            "GitHub License": "",
            "Text Topics": [
                "Legal advice",
                "Intellectual property rights",
                "Legal procedures and debt collection",
                "Property ownership and transfer",
                "Property law",
                "Family law",
                "Consumer rights and protection",
                "Family dynamics and responsibilities",
                "Real estate law and contracts",
                "Legal procedures and documentation"
            ],
            "Github Date": "",
            "HF Date": "2023-01-18",
            "HF Downloads (September 2023)": 517,
            "HF Likes (September 2023)": 93,
            "PwC Description": "The HC3 (Human ChatGPT Comparison Corpus) dataset consists of nearly 40K questions and their corresponding human/ChatGPT answers. The motivation for this dataset was to study ChatGPT's answers in contrast to human's answers. The questions range from a wide variety of domains, including open-domain, financial, medical, legal, and psychological areas.",
            "S2 Citation Count (September 2023)": 121,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "ELI5 dataset",
            "WikiQA dataset",
            "Wikipedia",
            "Medical Dialog dataset",
            "FiQA dataset",
            "WebTextQA dataset",
            "BaikeQA dataset",
            "BaiduBake",
            "NLPCC-DBQA dataset",
            "Chinese Psychological Exams",
            "LegalQA dataset",
            "FinanceZhidao dataset"
        ],
        "Human Annotation": "Yes"
    },
    "hc3_zh-medicine": {
        "Unique Dataset Identifier": "hc3_zh-medicine",
        "Dataset Name": "hc3_zh_medicine",
        "Collection": "HC3 (Chinese)",
        "Collection URL": "https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese",
        "Dataset URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection",
        "GitHub URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection",
        "Hugging Face URL": "https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese",
        "Paper Title": "How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hc3",
        "ArXiv URL": "https://arxiv.org/abs/2301.07597",
        "Semantic Scholar Corpus ID": 255998637,
        "Languages": [
            "Mandarin Chinese"
        ],
        "Task Categories": [
            "Question Answering",
            "Response Ranking",
            "Data Analysis",
            "Open-form Text Generation",
            "Creativity"
        ],
        "Format": [
            "Response Ranking"
        ],
        "Text Metrics": {
            "Num Dialogs": 1074,
            "Mean Inputs Length": 65.1061,
            "Mean Targets Length": 215.7756,
            "Max Inputs Length": 273,
            "Max Targets Length": 3341,
            "Min Inputs Length": 8,
            "Min Targets Length": 12,
            "Min Dialog Turns": 3,
            "Max Dialog Turns": 3,
            "Mean Dialog Turns": 3.0
        },
        "Text Sources": [
            "crowdsourced",
            "web exams",
            "wikipedia.org",
            "iclinic.com",
            "healthcaremagic.com",
            "financial news",
            "financial blogs"
        ],
        "Model Generated": [
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "Shanghai University of Finance and Economics",
            "Harbin Institute of Technology",
            "Beijing Language and Culture University",
            "Xidian University",
            "Queen’s University",
            "Wind Information Co."
        ],
        "Licenses": [
            {
                "License": "CC BY-NC 4.0",
                "License URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection#dataset-copyright"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2301.07597"
            }
        ],
        "License Notes": "Provides human and ChatGPT responses for different domains and languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "medicine"
        ],
        "Inferred Metadata": {
            "HF Dataset": "Hello-SimpleAI/HC3-Chinese",
            "HF Config": "all",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-01-18",
            "GitHub License": "",
            "Text Topics": [
                "Health",
                "Women's health",
                "Medical conditions",
                "Health and wellness",
                "Gynecological conditions",
                "Pain management",
                "Sexual health",
                "Medical treatment",
                "Women's health and menstrual cycle",
                "Women's health and gynecological conditions"
            ],
            "Github Date": "",
            "HF Date": "2023-01-18",
            "HF Downloads (September 2023)": 517,
            "HF Likes (September 2023)": 93,
            "PwC Description": "The HC3 (Human ChatGPT Comparison Corpus) dataset consists of nearly 40K questions and their corresponding human/ChatGPT answers. The motivation for this dataset was to study ChatGPT's answers in contrast to human's answers. The questions range from a wide variety of domains, including open-domain, financial, medical, legal, and psychological areas.",
            "S2 Citation Count (September 2023)": 121,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "ELI5 dataset",
            "WikiQA dataset",
            "Wikipedia",
            "Medical Dialog dataset",
            "FiQA dataset",
            "WebTextQA dataset",
            "BaikeQA dataset",
            "BaiduBake",
            "NLPCC-DBQA dataset",
            "Chinese Psychological Exams",
            "LegalQA dataset",
            "FinanceZhidao dataset"
        ],
        "Human Annotation": "Yes"
    },
    "hc3_zh-nlpcc_dbqa": {
        "Unique Dataset Identifier": "hc3_zh-nlpcc_dbqa",
        "Dataset Name": "hc3_zh_nlpcc_dbqa",
        "Collection": "HC3 (Chinese)",
        "Collection URL": "https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese",
        "Dataset URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection",
        "GitHub URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection",
        "Hugging Face URL": "https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese",
        "Paper Title": "How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hc3",
        "ArXiv URL": "https://arxiv.org/abs/2301.07597",
        "Semantic Scholar Corpus ID": 255998637,
        "Languages": [
            "Mandarin Chinese"
        ],
        "Task Categories": [
            "Question Answering",
            "Response Ranking",
            "Data Analysis",
            "Open-form Text Generation",
            "Creativity"
        ],
        "Format": [
            "Response Ranking"
        ],
        "Text Metrics": {
            "Num Dialogs": 1709,
            "Mean Inputs Length": 16.7174,
            "Mean Targets Length": 99.8568,
            "Max Inputs Length": 62,
            "Max Targets Length": 1303,
            "Min Inputs Length": 6,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 3,
            "Mean Dialog Turns": 2.9865
        },
        "Text Sources": [
            "crowdsourced",
            "web exams",
            "wikipedia.org",
            "iclinic.com",
            "healthcaremagic.com",
            "financial news",
            "financial blogs"
        ],
        "Model Generated": [
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "Shanghai University of Finance and Economics",
            "Harbin Institute of Technology",
            "Beijing Language and Culture University",
            "Xidian University",
            "Queen’s University",
            "Wind Information Co."
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection#dataset-copyright"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2301.07597"
            }
        ],
        "License Notes": "Provides human and ChatGPT responses for different domains and languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "nlpcc_dbqa"
        ],
        "Inferred Metadata": {
            "HF Dataset": "Hello-SimpleAI/HC3-Chinese",
            "HF Config": "all",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-01-18",
            "GitHub License": "",
            "Text Topics": [
                "Education",
                "History",
                "Geography",
                "School administration",
                "Education history",
                "Technology",
                "School name changes",
                "Education system in China",
                "Private universities in Japan",
                "Gaming"
            ],
            "Github Date": "",
            "HF Date": "2023-01-18",
            "HF Downloads (September 2023)": 517,
            "HF Likes (September 2023)": 93,
            "PwC Description": "The HC3 (Human ChatGPT Comparison Corpus) dataset consists of nearly 40K questions and their corresponding human/ChatGPT answers. The motivation for this dataset was to study ChatGPT's answers in contrast to human's answers. The questions range from a wide variety of domains, including open-domain, financial, medical, legal, and psychological areas.",
            "S2 Citation Count (September 2023)": 121,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "ELI5 dataset",
            "WikiQA dataset",
            "Wikipedia",
            "Medical Dialog dataset",
            "FiQA dataset",
            "WebTextQA dataset",
            "BaikeQA dataset",
            "BaiduBake",
            "NLPCC-DBQA dataset",
            "Chinese Psychological Exams",
            "LegalQA dataset",
            "FinanceZhidao dataset"
        ],
        "Human Annotation": "Yes"
    },
    "hc3_zh-psychology": {
        "Unique Dataset Identifier": "hc3_zh-psychology",
        "Dataset Name": "hc3_zh_psychology",
        "Collection": "HC3 (Chinese)",
        "Collection URL": "https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese",
        "Dataset URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection",
        "GitHub URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection",
        "Hugging Face URL": "https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese",
        "Paper Title": "How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection",
        "Papers with Code URL": "https://paperswithcode.com/dataset/hc3",
        "ArXiv URL": "https://arxiv.org/abs/2301.07597",
        "Semantic Scholar Corpus ID": 255998637,
        "Languages": [
            "Mandarin Chinese"
        ],
        "Task Categories": [
            "Question Answering",
            "Response Ranking",
            "Data Analysis",
            "Open-form Text Generation",
            "Creativity"
        ],
        "Format": [
            "Response Ranking"
        ],
        "Text Metrics": {
            "Num Dialogs": 1099,
            "Mean Inputs Length": 20.2375,
            "Mean Targets Length": 266.0828,
            "Max Inputs Length": 29,
            "Max Targets Length": 7062,
            "Min Inputs Length": 11,
            "Min Targets Length": 23,
            "Min Dialog Turns": 3,
            "Max Dialog Turns": 3,
            "Mean Dialog Turns": 3.0
        },
        "Text Sources": [
            "crowdsourced",
            "web exams",
            "wikipedia.org",
            "iclinic.com",
            "healthcaremagic.com",
            "financial news",
            "financial blogs"
        ],
        "Model Generated": [
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "Shanghai University of Finance and Economics",
            "Harbin Institute of Technology",
            "Beijing Language and Culture University",
            "Xidian University",
            "Queen’s University",
            "Wind Information Co."
        ],
        "Licenses": [
            {
                "License": "CC0 1.0",
                "License URL": "https://github.com/Hello-SimpleAI/chatgpt-comparison-detection#dataset-copyright"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2301.07597"
            }
        ],
        "License Notes": "Provides human and ChatGPT responses for different domains and languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "psychology"
        ],
        "Inferred Metadata": {
            "HF Dataset": "Hello-SimpleAI/HC3-Chinese",
            "HF Config": "all",
            "HF Config License": "",
            "HF Yaml License": "",
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Date": "2023-01-18",
            "GitHub License": "",
            "Text Topics": [
                "Relationships and emotions",
                "Personal growth and self-improvement",
                "Emotional well-being",
                "Relationship advice",
                "Relationships and Marriage",
                "Mental health and depression",
                "Self-reflection and personal growth",
                "Psychology",
                "Domestic violence",
                "Love and relationships"
            ],
            "Github Date": "",
            "HF Date": "2023-01-18",
            "HF Downloads (September 2023)": 517,
            "HF Likes (September 2023)": 93,
            "PwC Description": "The HC3 (Human ChatGPT Comparison Corpus) dataset consists of nearly 40K questions and their corresponding human/ChatGPT answers. The motivation for this dataset was to study ChatGPT's answers in contrast to human's answers. The questions range from a wide variety of domains, including open-domain, financial, medical, legal, and psychological areas.",
            "S2 Citation Count (September 2023)": 121,
            "GitHub Stars": "",
            "GitHub Topics": []
        },
        "Derived from Datasets": [
            "ELI5 dataset",
            "WikiQA dataset",
            "Wikipedia",
            "Medical Dialog dataset",
            "FiQA dataset",
            "WebTextQA dataset",
            "BaikeQA dataset",
            "BaiduBake",
            "NLPCC-DBQA dataset",
            "Chinese Psychological Exams",
            "LegalQA dataset",
            "FinanceZhidao dataset"
        ],
        "Human Annotation": "Yes"
    }
}