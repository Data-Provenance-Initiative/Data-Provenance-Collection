{
    "MSR-VTT": {
        "Unique Dataset Identifier": "msr-vtt",
        "Collection": "msr-vtt",
        "Collection URL": "https://ieeexplore.ieee.org/document/7780940",
        "Dataset Name": "MSR-VTT",
        "Paper Title": "MSR-VTT",
        "Paper URL": "https://ieeexplore.ieee.org/document/7780940",
        "GitHub URL": "",
        "Hugging Face URL": "",
        "Papers with Code URL": "https://paperswithcode.com/dataset/msr-vtt",
        "ArXiv URL": "https://ieeexplore.ieee.org/document/7780940",
        "Semantic Scholar Corpus ID": 206594535,
        "Year Released": 2016,
        "Text Sources": [
            "undisclosed web"
        ],
        "Licenses": [
            {
                "License": "Unspecified",
                "License URL": ""
            }
        ],
        "Creators": [
            "Microsoft Research"
        ],
        "Countries": [
            "United States of America"
        ],
        "License Verified By": "Vivek Sharma",
        "Video Hours": 41.2,
        "Taken Down": "False",
        "Video Sources": [
            "undisclosed web"
        ],
        "Inferred Metadata": {
            "GitHub License": "",
            "GitHub Stars (June 2024)": "",
            "GitHub Topics": "",
            "Github Date": "",
            "HF Config": "",
            "HF Config License": "",
            "HF Dataset": "",
            "HF Date": "",
            "HF Downloads (June 2024)": "",
            "HF Likes (June 2024)": "",
            "HF Yaml License": "",
            "PwC Date": "2016-01-01",
            "PwC Description": "MSR-VTT (Microsoft Research Video to Text) is a large-scale dataset for the open domain video captioning, which consists of 10,000 video clips from 20 categories, and each video clip is annotated with 20 English sentences by Amazon Mechanical Turks. There are about 29,000 unique words in all captions. The standard splits uses 6,513 clips for training, 497 clips for validation, and 2,990 clips for testing.",
            "PwC License Name": "Unspecified",
            "PwC License URL": null,
            "S2 Citation Count (June 2024)": "",
            "S2 Date": ""
        },
        "Bibtex": "@Article{Xu2016MSRVTTAL,\n author = {Jun Xu and Tao Mei and Ting Yao and Y. Rui},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {5288-5296},\n title = {MSR-VTT: A Large Video Description Dataset for Bridging Video and Language},\n year = {2016}\n}\n"
    }
}