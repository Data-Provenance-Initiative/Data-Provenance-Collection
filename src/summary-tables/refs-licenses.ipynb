{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1937b851-b7a2-4b52-adae-a4f32552376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af21738b-828d-4f9c-94fd-712f092dc766",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser('~/github/Data-Provenance-Collection'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c05ed-0cfd-42d8-82f4-79461080f91c",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0784d801-73b6-4b53-8188-1e9fd496574f",
   "metadata": {},
   "source": [
    "## List of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56769fb1-1631-46e6-af15-5b1196ba4fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('notebooks/papers.csv') \\\n",
    "    .rename({'collection': 'Collection', 'cites': 'Cite', 'modality': 'Modality'}, axis=1) \\\n",
    "    .set_index('Collection')\n",
    "\n",
    "dat['Cite'] = dat['Cite'].fillna('--').replace('--', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bdb1c56-397d-4910-93cc-bb546eaca177",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = set([y for x in dat['summary_keys'].str.split('|').tolist() for y in x])\n",
    "\n",
    "ft_files = set([\n",
    "    os.path.splitext(f)[0]\n",
    "    for f in os.listdir('data_summaries')\n",
    "    if not f.startswith('_template') and f not in ('video', 'audio')\n",
    "])\n",
    "\n",
    "vd_files = set([\n",
    "    os.path.splitext(f)[0].strip()\n",
    "    for f in os.listdir('data_summaries-video')\n",
    "    if not f.startswith('_template')\n",
    "])\n",
    "\n",
    "ad_files = set([\n",
    "    os.path.splitext(f)[0].strip()\n",
    "    for f in os.listdir('data_summaries-speech')\n",
    "    if not f.startswith('_template')\n",
    "])\n",
    "\n",
    "assert keys <= ft_files | vd_files | ad_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2516a97b-531a-4789-bfdd-9845b04cd0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcites = dat['Cite'].str.split('|').tolist()\n",
    "allcites = [x for y in allcites for x in y if x != '']\n",
    "allcites = list(set(allcites))\n",
    "\n",
    "len(allcites)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9f63d4-8588-43c1-90af-dbe5bc65f2e8",
   "metadata": {},
   "source": [
    "## Dimension data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddabc229-c3cf-4e19-8257-9c7642c6f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = {}\n",
    "for file in os.listdir('data_summaries'):\n",
    "    if file.startswith('_template'):\n",
    "        continue\n",
    "    \n",
    "    with open(os.path.join('data_summaries', file), 'rt') as f:\n",
    "        key = '.'.join(file.split('.')[:-1]).strip()\n",
    "        summaries[key] = json.load(f)\n",
    "\n",
    "for file in os.listdir('data_summaries-video'):\n",
    "    if file.startswith('_template'):\n",
    "        continue\n",
    "    \n",
    "    with open(os.path.join('data_summaries-video', file), 'rt') as f:\n",
    "        key = '.'.join(file.split('.')[:-1]).strip()\n",
    "        summaries[key] = json.load(f)\n",
    "\n",
    "for file in os.listdir('data_summaries-speech'):\n",
    "    if file.startswith('_template'):\n",
    "        continue\n",
    "    \n",
    "    with open(os.path.join('data_summaries-speech', file), 'rt') as f:\n",
    "        key = '.'.join(file.split('.')[:-1]).strip()\n",
    "        summaries[key] = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2bce0-f790-42bd-a420-ed3fde6efd1d",
   "metadata": {},
   "source": [
    "# Make tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34659407-729b-4c53-87d3-efdce68c6e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "licenses = {}\n",
    "for collection in dat.index:\n",
    "    for file in dat.loc[collection, 'summary_keys'].split('|'):\n",
    "        for k in summaries[file].keys():\n",
    "            lics = summaries[file][k]['Licenses']\n",
    "            for lic in lics:\n",
    "                licenses[collection] = licenses.get(collection, []) + [lic['License']]\n",
    "licenses = pd.Series({k : list(set(v)) for k, v in licenses.items()})\n",
    "\n",
    "dat['License'] = licenses.apply(lambda s: [v for v in s if v != 'OpenAI' and v != 'OANC'])\n",
    "license_table = dat[['License', 'Cite', 'Modality']].copy()\n",
    "\n",
    "license_table['License'] = license_table['License'].apply(lambda s: [v for v in s if v != 'OpenAI'])\n",
    "license_table['License'] = license_table['License'].apply(lambda s: [v if v != 'Academic Research Purposes Only' else 'Academic Only' for v in s])\n",
    "license_table['License'] = license_table['License'].apply(lambda s: s if 'Various' not in s else ['Various'])\n",
    "license_table['License'] = license_table['License'].apply(lambda s: s if len(s) > 0 else ['Unspecified'])\n",
    "license_table['License'] = license_table['License'].apply(lambda s: s if len(s) <= 3 else ['Various'])\n",
    "license_table['License'] = license_table['License'].str.join(', ')\n",
    "license_table.rename({'License': 'Licenses'}, axis=1, inplace=True)\n",
    "\n",
    "license_table['Cite'] = license_table['Cite'].apply(lambda s: r'\\cite{' + s.replace('|', ',') + '}')\n",
    "license_table.loc[license_table['Cite'] == r'\\cite{}', 'Cite'] = '--'\n",
    "\n",
    "audio_license_table = license_table.loc[license_table['Modality'] == 'audio'].drop('Modality', axis=1)\n",
    "text_license_table = license_table.loc[license_table['Modality'] == 'finetune'].drop('Modality', axis=1)\n",
    "video_license_table = license_table.loc[license_table['Modality'] == 'video'].drop('Modality', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3abd2b9d-b83f-4c68-a24b-3787f13caec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{longtable}{p{5cm}|p{5cm}|p{5cm}}\n",
      "\\caption[\\textbf{References and licenses: alignment tuning (text}]{\\textbf{References and licenses for alignment-tuning (text)} dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having ``Various'' licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.} \\label{tab:refs-licenses-text} \\\\\n",
      "\\toprule\n",
      "Collection & Licenses & Cite \\\\\n",
      "\\midrule\n",
      "\\endfirsthead\n",
      "\\caption[]{\\textbf{References and licenses for alignment-tuning (text)} dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having ``Various'' licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.} \\\\\n",
      "\\toprule\n",
      "Collection & Licenses & Cite \\\\\n",
      "\\midrule\n",
      "\\endhead\n",
      "\\midrule\n",
      "\\multicolumn{3}{r}{Continued on next page} \\\\\n",
      "\\midrule\n",
      "\\endfoot\n",
      "\\bottomrule\n",
      "\\endlastfoot\n",
      "10k Prompt Ranked & Unspecified & -- \\\\\n",
      "AgentInstruct & MIT License, CC BY 4.0, Unspecified & \\cite{shridharALFWorldAligningText2021,yaoWebShopScalableRealWorld2023,liuAgentBenchEvaluatingLLMs2023,zengAgentTuningEnablingGeneralized2023,dengMind2WebGeneralistAgent2023} \\\\\n",
      "Aya & Apache License 2.0 & \\cite{singhAyaDatasetOpenAccess2024} \\\\\n",
      "Bactrian-X & CC BY-NC 4.0, CC BY-SA 3.0 & \\cite{liBactrianXMultilingualReplicable2023} \\\\\n",
      "COBRA Frames & BigScience OpenRAIL-M & \\cite{zhouCOBRAFramesContextual2023} \\\\\n",
      "COIG & Various & \\cite{zhangChineseOpenInstruction2023,baiCOIGCQIAQualityAll2024} \\\\\n",
      "Capybara & Various & -- \\\\\n",
      "ChatDoctor & Unspecified & \\cite{liChatDoctorMedicalChat2023} \\\\\n",
      "ChatbotArena & CC BY 4.0, CC BY-NC 4.0 & \\cite{zhengJudgingLLMasaJudgeMTBench2023} \\\\\n",
      "Cidar & CC BY-NC 4.0 & \\cite{alyafeaiCIDARCulturallyRelevant2024} \\\\\n",
      "CollectiveCognition & MIT License & -- \\\\\n",
      "Conifer & Apache License 2.0 & \\cite{sunConiferImprovingComplex2024} \\\\\n",
      "Deita 10K & Apache License 2.0, CC BY-NC 4.0 & \\cite{liuWhatMakesGood2024} \\\\\n",
      "DialogStudio & Various & \\cite{chenActionBasedConversationsDataset2021,weiAirDialogueEnvironmentGoalOriented2018,linBiToDBilingualMultiDomain2021,chawlaCaSiNoCorpusCampsite2021,heDecouplingStrategyGeneration2018,mrksicNeuralBeliefTracker2017,qianDatabaseSearchResults2022,liuDuRecDialBilingualParallel2021,elasriFramesCorpusAdding2017,quanGECOREndtoEndGenerative2019,chenSemanticallyConditionedDialog2019a,chenKETODKnowledgeEnrichedTaskOriented2022,ericKeyValueRetrievalNetworks2017,zangMultiWOZDialogueDataset2020,shalyminovFewShotDialogueGeneration2019,martinMuDoCoCorpusMultidomain2020,peskovMultiDomainGoalOrientedDialogues2019,ericMultiWOZConsolidatedMultiDomain2019,moonOpenDialKGExplainableConversational2019,rastogiScalableMultidomainConversational2020,mosigSTARSchemaGuidedDialog2020,chiuSalesBotTransitioningChitChat2022,shahBuildingConversationalAgent2018,byrneTaskmaster1RealisticDiverse2019,mrksicFullyStatisticalNeural2018,shangUnsupervisedAbstractiveMeeting2018,rameshkumarStorytellingDialogueCritical2020,fabbriConvoSummConversationSummarization2021,chenDialogSumRealLifeScenario2021,mukherjeeECTSumNewBenchmark2022,shangUnsupervisedAbstractiveMeeting2018,zhuMediaSumLargescaleMedia2021,zhongQMSumNewBenchmark2021,gliwaSAMSumCorpusHumanannotated2019,chenSummScreenDatasetAbstractive2022,feigenblatTWEETSUMMDialogSummarization2021,liEndtoEndTrainableNonCollaborative2019,dinanSecondConversationalIntelligence2019,rashkinEmpatheticOpendomainConversation2019,baiTrainingHelpfulHarmless2022,chenPLACESPromptingLanguage2023,kimProsocialDialogProsocialBackbone2022,myersConversationalScaffoldingAnalogybased2020,reddyCoQAConversationalQuestion2019,yuCoSQLConversationalTexttoSQL2019,talmorWebKnowledgeBaseAnswering2018,nanDARTOpenDomainStructured2021,nanFeTaQAFreeformTable2022,guThreeLevelsGeneralization2021,chenHybridQADatasetMultiHop2020,guptaMMQAMultidomainMultilingual2018,liMTOPComprehensiveMultilingual2021,talmorMultiModalQAComplexQuestion2021,yuSParCCrossDomainSemantic2019,iyyerSearchbasedNeuralStructured2017,yuSpiderLargeScaleHumanLabeled2019,parikhToTToControlledTableToText2020,yihValueSemanticParse2016,zhongSeq2SQLGeneratingStructured2017,pasupatCompositionalSemanticParsing2015,komeiliInternetAugmentedDialogueGeneration2022,dinanWizardWikipediaKnowledgePowered2019,hemphillATISSpokenLanguage1990,casanuevaEfficientIntentDetection2020,zhangArePretrainedTransformers2022,larsonEvaluationDatasetIntent2019,rastogiScalableMultidomainConversational2020,liuBenchmarkingNaturalLanguage2019,liuAsgardPortableArchitecture2013,coopeSpanConveRTFewshotSpan2020,couckeSnipsVoicePlatform2018,guptaSemanticParsingTask2018} \\\\\n",
      "EverythingLM & MIT License & -- \\\\\n",
      "ExpertQA & MIT License & \\cite{malaviyaExpertQAExpertCuratedQuestions2024} \\\\\n",
      "Feedback Coll. & MIT License & \\cite{kimPrometheusInducingFinegrained2024} \\\\\n",
      "Glaive Code Asst. & Apache License 2.0 & -- \\\\\n",
      "Gretel Text-to-SQL & Apache License 2.0 & -- \\\\\n",
      "HelpSteer & CC BY 4.0 & \\cite{wangHelpSteerMultiattributeHelpfulness2023} \\\\\n",
      "Indic-Instr. & Various & \\cite{galaAiravataIntroducingHindi2024} \\\\\n",
      "KIWI & CC BY-SA 4.0 & \\cite{xuKIWIDatasetKnowledgeIntensive2024} \\\\\n",
      "LMSYS-Chat-1M & LMSYS-Chat-1M Dataset License, Anthropic, Llama 2 & \\cite{zhengLMSYSChat1MLargeScaleRealWorld2024} \\\\\n",
      "Llama2-MedTuned-Instr. & CC BY-NC 4.0 & \\cite{rohanianExploringEffectivenessInstruction2023} \\\\\n",
      "LongAlign-10k & Apache License 2.0, Anthropic & \\cite{baiLongAlignRecipeLong2024} \\\\\n",
      "MathDial & CC BY-SA 4.0, MIT License & \\cite{macinaMathDialDialogueTutoring2023} \\\\\n",
      "MathInstr. & MIT License & \\cite{yueMAmmoTHBuildingMath2023} \\\\\n",
      "MedInstr. & Unspecified & \\cite{zhangAlpaCareInstructiontunedLarge2024} \\\\\n",
      "Medical Meadow & Various & \\cite{hanMedAlpacaOpenSourceCollection2023,wangCORD19COVID19Open2020,jinWhatDiseaseDoes2020,saveryQuestionDrivenSummarizationAnswers2020} \\\\\n",
      "MegaWika & CC BY-SA 4.0 & \\cite{barhamMegaWikaMillionsReports2023} \\\\\n",
      "MetaMathQA & MIT License & \\cite{yuMetaMathBootstrapYour2023} \\\\\n",
      "Nectar & Various & -- \\\\\n",
      "No Robots & CC BY-NC 4.0 & -- \\\\\n",
      "Open Asst. v2 & Apache License 2.0 & \\cite{kopfOpenAssistantConversationsDemocratizing2023} \\\\\n",
      "Open-Platypus & Various & \\cite{sawadaARBAdvancedReasoning2023,dettmersQLoRAEfficientFinetuning2023,lightmanLetVerifyStep2023a,yuReClorReadingComprehension2020,wangSciBenchEvaluatingCollegeLevel2024,luLearnExplainMultimodal2022,chenTheoremQATheoremdrivenQuestion2023} \\\\\n",
      "OpenGPT Healthcare & Unspecified, OGL 3.0 & -- \\\\\n",
      "OpenMathInstr.-1 & Apache License 2.0, MIT License, Custom & \\cite{toshniwalOpenMathInstruct1MillionMath2024} \\\\\n",
      "Orca-Math & Various & \\cite{mitraOrcaMathUnlockingPotential2024} \\\\\n",
      "PII-Masking-200k & Non Commercial & -- \\\\\n",
      "PMC-LLaMA Instr. & Apache License 2.0, Unspecified & \\cite{wuPMCLLaMABuildingOpensource2023,jinPubMedQADatasetBiomedical2019} \\\\\n",
      "Pure-Dove & Apache License 2.0 & -- \\\\\n",
      "PygmalionAI-PIPPA & Apache License 2.0 & \\cite{goslingPIPPAPartiallySynthetic2023} \\\\\n",
      "RiddleSense & MIT License & \\cite{linRiddleSenseReasoningRiddle2021} \\\\\n",
      "SeaBench & Apache License 2.0 & \\cite{nguyenSeaLLMsLargeLanguage2023} \\\\\n",
      "SelFee & MIT License & \\cite{yeSelFeeIterativeSelfRevising2023} \\\\\n",
      "Thai Gen AI & Various & -- \\\\\n",
      "UltraChat-200k & CC BY-NC 4.0 & \\cite{dingEnhancingChatLanguage2023} \\\\\n",
      "UltraFeedback Argilla & Various & -- \\\\\n",
      "WildChat & AI2 ImpACT License - Low Risk & \\cite{zhaoWildChat1MChatGPT2023} \\\\\n",
      "\\end{longtable}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    'environment': 'longtable',\n",
    "    \n",
    "    'label': 'tab:refs-licenses-text',\n",
    "    'column_format': 'p{5cm}|p{5cm}|p{5cm}',\n",
    "    \n",
    "    'caption': (r'''\n",
    "    \\textbf{References and licenses for alignment-tuning (text)} dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having ``Various'' licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.\n",
    "    '''.strip(), r'\\textbf{References and licenses: alignment tuning (text}'),\n",
    "    \n",
    "    'hrules': True,\n",
    "    'convert_css': True,\n",
    "}\n",
    "\n",
    "print(text_license_table\n",
    "    .sort_index()\n",
    "    .reset_index()\n",
    "    .style\n",
    "    .hide()\n",
    "    .to_latex(**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa945fa4-75d7-4b50-aeb5-52e126e219e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{longtable}{p{5cm}|p{5cm}|p{5cm}}\n",
      "\\caption[\\textbf{References and licenses: audio}]{\\textbf{References and licenses for audio} dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having ``Various'' licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.} \\label{tab:refs-licenses-audio} \\\\\n",
      "\\toprule\n",
      "Collection & Licenses & Cite \\\\\n",
      "\\midrule\n",
      "\\endfirsthead\n",
      "\\caption[]{\\textbf{References and licenses for audio} dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having ``Various'' licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.} \\\\\n",
      "\\toprule\n",
      "Collection & Licenses & Cite \\\\\n",
      "\\midrule\n",
      "\\endhead\n",
      "\\midrule\n",
      "\\multicolumn{3}{r}{Continued on next page} \\\\\n",
      "\\midrule\n",
      "\\endfoot\n",
      "\\bottomrule\n",
      "\\endlastfoot\n",
      "1111 Hours Hindi & Custom & \\cite{bhanushaliGramVaaniASR2022} \\\\\n",
      "120h Spanish Speech & CC0 1.0 & -- \\\\\n",
      "AFRISPEECH-200 & CC BY-NC-SA 4.0 & \\cite{olatunjiAfriSpeech200PanAfricanAccented2023} \\\\\n",
      "AISHELL-1 & Apache 2.0 & \\cite{buAISHELL1OpenSourceMandarin2017} \\\\\n",
      "AISHELL-2 & Unspecified & \\cite{duAISHELL2TransformingMandarin2018} \\\\\n",
      "AISHELL-4 & CC BY-SA 4.0 & \\cite{fuAISHELL4OpenSource2021} \\\\\n",
      "ALLSSTAR & CC BY 4.0 & \\cite{bradlowALLSSTARArchiveL12010} \\\\\n",
      "AMI & CC BY 4.0 & \\cite{carlettaAMIMeetingCorpus2006} \\\\\n",
      "Aalto Finnish Parl. & Custom & \\cite{virkkunenFinnishParliamentASR2022} \\\\\n",
      "African Acc. French & Apache 2.0 & -- \\\\\n",
      "Basq., Cat. and Gal. & CC BY-SA 4.0 & \\cite{kjartanssonOpenSourceHighQuality2020} \\\\\n",
      "Bloom Speech & Various & \\cite{leongBloomLibraryMultimodal2022} \\\\\n",
      "Bud500 & Apache 2.0, CC BY-NC-SA 4.0 & -- \\\\\n",
      "CSJ & Custom & \\cite{maekawaCorpusSpontaneousJapanese2003} \\\\\n",
      "CSLU 1.2 & CSLU Agreement & \\cite{landertCSLUForeignAccented2007} \\\\\n",
      "CSLU 22 Langs. & CSLU Agreement & \\cite{landertCSLU22Languages2005} \\\\\n",
      "ClarinPL & CC BY 4.0 & \\cite{korzinekPolishReadSpeech2017} \\\\\n",
      "CoNASE & Custom & \\cite{coatsCorpusRegionalAmerican2019} \\\\\n",
      "CoVoST-2 & CC0 1.0 & \\cite{wangCoVoSTMassivelyMultilingual2020} \\\\\n",
      "Common Voice 17 & CC0 1.0 & \\cite{ardilaCommonVoiceMassivelyMultilingual2020} \\\\\n",
      "Crowd Sourced Speech & CC BY-SA 4.0 & \\cite{kjartanssonCrowdSourcedSpeechCorpora2018} \\\\\n",
      "Czech Parliament & CC BY 4.0 & \\cite{kratochvilLargeCorpusCzech2020} \\\\\n",
      "DiDiSpeech & Unspecified & \\cite{guoDiDiSpeechLargeScale2021} \\\\\n",
      "Earnings-22 & Unspecified & \\cite{delrioEarnings22PracticalBenchmark2022} \\\\\n",
      "EdAcc & CC BY-SA 4.0 & \\cite{sanabriaEdinburghInternationalAccents2023} \\\\\n",
      "Eng. Acc. in Brit. Isles & CC BY-SA 4.0 & \\cite{demirsahinOpensourceMultispeakerCorpora2020} \\\\\n",
      "English-Vietnamese & CC BY-NC-ND 4.0 & \\cite{nguyenHighQualityLargeScaleDataset2022} \\\\\n",
      "FT SPEECH & Custom & \\cite{kirkedalFTSpeechDanish2020} \\\\\n",
      "Fisher & LDC User Agreement & \\cite{cieriFisherCorpusResource2004} \\\\\n",
      "Fleurs & CC BY 4.0 & \\cite{conneauFLEURSFewshotLearning2022} \\\\\n",
      "GigaSpeech & Apache 2.0 & \\cite{chenGigaSpeechEvolvingMultidomain2021} \\\\\n",
      "Golos & Custom & \\cite{karpovGolosRussianDataset2021} \\\\\n",
      "Hebrew Coursera & Unspecified & -- \\\\\n",
      "Hebrew Kan & Unspecified & -- \\\\\n",
      "Highland Puebla Nahuatl & CC BY-NC-SA 3.0 & \\cite{shiHighlandPueblaNahuatl2021} \\\\\n",
      "JTUBESPEECH & Unspecified & \\cite{takamichiJTubeSpeechCorpusJapanese2021} \\\\\n",
      "Japanese Anime Speech & CC0 1.0 & -- \\\\\n",
      "KSC & CC BY 4.0 & \\cite{khassanovCrowdsourcedOpenSourceKazakh2021} \\\\\n",
      "Kathbath & CC0 1.0 & \\cite{javedIndicSUPERBSpeechProcessing2022} \\\\\n",
      "KeSpeech & Custom & \\cite{tangKeSpeechOpenSource2021} \\\\\n",
      "KsponSpeech & Unspecified & \\cite{bangKsponSpeechKoreanSpontaneous2020} \\\\\n",
      "LJSpeech & Public Domain & \\cite{itoLJSpeechDataset2017} \\\\\n",
      "LaboroTVSpeech & Custom & \\cite{andoConstructionLargescaleJapanese2021} \\\\\n",
      "LibriSpeech & CC BY 4.0 & \\cite{panayotovLibrispeechASRCorpus2015} \\\\\n",
      "M-AILABS & Custom & \\cite{solakMAILABSSpeechDataset2024} \\\\\n",
      "M2ASR & Unspecified & \\cite{shiFreeKazakhSpeech2017,mamtiminM2ASRKIRGHIZFreeKirghiz2023,zhiM2ASRMONGOFreeMongolian2021,liFreeLinguisticSpeech2017} \\\\\n",
      "MAGICDATA & CC BY-NC-ND 4.0 & -- \\\\\n",
      "MASC & CC BY 4.0 & \\cite{al-fetyaniMASCMassiveArabic2023} \\\\\n",
      "MaSS & Unspecified & \\cite{boitoMaSSLargeClean2020} \\\\\n",
      "MagicData-RAMC & CC BY-NC-ND 4.0 & \\cite{yangOpenSourceMagicDataRAMC2022} \\\\\n",
      "MediaSpeech & CC BY 4.0 & \\cite{kolobovMediaSpeechMultilanguageASR2021} \\\\\n",
      "Minds14 & CC BY 4.0 & \\cite{gerzMultilingualCrossLingualIntent2021} \\\\\n",
      "MuST-C & CC BY-NC-ND 4.0 & \\cite{digangiMuSTCMultilingualSpeech2019} \\\\\n",
      "Multiling. LibriSpeech & CC BY 4.0 & \\cite{pratapMLSLargeScaleMultilingual2020} \\\\\n",
      "Multiling. TEDx & CC BY-NC-ND 4.0 & \\cite{saleskyMultilingualTEDxCorpus2021} \\\\\n",
      "NST Danish & CC0 1.0 & -- \\\\\n",
      "NST Norwegian & CC0 1.0 & -- \\\\\n",
      "NST Swedish & CC0 1.0 & -- \\\\\n",
      "Nigerian English & CC BY-SA 4.0 & -- \\\\\n",
      "Norwegian Parl. & CC0 1.0 & \\cite{solbergNorwegianParliamentarySpeech2022} \\\\\n",
      "Norwegian Parl. Speech & CC0 1.0 & \\cite{solbergNorwegianParliamentarySpeech2022} \\\\\n",
      "OLKAVS & Custom & \\cite{parkOLKAVSOpenLargeScale2023} \\\\\n",
      "OpenSTT & CC BY-NC 4.0 & \\cite{andrusenkoExplorationEndtoEndASR2020} \\\\\n",
      "People's Speech & Various & \\cite{galvezPeopleSpeechLargeScale2021} \\\\\n",
      "QASR & Unspecified & \\cite{mubarakQASRQCRIAljazeera2021} \\\\\n",
      "RTVE & Custom & -- \\\\\n",
      "ReazonSpeech & CDLA-Sharing-1.0 & \\cite{yinReazonSpeechFreeMassive2023} \\\\\n",
      "Regional Af. Am. Lang. & CC BY-NC-SA 4.0 & -- \\\\\n",
      "RixVox & CC BY 4.0 & -- \\\\\n",
      "SDS-200 & Custom & \\cite{plussSDS200SwissGerman2022} \\\\\n",
      "SPGISpeech & Custom & \\cite{oneillSPGISpeech000Hours2021} \\\\\n",
      "Samromur & CC BY 4.0 & \\cite{mollbergSamromurCrowdsourcingData2020} \\\\\n",
      "Samromur Children & CC BY 4.0 & \\cite{hernandezmenaSamromurChildrenIcelandic2022} \\\\\n",
      "Samromur Milljon & CC BY 4.0 & -- \\\\\n",
      "Shrutilipi & CC0 1.0 & \\cite{bhogaleEffectivenessMiningAudio2022} \\\\\n",
      "Snow Mountain & CC BY-SA 4.0 & \\cite{rajuSnowMountainDataset2023} \\\\\n",
      "Spoken Wikipedia & CC BY-SA 4.0 & \\cite{baumannSpokenWikipediaCorpus2019} \\\\\n",
      "Switchboard & LDC User Agreement & \\cite{godfreySWITCHBOARDTelephoneSpeech1992} \\\\\n",
      "TED-LIUM3 & CC BY-NC-ND 3.0 & \\cite{hernandezTEDLIUMTwiceMuch2018} \\\\\n",
      "THCHS-30 & Apache 2.0 & \\cite{wangTHCHS30FreeChinese2015} \\\\\n",
      "THUYG-20 & Apache 2.0 & \\cite{roziOpenFreeDatabase2015} \\\\\n",
      "TIMIT & LDC User Agreement & \\cite{garofolojohns.TIMITAcousticPhoneticContinuous1993} \\\\\n",
      "VCTK & CC BY 4.0 & -- \\\\\n",
      "VibraVox & CC BY 4.0 & -- \\\\\n",
      "VoxPopuli & CC0 1.0 & \\cite{wangVoxPopuliLargeScaleMultilingual2021} \\\\\n",
      "Vystadial & CC BY-SA 3.0 & \\cite{korvasFreeEnglishCzech2014} \\\\\n",
      "WenetSpeech & CC BY 4.0 & \\cite{zhangWenetSpeech10000Hours2022} \\\\\n",
      "West Afr. Radio & CC BY-SA 4.0 & \\cite{doumbouyaUsingRadioArchives2021} \\\\\n",
      "West Afr. Virt. Asst. & CC BY-SA 4.0 & \\cite{doumbouyaUsingRadioArchives2021} \\\\\n",
      "YODAS & CC BY 3.0 & \\cite{liYodasYoutubeOrientedDataset2023} \\\\\n",
      "Zeroth-Korean & CC BY 4.0 & -- \\\\\n",
      "aidatatang & CC BY-NC-ND 4.0 & -- \\\\\n",
      "\\end{longtable}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    'environment': 'longtable',\n",
    "    \n",
    "    'label': 'tab:refs-licenses-audio',\n",
    "    'column_format': 'p{5cm}|p{5cm}|p{5cm}',\n",
    "    \n",
    "    'caption': (r'''\n",
    "    \\textbf{References and licenses for audio} dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having ``Various'' licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.\n",
    "    '''.strip(), r'\\textbf{References and licenses: audio}'),\n",
    "    \n",
    "    'hrules': True,\n",
    "    'convert_css': True,\n",
    "}\n",
    "\n",
    "print(audio_license_table\n",
    "    .sort_index()\n",
    "    .reset_index()\n",
    "    .style\n",
    "    .hide()\n",
    "    .to_latex(**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32200837-fc0a-49b6-86ba-65b5a08b3170",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{longtable}{p{5cm}|p{5cm}|p{5cm}}\n",
      "\\caption[\\textbf{References and licenses: video}]{\\textbf{References and licenses for video} dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having ``Various'' licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.} \\label{tab:refs-licenses-video} \\\\\n",
      "\\toprule\n",
      "Collection & Licenses & Cite \\\\\n",
      "\\midrule\n",
      "\\endfirsthead\n",
      "\\caption[]{\\textbf{References and licenses for video} dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having ``Various'' licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.} \\\\\n",
      "\\toprule\n",
      "Collection & Licenses & Cite \\\\\n",
      "\\midrule\n",
      "\\endhead\n",
      "\\midrule\n",
      "\\multicolumn{3}{r}{Continued on next page} \\\\\n",
      "\\midrule\n",
      "\\endfoot\n",
      "\\bottomrule\n",
      "\\endlastfoot\n",
      "100DOH & Custom & \\cite{shanUnderstandingHumanHands2020} \\\\\n",
      "20BN-SOMETHING & Custom & \\cite{goyalSomethingSomethingVideo2017} \\\\\n",
      "20BN-jester & Custom & \\cite{materzynskaJesterDatasetLargeScale2019} \\\\\n",
      "50 Salads & CC BY-NC-SA 4.0 & \\cite{steinCombiningEmbeddedAccelerometers2013} \\\\\n",
      "ActivityNet & MIT License & \\cite{heilbronActivityNetLargescaleVideo2015} \\\\\n",
      "Apes & Unspecified & \\cite{alcazarAPESAudiovisualPerson2021} \\\\\n",
      "Ava & CC BY 4.0 & \\cite{rothAVAActiveSpeakerAudioVisualDataset2019,guAVAVideoDataset2018} \\\\\n",
      "Breakfast & CC BY 4.0 & \\cite{kuehneLanguageActionsRecovering2014} \\\\\n",
      "CDAD & Unspecified & \\cite{xiangCDADCommonDaily2022} \\\\\n",
      "COIN & Custom & \\cite{tangCOINLargescaleDataset2019} \\\\\n",
      "Charades & Custom & \\cite{sigurdssonHollywoodHomesCrowdsourcing2016} \\\\\n",
      "Charades-Ego & Custom & \\cite{sigurdssonActorObserverJoint2018} \\\\\n",
      "Collective & Unspecified & \\cite{wongunchoiWhatAreThey2009} \\\\\n",
      "Condensed Movies & CC BY 4.0 & \\cite{bainCondensedMoviesStory2020} \\\\\n",
      "CrossTask & Unspecified & \\cite{zhukovCrosstaskWeaklySupervised2019} \\\\\n",
      "Davis & Custom & \\cite{perazziBenchmarkDatasetEvaluation2016} \\\\\n",
      "DiDeMo & BSD 2-Clause License & \\cite{hendricksLocalizingMomentsVideo2018} \\\\\n",
      "EEV & CC BY 4.0 & \\cite{sunEEVLargeScaleDataset2021} \\\\\n",
      "EPIC-KITCHENS & CC BY-NC 4.0 & \\cite{damenScalingEgocentricVision2018} \\\\\n",
      "Ego4D & MIT License, Custom & \\cite{graumanEgo4DWorld0002022} \\\\\n",
      "FERV39k & CC BY-NC 4.0 & \\cite{wangFERV39kLargeScaleMultiScene2022} \\\\\n",
      "FineGym & CC BY-NC 4.0 & \\cite{shaoFineGymHierarchicalVideo2020} \\\\\n",
      "HAA500 & Unspecified & \\cite{chungHAA500HumanCentricAtomic2021} \\\\\n",
      "HACS & Custom & \\cite{zhaoHACSHumanAction2019} \\\\\n",
      "HD-VILA-100M & Custom & \\cite{xueAdvancingHighResolutionVideoLanguage2022} \\\\\n",
      "HMDB & CC BY 4.0 & \\cite{kuehneHMDBLargeVideo2011} \\\\\n",
      "HOLLYWOOD2 & Unspecified & \\cite{marszalekActionsContext2009} \\\\\n",
      "HOMAGE & Unspecified & \\cite{raiHomeActionGenome2021} \\\\\n",
      "HVU & Custom & \\cite{dibaLargeScaleHolistic2020} \\\\\n",
      "Hollywood Ext. & MIT License & \\cite{bojanowskiWeaklySupervisedAction2014} \\\\\n",
      "How2 & Various & \\cite{sanabriaHow2LargescaleDataset2018} \\\\\n",
      "HowTo100M & Unspecified & \\cite{miechHowTo100MLearningTextVideo2019} \\\\\n",
      "ImageNet-Vid & CC BY-NC 4.0 & \\cite{russakovskyImageNetLargeScale2015} \\\\\n",
      "Kinetics & Unspecified & \\cite{kayKineticsHumanAction2017,carreiraShortNoteKinetics6002018,smairaShortNoteKinetics70020202020} \\\\\n",
      "LEMMA & Unspecified & \\cite{jiaLEMMAMultiviewDataset2020} \\\\\n",
      "LSMDC & MIT License, Custom & \\cite{rohrbachMovieDescription2016,sharmaDeepMultimodalFeature2020} \\\\\n",
      "M-MiT & Unspecified & \\cite{monfortMultiMomentsTimeLearning2021} \\\\\n",
      "MAD & Custom & \\cite{soldanMADScalableDataset2022} \\\\\n",
      "MMAct & Custom & \\cite{kongMMActLargeScaleDataset2019} \\\\\n",
      "MPII & Custom, Unspecified & \\cite{rohrbachRecognizingFineGrainedComposite2016,rohrbachDatasetMovieDescription2015} \\\\\n",
      "MSA & Unspecified & \\cite{xiongGraphBasedFrameworkBridge2019} \\\\\n",
      "MSR-VTT & Unspecified & \\cite{xuMSRVTTLargeVideo2016} \\\\\n",
      "Mars & Unspecified & \\cite{zhengMARSVideoBenchmark2016} \\\\\n",
      "Mimetics & Unspecified & \\cite{weinzaepfelMimeticsUnderstandingHuman2021} \\\\\n",
      "Moments in Time & Custom & \\cite{monfortMomentsTimeDataset2019} \\\\\n",
      "Movie-Net & Unspecified & \\cite{huangMovieNetHolisticDataset2020} \\\\\n",
      "MovieGraphs & Custom & \\cite{vicolMovieGraphsUnderstandingHumanCentric2018} \\\\\n",
      "MovieQA & Unspecified & \\cite{tapaswiMovieQAUnderstandingStories2016} \\\\\n",
      "MovieScenes & Unspecified & \\cite{raoLocaltoGlobalApproachMultimodal2020} \\\\\n",
      "MultiTHUMOS & CC BY 4.0 & \\cite{yeungEveryMomentCounts2017} \\\\\n",
      "NTU RGB+D & Custom & \\cite{shahroudyNTURGBLarge2016} \\\\\n",
      "Narrated Instr. Vid. & MIT License & \\cite{alayracUnsupervisedLearningNarrated2016} \\\\\n",
      "OmniSource-Web & Apache License 2.0 & \\cite{duanOmnisourcedWeblysupervisedLearning2020} \\\\\n",
      "Oops! & CC BY-NC-SA 4.0 & \\cite{epsteinOopsPredictingUnintentional2020} \\\\\n",
      "PKU-MMD & Unspecified & \\cite{liuPKUMMDLargeScale2017} \\\\\n",
      "Project-Aria & Apache License 2.0 & \\cite{panAriaDigitalTwin2023,lvAriaEverydayActivities2024} \\\\\n",
      "QFVS & Unspecified & \\cite{sharghiQueryFocusedVideoSummarization2017} \\\\\n",
      "QuerYD & Unspecified & \\cite{oncescuQuerYDVideoDataset2021} \\\\\n",
      "RareAct & Unspecified & \\cite{miechRareActVideoDataset2020} \\\\\n",
      "SOA & Unspecified & \\cite{dibaLargeScaleHolistic2020} \\\\\n",
      "Spoken Moments & Custom & \\cite{monfortSpokenMomentsLearning2021} \\\\\n",
      "Sports-1M & CC BY 3.0 & \\cite{karpathyLargeScaleVideoClassification2014} \\\\\n",
      "StoryGraphs & Unspecified & \\cite{tapaswiStoryGraphsVisualizingCharacter2014} \\\\\n",
      "SumMe & Unspecified & \\cite{gygliCreatingSummariesUser2014} \\\\\n",
      "TGIF & Custom & \\cite{liTGIFNewDataset2016} \\\\\n",
      "THUMOS & Custom & \\cite{idreesTHUMOSChallengeAction2017} \\\\\n",
      "TITAN & Non Commercial & \\cite{mallaTITANFutureForecast2020} \\\\\n",
      "TRECVid & CC BY-NC-SA 4.0 & \\cite{awadTRECVID2019Evaluation2020} \\\\\n",
      "TVSum & CC BY 3.0 & \\cite{yalesongTVSumSummarizingWeb2015} \\\\\n",
      "TinyVIRAT & Unspecified & \\cite{demirTinyVIRATLowresolutionVideo2020} \\\\\n",
      "Toyota Smarthome & Custom & \\cite{dasToyotaSmarthomeRealWorld2019} \\\\\n",
      "UAV-Human & Custom & \\cite{liUAVHumanLargeBenchmark2021} \\\\\n",
      "UCF101 & Unspecified & \\cite{soomroUCF101Dataset1012012} \\\\\n",
      "VIOLIN & Unspecified & \\cite{liuVIOLINLargeScaleDataset2020} \\\\\n",
      "VLOG & Custom & \\cite{fouheyLifestyleVlogsEveryday2017} \\\\\n",
      "VTW & Unspecified & \\cite{zengTitleGenerationUser2016} \\\\\n",
      "VaTeX & CC BY 4.0 & \\cite{wangVATEXLargeScaleHighQuality2020} \\\\\n",
      "VideoLT & Non Commercial & \\cite{zhangVideoLTLargescaleLongtailed2021} \\\\\n",
      "VideoStory & Unspecified & \\cite{habibianVideoStoryNewMultimedia2014} \\\\\n",
      "Volleyball & Unspecified & \\cite{ibrahimHierarchicalDeepTemporal2016} \\\\\n",
      "VoxCeleb & Custom & \\cite{nagraniVoxCelebLargescaleSpeaker2018} \\\\\n",
      "WebVid & Custom & \\cite{bainFrozenTimeJoint2022} \\\\\n",
      "YouCook & Unspecified & \\cite{dasThousandFramesJust2013} \\\\\n",
      "YouCook2 & MIT License & \\cite{zhouAutomaticLearningProcedures2017} \\\\\n",
      "Youtube-8M & Unspecified & \\cite{abu-el-haijaYouTube8MLargeScaleVideo2016} \\\\\n",
      "\\end{longtable}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    'environment': 'longtable',\n",
    "    \n",
    "    'label': 'tab:refs-licenses-video',\n",
    "    'column_format': 'p{5cm}|p{5cm}|p{5cm}',\n",
    "    \n",
    "    'caption': (r'''\n",
    "    \\textbf{References and licenses for video} dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having ``Various'' licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.\n",
    "    '''.strip(), r'\\textbf{References and licenses: video}'),\n",
    "    \n",
    "    'hrules': True,\n",
    "    'convert_css': True,\n",
    "}\n",
    "\n",
    "print(video_license_table\n",
    "    .sort_index()\n",
    "    .reset_index()\n",
    "    .style\n",
    "    .hide()\n",
    "    .to_latex(**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c730a4c9-a2f4-46ce-986a-08bbf59381b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DPC",
   "language": "python",
   "name": "pdc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
