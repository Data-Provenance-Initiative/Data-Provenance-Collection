{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q -U pandas altair vega_datasets iso3166"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Append system path\n",
    "sys.path = [p for p in sys.path if not p.endswith(\"../..\")]  # Cleans duplicated '../..'\n",
    "sys.path.insert(0, \"../\")  # This adds `src` to the path\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows() # Allow using more than 5000 rows, for now\n",
    "from collections import defaultdict\n",
    "from vega_datasets import data\n",
    "from iso3166 import countries\n",
    "from helpers import io, filters\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Utility functions to process and transform data summaries:\n",
    "\n",
    "---\n",
    "```python\n",
    "def invert_dict_of_lists(\n",
    "  d: dict[str, list[str]]\n",
    ") -> dict[str, str]\n",
    "```\n",
    "- Inverts a dictionary of lists for easier mapping of constants.\n",
    "---\n",
    "```python\n",
    "def remap_licenses_with_paraphrases(\n",
    "  summaries: list[dict[str, Any]],\n",
    "  paraphrases: dict[str, str]\n",
    ") -> dict[str, Any]\n",
    "``` \n",
    "- Standardizes inconsistent license names in data summaries using predefined paraphrases.\n",
    "---\n",
    "```python\n",
    "def map_license_criteria_multimodal(\n",
    "  data_summary: list[dict[str, Any]],\n",
    "  all_constants: dict[str, dict[str, list[str]]]\n",
    ") -> list[dict[str, Any]]\n",
    "```\n",
    "- Maps license criteria for multimodal datasets, resolving them according to predefined constants.\n",
    "---\n",
    "```python\n",
    "def get_country(x: str) -> list[int]\n",
    "```\n",
    "- Takes a country name as input and returns a list of ISO3166 codes (mostly, of length 1). It handles a special case that appears in some text annotations (\"African Continent\" -> list of ISO codes) and logs a warning for any countries not found in the mapping.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_dict_of_lists(d: dict[str, list[str]]) -> dict[str, str]:\n",
    "    \"\"\"Useful for mapping constants, paraphrases, etc.\n",
    "    These are normally in the form:\n",
    "        { \"Category\": [\"item1\", \"item2\", … ] }\n",
    "    Whereas we want to invert it to:\n",
    "        { \"item1\": \"Category\", \"item2\": \"Category\", … }\n",
    "    \"\"\"\n",
    "    inverted = {}\n",
    "    for k, v in d.items():\n",
    "        for item in v:\n",
    "            inverted[item] = k\n",
    "    return inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_licenses_with_paraphrases(\n",
    "        summaries: list[dict[str, Any]],\n",
    "        paraphrases: dict[str, str]\n",
    "    ) -> dict[str, Any]:\n",
    "    \"\"\"Map inconsistent license names to shared paraphrases using the constants.\n",
    "    E.g. \"CC-BY-SA 4.0\", \"CC BY SA 4.0\" -> \"CC BY-SA 4.0\"\n",
    "    \"\"\"\n",
    "\n",
    "    for i, summary in enumerate(summaries):\n",
    "        for j, license in enumerate(summary[\"Licenses\"]):\n",
    "            license = license[\"License\"]\n",
    "            summaries[i][\"Licenses\"][j][\"License\"] = paraphrases.get(\n",
    "                license,\n",
    "                license\n",
    "            )\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_resolve_licenses(\n",
    "    license_infos: list[tuple[str, str]],\n",
    "    all_constants: dict[str, dict[str, list[str]]]\n",
    ") -> list[str]:\n",
    "    \"\"\"Function taken from `text_ft_plots.ipynb`\"\"\"\n",
    "    classified_licenses = []\n",
    "    for (license_name, license_url) in license_infos:\n",
    "        # Classify an individual license\n",
    "        classifications = filters.classify_license(license_name, license_url, all_constants)\n",
    "        classified_licenses.append(classifications)\n",
    "\n",
    "    # By default, multiple licenses yield to the most restrictive one\n",
    "    resolved_criteria = filters.resolve_multiple_licenses(classified_licenses)\n",
    "    return resolved_criteria\n",
    "\n",
    "\n",
    "def add_license_classes_to_summaries(\n",
    "    data_summary: list[dict[str, Any]],\n",
    "    resolved_classes: dict[str, list[str]],\n",
    "    aggregator: str\n",
    "):\n",
    "    \"\"\"Function taken from `text_ft_plots.ipynb`\"\"\"\n",
    "    # Update DataFrame with columns for use, attribution, share_alike\n",
    "    for row in data_summary:\n",
    "        row[f\"License Use ({aggregator})\"] = resolved_classes[row[\"Unique Dataset Identifier\"]][0]\n",
    "        row[f\"License Attribution ({aggregator})\"] = resolved_classes[row[\"Unique Dataset Identifier\"]][1]\n",
    "        row[f\"License Share Alike ({aggregator})\"] = resolved_classes[row[\"Unique Dataset Identifier\"]][2]\n",
    "    return data_summary\n",
    "\n",
    "\n",
    "def map_license_criteria_multimodal(\n",
    "    data_summary: list[dict[str, Any]],\n",
    "    all_constants: dict[str, dict[str, list[str]]]\n",
    ") -> list[dict[str, Any]]:\n",
    "    \"\"\"Variant of `map_license_criteria` that works with multimodal datasets.\n",
    "    Simplified to only include `Licenses` (not HF, etc.).\n",
    "\n",
    "    Function adapted from `text_ft_plots.ipynb`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack licenses for each dataset. {uid --> (license_name, license_url)}\n",
    "    our_uid_to_license_infos = defaultdict(list)\n",
    "\n",
    "    # Same as ours, but excludes OpenAI Terms:\n",
    "    our_uid_to_license_infos_no_openai = defaultdict(list)\n",
    "\n",
    "    for row in data_summary:\n",
    "        uid = row[\"Unique Dataset Identifier\"]\n",
    "        for license_info in row[\"Licenses\"]:\n",
    "            license_name = license_info[\"License\"]\n",
    "            license_url = license_info.get(\"License URL\", None) # FOR NOW\n",
    "            our_uid_to_license_infos[uid].append((license_name, license_url))\n",
    "            if license_info[\"License\"] != \"OpenAI\":\n",
    "                our_uid_to_license_infos_no_openai[uid].append((license_name, license_url))\n",
    "\n",
    "        # If OpenAI was the only license, we add Unspecified so there isn't nothing there.\n",
    "        if len(our_uid_to_license_infos_no_openai[uid]) == 0:\n",
    "            our_uid_to_license_infos_no_openai[uid].append((\"Unspecified\", None))\n",
    "\n",
    "\n",
    "    # classify and resolve licenses for each dataset and each aggregator\n",
    "    ours_resolved, ours_openai_resolved = {}, {}\n",
    "    for uid in our_uid_to_license_infos.keys():\n",
    "        ours_resolved[uid] = classify_and_resolve_licenses(our_uid_to_license_infos[uid], all_constants)\n",
    "        ours_openai_resolved[uid] = classify_and_resolve_licenses(our_uid_to_license_infos_no_openai[uid], all_constants)\n",
    "\n",
    "\n",
    "    data_summary = add_license_classes_to_summaries(data_summary, ours_resolved, \"DataProvenance\")\n",
    "    data_summary = add_license_classes_to_summaries(data_summary, ours_openai_resolved, \"DataProvenance IgnoreOpenAI\")\n",
    "\n",
    "    return data_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_replace = { # These names need to be remapped from the original set to ISO3166\n",
    "    \"South Korea\": \"KOREA, REPUBLIC OF\",\n",
    "    \"United Kingdom\": \"UNITED KINGDOM OF GREAT BRITAIN AND NORTHERN IRELAND\",\n",
    "    \"Czech Republic\": \"CZECHIA\",\n",
    "    \"Vietnam\": \"VIET NAM\",\n",
    "    \"Iran\": \"IRAN, ISLAMIC REPUBLIC OF\",\n",
    "    \"Russia\": \"RUSSIAN FEDERATION\",\n",
    "    \"UAE\": \"UNITED ARAB EMIRATES\",\n",
    "    \"United States\": \"UNITED STATES OF AMERICA\",\n",
    "    \"Scotland\": \"UNITED KINGDOM OF GREAT BRITAIN AND NORTHERN IRELAND\",\n",
    "    \"Turkey\": \"TÜRKIYE\",\n",
    "    \"International/Other/Unknown\": \"\"\n",
    "}\n",
    "\n",
    "# Text annotations contain \"African Continent\" in several cases\n",
    "# This is a list of ISO3166 codes for the countries in the African Continent, for mapping purposes\n",
    "african_continent_iso_codes = [12, 24, 204, 72, 86, 854, 108, 132, 120, 140, 148, 174, 178, 180, 384, 262, 818, 226, 232, 748, 231, 260, 266, 270, 288, 324, 624, 404, 426, 430, 434, 450, 454, 466, 478, 480, 175, 504, 508, 516, 562, 566, 638, 646, 654, 678, 686, 690, 694, 706, 710, 728, 729, 834, 768, 788, 800, 732, 894, 716]\n",
    "\n",
    "def get_country(x: str) -> list[int]:\n",
    "    \"\"\"Get the ISO3166 code for a country name. Returns a list for compatibility with x == \"African Continent\".\n",
    "\n",
    "    Will log warnings for any countries not found.\n",
    "    \"\"\"\n",
    "    if x == \"African Continent\":\n",
    "        return african_continent_iso_codes\n",
    "    try:\n",
    "        return [countries.get(countries_replace.get(x, x))[-2]]\n",
    "    except KeyError:\n",
    "            logging.warning(\"Could not find country for %s\" % x)\n",
    "            return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Constants and Summaries\n",
    "\n",
    "Load constants and data summaries from JSON files. Constants provide mappings and criteria for licenses, creator groups, various other categories. Data summaries contain modality-specific information about datasets.\n",
    "\n",
    "- `all_constants`: Dictionary containing all predefined constants.\n",
    "- `{text/speech/video}_summaries`: Data summaries by modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read constants\n",
    "all_constants = io.read_all_constants(\"../../constants/\")\n",
    "\n",
    "# Read individual modality summaries\n",
    "text_summaries = io.read_data_summary_json(\"../../data_summaries/\")\n",
    "speech_summaries = io.read_data_summary_json(\"../../data_summaries-speech/\")\n",
    "video_summaries = io.read_data_summary_json(\"../../data_summaries-video/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License Use by Modality\n",
    "\n",
    "Show the proportion of license types by modality using a stacked bar chart (normalized). Licenses are mapped to a higher-level categorization: either **Non-Commercial/Academic**, **Unspecified**, or **Commercial** depending on the permisiveness of the original license."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting constants\n",
    "LICENSE_ORDER = [\"Non-Commercial/\\nAcademic\", \"Unspecified\", \"Commercial\"]\n",
    "LICENSE_PALETTE = [\"#e04c71\", \"#e0cd92\", \"#82b5cf\"]\n",
    "LICENSE_PLOTW = 600\n",
    "LICENSE_PLOTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "license_paraphrases = invert_dict_of_lists(all_constants[\"LICENSE_PARAPHRASES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summaries = map_license_criteria_multimodal(\n",
    "    remap_licenses_with_paraphrases(\n",
    "        text_summaries,\n",
    "        license_paraphrases\n",
    "    ),\n",
    "    all_constants\n",
    ")\n",
    "\n",
    "speech_summaries = map_license_criteria_multimodal(\n",
    "    remap_licenses_with_paraphrases(\n",
    "        speech_summaries,\n",
    "        license_paraphrases\n",
    "    ),\n",
    "    all_constants\n",
    ")\n",
    "\n",
    "video_summaries = map_license_criteria_multimodal(\n",
    "    remap_licenses_with_paraphrases(\n",
    "        video_summaries,\n",
    "        license_paraphrases\n",
    "    ),\n",
    "    all_constants\n",
    ")\n",
    "\n",
    "df_text = pd.DataFrame(text_summaries).assign(Modality=\"Text\")\n",
    "df_speech = pd.DataFrame(speech_summaries).assign(Modality=\"Speech\").rename(columns={\"Location\": \"Countries\"})\n",
    "df_video = pd.DataFrame(video_summaries).assign(Modality=\"Video\").rename(columns={\"Video Sources\": \"Source Category\"})\n",
    "\n",
    "df = pd.concat([df_text, df_speech, df_video])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"License Type\"] = df[\"License Use (DataProvenance)\"].map({\n",
    "    \"academic-only\": \"Non-Commercial/\\nAcademic\",\n",
    "    \"non-commercial\": \"Non-Commercial/\\nAcademic\",\n",
    "    \"unspecified\": \"Unspecified\",\n",
    "    \"commercial\": \"Commercial\"\n",
    "})\n",
    "df[\"License Type\"] = pd.Categorical(\n",
    "    df[\"License Type\"],\n",
    "    categories=LICENSE_ORDER,\n",
    "    ordered=True\n",
    ")\n",
    "df = df.sort_values(by=\"License Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_bar().encode(\n",
    "    x=alt.Y(\n",
    "        \"count():Q\",\n",
    "        stack=\"normalize\",\n",
    "        axis=alt.Axis(format=\"%\"),\n",
    "        title=\"Pct. Datasets\"\n",
    "    ),\n",
    "    y=alt.X(\"Modality:N\"),\n",
    "    color=alt.Color(\n",
    "        \"License Type:N\",\n",
    "        scale=alt.Scale(range=LICENSE_PALETTE),\n",
    "        title=\"License Use\",\n",
    "        sort=LICENSE_ORDER\n",
    "    ),\n",
    "    order=\"order:Q\"\n",
    ").properties(\n",
    "    title=\"License Use by Modality\",\n",
    "    width=LICENSE_PLOTW,\n",
    "    height=LICENSE_PLOTH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Creator Categories (e.g. Academic, Industry) by Modality\n",
    "\n",
    "Show the distribution of creator categories across modalities. Plots a normalized stacked bar chart, and also donut/pie for comparison (for now).\n",
    "\n",
    "- `df_categories`: DataFrame unlisted to handle multiple creator categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting constants\n",
    "CREATORCATEGORY_ORDER = [\"Academic\", \"Research Group\", \"Industry Lab\", \"Corporation\", \"Startup\", \"Other\", \"Government\", \"Unspecified\"]\n",
    "CREATORCATEGORY_PALETTE = [\"#CF4E9CFF\", \"#8C57A2FF\", \"#358DB9FF\", \"#82581FFF\", \"#2F509EFF\", \"#E5614CFF\", \"#97A1A7FF\", \"#2E2A2BFF\"]\n",
    "CREATORCATEGORY_PLOTW = 600\n",
    "CREATORCATEGORY_PLOTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator_groupmap = invert_dict_of_lists(all_constants[\"CREATOR_GROUPS\"])\n",
    "creator_countrymap = invert_dict_of_lists(all_constants[\"CREATOR_COUNTRY_GROUPS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map creators to categories (all modalities from constants, for this)\n",
    "df[\"Creator Categories\"] = df[\"Creators\"].map(lambda c : [creator_groupmap[ci] for ci in c])\n",
    "df_categories = df.explode(\"Creator Categories\").fillna(\"Unspecified\") # For now, we fill in Unspecified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Text, we can infer the country from the creator group using the constants\n",
    "# For other modalities, they're taken from the summaries (annotated indenenpendently)\n",
    "df_categories.loc[\n",
    "    df_categories[\"Modality\"] == \"Text\",\n",
    "    \"Countries\"\n",
    "] = df_categories.loc[\n",
    "    df_categories[\"Modality\"] == \"Text\",\n",
    "    \"Creators\"\n",
    "].map(\n",
    "    lambda x: [creator_countrymap[ci] for ci in x]\n",
    ")\n",
    "\n",
    "df_categories[\"Creator Categories\"] = pd.Categorical(\n",
    "    df_categories[\"Creator Categories\"],\n",
    "    categories=CREATORCATEGORY_ORDER,\n",
    "    ordered=True\n",
    ")\n",
    "df_categories = df_categories.sort_values(by=\"Creator Categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_categories).mark_bar().encode(\n",
    "    x=alt.Y(\n",
    "        \"count():Q\",\n",
    "        stack=\"normalize\",\n",
    "        axis=alt.Axis(format=\"%\"),\n",
    "        title=\"Pct. Datasets\"\n",
    "    ),\n",
    "    y=alt.X(\"Modality:N\"),\n",
    "    color=alt.Color(\n",
    "        \"Creator Categories:N\",\n",
    "        scale=alt.Scale(range=CREATORCATEGORY_PALETTE),\n",
    "        title=\"Creator Category\",\n",
    "        sort=CREATORCATEGORY_ORDER\n",
    "    ),\n",
    "    order=\"order:Q\"\n",
    ").properties(\n",
    "    title=\"Creator Categories by Modality\",\n",
    "    width=CREATORCATEGORY_PLOTW,\n",
    "    height=CREATORCATEGORY_PLOTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donut chart as alternate, to test\n",
    "alt.Chart(df_categories).mark_arc(innerRadius=40).encode(\n",
    "    theta=\"count():Q\",\n",
    "    color=alt.Color(\n",
    "        \"Creator Categories:N\",\n",
    "        scale=alt.Scale(range=CREATORCATEGORY_PALETTE),\n",
    "        title=\"Creator Category\",\n",
    "        sort=CREATORCATEGORY_ORDER\n",
    "    ),\n",
    "    order=\"order:Q\"\n",
    ").properties(\n",
    "    title=\"Creator Categories by Modality\",\n",
    "    width=CREATORCATEGORY_PLOTH, # Use height as width for square aspect ratio\n",
    "    height=CREATORCATEGORY_PLOTH\n",
    ").facet(\n",
    "    \"Modality:N\",\n",
    "    columns=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Dataset Count by Creator Country/Region and Modality\n",
    "\n",
    "Global distribution of datasets by modality. Uses a world map with color-coded regions to indicate the count of datasets from different regions.\n",
    "\n",
    "- `df_countries`: DataFrame with country codes for plotting.\n",
    "- `base`: Base map (shared across all modalities).\n",
    "- `charts`: List of modality-specific maps (to concatenate into facets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting constants\n",
    "CREATORCOUNTRY_PLOTDIM = 600\n",
    "MODALITY_COLORS = {\n",
    "    \"Text\": \"reds\",\n",
    "    \"Speech\": \"blues\",\n",
    "    \"Video\": \"greens\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_src = data.world_110m.url # World map for plotting\n",
    "df_countries = df_categories.explode(\"Countries\").dropna() # Drop rows with no country for the moment\n",
    "df_countries = df_countries[[\"Countries\", \"Modality\"]].value_counts().reset_index(name=\"Count\")\n",
    "df_countries[\"Country ID\"] = df_countries[\"Countries\"].map(get_country)\n",
    "df_countries = df_countries.explode(\"Country ID\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(\n",
    "    alt.topo_feature(countries_src, \"countries\")\n",
    ").mark_geoshape(\n",
    "    stroke=\"white\"\n",
    ").project(\n",
    "    type=\"equalEarth\"\n",
    ")\n",
    "\n",
    "charts = []\n",
    "\n",
    "for modality, color in MODALITY_COLORS.items():\n",
    "    modality_data = df_countries[df_countries[\"Modality\"] == modality]\n",
    "    chart = base.encode(\n",
    "        color=alt.Color(\n",
    "            \"Count:Q\",\n",
    "            # log scale\n",
    "            scale=alt.Scale(scheme=color, type=\"symlog\"),\n",
    "            title=\"Datasets\"\n",
    "        ),\n",
    "        tooltip=[\"Countries:N\", \"Count:Q\", \"Modality:N\"]\n",
    "    ).properties(\n",
    "        width=CREATORCOUNTRY_PLOTDIM,\n",
    "        height=CREATORCOUNTRY_PLOTDIM//2\n",
    "    ).transform_lookup(\n",
    "        lookup=\"id\",\n",
    "        from_=alt.LookupData(modality_data, \"Country ID\", [\"Count\", \"Modality\", \"Countries\"])\n",
    "    ).transform_calculate(\n",
    "        Count=\"isValid(datum.Count) ? datum.Count : 0\",\n",
    "        Modality=\"isValid(datum.Modality) ? datum.Modality : ''\",\n",
    "        Countries=\"isValid(datum.Countries) ? datum.Countries : ''\"\n",
    "    ).properties(\n",
    "        title=modality\n",
    "    )\n",
    "    charts.append(chart)\n",
    "\n",
    "alt.vconcat(\n",
    "    *charts\n",
    ").resolve_scale(\n",
    "    color=\"independent\"\n",
    ").properties(\n",
    "    title=\"Dataset Count by Country and Modality\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data Source Categories by Modality\n",
    "\n",
    "Distribution of source categories, mapped to higher-level groups in `domain_types.json`, across modalities.\n",
    "\n",
    "- `df_sources`: DataFrame with grouped sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_groupmap = invert_dict_of_lists(all_constants[\"DOMAIN_GROUPS\"])\n",
    "domain_typemap = invert_dict_of_lists(all_constants[\"DOMAIN_TYPES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting constants\n",
    "SOURCECATEGORY_PLOTW = 600\n",
    "SOURCECATEGORY_PLOTH = 200\n",
    "SOURCECATEGORY_ORDER = sorted(set(domain_typemap.values()) - {\"Other\"}) + [\"Other\", \"Unspecified\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Text, we can infer the domain from the text sources using the constants\n",
    "# For other modalities, they're taken from the summaries (renamed columns)\n",
    "df.loc[\n",
    "    df[\"Modality\"] == \"Text\",\n",
    "    \"Source Category\"\n",
    "] = df.loc[\n",
    "    df[\"Modality\"] == \"Text\",\n",
    "    \"Text Sources\"\n",
    "].map(\n",
    "    lambda x: [domain_groupmap[ci] for ci in x]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlist to have one row per source category (atomic components)\n",
    "df_sources = df.explode(\"Source Category\")\n",
    "df_sources[\"Source Category\"] = df_sources[\"Source Category\"].map(\n",
    "    domain_typemap\n",
    ").fillna(\"Unspecified\") # For now, we fill in Unspecified\n",
    "\n",
    "df_sources[\"Source Category\"] = pd.Categorical(\n",
    "    df_sources[\"Source Category\"],\n",
    "    categories=SOURCECATEGORY_ORDER,\n",
    "    ordered=True\n",
    ")\n",
    "df_sources = df_sources.sort_values(by=\"Source Category\")\n",
    "\n",
    "alt.Chart(df_sources).mark_bar().encode(\n",
    "    x=alt.Y(\n",
    "        \"count():Q\",\n",
    "        stack=\"normalize\",\n",
    "        axis=alt.Axis(format=\"%\"),\n",
    "        title=\"Pct. Datasets\"\n",
    "    ),\n",
    "    y=alt.X(\"Modality:N\"),\n",
    "    color=alt.Color(\n",
    "        \"Source Category:N\",\n",
    "        title=\"Source Category\",\n",
    "        sort=SOURCECATEGORY_ORDER\n",
    "    ),\n",
    "    order=\"order:Q\"\n",
    ").configure_legend(\n",
    "    orient=\"bottom\",\n",
    "    columns=3,\n",
    "    labelLimit=0\n",
    ").properties(\n",
    "    title=\"Source Categories by Modality\",\n",
    "    width=SOURCECATEGORY_PLOTW,\n",
    "    height=SOURCECATEGORY_PLOTH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we re-plot the source category distributions, but aggregating within collections for text data (i.e. we use the majority source within collections). For possible ToS mapping (since those annotations are collection level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df_sources[df_sources[\"Modality\"] == \"Text\"].copy()\n",
    "df_nontext = df_sources[df_sources[\"Modality\"] != \"Text\"]\n",
    "\n",
    "df_text.loc[:, \"Source Category\"] = df_text.groupby(\"Collection\")[\"Source Category\"].transform(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else \"Unspecified\"\n",
    ")\n",
    "\n",
    "df_text = df_text.drop_duplicates(subset=\"Collection\")\n",
    "\n",
    "df_sources = pd.concat([df_nontext, df_text], ignore_index=True)\n",
    "\n",
    "logging.warning(\"Aggregating to %d collections\" % len(df_sources.loc[df_sources[\"Modality\"] == \"Text\", \"Collection\"].unique()))\n",
    "\n",
    "df_sources = df_sources.sort_values(by=\"Source Category\")\n",
    "alt.Chart(df_sources).mark_bar().encode(\n",
    "    x=alt.Y(\n",
    "        \"count():Q\",\n",
    "        stack=\"normalize\",\n",
    "        axis=alt.Axis(format=\"%\"),\n",
    "        title=\"Pct. Datasets\"\n",
    "    ),\n",
    "    y=alt.X(\"Modality:N\"),\n",
    "    color=alt.Color(\n",
    "        \"Source Category:N\",\n",
    "        title=\"Source Category\",\n",
    "        sort=SOURCECATEGORY_ORDER\n",
    "    ),\n",
    "    order=\"order:Q\"\n",
    ").configure_legend(\n",
    "    orient=\"bottom\",\n",
    "    columns=3,\n",
    "    labelLimit=0\n",
    ").properties(\n",
    "    title=\"Source Categories by Modality (Aggregated Collections)\",\n",
    "    width=SOURCECATEGORY_PLOTW,\n",
    "    height=SOURCECATEGORY_PLOTH\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpiv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
