{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -q -U pandas altair vega_datasets iso3166 vl-convert-python matplotlib seaborn scipy scikit-learn langcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Append system path\n",
    "sys.path = [p for p in sys.path if not p.endswith(\"../..\")]  # Cleans duplicated '../..\"\n",
    "sys.path.insert(0, \"../\")  # This adds `src` to the path\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import langcodes\n",
    "from collections import Counter, defaultdict\n",
    "alt.data_transformers.disable_max_rows() # Allow using more than 5000 rows, for now\n",
    "logging.basicConfig(level=logging.DEBUG, handlers=[logging.StreamHandler(stream=sys.stdout)])\n",
    "from vega_datasets import data\n",
    "from helpers import io\n",
    "from analysis import multimodal_util\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Constants (All Plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def times_newroman():\n",
    "    font = \"Times New Roman\"\n",
    "\n",
    "    return {\n",
    "          \"config\" : {\n",
    "               \"title\": {\"font\": font},\n",
    "               \"axis\": {\n",
    "               \"labelFont\": font,\n",
    "               \"titleFont\": font\n",
    "          },\n",
    "          \"header\": {\n",
    "               \"labelFont\": font,\n",
    "               \"titleFont\": font\n",
    "          },\n",
    "          \"legend\": {\n",
    "               \"labelFont\": font,\n",
    "               \"titleFont\": font\n",
    "          },\n",
    "          \"text\": {\n",
    "               \"font\": font\n",
    "          }\n",
    "     }\n",
    "}\n",
    "\n",
    "alt.themes.register(\"times_newroman\", times_newroman)\n",
    "alt.themes.enable(\"times_newroman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT_SIZE = 16\n",
    "LEGEND_POSITION = \"bottom\"\n",
    "PLOT_TOFILE = True # Whether and where to output plots\n",
    "PLOT_DIR = \"~/dpi-plotsmultimodal/\"\n",
    "PLOT_PPI = 300\n",
    "MAX_LABELLIMIT = 400 # Large number to avoid label summarization in plots\n",
    "\n",
    "PLOT_DIR = os.path.expanduser(PLOT_DIR)\n",
    "\n",
    "# Create directory if needed\n",
    "if PLOT_TOFILE:\n",
    "    os.makedirs(PLOT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Constants and Summaries\n",
    "\n",
    "Load constants and data summaries from JSON files. Constants provide mappings and criteria for licenses, creator groups, various other categories. Data summaries contain modality-specific information about datasets.\n",
    "\n",
    "- `all_constants`: Dictionary containing all predefined constants.\n",
    "- `{text/speech/video}_summaries`: Data summaries by modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether and where to output plots\n",
    "PLOT_TOFILE = True\n",
    "PLOT_DIR = \"~/dpi-plotsmultimodal/\"\n",
    "PLOT_PPI = 300\n",
    "MAX_LABELLIMIT = 400 # Large number to avoid label summarization in plots\n",
    "\n",
    "PLOT_DIR = os.path.expanduser(PLOT_DIR)\n",
    "\n",
    "# Create directory if needed\n",
    "if PLOT_TOFILE:\n",
    "    os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "\n",
    "# Plotting constants\n",
    "LICENSE_ORDER = [\"NC/Acad\", \"Unspecified\", \"Commercial\"]\n",
    "LICENSE_PALETTE = [\"#e04c71\", \"#e0cd92\", \"#82b5cf\"]\n",
    "LICENSE_TERMS_ORDER = [\n",
    "    \"NC/Acad | Model Closed\", \"NC/Acad | Source Closed\", \"NC/Acad | Unspecified\", \"NC/Acad | Unrestricted\",\n",
    "    \"Unspecified | Model Closed\", \"Unspecified | Source Closed\", \"Unspecified | Unspecified\", \"Unspecified | Unrestricted\",\n",
    "    \"Commercial | Model Closed\", \"Commercial | Source Closed\", \"Commercial | Unspecified\", \"Commercial | Unrestricted\",\n",
    "]\n",
    "LICENSE_TERMS_ORDER_VARIANT = [\n",
    "    \"NC/Acad | Restricted\", \"NC/Acad | Unspecified\", \"NC/Acad | Unrestricted\",\n",
    "    \"Unspecified | Restricted\", \"Unspecified | Unspecified\", \"Unspecified | Unrestricted\",\n",
    "    \"Commercial | Restricted\", \"Commercial | Unspecified\", \"Commercial | Unrestricted\"\n",
    "]\n",
    "LICENSE_TERMS_PALETTE = [\n",
    "    '#9d354f', '#c24262', '#e04c71',\n",
    "    '#9d9066', '#c2b27f', '#e0cd92',\n",
    "    '#5b7f91', '#719db3', '#82b5cf',\n",
    "]\n",
    "\n",
    "LICENSE_PLOTW = 400\n",
    "LICENSE_PLOTH = 100\n",
    "YEAR_CATEGORIES = [\"Unknown\", \"<2013\", *list(map(str, range(2013, 2025)))]\n",
    "\n",
    "# Read constants\n",
    "all_constants = io.read_all_constants(\"../../constants/\")\n",
    "\n",
    "# Read Terms data\n",
    "collection_to_terms_mapper = multimodal_util.load_terms_metadata(\"data/multimodal_terms_data\")\n",
    "\n",
    "# Read individual modality summaries\n",
    "text_summaries = io.read_data_summary_json(\"../../data_summaries/\")\n",
    "logging.info(\"Checking Text Data Summaries against Constants\")\n",
    "# analysis_util.check_datasummary_in_constants(text_summaries, all_constants)\n",
    "\n",
    "speech_summaries = io.read_data_summary_json(\"../../data_summaries-speech/\")\n",
    "logging.info(\"Checking Speech Data Summaries against Constants\")\n",
    "# analysis_util.check_datasummary_in_constants(speech_summaries, all_constants)\n",
    "\n",
    "video_summaries = io.read_data_summary_json(\"../../data_summaries-video/\")\n",
    "logging.info(\"Checking Video Data Summaries against Constants\")\n",
    "# analysis_util.check_datasummary_in_constants(video_summaries, all_constants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep dataframes\n",
    "df = multimodal_util.prep_summaries_for_visualization(\n",
    "    text_summaries,\n",
    "    speech_summaries,\n",
    "    video_summaries,\n",
    "    all_constants,\n",
    "    collection_to_terms_mapper,\n",
    "    YEAR_CATEGORIES,\n",
    "    LICENSE_ORDER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_text = df[df[\"Modality\"] == \"Text\"]\n",
    "# nan_rows = df_text[df_text[\"Total Tokens\"].isna()]\n",
    "# print(nan_rows[[\"Collection\", \"Total Tokens\"]])\n",
    "# print(nan_rows[\"Collection\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Data Terms\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['License'] = df['License | Terms'].str.split(' | ').apply(lambda s: s[0])\n",
    "# df['Terms'] = df['License | Terms'].str.split(' | ').apply(lambda s: s[2])\n",
    "\n",
    "# df['is_acad'] = (df['License'] == 'NC/Acad').astype(int)\n",
    "# df['is_restricted'] = (df['Terms'].isin(['Source', 'Model'])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['is_acad', 'is_restricted']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('Collection')[['is_acad', 'is_restricted']].max().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bads = df.groupby('Collection')[['is_acad', 'is_restricted']].max()\n",
    "# bads = bads.loc[(bads['is_acad'] == 1) | (bads['is_restricted'] == 1)].index\n",
    "\n",
    "# df['Collection'].isin(bads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Data Terms\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License Use by Modality\n",
    "\n",
    "Show the proportion of license types by modality using a stacked bar chart (normalized). Licenses are mapped to a higher-level categorization: either **Non-Commercial/Academic**, **Unspecified**, or **Commercial** depending on the permisiveness of the original license."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# license_chart = multimodal_util.plot_license_terms_stacked_bar_chart_collections(\n",
    "#     df, \"License Type\", LICENSE_PALETTE, LICENSE_ORDER, LICENSE_PLOTW, LICENSE_PLOTH, PLOT_DIR, PLOT_PPI, return_license_table=False, configure_chart=True\n",
    "# )\n",
    "\n",
    "# license_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# license_chart = multimodal_util.plot_license_terms_stacked_bar_chart_collections(\n",
    "#     df, \"License Type\", LICENSE_PALETTE, LICENSE_ORDER, LICENSE_PLOTW, LICENSE_PLOTH, PLOT_DIR, PLOT_PPI, return_license_table=False, configure_chart=False\n",
    "# )\n",
    "\n",
    "# license_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LICENSE_TERMS_MODALITY_ORDER = [\"Text\", \"Speech\", \"Video\"]\n",
    "\n",
    "license_terms_chart, license_terms_table = multimodal_util.plot_license_terms_stacked_bar_chart_collections(\n",
    "    df, \"License | Terms\", LICENSE_TERMS_PALETTE, LICENSE_TERMS_ORDER_VARIANT, LICENSE_TERMS_MODALITY_ORDER,\n",
    "    800, 120, PLOT_DIR, PLOT_PPI, return_df=False\n",
    ")\n",
    "\n",
    "license_terms_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LICENSE_TERMS_MODALITY_ORDER_2 = [\"Text (Collections)\", \"Text (Datasets)\", \"Speech\", \"Video\"]\n",
    "\n",
    "license_terms_chart_2, license_terms_table_2, *_ = multimodal_util.plot_license_terms_stacked_bar_chart_collections(\n",
    "    df, \"License | Terms\", LICENSE_TERMS_PALETTE, LICENSE_TERMS_ORDER_VARIANT,\n",
    "    LICENSE_TERMS_MODALITY_ORDER_2, 800, 140,\n",
    "    # save_dir=PLOT_DIR,  # svg saving package compatibility issues, and you can save from the notebook anyway\n",
    "    plot_ppi=PLOT_PPI,\n",
    "    title=\"Dataset & Source Restrictions (Dataset Count)\",\n",
    "    no_legend=True,\n",
    "    split_text_mod=True,\n",
    "    return_df=True\n",
    ")\n",
    "\n",
    "license_terms_chart_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LICENSE_TERMS_MODALITY_ORDER_3 = [\"Text (Collections)\", \"Text (Datasets)\", \"Speech\", \"Video\"]\n",
    "\n",
    "license_terms_chart_3, license_terms_table_3, df_new, df_grouped, df_melted = multimodal_util.plot_license_terms_stacked_bar_chart_collections(\n",
    "    df, \"License | Terms\", LICENSE_TERMS_PALETTE, LICENSE_TERMS_ORDER_VARIANT,\n",
    "    LICENSE_TERMS_MODALITY_ORDER_2, 800, 140,\n",
    "    # save_dir=PLOT_DIR,\n",
    "    plot_ppi=PLOT_PPI,\n",
    "    title=\"Dataset & Source Restrictions (Total Tokens or Hours)\",\n",
    "    no_legend=False,\n",
    "    split_text_mod=True,\n",
    "    pct_by_tokens=True,\n",
    "    return_df=True\n",
    ")\n",
    "\n",
    "license_terms_chart_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(license_terms_table_3['Text (Datasets)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted['License'] = df_melted['License | Terms'].str.split(' | ').apply(lambda s: s[0])\n",
    "df_melted['Terms'] = df_melted['License | Terms'].str.split(' | ').apply(lambda s: s[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted.loc[df_melted['Modality'] == 'Text (Collections)', ['Terms', 'License', 'percentage']].pivot(index='License', columns='Terms', values='percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted.loc[df_melted['Modality'] == 'Text (Datasets)', ['Terms', 'License', 'percentage']].pivot(index='License', columns='Terms', values='percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Datasets level\n",
    "\n",
    "dg2 = df.copy()\n",
    "dg2['License | Terms'] = dg2['License | Terms'].apply(multimodal_util.merge_to_restricted)\n",
    "\n",
    "dg2 = dg2.groupby(['Modality', 'License | Terms']).size().reset_index()\n",
    "\n",
    "dg2.rename({0: 'quantity'}, axis=1, inplace=True)\n",
    "\n",
    "dg2['percentage'] = dg2.groupby('Modality')['quantity'].transform(lambda x: (x / x.sum()) * 100)\n",
    "df_melted_count = dg2.melt(id_vars=['Modality', 'License | Terms', 'percentage'], value_vars=['quantity'], var_name='metric', value_name='value')\n",
    "\n",
    "df_melted_count['License'] = df_melted_count['License | Terms'].str.split(' | ').apply(lambda s: s[0])\n",
    "df_melted_count['Terms'] = df_melted_count['License | Terms'].str.split(' | ').apply(lambda s: s[2])\n",
    "\n",
    "df_melted_count.loc[df_melted_count['Modality'] == 'Text', ['Terms', 'License', 'percentage']].pivot(index='License', columns='Terms', values='percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collections level\n",
    "\n",
    "dg3 = df.copy()\n",
    "dg3 = dg3.loc[dg3['Modality'] == 'Text']\n",
    "dg3['cnt'] = 1\n",
    "\n",
    "dg3['License | Terms'] = dg3['License | Terms'].apply(multimodal_util.merge_to_restricted)\n",
    "\n",
    "dg3['License | Terms'] = pd.Categorical(\n",
    "    dg3['License | Terms'],\n",
    "    categories=LICENSE_TERMS_ORDER_VARIANT,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "dg3 = dg3.groupby('Collection')[['Modality', 'License | Terms', 'cnt']].agg({\n",
    "    'Modality': 'min',\n",
    "    'License | Terms': 'min',\n",
    "    'cnt': 'sum',\n",
    "}).reset_index()\n",
    "dg3 = dg3.groupby(['Modality', 'License | Terms'])['cnt'].sum().reset_index()\n",
    "\n",
    "dg3.rename({'cnt': 'quantity'}, axis=1, inplace=True)\n",
    "\n",
    "dg3['percentage'] = dg3.groupby('Modality')['quantity'].transform(lambda x: (x / x.sum()) * 100)\n",
    "df_melted_count = dg3.melt(id_vars=['Modality', 'License | Terms', 'percentage'], value_vars=['quantity'], var_name='metric', value_name='value')\n",
    "\n",
    "df_melted_count['License'] = df_melted_count['License | Terms'].str.split(' | ').apply(lambda s: s[0])\n",
    "df_melted_count['Terms'] = df_melted_count['License | Terms'].str.split(' | ').apply(lambda s: s[2])\n",
    "\n",
    "df_melted_count.loc[df_melted_count['Modality'] == 'Text', ['Terms', 'License', 'percentage']].pivot(index='License', columns='Terms', values='percentage')#.sum(axis=1).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_grouped['Terms'] = df_grouped['License | Terms'].str.split(' | ').apply(lambda s: s[2])\n",
    "# df_grouped.groupby(['Modality', 'Terms'], observed=False)['Total Tokens'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_melted['License'] = df_melted['License | Terms'].str.split(' | ').apply(lambda s: s[0])\n",
    "# df_melted['Terms'] = df_melted['License | Terms'].str.split(' | ').apply(lambda s: s[2])\n",
    "# df_melted.groupby(['Modality', 'License'], observed=False)['percentage'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new['Terms'] = df_new['License | Terms'].str.split(' | ').apply(lambda s: s[2])\n",
    "# df_new.groupby(['Modality', 'Terms'], observed=False)['Total Tokens'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_grouped['Terms'] = df_grouped['License | Terms'].str.split(' | ').apply(lambda s: s[2])\n",
    "# df_grouped.groupby(['Modality', 'Terms'], observed=False)['percentage'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = df_new.merge(\n",
    "#     df_new \\\n",
    "#         .loc[df_new['Modality'] == 'Text (Collections)', ['Collection', 'License | Terms']] \\\n",
    "#         .rename({'License | Terms': 'collection_license_terms'}, axis=1),\n",
    "#     how='inner',\n",
    "#     on='Collection'\n",
    "# )\n",
    "\n",
    "# pd.crosstab(tmp['License | Terms'], tmp['collection_license_terms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Creator Categories (e.g. Academic, Industry) by Modality\n",
    "\n",
    "Show the distribution of creator categories across modalities. Plots a normalized stacked bar chart, and also donut/pie for comparison (for now).\n",
    "\n",
    "- `df_categories`: DataFrame unlisted to handle multiple creator categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting constants\n",
    "CREATORCATEGORY_ORDER = [\"Academic\", \"Research Group\", \"Industry Lab\", \"Corporation\", \"Startup\", \"Other\", \"Government\", \"Unspecified\"]\n",
    "CREATORCATEGORY_MODALITY_ORDER = [\"Text\", \"Speech\", \"Video\"]\n",
    "CREATORCATEGORY_PALETTE = [\"#CF4E9CFF\", \"#8C57A2FF\", \"#358DB9FF\", \"#82581FFF\", \"#2F509EFF\", \"#E5614CFF\", \"#97A1A7FF\", \"#2E2A2BFF\"]\n",
    "CREATORCATEGORY_PLOTW = 800\n",
    "CREATORCATEGORY_PLOTH = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator_chart = multimodal_util.plot_stacked_creator_categories(\n",
    "    df, CREATORCATEGORY_ORDER, CREATORCATEGORY_MODALITY_ORDER, CREATORCATEGORY_PALETTE, CREATORCATEGORY_PLOTW, CREATORCATEGORY_PLOTH, PLOT_DIR, collection_level=True\n",
    ")\n",
    "\n",
    "creator_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multimodal_util.plot_donut_creator_categories(\n",
    "#     df, CREATORCATEGORY_ORDER, CREATORCATEGORY_PALETTE, CREATORCATEGORY_PLOTH, PLOT_DIR\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Dataset Count by Creator Country/Region and Modality\n",
    "\n",
    "Global distribution of datasets by modality. Uses a world map with color-coded regions to indicate the count of datasets from different regions.\n",
    "\n",
    "- `df_countries`: DataFrame with country codes for plotting.\n",
    "- `base`: Base map (shared across all modalities).\n",
    "- `charts`: List of modality-specific maps (to concatenate into facets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting constants\n",
    "CREATORCOUNTRY_PLOTDIM = 400\n",
    "MODALITY_COLORS = {\n",
    "    \"Text\": \"reds\",\n",
    "    \"Speech\": \"blues\",\n",
    "    \"Video\": \"greens\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_scores = {\n",
    "    \"Text\": 0.92,\n",
    "    \"Speech\": 0.86,\n",
    "    \"Video\": 0.74\n",
    "}\n",
    "\n",
    "\n",
    "map_charts = multimodal_util.plot_altair_worldmap_country(\n",
    "    df,\n",
    "    data.world_110m.url,\n",
    "     # World map for plotting\n",
    "    MODALITY_COLORS,\n",
    "    CREATORCOUNTRY_PLOTDIM,\n",
    "    PLOT_DIR,\n",
    "     gini_scores\n",
    ")\n",
    "\n",
    "map_charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_charts = multimodal_util.plot_altair_worldmap_continent(\n",
    "#     df,\n",
    "#     data.world_110m.url, # World map for plotting\n",
    "#     MODALITY_COLORS,\n",
    "#     CREATORCOUNTRY_PLOTDIM,\n",
    "#     PLOT_DIR\n",
    "# )\n",
    "\n",
    "# map_charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex1, latex2 = multimodal_util.map_country_to_continent(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data Source Categories by Modality\n",
    "\n",
    "Distribution of source categories, mapped to higher-level groups in `domain_types.json`, across modalities.\n",
    "\n",
    "- `df_sources`: DataFrame with grouped sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting constants\n",
    "DOMAIN_TYPEMAP = multimodal_util.invert_dict_of_lists(all_constants[\"DOMAIN_TYPES\"])\n",
    "SOURCECATEGORY_PLOTW = 400\n",
    "SOURCECATEGORY_PLOTH = 100\n",
    "SOURCECATEGORY_ORDER = sorted(set(DOMAIN_TYPEMAP.values()) - {\"Other\"}) + [\"Other\", \"Unspecified\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_util.plot_source_domain_stacked_chart(\n",
    "    df, DOMAIN_TYPEMAP, SOURCECATEGORY_ORDER, SOURCECATEGORY_PLOTW, SOURCECATEGORY_PLOTH, PLOT_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we plot source/domain type distributions by year and modality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we re-plot the source category distributions, but aggregating within collections for text data (i.e. we use the majority source within collections). For possible ToS mapping (since those annotations are collection level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_chart = multimodal_util.plot_source_domain_stacked_chart_collections(\n",
    "    df, DOMAIN_TYPEMAP, SOURCECATEGORY_ORDER, SOURCECATEGORY_PLOTW, SOURCECATEGORY_PLOTH, PLOT_DIR\n",
    ")\n",
    "\n",
    "source_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_TYPEMAP = multimodal_util.invert_dict_of_lists(all_constants[\"TASK_GROUPS\"])\n",
    "TASKCATEGORY_PLOTW = 280\n",
    "TASKCATEGORY_PLOTH = 200\n",
    "TASKCATEGORY_FONT_SIZE = 16\n",
    "TASKCATEGORY_ORDER = sorted(set(TASK_TYPEMAP.values()) - {\"null\"})\n",
    "PLOT_TOFILE_TASKS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_task_chart_datasets = multimodal_util.plot_tasks_chart(\n",
    "    df, TASK_TYPEMAP, TASKCATEGORY_ORDER, TASKCATEGORY_PLOTW, TASKCATEGORY_PLOTH, PLOT_DIR, TASKCATEGORY_FONT_SIZE, \"Speech\", \"Tasks\", \"Datasets\"\n",
    ")\n",
    "\n",
    "# speech_task_chart_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_chart_text_collections = multimodal_util.plot_tasks_chart(\n",
    "    # df, TASK_TYPEMAP, TASKCATEGORY_ORDER, TASKCATEGORY_PLOTW, TASKCATEGORY_PLOTH, PLOT_DIR, TASKCATEGORY_FONT_SIZE, \"Text\", \"Task Categories\", \"Datasets\"\n",
    "    df, TASK_TYPEMAP, TASKCATEGORY_ORDER, TASKCATEGORY_PLOTW, TASKCATEGORY_PLOTH, PLOT_DIR, TASKCATEGORY_FONT_SIZE, \"Text\", \"Task Categories\", \"Collections\"\n",
    ")\n",
    "\n",
    "# task_chart_text_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_task_chart_collections = multimodal_util.plot_tasks_chart(\n",
    "    df, TASK_TYPEMAP, TASKCATEGORY_ORDER, TASKCATEGORY_PLOTW, TASKCATEGORY_PLOTH, PLOT_DIR, TASKCATEGORY_FONT_SIZE, \"Video\", \"Task Categories\", \"Datasets\"\n",
    ")\n",
    "\n",
    "# video_task_chart_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tasks_chart = multimodal_util.concatenate_task_charts(task_chart_text_collections, speech_task_chart_datasets, video_task_chart_collections, 14)\n",
    "\n",
    "if PLOT_TOFILE_TASKS:\n",
    "    combined_tasks_chart.save(\n",
    "        os.path.join(PLOT_DIR, \"multimodal-combined_tasks_chart.png\"),\n",
    "        ppi=300\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tasks_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Dataset dimensions by tokens (Datasets and Collections)\n",
    "Tokens calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets split by tokens bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tokens.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collections split by tokens bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins_collection = [0, 1000000, 50000000,100000000, 500000000, 1000000000, float('inf')]\n",
    "# labels_collection = ['0-1M', '1M-50M', '50M-100M', '100M-500M', '500m-1B', '1B+']\n",
    "text_bins_collection = [0, 1000000, 10000000,100000000, 1000000000, 10000000000, float('inf')]\n",
    "text_labels_collection = ['0-1M', '1M-10M', '10M-100M', '100M-1B', '1B-10B', '10B+']\n",
    "\n",
    "# df_tokens = multimodal_util.tokens_calculation(df)\n",
    "text_collection_chart, text_max_count_collection = multimodal_util.data_aggregation_for_chart(\n",
    "    df,'Text', text_bins_collection, text_labels_collection, by_collection=True, measure_column='Total Tokens', group_column='Tokens')\n",
    "\n",
    "speech_bins_collection = [0, 100, 1000,10000, 100000, float('inf')]\n",
    "speech_labels_collection = ['0-100', '100-1K', '1K-10K', '10K-100K', '100K+']\n",
    "speech_collection_chart, speech_max_count_collection = multimodal_util.data_aggregation_for_chart(\n",
    "    df,'Speech', speech_bins_collection, speech_labels_collection, by_collection=False, measure_column='Hours', group_column='Hours')\n",
    "\n",
    "video_bins_collection = [0, 100, 1000,10000, 100000, float('inf')]\n",
    "video_labels_collection = ['0-100', '100-1K', '1K-10K', '10K-100K', '100K+']\n",
    "video_collection_chart, video_max_count_collection = multimodal_util.data_aggregation_for_chart(\n",
    "    df,'Video', speech_bins_collection, speech_labels_collection, by_collection=False, measure_column='Hours', group_column='Hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine graphs for dataset and collections split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart1 = multimodal_util.chart_creation(\n",
    "#     dataset_chart, \n",
    "#     max_count_dataset, \n",
    "#     x_field='Token Groups',  \n",
    "#     labels=labels_dataset,\n",
    "#     ratio=1.15,\n",
    "#     title='Token distributions by Datasets',\n",
    "#     width=400,\n",
    "#     height=300,\n",
    "#     color='skyblue'\n",
    "# )\n",
    "\n",
    "DIM_CHART_WIDTH = 300\n",
    "DIM_CHART_HEIGHT = 200\n",
    "\n",
    "\n",
    "text_dim_chart = multimodal_util.chart_creation(\n",
    "    text_collection_chart, \n",
    "    text_max_count_collection, \n",
    "    x_field='Tokens',  \n",
    "    labels=text_labels_collection,\n",
    "    ratio=1.15,\n",
    "    title='Text (Tokens)',\n",
    "    width=DIM_CHART_WIDTH,\n",
    "    height=DIM_CHART_HEIGHT,\n",
    "    color='salmon'\n",
    ")\n",
    "\n",
    "speech_dim_chart = multimodal_util.chart_creation(\n",
    "    speech_collection_chart, \n",
    "    speech_max_count_collection, \n",
    "    x_field='Hours',  \n",
    "    labels=speech_labels_collection,\n",
    "    ratio=1.15,\n",
    "    title='Speech (Hours)',\n",
    "    width=DIM_CHART_WIDTH,\n",
    "    height=DIM_CHART_HEIGHT,\n",
    "    color='skyblue'\n",
    ")\n",
    "\n",
    "video_dim_chart = multimodal_util.chart_creation(\n",
    "    video_collection_chart, \n",
    "    video_max_count_collection, \n",
    "    x_field='Hours',  \n",
    "    labels=video_labels_collection,\n",
    "    ratio=1.15,\n",
    "    title='Video (Hours)',\n",
    "    width=DIM_CHART_WIDTH,\n",
    "    height=DIM_CHART_HEIGHT,\n",
    "    color='forestgreen'\n",
    ")\n",
    "\n",
    "\n",
    "# Concatenate the two charts horizontally with different scales for the y-axes\n",
    "combined_chart = multimodal_util.combined_dim_charts(text_dim_chart, speech_dim_chart, video_dim_chart)\n",
    "combined_chart = combined_chart.configure_view(strokeOpacity=0)\n",
    "\n",
    "# Save the plot if PLOT_TOFILE is True\n",
    "if PLOT_TOFILE:\n",
    "    output_file = os.path.join(PLOT_DIR, \"Token_&_collection.png\")\n",
    "    combined_chart.save(output_file, scale_factor=PLOT_PPI/100)\n",
    "\n",
    "# Display the chart\n",
    "combined_chart.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Categories by Hours/Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INCLUDE_TOP_N_CATEGORIES = 12\n",
    "SRC_CAT_CUMULATIVE_PLOTW = 380\n",
    "SRC_CAT_CUMULATIVE_PLOTH = 190\n",
    "EARLIEST_YEAR = 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_chart_sourceyearhours = multimodal_util.plot_temporal_cumulative_sources(\n",
    "    df, \"Speech\", INCLUDE_TOP_N_CATEGORIES, \"Hours\", EARLIEST_YEAR, SRC_CAT_CUMULATIVE_PLOTW, SRC_CAT_CUMULATIVE_PLOTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_chart_sourceyearhours = multimodal_util.plot_temporal_cumulative_sources(\n",
    "    df, \"Video\", INCLUDE_TOP_N_CATEGORIES, \"Hours\", EARLIEST_YEAR, SRC_CAT_CUMULATIVE_PLOTW, SRC_CAT_CUMULATIVE_PLOTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chart_sourceyearhours = multimodal_util.plot_temporal_cumulative_sources(\n",
    "    df, \"Text\", 13, \"Total Tokens\", EARLIEST_YEAR, SRC_CAT_CUMULATIVE_PLOTW, SRC_CAT_CUMULATIVE_PLOTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cumulative_source_chart = multimodal_util.combined_dim_charts(text_chart_sourceyearhours, speech_chart_sourceyearhours, video_chart_sourceyearhours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_combined_chart(hconchart):\n",
    "    return hconchart.configure_axis(\n",
    "        grid=False,\n",
    "        labelFontSize=13,\n",
    "        titleFontSize=15\n",
    "    ).configure_axisX(\n",
    "        labelExpr=\"datum.value == '<2013' || datum.value == '2014' || (year(datum.value) % 2 == 1 && datum.value != '<2013' && datum.value != '2014') ? datum.label : ''\",\n",
    "        labelAngle=0\n",
    "    ).configure_view(\n",
    "        stroke=None\n",
    "    )\n",
    "\n",
    "\n",
    "combined_cumulative_source_chart = post_process_combined_chart(combined_cumulative_source_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cumulative_source_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Coefficient Across Languages by (Cumulative) Total Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_textlanguagesfamilycumulativehoursgini, df_text_lang_explode = multimodal_util.prep_text_for_lang_gini(df, all_constants)\n",
    "df_textlanguagesfamilycumulativehoursgini['Type'] = 'Text ' + df_textlanguagesfamilycumulativehoursgini['Type']\n",
    "df_text_lang_explode['Modality'] = 'Text'\n",
    "df_speechlanguagesfamilycumulativehoursgini, df_speechlanguagesn = multimodal_util.prepare_speech_for_gini(df)\n",
    "df_speechlanguagesfamilycumulativehoursgini['Type'] = 'Speech ' + df_speechlanguagesfamilycumulativehoursgini['Type']\n",
    "df_speechlanguagesn['Modality'] = 'Speech'\n",
    "df_speech_text_gini = pd.concat([df_textlanguagesfamilycumulativehoursgini,df_speechlanguagesfamilycumulativehoursgini])\n",
    "df_speech_text_spec = pd.concat([df_text_lang_explode,df_speechlanguagesn])\n",
    "# df_speech_text_spec = df_speech_text_spec.rename(columns={'Language (ISO)': 'Languages (ISO)', \"Language Family\": \"Language Families\"})\n",
    "# gini_label_mapper = {\n",
    "#     \"Text Language (ISO)\": \"Text Languages (ISO)\", \"Speech Language (ISO)\": \"Speech Languages (ISO)\",\n",
    "#     \"Text Language Family\": \"Text Language Families\", \"Speech Language Family\": \"Speech Language Families\",\n",
    "# }\n",
    "# df_speech_text_gini[\"Type\"] = df_speech_text_gini[\"Type\"].map(lambda x: gini_label_mapper.get(x, x))\n",
    "lang_gini_chart = multimodal_util.plot_temporal_ginis(df_speech_text_gini, df_speech_text_spec, [\"Language (ISO)\", \"Language Family\"], columns=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gini_locs, df_spec_locs = multimodal_util.prepare_geo_gini_data(df)\n",
    "geo_gini_chart = multimodal_util.plot_temporal_ginis(df_gini_locs, df_spec_locs, [\"Countries\"], columns=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec_src = multimodal_util.prepare_data_cum_barchart(df_spec_locs, \"Countries\")\n",
    "geo_barchart = multimodal_util.plot_cum_barchart(df_spec_src, \"Countries\", domains=[\"Video\", \"Speech\", \"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec_src_lang = multimodal_util.prepare_data_cum_barchart(df_speech_text_spec, \"Language (ISO)\")\n",
    "lang_barchart = multimodal_util.plot_cum_barchart(df_spec_src_lang, \"Language (ISO)\", domains=[\"Speech\", \"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_gini_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_gini_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_spec_src_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df[df[\"Modality\"] == \"Text\"]\n",
    "df_text[\"Source\"] = df_text[\"Text Sources\"]\n",
    "df_speech = df[df[\"Modality\"] == \"Speech\"]\n",
    "df_speech[\"Task Categories\"] = df_speech[\"Tasks\"]\n",
    "df_video = df[df[\"Modality\"] == \"Video\"]\n",
    "df_video[\"Source\"] = df_video[\"Source Category\"]\n",
    "df_mod_merged = pd.concat([df_text, df_speech, df_video])\n",
    "# df_text_speech_merged = pd.concat([df_text, df_speech])\n",
    "\n",
    "# \\textsc{Modality} & \\multicolumn{2}{c}{\\textsc{Dimensions}} & \\multicolumn{2}{c}{\\textsc{Sources}} & \\multicolumn{2}{c}{\\textsc{Tasks}} \n",
    "# & \\multicolumn{2}{c}{\\textsc{Creators}} & \\multicolumn{2}{c}{\\textsc{Languages}} & \\textsc{Licenses}  \\\\\n",
    " # & \\textsc{Datasets} & \\textsc{|Size|} & \\textsc{|Unique|} & \\textsc{Domains} & \\textsc{|Unique|} & \\textsc{Categories} & \\textsc{|Unique|} & \\textsc{Countries} & \\textsc{|Unique|} & \\textsc{|Families|} & \\textsc{|Unique|} \\\\\n",
    "\n",
    "# Dimensions, Sources, Tasks, Creators, Licenses\n",
    "# Year Released? \n",
    "def unpack_key_stats(df_spec, sum_col, task_col, src_col):\n",
    "    df_spec['License Resolved'] = df_spec['Licenses'].apply(lambda x: [d['License'] for d in x])\n",
    "    return {\n",
    "        \"Num Datasets\": len(df_spec),\n",
    "        \"Total Size\": df_spec[sum_col].sum(),\n",
    "        \"Mean Size\": df_spec[sum_col].sum() / len(df_spec),\n",
    "        \"Unique Creators\": df_spec.explode(\"Creators\")[\"Creators\"].nunique(),\n",
    "        \"Countries\": df_spec.explode(\"Countries\")[\"Countries\"].nunique(),\n",
    "        \"Sources\": df_spec.explode(src_col)[src_col].nunique(),\n",
    "        \"Source Categories\": df_spec.explode(\"Source Category\")[\"Source Category\"].nunique(),\n",
    "        \"Task Categories\": df_spec.explode(task_col)[task_col].nunique(),\n",
    "        \"Unique Licenses\": df_spec.explode(\"License Resolved\")[\"License Resolved\"].nunique(),\n",
    "    }\n",
    "\n",
    "def unpack_total_stats(df_spec):\n",
    "    df_spec['License Resolved'] = df_spec['Licenses'].apply(lambda x: [d['License'] for d in x])\n",
    "    return {\n",
    "        \"Num Datasets\": len(df_spec),\n",
    "        # \"Total Size\": df_spec[sum_col].sum(),\n",
    "        # \"Mean Size\": df_spec[sum_col].sum() / len(df_spec),\n",
    "        \"Unique Creators\": df_spec.explode(\"Creators\")[\"Creators\"].nunique(),\n",
    "        \"Countries\": df_spec.explode(\"Countries\")[\"Countries\"].nunique(),\n",
    "        \"Sources\": df_spec.explode(\"Source\")[\"Source\"].nunique(),\n",
    "        \"Source Categories\": df_spec.explode(\"Source Category\")[\"Source Category\"].nunique(),\n",
    "        \"Task Categories\": df_spec.explode(\"Task Categories\")[\"Task Categories\"].nunique(),\n",
    "        \"Unique Licenses\": df_spec.explode(\"License Resolved\")[\"License Resolved\"].nunique(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpack_key_stats(df_video, \"Hours\", \"Task Categories\", \"Source Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpack_key_stats(df_speech, \"Hours\", \"Task Categories\", \"Source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpack_key_stats(df_text, \"Total Tokens\", \"Task Categories\", \"Text Sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpack_total_stats(df_mod_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_speech_text_spec[\"Language (ISO)\"].nunique())\n",
    "print(df_speech_text_spec[\"Language Family\"].nunique())\n",
    "# df_text_speech_merged[\"Language Families\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_speech_text_spec[df_speech_text_spec[\"Modality\"] == \"Speech\"][\"Language (ISO)\"].unique()\n",
    "df_speech_text_spec[\"Language (ISO)\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lang_codes = df_speech_text_spec[\"Language (ISO)\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_langs = df_speech_text_spec[df_speech_text_spec[\"Modality\"] == \"Text\"][\"Language (ISO)\"].unique()\n",
    "df_speech_langs = df_speech_text_spec[df_speech_text_spec[\"Modality\"] == \"Speech\"][\"Language (ISO)\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_human_language(code):\n",
    "    try:\n",
    "        lang = langcodes.Language.get(code)\n",
    "\n",
    "        # Ensure it's a valid language code and not a fallback\n",
    "        return lang.is_valid()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def dedup_langs(vals):\n",
    "    natlangs, proglangs = set(), set()\n",
    "    for val in vals:\n",
    "        if is_human_language(val):\n",
    "            natlangs.add(langcodes.Language.get(val).language)\n",
    "        else:\n",
    "            proglangs.add(val)\n",
    "\n",
    "    natlangs = sorted(natlangs)\n",
    "    proglangs = sorted(proglangs)\n",
    "\n",
    "    natlang_names = [\n",
    "        langcodes.Language.get(v).display_name()\n",
    "        for v in natlangs\n",
    "    ]\n",
    "\n",
    "    assert len(natlang_names) == len(set(natlang_names))\n",
    "\n",
    "    # print(f'Natural Languages ({len(natlangs)}): {natlangs}')\n",
    "    print(f'Natural Languages ({len(natlangs)})')\n",
    "    # print()\n",
    "    # print(f'Natural Language Names: {natlang_names}')\n",
    "    # print()\n",
    "    # print(f'Programming Languages ({len(proglangs)}): {proglangs}')\n",
    "    print(f'Programming Languages ({len(proglangs)})')\n",
    "    print(f\"Sum: {len(natlangs) + len(proglangs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedup_langs(all_lang_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedup_langs(df_text_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedup_langs(df_speech_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DPC",
   "language": "python",
   "name": "pdc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 6,
           "op": "addrange",
           "valuelist": "4"
          },
          {
           "key": 6,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": 0,
         "op": "patch"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ]
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
