{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f00a19d2-905f-4f34-af98-d748426c1b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langcodes in /Users/shayne/Documents/research/notebooks/venv/lib/python3.8/site-packages (3.4.1)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/shayne/Documents/research/notebooks/venv/lib/python3.8/site-packages (from langcodes) (1.2.0)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/shayne/Documents/research/notebooks/venv/lib/python3.8/site-packages (from language-data>=1.2->langcodes) (1.2.1)\n",
      "Requirement already satisfied: setuptools in /Users/shayne/Documents/research/notebooks/venv/lib/python3.8/site-packages (from marisa-trie>=0.7.7->language-data>=1.2->langcodes) (67.6.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install langcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ea5d2d9-0590-4833-94f2-5f99b75c0702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib:matplotlib data path: /Users/shayne/Documents/research/notebooks/venv/lib/python3.8/site-packages/matplotlib/mpl-data\n",
      "DEBUG:matplotlib:CONFIGDIR=/Users/shayne/.matplotlib\n",
      "DEBUG:matplotlib:interactive is False\n",
      "DEBUG:matplotlib:platform is darwin\n",
      "DEBUG:matplotlib:CACHEDIR=/Users/shayne/.matplotlib\n",
      "DEBUG:matplotlib.font_manager:Using fontManager instance from /Users/shayne/.matplotlib/fontlist-v330.json\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Append system path\n",
    "sys.path = [p for p in sys.path if not p.endswith(\"../..\")]  # Cleans duplicated '../..\"\n",
    "sys.path.insert(0, \"../\")  # This adds `src` to the path\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import langcodes\n",
    "from collections import Counter, defaultdict\n",
    "alt.data_transformers.disable_max_rows() # Allow using more than 5000 rows, for now\n",
    "logging.basicConfig(level=logging.DEBUG, handlers=[logging.StreamHandler(stream=sys.stdout)])\n",
    "from vega_datasets import data\n",
    "from helpers import io\n",
    "from analysis import multimodal_util\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b193a338-0808-47ee-92d7-3b84e77d067e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Checking Text Data Summaries against Constants\n",
      "INFO:root:Checking Speech Data Summaries against Constants\n",
      "INFO:root:Checking Video Data Summaries against Constants\n"
     ]
    }
   ],
   "source": [
    "# Whether and where to output plots\n",
    "PLOT_TOFILE = True\n",
    "PLOT_DIR = \"~/dpi-plotsmultimodal/\"\n",
    "PLOT_PPI = 300\n",
    "MAX_LABELLIMIT = 400 # Large number to avoid label summarization in plots\n",
    "\n",
    "PLOT_DIR = os.path.expanduser(PLOT_DIR)\n",
    "\n",
    "# Create directory if needed\n",
    "if PLOT_TOFILE:\n",
    "    os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "\n",
    "# Plotting constants\n",
    "LICENSE_ORDER = [\"NC/Acad\", \"Unspecified\", \"Commercial\"]\n",
    "LICENSE_PALETTE = [\"#e04c71\", \"#e0cd92\", \"#82b5cf\"]\n",
    "LICENSE_TERMS_ORDER = [\n",
    "    \"NC/Acad | Model Closed\", \"NC/Acad | Source Closed\", \"NC/Acad | Unspecified\", \"NC/Acad | Unrestricted\",\n",
    "    \"Unspecified | Model Closed\", \"Unspecified | Source Closed\", \"Unspecified | Unspecified\", \"Unspecified | Unrestricted\",\n",
    "    \"Commercial | Model Closed\", \"Commercial | Source Closed\", \"Commercial | Unspecified\", \"Commercial | Unrestricted\",\n",
    "]\n",
    "LICENSE_TERMS_ORDER_VARIANT = [\n",
    "    \"NC/Acad | Restricted\", \"NC/Acad | Unspecified\", \"NC/Acad | Unrestricted\",\n",
    "    \"Unspecified | Restricted\", \"Unspecified | Unspecified\", \"Unspecified | Unrestricted\",\n",
    "    \"Commercial | Restricted\", \"Commercial | Unspecified\", \"Commercial | Unrestricted\"\n",
    "]\n",
    "LICENSE_TERMS_PALETTE = [\n",
    "    '#9d354f', '#c24262', '#e04c71',\n",
    "    '#9d9066', '#c2b27f', '#e0cd92',\n",
    "    '#5b7f91', '#719db3', '#82b5cf',\n",
    "]\n",
    "\n",
    "LICENSE_PLOTW = 400\n",
    "LICENSE_PLOTH = 100\n",
    "YEAR_CATEGORIES = [\"Unknown\", \"<2013\", *list(map(str, range(2013, 2025)))]\n",
    "\n",
    "# Read constants\n",
    "all_constants = io.read_all_constants(\"../../constants/\")\n",
    "\n",
    "# Read Terms data\n",
    "collection_to_terms_mapper = multimodal_util.load_terms_metadata(\"data/multimodal_terms_data\")\n",
    "\n",
    "# Read individual modality summaries\n",
    "text_summaries = io.read_data_summary_json(\"../../data_summaries/\")\n",
    "logging.info(\"Checking Text Data Summaries against Constants\")\n",
    "# analysis_util.check_datasummary_in_constants(text_summaries, all_constants)\n",
    "\n",
    "speech_summaries = io.read_data_summary_json(\"../../data_summaries-speech/\")\n",
    "logging.info(\"Checking Speech Data Summaries against Constants\")\n",
    "# analysis_util.check_datasummary_in_constants(speech_summaries, all_constants)\n",
    "\n",
    "video_summaries = io.read_data_summary_json(\"../../data_summaries-video/\")\n",
    "logging.info(\"Checking Video Data Summaries against Constants\")\n",
    "# analysis_util.check_datasummary_in_constants(video_summaries, all_constants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "93db0311-b54b-4a3e-95de-fe3921834f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modality_task_annotation(df, modality, task_col, dset_col):\n",
    "    TASK_TYPEMAP = multimodal_util.invert_dict_of_lists(all_constants[\"TASK_GROUPS\"])\n",
    "    TASKCATEGORY_ORDER = sorted(set(TASK_TYPEMAP.values()) - {\"null\"})\n",
    "    df_speech = df[df['Modality'] == modality]\n",
    "        # Categorize the tasks into their respective groups\n",
    "    df_speech_tasks = multimodal_util.categorize_tasks(\n",
    "        df_speech, TASKCATEGORY_ORDER, TASK_TYPEMAP, task_col, modality, dset_col, False)\n",
    "    df_speech_tasks = df_speech_tasks[['Unique Dataset Identifier', task_col]]\n",
    "    df_speech_tasks = df_speech_tasks.rename(columns={task_col: 'Task Groups'})\n",
    "    df_speech_tasks_grouped = df_speech_tasks.groupby('Unique Dataset Identifier')['Task Groups'].apply(list).reset_index()\n",
    "    df_speech = pd.merge(df_speech, df_speech_tasks_grouped, on='Unique Dataset Identifier', how='inner')\n",
    "    return df_speech\n",
    "\n",
    "def get_terms_licenses(df):\n",
    "    LICENSE_TERMS_MODALITY_ORDER_2 = [\"Text (Collections)\", \"Text (Datasets)\", \"Speech\", \"Video\"]\n",
    "    \n",
    "    dflt = multimodal_util.plot_license_terms_stacked_bar_chart_collections(\n",
    "        df, \"License | Terms\", LICENSE_TERMS_PALETTE, LICENSE_TERMS_ORDER_VARIANT,\n",
    "        LICENSE_TERMS_MODALITY_ORDER_2, 800, 140,\n",
    "        # save_dir=PLOT_DIR,  # svg saving package compatibility issues, and you can save from the notebook anyway\n",
    "        plot_ppi=PLOT_PPI,\n",
    "        title=\"Dataset & Source Restrictions (Dataset Count)\",\n",
    "        no_legend=True,\n",
    "        split_text_mod=False,\n",
    "        return_df=True,\n",
    "        early_return=True,\n",
    "    )\n",
    "    dflt[['Dataset License', 'Collection Terms']] = dflt['License | Terms'].str.split('|', expand=True)\n",
    "    dflt['Dataset License'] = dflt['Dataset License'].str.strip()\n",
    "    dflt['Collection Terms'] = dflt['Collection Terms'].str.strip()\n",
    "    dflt = dflt[[\"Unique Dataset Identifier\", 'Dataset License', 'Collection Terms']]\n",
    "    return dflt\n",
    "\n",
    "def get_creators_info(df):\n",
    "    df_countries = df.explode(\"Countries\").dropna(subset=[\"Countries\"])  # Drop rows with no country for the moment\n",
    "    df_countries[\"Creator Country ID\"] = df_countries[\"Countries\"].map(multimodal_util.get_country)\n",
    "    df_countries_grouped = df_countries.groupby('Unique Dataset Identifier')['Creator Country ID'].apply(lambda x: [item for sublist in x for item in sublist]).reset_index()\n",
    "    df2 = pd.merge(df, df_countries_grouped, on='Unique Dataset Identifier', how='outer')\n",
    "    df2 = df2.rename(columns={\"Countries\": 'Creator Countries'})\n",
    "    return df2\n",
    "\n",
    "def get_langs_info(df):\n",
    "    _, df_text_lang_explode = multimodal_util.prep_text_for_lang_gini(df, all_constants)\n",
    "    df_text_lang_groups = df_text_lang_explode.groupby('Unique Dataset Identifier')['Language (ISO)'].apply(list).reset_index()\n",
    "    df_text_lang_groups2 = df_text_lang_explode.groupby('Unique Dataset Identifier')['Language Family'].apply(list).reset_index()\n",
    "    df_text_lang_combined = pd.merge(df_text_lang_groups, df_text_lang_groups2, on='Unique Dataset Identifier', how='outer')\n",
    "    _, df_speechlanguagesn = multimodal_util.prepare_speech_for_gini(df)\n",
    "    df_speech_lang_groups = df_speechlanguagesn.groupby('Unique Dataset Identifier')['Language (ISO)'].apply(list).reset_index()\n",
    "    df_speech_lang_groups2 = df_speechlanguagesn.groupby('Unique Dataset Identifier')['Language Family'].apply(list).reset_index()\n",
    "    df_speech_lang_combined = pd.merge(df_speech_lang_groups, df_speech_lang_groups2, on='Unique Dataset Identifier', how='outer')\n",
    "    df_langs_combined = pd.concat([df_text_lang_combined, df_speech_lang_combined])\n",
    "    return df_langs_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bbc561be-382e-43c3-b8e6-3fd3e53322f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep dataframes\n",
    "df = multimodal_util.prep_summaries_for_visualization(\n",
    "    text_summaries,\n",
    "    speech_summaries,\n",
    "    video_summaries,\n",
    "    all_constants,\n",
    "    collection_to_terms_mapper,\n",
    "    YEAR_CATEGORIES,\n",
    "    LICENSE_ORDER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "971a5397-af50-420a-87b8-6fe1cfaa2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speech = modality_task_annotation(df, \"Speech\", \"Tasks\", \"Datasets\")\n",
    "df_video = modality_task_annotation(df, \"Video\", \"Task Categories\", \"Datasets\")\n",
    "df_text = modality_task_annotation(df, \"Text\", \"Task Categories\", \"Collections\")\n",
    "df_w_tasks = pd.concat([df_text, df_speech, df_video])\n",
    "\n",
    "df_w_creators = get_creators_info(df)\n",
    "\n",
    "df_w_langs = get_langs_info(df)\n",
    "\n",
    "df_w_licterms = get_terms_licenses(df)\n",
    "\n",
    "df_merged = pd.merge(df, df_w_tasks, on='Unique Dataset Identifier', how='outer')\n",
    "df_merged = pd.merge(df_merged, df_w_creators, on='Unique Dataset Identifier', how='outer')\n",
    "df_merged = pd.merge(df_merged, df_w_langs, on='Unique Dataset Identifier', how='outer')\n",
    "df_merged = pd.merge(df_merged, df_w_licterms, on='Unique Dataset Identifier', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "049ddf24-050f-430a-a784-31ed66b645c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_short = df_merged[['Unique Dataset Identifier', 'Dataset Name', 'Paper Title',\n",
    "    'Dataset URL', 'GitHub URL', 'Hugging Face URL', 'Papers with Code URL',\n",
    "    'ArXiv URL', 'Semantic Scholar Corpus ID', 'Collection',\n",
    "    'Collection URL', 'Text Sources',\n",
    "    'Model Generated', 'Human Annotation', 'Derived from Datasets', 'Creators', 'Licenses', 'Bibtex',\n",
    "    'Inferred Metadata', 'Text Metrics', 'GitHub License',\n",
    "    'HF Yaml License', 'HF Config License', 'PwC License',\n",
    "    'License Use (DataProvenance)', 'License Attribution (DataProvenance)',\n",
    "    'License Share Alike (DataProvenance)', 'Modality', 'Total Tokens', 'Year Released', 'Hours', 'Speakers', 'Source Category',\n",
    "    'Paper URL', 'Website URL',\n",
    "    'Language (ISO)', 'Language Family', 'Task Groups', 'Dataset License', 'Collection Terms', 'Creator Countries',                  \n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bd18e6f9-7c7c-442c-b653-a6016ac8669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_short.to_csv(\"multimodal_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e25710-f62e-4d60-90a8-aa5cbd1eae9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcbc3aa-f503-42d2-bbdf-775a0705fb04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62366f62-91eb-4725-a9b2-c837fb06e034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee7e3a2-901c-4fa9-9b62-2dc68e3f11e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8298cf5d-994f-4fcf-bfc3-b921b144c100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6c1b3b68-7576-4a01-b66c-372b9ff0e1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6db787-81c3-49c4-b03a-af82559efe1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f831937-69ad-4fb4-8c52-baac7bf29b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ab180960-b24b-433b-b181-1e383156c1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2392b68a-a947-4c8e-9b09-1e50b00dd607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f71ee109-9a93-4970-b1f7-cf46a0fabb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85165f2-e063-4561-99b8-8da91c2990eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "663e40f7-41f0-4ba2-9223-299d3f6e1128",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8507671c-3c04-4737-811e-c7a08a111e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62f127-9c09-4106-b473-b92d6102608c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c9605a-9694-4f81-b09a-d75baca8468b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb948a-f3c4-4669-bad1-150585b0c0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
