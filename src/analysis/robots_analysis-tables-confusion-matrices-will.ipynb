{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271834be-94ee-4002-8ced-73a0790fbf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from scipy.stats import norm, normaltest, percentileofscore\n",
    "\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Append system path\n",
    "sys.path = [p for p in sys.path if not p.endswith('../..')]  # Cleans duplicated '../..'\n",
    "sys.path.insert(0, '../')  # This adds `src` to the path\n",
    "\n",
    "from helpers import io, filters, constants\n",
    "from analysis import analysis_util, analysis_constants, visualization_util\n",
    "from web_analysis import parse_robots\n",
    "from web_analysis import robots_util, forecasting_util\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4328e2d4-2ad6-49d6-b6cc-681cf754982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(os.path.expanduser('~/github/Data-Provenance-Collection/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb20c3-9ae5-4b07-9cad-57ba6be704b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def times_newroman():\n",
    "    font = \"Times New Roman\"\n",
    "\n",
    "    return {\n",
    "          \"config\" : {\n",
    "               \"title\": {\"font\": font},\n",
    "               \"axis\": {\n",
    "               \"labelFont\": font,\n",
    "               \"titleFont\": font\n",
    "          },\n",
    "          \"header\": {\n",
    "               \"labelFont\": font,\n",
    "               \"titleFont\": font\n",
    "          },\n",
    "          \"legend\": {\n",
    "               \"labelFont\": font,\n",
    "               \"titleFont\": font\n",
    "          },\n",
    "          \"text\": {\n",
    "               \"font\": font\n",
    "          }\n",
    "     }\n",
    "}\n",
    "\n",
    "alt.themes.register(\"times_newroman\", times_newroman)\n",
    "alt.themes.enable(\"times_newroman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff9fe53-c58f-4e63-8540-abeec244540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe935ae-6338-4e3b-bd10-13123b0a978a",
   "metadata": {},
   "source": [
    "### Define Paths to all relevant files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9911b890-bd6c-40ca-a15b-02a30aa70ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCEL_FNAME_ROBOTS = \"data/forecasted_robots_data.xlsx\"\n",
    "EXCEL_FNAME_TOS = \"data/forecasted_tos_data.xlsx\"\n",
    "EXCEL_FNAME_FINAL = \"data/forecasted_final_data.xlsx\"\n",
    "FPATH_TO_RELEVANT_URL_TOKENS = 'data/pretrain_data/relevant_url_token_counts.csv'\n",
    "FPATH_to_HEAD_ROBOTS = \"data/robots/temporal_robots_head.json\"\n",
    "FPATH_TO_RAND_ROBOTS = \"data/robots/temporal_robots_rand_10k.json\"\n",
    "FPATH_TO_TOS_DATA = \"data/GPT_analysis_results/tos_ai_scraping_policies.json\"\n",
    "FPATH_TO_TOS_LICENSE_DATA = \"data/GPT_analysis_results/tos_license_policies.json\"\n",
    "FPATH_TO_TOS_COMPETE_DATA = \"data/GPT_analysis_results/tos_competing_services_policies.json\"\n",
    "FPATH_TO_C4_TOKEN_ESTIMATES = \"data/raw_annotations/c4_total_token_estimates.csv\" \n",
    "FPATH_TO_DOLMA_TOKEN_ESTIMATES = \"data/raw_annotations/dolma_total_token_estimates.csv\"\n",
    "FPATH_TO_RF_TOKEN_ESTIMATES = \"data/raw_annotations/rf_total_token_estimates.csv\" \n",
    "DIRPATHS_TO_ANNOTATED_TASKS = [\"data/raw_annotations/task_1\", \"data/raw_annotations/task_2\"]\n",
    "START_DATES = \"data/raw_annotations/domain_start_dates.json\"\n",
    "\n",
    "ALL_COMPANIES_TO_TRACK = [\"Google\", \"OpenAI\", \"Anthropic\", \"Cohere\", \"Common Crawl\", \"Meta\", \"Internet Archive\", \"Google Search\", \"False Anthropic\"]\n",
    "COMPANIES_TO_ANALYZE = [\"Google\", \"OpenAI\", \"Anthropic\", \"Cohere\", \"Common Crawl\", \"Meta\"]\n",
    "TEMPORAL_ANALYSIS_START_DATE = '2016-01-01'\n",
    "TEMPORAL_ANALYSIS_END_DATE = '2024-04-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee96fd8b-6342-476c-bff6-72a525e1da36",
   "metadata": {},
   "source": [
    "### Load all URL splits (top vs random) and maps to Token Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3b2a93-5a35-4c7e-b087-73dd4db273f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_token_lookup = robots_util.URLTokenLookup(FPATH_TO_RELEVANT_URL_TOKENS) # 'c4', 'rf', 'dolma'\n",
    "c4_url_to_counts = url_token_lookup.get_url_to_token_map(\"c4\")\n",
    "rf_url_to_counts = url_token_lookup.get_url_to_token_map(\"rf\")\n",
    "dolma_url_to_counts = url_token_lookup.get_url_to_token_map(\"dolma\")\n",
    "top_c4_urls = url_token_lookup.top_k_urls(\"c4\", 2000)\n",
    "top_rf_urls = url_token_lookup.top_k_urls(\"rf\", 2000)\n",
    "top_dolma_urls = url_token_lookup.top_k_urls(\"dolma\", 2000)\n",
    "random_10k_urls = url_token_lookup.get_10k_random_sample()\n",
    "all_urls = set(random_10k_urls + top_c4_urls + top_rf_urls + top_dolma_urls)\n",
    "\n",
    "# Load website snapshots for relevant URLs\n",
    "website_start_dates = robots_util.read_start_dates(START_DATES, all_urls) # THIS WON'T WORK FOR THE 10k SAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54f01e-6c3a-4f48-a889-ba765dc9450f",
   "metadata": {},
   "source": [
    "### Define Agents and Agent Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b750e-3c52-4578-a486-b8ad1a2a88a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_groups_to_track = robots_util.get_bot_groups(ALL_COMPANIES_TO_TRACK)\n",
    "agents_to_track = robots_util.get_bots()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09644e3-d075-4a46-8445-d8179ae29bc9",
   "metadata": {},
   "source": [
    "### Load Robots.txt info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e969a9-1d0b-4b95-9ccf-ff15840d94e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL -> Date -> Robots.txt raw text\n",
    "head_robots = io.read_json(FPATH_to_HEAD_ROBOTS)\n",
    "random_10k_robots = io.read_json(FPATH_TO_RAND_ROBOTS)\n",
    "joined_robots = copy.deepcopy(head_robots)\n",
    "joined_robots.update(random_10k_robots)\n",
    "robots_util.print_out_robots_info(head_robots)\n",
    "robots_util.print_out_robots_info(random_10k_robots)\n",
    "\n",
    "# {URL --> Date --> Agent --> Status}\n",
    "url_robots_summary, agent_counter_df = robots_util.compute_url_date_agent_status(\n",
    "    data=joined_robots, \n",
    "    # relevant_agents=agents_to_track)\n",
    "    relevant_agents=[v for vs in agent_groups_to_track.values() for v in vs])\n",
    "\n",
    "# agent_counter_df.to_csv(\"src/analysis/all_agents_counter.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3988a4-0a7c-427f-a311-4b36cd8b5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_robots_summary_detailed = robots_util.compute_url_date_agent_status_detailed(\n",
    "    data=joined_robots, \n",
    "    relevant_agents=[v for vs in agent_groups_to_track.values() for v in vs]\n",
    ")\n",
    "print(len(url_robots_summary_detailed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e26ade-d9e9-4900-a3b3-a01af4a698b1",
   "metadata": {},
   "source": [
    "### Load ToS info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70351b94-b889-4f16-9c31-56fd61f43464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL --> Date --> ToS-suburl --> {\"verdict\": X, \"evidence\": Y}\n",
    "tos_policies = {robots_util.normalize_url(url): info for url, info in io.read_json(FPATH_TO_TOS_DATA).items()}\n",
    "tos_license_policies = {robots_util.normalize_url(url): info for url, info in io.read_json(FPATH_TO_TOS_LICENSE_DATA).items()}\n",
    "tos_compete_policies = {robots_util.normalize_url(url): info for url, info in io.read_json(FPATH_TO_TOS_COMPETE_DATA).items()}\n",
    "# tos_license_policies = robots_util.switch_dates_yearly_to_monthly(tos_license_policies)\n",
    "print(f\"Num ToS AI/Scraping URLs: {len(tos_policies)}\")\n",
    "print(f\"Num ToS License URLs: {len(tos_license_policies)}\")\n",
    "print(f\"Num ToS Compete URLs: {len(tos_compete_policies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36901240-db00-4c04-9ac3-6f5377233736",
   "metadata": {},
   "source": [
    "### Load Manual Pretraining Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e586df-d0ba-44f0-ba5c-e260380107c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_info, unannotated_urls = analysis_util.extract_url_annotations(DIRPATHS_TO_ANNOTATED_TASKS)\n",
    "url_results_df = analysis_util.process_url_annotations(url_to_info)\n",
    "url_results_df = analysis_util.encode_size_columns(url_results_df, url_token_lookup)\n",
    "manually_annotated_urls = url_results_df[\"URL\"].tolist()\n",
    "url_results_df = robots_util.encode_latest_tos_robots_into_df(\n",
    "    url_results_df, tos_policies, tos_license_policies, tos_compete_policies, url_robots_summary_detailed,\n",
    "    COMPANIES_TO_ANALYZE, True\n",
    ")\n",
    "service_to_urls = analysis_util.map_services_to_urls(url_results_df)\n",
    "\n",
    "assert url_results_df['URL'].nunique() == url_results_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269da64d-baab-4bfe-8988-1c5527411ad5",
   "metadata": {},
   "source": [
    "### DECISION POINT: Use C4, Dolma, or RefinedWeb here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345cd5b-51c5-4545-92be-0f1245c1ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_CORPUS = \"c4\" # 'c4', 'rf', 'dolma'\n",
    "if CHOSEN_CORPUS == \"c4\":\n",
    "    HEAD_URL_SET = top_c4_urls\n",
    "    URL_TO_COUNTS = c4_url_to_counts\n",
    "elif CHOSEN_CORPUS == \"rf\":\n",
    "    HEAD_URL_SET = top_rf_urls\n",
    "    URL_TO_COUNTS = rf_url_to_counts\n",
    "elif CHOSEN_CORPUS == \"dolma\":\n",
    "    HEAD_URL_SET = top_dolma_urls\n",
    "    URL_TO_COUNTS = dolma_url_to_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29cd94f-5f99-482a-ad60-beb4e8872de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_robots_summary_head = {url: url_robots_summary[url] for url in HEAD_URL_SET if url in url_robots_summary}\n",
    "url_robots_summary_head_detailed = {url: url_robots_summary_detailed[url] for url in HEAD_URL_SET if url in url_robots_summary_detailed}\n",
    "url_robots_summary_rand = {url: url_robots_summary[url] for url in random_10k_urls if url in url_robots_summary}\n",
    "url_robots_summary_rand_detailed = {url: url_robots_summary_detailed[url] for url in random_10k_urls if url in url_robots_summary_detailed}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68ecf56-190e-4bf0-b689-a22f24213028",
   "metadata": {},
   "source": [
    "# Robots Data for Ariel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0daa7-c5da-4c9d-806f-c796817c3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "DETAILED_ROBOTS_STRICTNESS_ORDER = [\n",
    "    'no_robots', 'none', 'none_sitemap', 'none_crawl_delay', 'some_pattern_restrictions', 'some_disallow_important_dir', 'some_other', 'all'\n",
    "]\n",
    "\n",
    "# C4\n",
    "urlsubset_to_robots_summary_c4, c4_url_subsets = robots_util.prepare_temporal_robots_for_corpus(\n",
    "    url_robots_summary_detailed,\n",
    "    top_c4_urls,\n",
    "    random_10k_urls,\n",
    "    service_to_urls,\n",
    "    c4_url_to_counts,\n",
    "    agent_groups_to_track,\n",
    "    DETAILED_ROBOTS_STRICTNESS_ORDER,\n",
    "    TEMPORAL_ANALYSIS_START_DATE,\n",
    "    TEMPORAL_ANALYSIS_END_DATE,\n",
    "    website_start_dates,   \n",
    ")\n",
    "# REFINEDWEB\n",
    "urlsubset_to_robots_summary_rf, rf_url_subsets = robots_util.prepare_temporal_robots_for_corpus(\n",
    "    url_robots_summary_detailed,\n",
    "    top_rf_urls,\n",
    "    random_10k_urls,\n",
    "    service_to_urls,\n",
    "    rf_url_to_counts,\n",
    "    agent_groups_to_track,\n",
    "    DETAILED_ROBOTS_STRICTNESS_ORDER,\n",
    "    TEMPORAL_ANALYSIS_START_DATE,\n",
    "    TEMPORAL_ANALYSIS_END_DATE,\n",
    "    website_start_dates,   \n",
    ")\n",
    "# DOLMA\n",
    "urlsubset_to_robots_summary_dolma, dolma_url_subsets = robots_util.prepare_temporal_robots_for_corpus(\n",
    "    url_robots_summary_detailed,\n",
    "    top_dolma_urls,\n",
    "    random_10k_urls,\n",
    "    service_to_urls,\n",
    "    dolma_url_to_counts,\n",
    "    agent_groups_to_track,\n",
    "    DETAILED_ROBOTS_STRICTNESS_ORDER,\n",
    "    TEMPORAL_ANALYSIS_START_DATE,\n",
    "    TEMPORAL_ANALYSIS_END_DATE,\n",
    "    website_start_dates,   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847e3034-7dd6-41ef-b45d-77bec4d67892",
   "metadata": {},
   "source": [
    "# ToS Data for Ariel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef2c5b-6cd5-4dc0-9d3d-f5c004496905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4\n",
    "urlsubset_to_tos_summary_c4, c4_tos_url_subsets = robots_util.prepare_temporal_tos_for_corpus(\n",
    "    tos_policies,\n",
    "    tos_license_policies,\n",
    "    tos_compete_policies,\n",
    "    top_c4_urls,\n",
    "    random_10k_urls,\n",
    "    service_to_urls,\n",
    "    c4_url_to_counts,\n",
    "    agent_groups_to_track,\n",
    "    TEMPORAL_ANALYSIS_START_DATE,\n",
    "    TEMPORAL_ANALYSIS_END_DATE,\n",
    "    manually_annotated_urls,\n",
    "    website_start_dates,\n",
    ")\n",
    "# REFINEDWEB\n",
    "urlsubset_to_tos_summary_rf, rf_tos_url_subsets = robots_util.prepare_temporal_tos_for_corpus(\n",
    "    tos_policies,\n",
    "    tos_license_policies,\n",
    "    tos_compete_policies,\n",
    "    top_rf_urls,\n",
    "    random_10k_urls,\n",
    "    service_to_urls,\n",
    "    rf_url_to_counts,\n",
    "    agent_groups_to_track,\n",
    "    TEMPORAL_ANALYSIS_START_DATE,\n",
    "    TEMPORAL_ANALYSIS_END_DATE,\n",
    "    manually_annotated_urls,\n",
    "    website_start_dates,\n",
    ")\n",
    "# DOLMA\n",
    "urlsubset_to_tos_summary_dolma, dolma_tos_url_subsets = robots_util.prepare_temporal_tos_for_corpus(\n",
    "    tos_policies,\n",
    "    tos_license_policies,\n",
    "    tos_compete_policies,\n",
    "    top_dolma_urls,\n",
    "    random_10k_urls,\n",
    "    service_to_urls,\n",
    "    dolma_url_to_counts,\n",
    "    agent_groups_to_track,\n",
    "    TEMPORAL_ANALYSIS_START_DATE,\n",
    "    TEMPORAL_ANALYSIS_END_DATE,\n",
    "    manually_annotated_urls,\n",
    "    website_start_dates,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c9dfba-95c2-4c5e-b9ae-c3a928fe5452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statuses_to_include = ['all', 'some_pattern_restrictions', 'some_disallow_important_dir']\n",
    "ROBOTS_STATUSES_TO_INCLUDE = ['all']\n",
    "TARGET_AGENT = 'Combined Agent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fffde7-c98f-43af-9c74-9ba130f73fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4\n",
    "robots_util.generate_corpus_restriction_estimates_per_url_split(\n",
    "    urlsubset_to_robots_summary_c4,\n",
    "    c4_url_subsets,\n",
    "    \"c4\",\n",
    "    url_token_lookup,\n",
    "    TARGET_AGENT,\n",
    "    ROBOTS_STATUSES_TO_INCLUDE,\n",
    "    save_dir=\"data/forecasting/robots\",\n",
    ")\n",
    "# REFINEDWEB\n",
    "robots_util.generate_corpus_restriction_estimates_per_url_split(\n",
    "    urlsubset_to_robots_summary_rf,\n",
    "    rf_url_subsets,\n",
    "    \"rf\",\n",
    "    url_token_lookup,\n",
    "    TARGET_AGENT,\n",
    "    ROBOTS_STATUSES_TO_INCLUDE,\n",
    "    save_dir=\"data/forecasting/robots\",\n",
    ")\n",
    "# DOLMA\n",
    "robots_util.generate_corpus_restriction_estimates_per_url_split(\n",
    "    urlsubset_to_robots_summary_dolma,\n",
    "    dolma_url_subsets,\n",
    "    \"dolma\",\n",
    "    url_token_lookup,\n",
    "    TARGET_AGENT,\n",
    "    ROBOTS_STATUSES_TO_INCLUDE,\n",
    "    save_dir=\"data/forecasting/robots\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c083ff8f-d215-46e5-8217-a89b708984e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOS_STATUSES_TO_EXCLUDE = [\n",
    "    'No Scraping & AI', 'NC Only', 'No Scraping', 'No Re-Distribution', 'Non-Compete', 'No AI', 'Conditional Use'\n",
    "]\n",
    "\n",
    "# # C4\n",
    "robots_util.generate_corpus_restriction_estimates_per_url_split(\n",
    "    urlsubset_to_tos_summary_c4,\n",
    "    c4_tos_url_subsets,\n",
    "    \"c4\",\n",
    "    url_token_lookup,\n",
    "    TARGET_AGENT,\n",
    "    TOS_STATUSES_TO_EXCLUDE,\n",
    "    save_dir=\"data/forecasting/tos\",\n",
    ")\n",
    "# REFINEDWEB\n",
    "robots_util.generate_corpus_restriction_estimates_per_url_split(\n",
    "    urlsubset_to_tos_summary_rf,\n",
    "    rf_tos_url_subsets,\n",
    "    \"rf\",\n",
    "    url_token_lookup,\n",
    "    TARGET_AGENT,\n",
    "    TOS_STATUSES_TO_EXCLUDE,\n",
    "    save_dir=\"data/forecasting/tos\",\n",
    ")\n",
    "# DOLMA\n",
    "robots_util.generate_corpus_restriction_estimates_per_url_split(\n",
    "    urlsubset_to_tos_summary_dolma,\n",
    "    dolma_tos_url_subsets,\n",
    "    \"dolma\",\n",
    "    url_token_lookup,\n",
    "    TARGET_AGENT,\n",
    "    TOS_STATUSES_TO_EXCLUDE,\n",
    "    save_dir=\"data/forecasting/tos\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3002a9-b499-4a0f-bee1-9e433c4cf5e3",
   "metadata": {},
   "source": [
    "# Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef5ed97-51c1-48e6-a76a-9eedc501db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ALL_VARS = [\n",
    "    'User Content', 'Paywall', 'Ads','Modality: Image', 'Modality: Video', 'Modality: Audio',\n",
    "    'Sensitive Content', 'services_Academic', 'services_Blogs',\n",
    "    'services_E-Commerce', 'services_Encyclopedia/Database',\n",
    "    'services_Government', 'services_News/Periodicals',\n",
    "    'services_Organization/Personal Website', 'services_Other',\n",
    "    'services_Social Media/Forums', 'Restrictive Robots.txt', 'Restrictive Terms'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def url_variable_instance(url_token_lookup, url_results_df, n_resamples=100000, n_pa_resamples=200):\n",
    "    url_correlation_df = analysis_util.analyze_url_variable_correlations(url_results_df, ALL_VARS)\n",
    "\n",
    "    def pop_analysis(df, domains=None):\n",
    "        if domains is not None:\n",
    "            c4_domains, rf_domains, dolma_domains = domains, domains, domains\n",
    "        else:\n",
    "            c4_domains = url_token_lookup.top_k_urls('c4', 2000)\n",
    "            rf_domains = url_token_lookup.top_k_urls('rf', 2000)\n",
    "            dolma_domains = url_token_lookup.top_k_urls('dolma', 2000)\n",
    "            \n",
    "        return {\n",
    "            'C4': analysis_util.run_population_analysis(\n",
    "                df,\n",
    "                url_token_lookup,\n",
    "                'c4',\n",
    "                ALL_VARS,\n",
    "                c4_domains,\n",
    "                # True,\n",
    "            )['est_tokens_pct'],\n",
    "            \n",
    "            'RW': analysis_util.run_population_analysis(\n",
    "                df, \n",
    "                url_token_lookup,\n",
    "                'rf',\n",
    "                ALL_VARS,\n",
    "                rf_domains,\n",
    "            )['est_tokens_pct'],\n",
    "            \n",
    "            'Dolma': analysis_util.run_population_analysis(\n",
    "                df, \n",
    "                url_token_lookup,\n",
    "                'dolma',\n",
    "                ALL_VARS,\n",
    "                dolma_domains,\n",
    "            )['est_tokens_pct']\n",
    "        }\n",
    "\n",
    "    # print(len(url_results_df))\n",
    "    pct_tokens_in_corpus = pop_analysis(url_results_df)\n",
    "    url_correlation_df['C4'] = pct_tokens_in_corpus['C4']\n",
    "    url_correlation_df['RW'] = pct_tokens_in_corpus['RW']\n",
    "    url_correlation_df['Dolma'] = pct_tokens_in_corpus['Dolma']\n",
    "    # return url_correlation_df, None, None\n",
    "\n",
    "    if n_resamples is not None and n_resamples > 0:\n",
    "        tmp = url_results_df.copy().set_index('URL')\n",
    "        keys = tmp.loc[tmp['sample'] == 'random'].index.unique().tolist()\n",
    "        \n",
    "        resamples = {}\n",
    "        for i in tqdm(range(n_resamples)):\n",
    "            domains = np.random.choice(keys, len(keys), replace=True)\n",
    "            resamples[i] = tmp.loc[domains, ALL_VARS].mean()\n",
    "        resamples = pd.DataFrame(resamples)\n",
    "            \n",
    "    pct_resamples = []\n",
    "    for i in tqdm(range(n_pa_resamples)):\n",
    "        tmp = url_results_df.copy().set_index('URL')\n",
    "        tmp = tmp.loc[tmp['sample'] == 'random']\n",
    "        \n",
    "        keys = tmp.index.unique().tolist()\n",
    "        domains = np.random.choice(keys, len(keys), replace=True)\n",
    "        tmp = tmp.loc[domains].reset_index()\n",
    "\n",
    "        try:\n",
    "            pct_resamples += [pd.DataFrame(pop_analysis(tmp, domains)).T.reset_index().rename({'index': 'corpus'}, axis=1).assign(i=i)]\n",
    "        except ValueError:  # <2 classes for LogisticRegression\n",
    "            continue\n",
    "    print(len(pct_resamples))\n",
    "    pct_resamples = pd.concat(pct_resamples).set_index(['i', 'corpus'])\n",
    "    \n",
    "    url_correlation_df.columns = pd.MultiIndex.from_tuples([\n",
    "        ('URL Group', 'Top 100'),\n",
    "        ('URL Group', 'Top 500'),\n",
    "        ('URL Group', 'Top 2000'),\n",
    "        ('URL Group', 'Random'),\n",
    "        ('Pct. Tokens in Corpus', 'C4'),\n",
    "        ('Pct. Tokens in Corpus', 'RW'),\n",
    "        ('Pct. Tokens in Corpus', 'Dolma'),\n",
    "    ])\n",
    "    \n",
    "    url_correlation_df[('Stats', 'Diff')] = url_correlation_df[('URL Group', 'Top 2000')] - url_correlation_df[('URL Group', 'Random')]\n",
    "    \n",
    "    url_correlation_df = url_correlation_df[[\n",
    "        ('URL Group', 'Top 100'),\n",
    "        ('URL Group', 'Top 500'),\n",
    "        ('URL Group', 'Top 2000'),\n",
    "        ('URL Group', 'Random'),\n",
    "        ('Stats', 'Diff'),\n",
    "        ('Pct. Tokens in Corpus', 'C4'),\n",
    "        ('Pct. Tokens in Corpus', 'RW'),\n",
    "        ('Pct. Tokens in Corpus', 'Dolma'),\n",
    "    ]]\n",
    "    \n",
    "    url_correlation_df.index = url_correlation_df.index.str.replace('services_', '')\n",
    "    url_correlation_df.index.name = 'Variable'\n",
    "\n",
    "    resamples.index = resamples.index.str.replace('services_', '')\n",
    "    resamples.index.name = 'Variable'\n",
    "\n",
    "    pct_resamples = pct_resamples.reset_index().drop('i', axis=1).groupby('corpus').std().T\n",
    "    pct_resamples.index.name = 'Variable'\n",
    "    pct_resamples.columns = pd.MultiIndex.from_tuples([('Pct. Tokens in Corpus', c) for c in pct_resamples.columns])\n",
    "    pct_resamples.index = pct_resamples.index.str.replace('services_', '')\n",
    "    \n",
    "    return url_correlation_df, resamples, pct_resamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f297b-648b-4315-99f3-d06bd48b824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_correlation_df, url_correlation_resamples, url_correlation_pct_resamples = url_variable_instance(url_token_lookup, url_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c9abf7-f150-4a5e-9cfd-41c9361236cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b1c5d-4541-4e4f-b26a-08c4259c79de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sanity-check the resampling results\n",
    "\n",
    "url_correlation_resamples.T.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4086e4-e592-4bf0-9d2e-e547d419e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will usually fail, but it's fine -- exact normality will generally\n",
    "# not happen for large n, the histograms look good and show that there's\n",
    "# nothing wrong with the resampling process\n",
    "url_correlation_resamples.apply(lambda s: normaltest(s).pvalue, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb5dcb2-864a-48d8-89c7-75c21a80facb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in url_correlation_resamples.index:\n",
    "    fig, ax = plt.subplots()\n",
    "    url_correlation_resamples.loc[i].hist(ax=ax)\n",
    "    ax.set_title(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d78ef0b-9011-4828-a5e3-7c6977e3c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests(point, boot, alpha=None):\n",
    "    if alpha is None:\n",
    "        alpha = norm.sf(5) / (3 * point.shape[0]) # 5 sigma level\n",
    "\n",
    "    tests = []\n",
    "    for i in point.index:\n",
    "        upper = boot.loc[i].quantile(1 - alpha / 2)\n",
    "        lower = boot.loc[i].quantile(alpha / 2)\n",
    "        \n",
    "        for col in ['Top 100', 'Top 500', 'Top 2000']:\n",
    "            observed = point.loc[i, ('URL Group', col)]\n",
    "            \n",
    "            tests += [{\n",
    "                'var': i,\n",
    "                'col': col,\n",
    "                'observed': observed,\n",
    "                'upper': upper,\n",
    "                'lower': lower,\n",
    "                'reject': (observed > upper or observed < lower),\n",
    "            }]\n",
    "    \n",
    "    return pd.DataFrame(tests).set_index(['var', 'col'])\n",
    "\n",
    "tests = run_tests(url_correlation_df, url_correlation_resamples)\n",
    "tests_05 = run_tests(url_correlation_df, url_correlation_resamples, alpha=0.05)\n",
    "\n",
    "(\n",
    "    tests['reject'].sum() / tests.shape[0],\n",
    "    tests_05['reject'].sum() / tests_05.shape[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228074c2-7321-41b7-90d4-68eb0dbe7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'environment': 'table',\n",
    "    \n",
    "    'label': 'tab:correlations',\n",
    "    'column_format': 'l' + 'r' * url_correlation_df.shape[1],\n",
    "    'multicol_align': 'c',\n",
    "    \n",
    "    'caption': (r'''\n",
    "    \\textbf{Mean incidence rates of web source features across C4, RefinedWeb, and Dolma.} We measure incidence rates for the top 100, 500, and 2000 URLs, ranked by number of tokens, as well as the random sample. The `Diff' column reports the \\% difference between the top 2k and random samples. We test for significant differences between the overall corpus and each of the top-100, top-500 and top-2000 sets with a Bonferroni-corrected two-sided permutation test, where differences significant at the Bonferroni-corrected $5 \\sigma$ level are indicated in bold. 81\\% of differences are significant at this level, while 93\\% are significant at the less strict $p = 0.05$ level. We also estimate the percentage of tokens in each corpus, C4, RefinedWeb, and Dolma, for which the web feature is present (\\pm 95\\% bootstrap CI shown in gray).\n",
    "    '''.strip(), r'\\textbf{Mean incidence rates of web source features across C4, RefinedWeb, and Dolma.}'),\n",
    "    \n",
    "    'hrules': True,\n",
    "    'convert_css': True,\n",
    "}\n",
    "\n",
    "def color_values(val):\n",
    "    color = 'red' if val < 0 else 'green' if val > 0 else 'black'\n",
    "    return f'background-color: {color}'\n",
    "\n",
    "def bold_rejects(column):\n",
    "    def style_cell(cell_value, index, column_name):\n",
    "        if column_name[0] != 'URL Group':\n",
    "            return ''\n",
    "        elif column_name[1] not in ('Top 100', 'Top 500', 'Top 2000'):\n",
    "            return ''\n",
    "        else:\n",
    "            reject = tests.loc[(index, column_name[1]), 'reject']\n",
    "            if reject:\n",
    "                return 'font-weight: bold;'\n",
    "            else:\n",
    "                return ''\n",
    "\n",
    "    return [style_cell(cell, idx, column.name) for cell, idx in zip(column, column.index)]\n",
    "\n",
    "z = norm.ppf(1 - 0.05 / 2)\n",
    "tmp = url_correlation_df.copy()\n",
    "tmp[('Pct. Tokens in Corpus', 'C4')] = tmp[('Pct. Tokens in Corpus', 'C4')].apply(lambda s: '{:.1f}'.format(100*s)) + r'\\scriptsize{\\color{gray} \\textpm ' + (z*url_correlation_pct_resamples[('Pct. Tokens in Corpus', 'C4')]).apply(lambda s: '{:.1f}'.format(100*s)) + '}'\n",
    "tmp[('Pct. Tokens in Corpus', 'RW')] = tmp[('Pct. Tokens in Corpus', 'RW')].apply(lambda s: '{:.1f}'.format(100*s)) + r'\\scriptsize{\\color{gray} \\textpm ' + (z*url_correlation_pct_resamples[('Pct. Tokens in Corpus', 'RW')]).apply(lambda s: '{:.1f}'.format(100*s)) + '}'\n",
    "tmp[('Pct. Tokens in Corpus', 'Dolma')] = tmp[('Pct. Tokens in Corpus', 'Dolma')].apply(lambda s: '{:.1f}'.format(100*s)) + r'\\scriptsize{\\color{gray} \\textpm ' + (z*url_correlation_pct_resamples[('Pct. Tokens in Corpus', 'Dolma')]).apply(lambda s: '{:.1f}'.format(100*s)) + '}'\n",
    "\n",
    "formatters = {}\n",
    "for c in url_correlation_df.columns:\n",
    "    if c == ('Stats', 'Diff'):\n",
    "        formatters[c] = lambda s: '{:+.1f}'.format(100 * s)\n",
    "    elif c[0] == 'Pct. Tokens in Corpus':\n",
    "        formatters[c] = lambda s: s\n",
    "    else:\n",
    "        formatters[c] = lambda s: '{:.1f}'.format(100 * s)\n",
    "\n",
    "print(tmp \\\n",
    "    .style \\\n",
    "    .apply(bold_rejects, axis=0) \\\n",
    "    .applymap(color_values, subset=[('Stats', 'Diff')]) \\\n",
    "    .format(formatter=formatters) \\\n",
    "    .to_latex(**kwargs)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de77b84a-3b07-4768-917b-883b559f6b6f",
   "metadata": {},
   "source": [
    "# Overall confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ffb99-30e3-4c85-92da-4bed6335a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    df,\n",
    "    yaxis_order=None, \n",
    "    xaxis_order=None,\n",
    "    text_axis=None,\n",
    "    color_axis=None,\n",
    "    color_scale=None,\n",
    "    yaxis_title=\"\",\n",
    "    xaxis_title=\"\",\n",
    "    font_size=20,\n",
    "    text_font_size=None,\n",
    "    font_style='sans-serif',\n",
    "    width=400,\n",
    "    height=400,\n",
    "):\n",
    "    if text_font_size is None:\n",
    "        text_font_size = font_size\n",
    "    \n",
    "    if color_scale is None:\n",
    "        # color_scale = alt.Scale(scheme='blues')\n",
    "        color_scale = alt.Scale(domain=[df[color_axis].min(), df[color_axis].max()], range=['#7ec1be', '#101f5b'])\n",
    "    \n",
    "    if yaxis_order is None:\n",
    "        yaxis_order = df[yaxis_title].unique()\n",
    "    if xaxis_order is None:\n",
    "        xaxis_order = df[xaxis_title].unique()\n",
    "    full_matrix = pd.MultiIndex.from_product([yaxis_order, xaxis_order], names=[yaxis_title, xaxis_title]).to_frame(index=False)\n",
    "    df_full = pd.merge(full_matrix, df, on=[yaxis_title, xaxis_title], how='outer')\n",
    "    df_full[text_axis] = df_full[text_axis].fillna('--')\n",
    "    df_full['text_color'] = df_full[text_axis].astype(str).str.replace('%', '').str.strip().apply(lambda s: float(s) if s != '--' else np.nan) > 10\n",
    "    \n",
    "    # Create the heatmap\n",
    "    heatmap = alt.Chart(df_full).mark_rect(invalid=None).encode(\n",
    "        x=alt.X(f'{xaxis_title}:N', title=xaxis_title, sort=xaxis_order if xaxis_order else None),\n",
    "        y=alt.Y(f'{yaxis_title}:N', title=yaxis_title, sort=yaxis_order if yaxis_order else None),\n",
    "        color=alt.condition(\n",
    "            f\"isValid(datum['{color_axis}'])\",\n",
    "            alt.Color(f'{color_axis}:Q', scale=color_scale),\n",
    "            alt.value('lightgray'),\n",
    "        ),\n",
    "        order=\"order:Q\"\n",
    "    )\n",
    "\n",
    "    text = heatmap.mark_text(\n",
    "        align='center',\n",
    "        baseline='middle',\n",
    "        fontSize=text_font_size,\n",
    "        font=font_style,\n",
    "    ).encode(\n",
    "        text=alt.Text(f'{text_axis}:N'),  # Format the text as \"XX.Y\"\n",
    "        color=alt.condition(\n",
    "            alt.datum.text_color,\n",
    "            alt.value('white'),\n",
    "            alt.value('black')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    final_plot = (heatmap + text).properties(\n",
    "        width=width,\n",
    "        height=height,\n",
    "    ).configure_axis(\n",
    "        labelFontSize=font_size,\n",
    "        labelFont=font_style,\n",
    "        titleFontSize=font_size,\n",
    "        titleFont=font_style,\n",
    "        domain=True,\n",
    "    ).configure_axisX(\n",
    "        labelAngle=0,\n",
    "        domain=True\n",
    "    ).configure_axisY(\n",
    "        domain=True     # Ensure the Y-axis domain line is shown\n",
    "    ).configure_view(\n",
    "        stroke='black'  # Add borders around the entire plot\n",
    "    ).configure_legend(\n",
    "        disable=True,\n",
    "    )\n",
    "    \n",
    "    return final_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55459440-08f8-4445-a4ee-f49f7b6e8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tos_robots_confusion_matrix(\n",
    "    tos_policies,\n",
    "    tos_license_policies,\n",
    "    tos_compete_policies,\n",
    "    url_robots_summary,\n",
    "    companies,\n",
    "    url_token_lookup,\n",
    "    use_token_counts=True,\n",
    "    corpora_choice=\"c4\",\n",
    "    font_size=20,\n",
    "    text_font_size=None,\n",
    "    font_style='sans-serif',\n",
    "    width=400,\n",
    "    height=400,\n",
    "):\n",
    "    recent_url_robots, recent_tos_verdicts = robots_util.prepare_recent_robots_tos_info(\n",
    "        tos_policies, tos_license_policies, tos_compete_policies, url_robots_summary, companies,\n",
    "    )\n",
    "\n",
    "    ROBOTS_LABELS = {\n",
    "        \"none\": \"None\",\n",
    "        \"some\": \"Partial\",\n",
    "        \"all\": \"Restricted\",\n",
    "    }\n",
    "\n",
    "\n",
    "    TOS_LABELS = {\n",
    "        \"Unrestricted Use\": \"None\",\n",
    "        \"Conditional Use\": \"Conditional\",\n",
    "        \"NC Only\": \"NC Only\",\n",
    "        \"No Re-Distribution\": \"No Distribution\",\n",
    "        \"Non-Compete\": \"Non-Compete\",\n",
    "        \"No AI\": \"No AI\",\n",
    "        \"No Scraping\": \"No Crawling\",\n",
    "        \"No Scraping & AI\": \"No Crawling or AI\",\n",
    "    }\n",
    "    \n",
    "    yaxis_order = [\"Restricted\", \"Partial\", \"None\"]\n",
    "    xaxis_order = [TOS_LABELS[\"Unrestricted Use\"],\n",
    "                   TOS_LABELS[\"Conditional Use\"],\n",
    "                   TOS_LABELS[\"No Re-Distribution\"],\n",
    "                   TOS_LABELS[\"Non-Compete\"],\n",
    "                   TOS_LABELS[\"NC Only\"],\n",
    "                   TOS_LABELS[\"No AI\"],\n",
    "                   TOS_LABELS[\"No Scraping\"],\n",
    "                   TOS_LABELS[\"No Scraping & AI\"]\n",
    "                  ]\n",
    "    \n",
    "    # Create a defaultdict to store counts\n",
    "    counts = defaultdict(lambda: defaultdict(int))\n",
    "    token_counts = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    # Count the occurrences of each (status, policy) pair\n",
    "    total_instances, total_tokens = 0, 0\n",
    "    url_token_counts = url_token_lookup.get_url_to_token_map(corpora_choice)\n",
    "    for url in set(recent_url_robots.keys()).intersection(set(recent_tos_verdicts.keys())):\n",
    "        status = ROBOTS_LABELS[recent_url_robots.get(url, \"none\")]\n",
    "        policy = TOS_LABELS[recent_tos_verdicts.get(url, \"No Restrictions\")]\n",
    "        counts[status][policy] += 1\n",
    "        total_instances += 1\n",
    "        token_counts[status][policy] += url_token_counts[url]\n",
    "        total_tokens += url_token_counts[url]\n",
    "    \n",
    "    # Create a list of tuples (status, policy, count)\n",
    "    data = [{\"Robots Restrictions\": status, \"Terms of Service Policies\": policy, \"Count\": count, \"Token Counts\": token_counts[status][policy],\n",
    "             \"Percent\": round(100 * count / total_instances, 2), \n",
    "             \"Percent Tokens\": round(100 * token_counts[status][policy] / total_tokens, 2),}\n",
    "            for status in yaxis_order\n",
    "            for policy in xaxis_order\n",
    "            if (count := counts[status][policy]) > 0]\n",
    "    \n",
    "    # Create a DataFrame from the list of tuples\n",
    "    df = pd.DataFrame(data)\n",
    "    df['Formatted Percent'] = df['Percent'].apply(lambda x: f\"{x:.1f} %\")\n",
    "    df['Formatted Percent Tokens'] = df['Percent Tokens'].apply(lambda x: f\"{x:.1f} %\")\n",
    "    \n",
    "    if use_token_counts:\n",
    "        color_axis, text_axis = \"Percent Tokens\", \"Formatted Percent Tokens\"\n",
    "    else:\n",
    "        color_axis, text_axis = \"Percent\", \"Formatted Percent\"\n",
    "\n",
    "    return plot_confusion_matrix(\n",
    "        df,\n",
    "        yaxis_order=yaxis_order, \n",
    "        xaxis_order=xaxis_order,\n",
    "        text_axis=text_axis,\n",
    "        color_axis=color_axis,\n",
    "        yaxis_title=\"Robots Restrictions\",\n",
    "        xaxis_title=\"Terms of Service Policies\",\n",
    "        font_size=font_size,\n",
    "        text_font_size=text_font_size,\n",
    "        font_style=font_style,\n",
    "        width=width,\n",
    "        height=height,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa9195-b1e7-491b-b3b6-3e0cc156058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_tos_robots_confusion_matrix(\n",
    "    tos_policies,\n",
    "    tos_license_policies,\n",
    "    tos_compete_policies,\n",
    "    url_robots_summary,\n",
    "    COMPANIES_TO_ANALYZE,\n",
    "    url_token_lookup,\n",
    "    corpora_choice=\"dolma\",\n",
    "    font_size=18,\n",
    "    text_font_size=24,\n",
    "    width=1000,\n",
    "    height=220,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb624a-0fb1-4ccb-9241-b5d52261231c",
   "metadata": {},
   "source": [
    "# Company to company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2035e1f7-db57-4ae0-b51c-1df7583c70fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_to_company_restrictions(url_robots_summary, companies, font_size=20, font_style='sans-serif', width=600, height=400):\n",
    "    # Create a dictionary to hold the URL statuses for each company\n",
    "    url_status_dict = {}\n",
    "    \n",
    "    for company in companies:\n",
    "        # Get the latest URL robot statuses for the company\n",
    "        agent_names = robots_util.get_bots(company)\n",
    "        url_status = robots_util.get_latest_url_robot_statuses(url_robots_summary, agent_names)\n",
    "        url_status_dict[company] = url_status\n",
    "\n",
    "    # Create a list to hold the conditional probability data\n",
    "    conditional_prob_data = []\n",
    "    \n",
    "    # Compare each pair of companies\n",
    "    for company_a in companies:\n",
    "        for company_b in companies:\n",
    "            if company_a == company_b:\n",
    "                continue  # Skip self-comparison\n",
    "            \n",
    "            status_a = url_status_dict[company_a]\n",
    "            status_b = url_status_dict[company_b]\n",
    "            \n",
    "            total_restricted_a = sum(1 for status in status_a.values() if status == 'all')\n",
    "            restricted_b_if_a_restricted = sum(1 for url, status in status_a.items() if status == 'all' and status_b.get(url) == 'all')\n",
    "            \n",
    "            if total_restricted_a > 0:\n",
    "                pct_b_restricted_if_a_restricted = round((restricted_b_if_a_restricted / total_restricted_a) * 100, 1)\n",
    "            else:\n",
    "                pct_b_restricted_if_a_restricted = 0\n",
    "            \n",
    "            conditional_prob_data.append({\n",
    "                'Company A': company_a,\n",
    "                'Company B': company_b,\n",
    "                'pct_a_restricted_if_b_restricted': pct_b_restricted_if_a_restricted\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(conditional_prob_data)\n",
    "\n",
    "    COMPANY_MAP = {\n",
    "        'Google': 'Google',\n",
    "        'OpenAI': 'OpenAI',\n",
    "        'Anthropic': 'Anthr',\n",
    "        'Cohere': 'Cohere',\n",
    "        'Common Crawl': 'CC',\n",
    "        'Meta': 'Meta',\n",
    "        'Internet Archive': 'IA',\n",
    "        'Google Search': 'Search',\n",
    "        'False Anthropic': 'F. Anthr',\n",
    "    }\n",
    "\n",
    "    df['Company A'] = df['Company A'].map(COMPANY_MAP)\n",
    "    df['Company B'] = df['Company B'].map(COMPANY_MAP)\n",
    "\n",
    "    return plot_confusion_matrix(\n",
    "        df,\n",
    "        yaxis_order=[COMPANY_MAP[c] for c in companies], \n",
    "        xaxis_order=[COMPANY_MAP[c] for c in companies],\n",
    "        text_axis='pct_a_restricted_if_b_restricted',\n",
    "        color_axis='pct_a_restricted_if_b_restricted',\n",
    "        color_scale=alt.Scale(\n",
    "            domain=[\n",
    "                df['pct_a_restricted_if_b_restricted'].min(),\n",
    "                df['pct_a_restricted_if_b_restricted'].max()\n",
    "            ],\n",
    "            range=['#7ec1be', '#101f5b']\n",
    "        ),\n",
    "        yaxis_title=\"Company A\",\n",
    "        xaxis_title=\"Company B\",\n",
    "        font_size=font_size, \n",
    "        font_style=font_style,\n",
    "        width=width,\n",
    "        height=height,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4dcfe3-423c-42a3-95d2-670590683d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_to_company_restrictions(url_robots_summary_head, ALL_COMPANIES_TO_TRACK, width=800, height=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a7c669ac595445ca55920dfaae9292f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8a4006cde43147adaad832934368c891",
        "IPY_MODEL_776107acd4844ae49950495e08033889",
        "IPY_MODEL_14f602c979a242eda8784d11053c6bfd"
       ],
       "layout": "IPY_MODEL_574f581eef354cb8a7ffef1bd9e069dc"
      }
     },
     "14f602c979a242eda8784d11053c6bfd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_39fec2e6e26c489598156c60b5c363a6",
       "style": "IPY_MODEL_204701b3b0ac4d4da7ef410dfc0b6326",
       "value": " 100000/100000 [03:17&lt;00:00, 506.70it/s]"
      }
     },
     "204701b3b0ac4d4da7ef410dfc0b6326": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "30d6af9be7174ad39772d08236afc280": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "39fec2e6e26c489598156c60b5c363a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "44ba7e8e43fe4e5d9b37ea22ea2ebc89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_53d16c8ccbab42ab818d85f3481dc45a",
        "IPY_MODEL_aaa177813ccf4684840233ea53568fb2",
        "IPY_MODEL_cf5fe07c66904edeadc6671cad2e2b3d"
       ],
       "layout": "IPY_MODEL_c576ea5755c04b81b2fd835cd7a043de"
      }
     },
     "4d7b3fa5647d45b3b47b4b2d6933865d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "53d16c8ccbab42ab818d85f3481dc45a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9ee62777d28842ea80d5e20a3b5d81cd",
       "style": "IPY_MODEL_4d7b3fa5647d45b3b47b4b2d6933865d",
       "value": "100%"
      }
     },
     "574f581eef354cb8a7ffef1bd9e069dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "590e0a63eb96406d8bbd5714e5d79f16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "73fc144b590b4a21961a9c1c1155cb91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "776107acd4844ae49950495e08033889": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_30d6af9be7174ad39772d08236afc280",
       "max": 100000,
       "style": "IPY_MODEL_fbc598ab7d3440028c1d29a19ea854f6",
       "value": 100000
      }
     },
     "7c281c1881704eb3abcb04455876fc29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8a4006cde43147adaad832934368c891": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_73fc144b590b4a21961a9c1c1155cb91",
       "style": "IPY_MODEL_7c281c1881704eb3abcb04455876fc29",
       "value": "100%"
      }
     },
     "9bed7efc937b4647960d61c9aa800944": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9ee62777d28842ea80d5e20a3b5d81cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "aaa177813ccf4684840233ea53568fb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_9bed7efc937b4647960d61c9aa800944",
       "max": 200,
       "style": "IPY_MODEL_c59b0c339d2f4a12882b2b7aa22a64c0",
       "value": 200
      }
     },
     "c576ea5755c04b81b2fd835cd7a043de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c59b0c339d2f4a12882b2b7aa22a64c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cf5fe07c66904edeadc6671cad2e2b3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_590e0a63eb96406d8bbd5714e5d79f16",
       "style": "IPY_MODEL_eb4571d286e94d868d40e5d1a2823f7e",
       "value": " 200/200 [00:07&lt;00:00, 25.88it/s]"
      }
     },
     "eb4571d286e94d868d40e5d1a2823f7e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fbc598ab7d3440028c1d29a19ea854f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
