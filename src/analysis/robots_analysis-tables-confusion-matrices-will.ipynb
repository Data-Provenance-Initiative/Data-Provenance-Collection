{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "271834be-94ee-4002-8ced-73a0790fbf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from scipy.stats import norm, normaltest, percentileofscore\n",
    "\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Append system path\n",
    "sys.path = [p for p in sys.path if not p.endswith('../..')]  # Cleans duplicated '../..'\n",
    "sys.path.insert(0, '../')  # This adds `src` to the path\n",
    "\n",
    "from helpers import io, filters, constants\n",
    "from analysis import analysis_util, analysis_constants, visualization_util\n",
    "from web_analysis import parse_robots\n",
    "from web_analysis import robots_util, forecasting_util\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4328e2d4-2ad6-49d6-b6cc-681cf754982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(os.path.expanduser('~/github/Data-Provenance-Collection/'))\n",
    "os.chdir(os.path.expanduser('~/Documents/research/opal/Data-Provenance-Collection/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34bb20c3-9ae5-4b07-9cad-57ba6be704b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThemeRegistry.enable('times_newroman')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def times_newroman():\n",
    "    font = \"Times New Roman\"\n",
    "\n",
    "    return {\n",
    "          \"config\" : {\n",
    "               \"title\": {\"font\": font},\n",
    "               \"axis\": {\n",
    "               \"labelFont\": font,\n",
    "               \"titleFont\": font\n",
    "          },\n",
    "          \"header\": {\n",
    "               \"labelFont\": font,\n",
    "               \"titleFont\": font\n",
    "          },\n",
    "          \"legend\": {\n",
    "               \"labelFont\": font,\n",
    "               \"titleFont\": font\n",
    "          },\n",
    "          \"text\": {\n",
    "               \"font\": font\n",
    "          }\n",
    "     }\n",
    "}\n",
    "\n",
    "alt.themes.register(\"times_newroman\", times_newroman)\n",
    "alt.themes.enable(\"times_newroman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ff9fe53-c58f-4e63-8540-abeec244540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe935ae-6338-4e3b-bd10-13123b0a978a",
   "metadata": {},
   "source": [
    "### Define Paths to all relevant files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2133323-eca3-44bc-9694-d8b0fbd51069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPATH_TO_RELEVANT_URL_TOKENS = 'src/analysis/pretrain_data/relevant_url_token_counts.csv'\n",
    "# FPATH_to_HEAD_ROBOTS = \"plot-stuff/temporal_robots_head.json\"\n",
    "# FPATH_TO_RAND_ROBOTS = \"plot-stuff/temporal_robots_rand_10k.json\"\n",
    "# FPATH_TO_TOS_DATA = \"plot-stuff/tos_ai_scraping_policies.json\"\n",
    "# DIRPATHS_TO_ANNOTATED_TASKS = [\"plot-stuff/task-1\", \"plot-stuff/task-2\"]\n",
    "# START_DATES = \"plot-stuff/domain_start_dates.json\"\n",
    "\n",
    "# ALL_COMPANIES_TO_TRACK = [\"Google\", \"OpenAI\", \"Anthropic\", \"Cohere\", \"Common Crawl\", \"Meta\", \"Internet Archive\", \"Google Search\", \"False Anthropic\"]\n",
    "# COMPANIES_TO_ANALYZE = [\"Google\", \"OpenAI\", \"Anthropic\", \"Cohere\", \"Common Crawl\", \"Meta\"]\n",
    "# TEMPORAL_ANALYSIS_START_DATE = '2016-01-01'\n",
    "# TEMPORAL_ANALYSIS_END_DATE = '2024-04-30'\n",
    "\n",
    "FPATH_TO_RELEVANT_URL_TOKENS = 'pretrain_data/relevant_url_token_counts.csv'\n",
    "FPATH_to_HEAD_ROBOTS = \"robots_data/temporal_robots_head.json\"\n",
    "FPATH_TO_RAND_ROBOTS = \"robots_data/temporal_robots_rand_10k.json\"\n",
    "FPATH_TO_TOS_DATA = \"robots_data/tos_ai_scraping_policies.json\"\n",
    "FPATH_TO_TOS_LICENSE_DATA = \"robots_data/tos_license_type_verdicts.json\"\n",
    "FPATH_TO_TOS_COMPETE_DATA = \"robots_data/tos_competing_services_policies.json\"\n",
    "DIRPATHS_TO_ANNOTATED_TASKS = [\"annotated_websites/Task 1\", \"annotated_websites/Task 2\"]\n",
    "START_DATES = \"robots_data/domain_start_dates.json\"\n",
    "\n",
    "ALL_COMPANIES_TO_TRACK = [\"Google\", \"OpenAI\", \"Anthropic\", \"Cohere\", \"Common Crawl\", \"Meta\", \"Internet Archive\", \"Google Search\", \"False Anthropic\"]\n",
    "COMPANIES_TO_ANALYZE = [\"Google\", \"OpenAI\", \"Anthropic\", \"Cohere\", \"Common Crawl\", \"Meta\"]\n",
    "TEMPORAL_ANALYSIS_START_DATE = '2016-01-01'\n",
    "TEMPORAL_ANALYSIS_END_DATE = '2024-04-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee96fd8b-6342-476c-bff6-72a525e1da36",
   "metadata": {},
   "source": [
    "### Load all URL splits (top vs random) and maps to Token Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a3b2a93-5a35-4c7e-b087-73dd4db273f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in 2000 URLs: 18447797380 | 10.85% of c4\n",
      "Number of tokens in 2000 URLs: 67098747294 | 15.56% of rf\n",
      "Number of tokens in 2000 URLs: 429152555144 | 21.74% of dolma\n"
     ]
    }
   ],
   "source": [
    "url_token_lookup = robots_util.URLTokenLookup(FPATH_TO_RELEVANT_URL_TOKENS) # 'c4', 'rf', 'dolma'\n",
    "c4_url_to_counts = url_token_lookup.get_url_to_token_map(\"c4\")\n",
    "rf_url_to_counts = url_token_lookup.get_url_to_token_map(\"rf\")\n",
    "dolma_url_to_counts = url_token_lookup.get_url_to_token_map(\"dolma\")\n",
    "top_c4_urls = url_token_lookup.top_k_urls(\"c4\", 2000)\n",
    "top_rf_urls = url_token_lookup.top_k_urls(\"rf\", 2000)\n",
    "top_dolma_urls = url_token_lookup.top_k_urls(\"dolma\", 2000)\n",
    "random_10k_urls = url_token_lookup.get_10k_random_sample()\n",
    "all_urls = set(random_10k_urls + top_c4_urls + top_rf_urls + top_dolma_urls)\n",
    "\n",
    "# Load website snapshots for relevant URLs\n",
    "website_start_dates = robots_util.read_start_dates(START_DATES, all_urls) # THIS WON'T WORK FOR THE 10k SAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54f01e-6c3a-4f48-a889-ba765dc9450f",
   "metadata": {},
   "source": [
    "### Define Agents and Agent Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb8b750e-3c52-4578-a486-b8ad1a2a88a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_groups_to_track = robots_util.get_bot_groups(ALL_COMPANIES_TO_TRACK)\n",
    "agents_to_track = robots_util.get_bots()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09644e3-d075-4a46-8445-d8179ae29bc9",
   "metadata": {},
   "source": [
    "### Load Robots.txt info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41e969a9-1d0b-4b95-9ccf-ff15840d94e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num robot URLs loaded: 2985\n",
      "Earliest time: 2016-01-01\n",
      "Last time: 2024-04-19\n",
      "Num robot URLs loaded: 6331\n",
      "Earliest time: 2016-01-01\n",
      "Last time: 2024-04-19\n"
     ]
    }
   ],
   "source": [
    "# URL -> Date -> Robots.txt raw text\n",
    "head_robots = io.read_json(FPATH_to_HEAD_ROBOTS)\n",
    "random_10k_robots = io.read_json(FPATH_TO_RAND_ROBOTS)\n",
    "joined_robots = copy.deepcopy(head_robots)\n",
    "joined_robots.update(random_10k_robots)\n",
    "robots_util.print_out_robots_info(head_robots)\n",
    "robots_util.print_out_robots_info(random_10k_robots)\n",
    "\n",
    "# {URL --> Date --> Agent --> Status}\n",
    "url_robots_summary, agent_counter_df = robots_util.compute_url_date_agent_status(\n",
    "    data=joined_robots, \n",
    "    # relevant_agents=agents_to_track)\n",
    "    relevant_agents=[v for vs in agent_groups_to_track.values() for v in vs])\n",
    "\n",
    "agent_counter_df.to_csv(\"all_agents_counter.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a3988a4-0a7c-427f-a311-4b36cd8b5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_robots_summary_detailed = robots_util.compute_url_date_agent_status_detailed(\n",
    "    data=joined_robots, \n",
    "    relevant_agents=[v for vs in agent_groups_to_track.values() for v in vs]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e26ade-d9e9-4900-a3b3-a01af4a698b1",
   "metadata": {},
   "source": [
    "### Load ToS info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70351b94-b889-4f16-9c31-56fd61f43464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num ToS AI/Scraping URLs: 3068\n",
      "Num ToS License URLs: 3070\n",
      "Num ToS Compete URLs: 3070\n"
     ]
    }
   ],
   "source": [
    "# URL --> Date --> ToS-suburl --> {\"verdict\": X, \"evidence\": Y}\n",
    "tos_policies = io.read_json(FPATH_TO_TOS_DATA)\n",
    "tos_license_policies = io.read_json(FPATH_TO_TOS_LICENSE_DATA)\n",
    "tos_compete_policies = io.read_json(FPATH_TO_TOS_COMPETE_DATA)\n",
    "# tos_license_policies = robots_util.switch_dates_yearly_to_monthly(tos_license_policies)\n",
    "print(f\"Num ToS AI/Scraping URLs: {len(tos_policies)}\")\n",
    "print(f\"Num ToS License URLs: {len(tos_license_policies)}\")\n",
    "print(f\"Num ToS Compete URLs: {len(tos_compete_policies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36901240-db00-4c04-9ac3-6f5377233736",
   "metadata": {},
   "source": [
    "### Load Manual Pretraining Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31e586df-d0ba-44f0-ba5c-e260380107c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6664 rows before filtering.\n",
      "4029 rows after filtering. 1580 issues, 1055 unannotated.\n",
      "<class 'collections.defaultdict'>\n",
      "9312\n"
     ]
    }
   ],
   "source": [
    "url_to_info = analysis_util.extract_url_annotations(DIRPATHS_TO_ANNOTATED_TASKS)\n",
    "url_results_df = analysis_util.process_url_annotations(url_to_info)\n",
    "url_results_df = analysis_util.encode_size_columns(url_results_df, url_token_lookup)\n",
    "url_results_df = robots_util.encode_latest_tos_robots_into_df(\n",
    "    url_results_df, tos_policies, tos_license_policies, tos_compete_policies, url_robots_summary,\n",
    "    COMPANIES_TO_ANALYZE\n",
    ")\n",
    "\n",
    "assert url_results_df['URL'].nunique() == url_results_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269da64d-baab-4bfe-8988-1c5527411ad5",
   "metadata": {},
   "source": [
    "### DECISION POINT: Use C4, Dolma, or RefinedWeb here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1345cd5b-51c5-4545-92be-0f1245c1ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_CORPUS = \"c4\" # 'c4', 'rf', 'dolma'\n",
    "if CHOSEN_CORPUS == \"c4\":\n",
    "    HEAD_URL_SET = top_c4_urls\n",
    "    URL_TO_COUNTS = c4_url_to_counts\n",
    "elif CHOSEN_CORPUS == \"rf\":\n",
    "    HEAD_URL_SET = top_rf_urls\n",
    "    URL_TO_COUNTS = rf_url_to_counts\n",
    "elif CHOSEN_CORPUS == \"dolma\":\n",
    "    HEAD_URL_SET = top_dolma_urls\n",
    "    URL_TO_COUNTS = dolma_url_to_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d29cd94f-5f99-482a-ad60-beb4e8872de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_robots_summary_head = {url: url_robots_summary[url] for url in HEAD_URL_SET if url in url_robots_summary}\n",
    "url_robots_summary_head_detailed = {url: url_robots_summary_detailed[url] for url in HEAD_URL_SET if url in url_robots_summary_detailed}\n",
    "url_robots_summary_rand = {url: url_robots_summary[url] for url in random_10k_urls if url in url_robots_summary}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3002a9-b499-4a0f-bee1-9e433c4cf5e3",
   "metadata": {},
   "source": [
    "# Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1cf458b4-89c7-41dd-838e-c4413f0062ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ALL_VARS = [\n",
    "    'User Content', 'Paywall', 'Ads','Modality: Image', 'Modality: Video', 'Modality: Audio',\n",
    "    'Sensitive Content', 'services_Academic', 'services_Blogs',\n",
    "    'services_E-Commerce', 'services_Encyclopedia/Database',\n",
    "    'services_Government', 'services_News/Periodicals',\n",
    "    'services_Organization/Personal Website', 'services_Other',\n",
    "    'services_Social Media/Forums', 'Restrictive Robots.txt', 'Restrictive Terms'\n",
    "]\n",
    "\n",
    "def calculate_bucket_estimates(buckets, predicted_probs):\n",
    "    \"\"\"Calculate the expected summed magnitude and counts of points with a positive state for each bucket.\"\"\"\n",
    "    buckets['predicted_prob'] = predicted_probs\n",
    "    buckets['expected_positive_magnitude'] = buckets['bucket_midpoint'] * buckets['predicted_prob'] * buckets['count']\n",
    "    total_summed_magnitude = buckets['expected_positive_magnitude'].sum()\n",
    "    \n",
    "    total_positive_count = (buckets['predicted_prob'] * buckets['count']).sum()\n",
    "    total_negative_count = buckets['count'].sum() - total_positive_count\n",
    "    \n",
    "    return total_summed_magnitude, total_positive_count, total_negative_count\n",
    "\n",
    "def run_empirical_bayes(data_head, data_random, buckets):\n",
    "    \"\"\"Run the Empirical Bayes method for a single population.\"\"\"\n",
    "    data_combined = pd.concat([data_head, data_random])\n",
    "    \n",
    "    # Fit logistic regression model\n",
    "    X = data_combined[['magnitude']]\n",
    "    y = data_combined['binary_state']\n",
    "    model = LogisticRegression(max_iter=1000).fit(X, y)\n",
    "    \n",
    "    # Predict probabilities for the magnitude buckets\n",
    "    X_buckets = buckets[['bucket_midpoint']]\n",
    "    X_buckets = X_buckets.rename(columns={'bucket_midpoint': 'magnitude'})\n",
    "    # print(X_buckets)\n",
    "    predicted_probs = model.predict_proba(X_buckets)[:, 1]\n",
    "    \n",
    "    # Calculate expected summed magnitude and binary variable counts\n",
    "    total_summed_magnitude, total_positive_count, total_negative_count = calculate_bucket_estimates(buckets, predicted_probs)\n",
    "    \n",
    "    # Fill in the known head distribution stats\n",
    "    data_head['predicted_prob'] = data_head['binary_state']\n",
    "    # Create a combined DataFrame of head and bucket predictions\n",
    "    head_sum = data_head['magnitude'].sum()\n",
    "    head_positive_sum = data_head[data_head['binary_state'] == 1]['magnitude'].sum()\n",
    "    head_positive_count = data_head['binary_state'].sum()\n",
    "    head_negative_count = len(data_head) - head_positive_count\n",
    "\n",
    "    # Add head stats to bucket stats\n",
    "    total_summed_magnitude += head_positive_sum\n",
    "    total_positive_count += head_positive_count\n",
    "    total_negative_count += head_negative_count\n",
    "\n",
    "    return model, total_summed_magnitude, total_positive_count, total_negative_count\n",
    "\n",
    "def conservative_estimate(data_head, data_random, buckets):\n",
    "    \"\"\"Conservative estimate using known head distribution stats and predicted stats for the rest.\"\"\"\n",
    "    # Fit logistic regression model\n",
    "    X = data_random[['magnitude']]\n",
    "    y = data_random['binary_state']\n",
    "    model = LogisticRegression(max_iter=1000).fit(X, y)\n",
    "    \n",
    "    # Predict probabilities for the magnitude buckets\n",
    "    X_buckets = buckets[['bucket_midpoint']]\n",
    "    X_buckets = X_buckets.rename(columns={'bucket_midpoint': 'magnitude'})\n",
    "    predicted_probs = model.predict_proba(X_buckets)[:, 1]\n",
    "    \n",
    "    # Fill in the known head distribution stats\n",
    "    data_head['predicted_prob'] = data_head['binary_state']\n",
    "    \n",
    "    # Create a combined DataFrame of head and bucket predictions\n",
    "    head_sum = data_head['magnitude'].sum()\n",
    "    head_positive_sum = data_head[data_head['binary_state'] == 1]['magnitude'].sum()\n",
    "    head_positive_count = data_head['binary_state'].sum()\n",
    "    head_negative_count = len(data_head) - head_positive_count\n",
    "    \n",
    "    # Calculate expected summed magnitude and binary variable counts for buckets excluding head\n",
    "    total_summed_magnitude, total_positive_count, total_negative_count = calculate_bucket_estimates(buckets, predicted_probs)\n",
    "    \n",
    "    # Add head stats to bucket stats\n",
    "    total_summed_magnitude += head_positive_sum\n",
    "    total_positive_count += head_positive_count\n",
    "    total_negative_count += head_negative_count\n",
    "    \n",
    "    return model, total_summed_magnitude, total_positive_count, total_negative_count\n",
    "\n",
    "def process_url_population(data, method='empirical_bayes'):\n",
    "    \"\"\"Process population and its binary variables.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    data_head = data['head']\n",
    "    data_random = data['random']\n",
    "    buckets = data['buckets']\n",
    "    \n",
    "    for binary_var in data['binary_vars']:\n",
    "        # Update binary state column\n",
    "        data_head['binary_state'] = data_head[binary_var]\n",
    "        data_random['binary_state'] = data_random[binary_var]\n",
    "        \n",
    "        assert method in ('empirical_bayes', 'conservative')\n",
    "        func = (run_empirical_bayes if method == 'empirical_bayes' else conservative_estimate)\n",
    "        model, total_summed_magnitude, total_positive_count, total_negative_count = func(data_head, data_random, buckets)\n",
    "    \n",
    "        results[binary_var] = {\n",
    "            'model': model,\n",
    "            'total_summed_magnitude': round(total_summed_magnitude, 2),\n",
    "            'total_positive_count': round(total_positive_count, 2),\n",
    "            'total_negative_count': round(total_negative_count, 2),\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def run_population_analysis(\n",
    "    url_results_df, \n",
    "    top_corpus_urls, \n",
    "    corpus_name,\n",
    "    data_buckets_fpath,\n",
    "    url_token_lookup,\n",
    "    verbose=False,\n",
    "):\n",
    "    total_tokens = url_token_lookup._TOTAL_TOKENS[corpus_name]\n",
    "    total_urls = url_token_lookup._TOTAL_URLS[corpus_name]\n",
    "    \n",
    "    top_results_df = url_results_df[url_results_df['URL'].isin(top_corpus_urls)]\n",
    "    random_results_df = url_results_df[url_results_df['sample'] == \"random\"]\n",
    "    print(f\"Head sample size: {len(top_results_df)}\")\n",
    "    print(f\"Rand sample size: {len(random_results_df)}\")\n",
    "    head_tokens = list(top_results_df[f\"{corpus_name} tokens\"])\n",
    "    rand_tokens = list(random_results_df[f\"{corpus_name} tokens\"])\n",
    "\n",
    "    cols = ALL_VARS\n",
    "    \n",
    "    # var_name --> {head -> vals, rand -> vals}\n",
    "    vars_data = {}\n",
    "    for col in cols:\n",
    "        vars_data[col] = {\n",
    "            \"head\": [int(x) for x in top_results_df[col]],\n",
    "            \"rand\": [int(x) for x in random_results_df[col]],\n",
    "        }\n",
    "\n",
    "    head_info = {k: v[\"head\"] for k, v in vars_data.items()}\n",
    "    head_info.update({'magnitude': head_tokens})\n",
    "    rand_info = {k: v[\"rand\"] for k, v in vars_data.items()}\n",
    "    rand_info.update({'magnitude': rand_tokens})\n",
    "    \n",
    "    results = process_url_population({\n",
    "        'head': pd.DataFrame(head_info),\n",
    "        'random': pd.DataFrame(rand_info),\n",
    "        'buckets': pd.read_csv(data_buckets_fpath),\n",
    "        'binary_vars': cols,\n",
    "    }, method='conservative')\n",
    "\n",
    "    final_results = {}\n",
    "    for bvar, var_results in results.items():\n",
    "        pos_pct = var_results['total_positive_count'] / total_urls\n",
    "        pos_t_pct = var_results['total_summed_magnitude'] / total_tokens\n",
    "        pos_t = var_results['total_summed_magnitude']\n",
    "        \n",
    "        if verbose:\n",
    "            head_pct = np.mean(vars_data[bvar][\"head\"])\n",
    "            rand_pct = np.mean(vars_data[bvar][\"rand\"])\n",
    "            \n",
    "            print(f\"{bvar} | Head = {100 * head_pct} % | Rand = {100 * rand_pct} %\")\n",
    "            print(f\"Estimated URLs = {var_results['total_positive_count']} / {total_urls} = {pos_pct} %\")\n",
    "            print(f\"Estimated Tokens = {pos_t} / {total_tokens} = {pos_t_pct} %\")\n",
    "        \n",
    "        final_results[bvar] = {\n",
    "            \"Estimated URL Pct\": pos_pct,\n",
    "            \"Estimated Tokens Pct\": pos_t_pct,\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(final_results).T\n",
    "\n",
    "def analyze_url_variable_correlations(df, top_n_list=[100, 500, 2000]):\n",
    "    ret = {}\n",
    "    for top_n in top_n_list:\n",
    "        top_n_c4_df = df.loc[df['c4 rank'] <= top_n]\n",
    "        top_n_rf_df = df.loc[df['rf rank'] <= top_n]\n",
    "        top_n_dolma_df = df.loc[df['dolma rank'] <= top_n]\n",
    "\n",
    "        ret[f'Top {top_n}'] = (\n",
    "            top_n_c4_df[ALL_VARS].mean() +\n",
    "            top_n_rf_df[ALL_VARS].mean() +\n",
    "            top_n_dolma_df[ALL_VARS].mean()\n",
    "        ) / 3\n",
    "    \n",
    "    ret['Random'] = df.loc[df['sample'] == 'random', ALL_VARS].mean()\n",
    "\n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "def url_variable_instance(url_token_lookup, url_results_df, n_resamples=100000):\n",
    "    url_correlation_df = analyze_url_variable_correlations(url_results_df)\n",
    "\n",
    "    if n_resamples is not None and n_resamples > 0:\n",
    "        tmp = url_results_df.copy().set_index('URL')\n",
    "        \n",
    "        resamples = {}\n",
    "        for i in tqdm(range(n_resamples)):\n",
    "            keys = tmp.loc[tmp['sample'] == 'random'].index.unique().tolist()\n",
    "            domains = np.random.choice(keys, len(keys), replace=True)\n",
    "            resamples[i] = tmp.loc[domains, ALL_VARS].mean()\n",
    "        resamples = pd.DataFrame(resamples)\n",
    "        \n",
    "    url_correlation_df['C4'] = run_population_analysis(\n",
    "        url_results_df,\n",
    "        url_token_lookup.top_k_urls(\"c4\", 2000), \n",
    "        \"c4\",\n",
    "        \"src/analysis/pretrain_data/corpus_token_bucket_counts/c4_buckets.csv\",\n",
    "        url_token_lookup,\n",
    "        verbose=False,\n",
    "    )[\"Estimated Tokens Pct\"]\n",
    "    \n",
    "    url_correlation_df['RW'] = run_population_analysis(\n",
    "        url_results_df, \n",
    "        url_token_lookup.top_k_urls(\"rf\", 2000), \n",
    "        \"rf\",\n",
    "        \"src/analysis/pretrain_data/corpus_token_bucket_counts/rf_buckets.csv\",\n",
    "        url_token_lookup,\n",
    "        verbose=False,\n",
    "    )[\"Estimated Tokens Pct\"]\n",
    "    \n",
    "    url_correlation_df['Dolma'] = run_population_analysis(\n",
    "        url_results_df, \n",
    "        url_token_lookup.top_k_urls(\"dolma\", 2000), \n",
    "        \"dolma\",\n",
    "        \"src/analysis/pretrain_data/corpus_token_bucket_counts/dolma_buckets.csv\",\n",
    "        url_token_lookup,\n",
    "        verbose=False,\n",
    "    )[\"Estimated Tokens Pct\"]\n",
    "\n",
    "    url_correlation_df.columns = pd.MultiIndex.from_tuples([\n",
    "        ('URL Group', 'Top 100'),\n",
    "        ('URL Group', 'Top 500'),\n",
    "        ('URL Group', 'Top 2000'),\n",
    "        ('URL Group', 'Random'),\n",
    "        ('Pct. Tokens in Corpus', 'C4'),\n",
    "        ('Pct. Tokens in Corpus', 'RW'),\n",
    "        ('Pct. Tokens in Corpus', 'Dolma'),\n",
    "    ])\n",
    "    \n",
    "    url_correlation_df[('Stats', 'Diff')] = url_correlation_df[('URL Group', 'Top 2000')] - url_correlation_df[('URL Group', 'Random')]\n",
    "    \n",
    "    url_correlation_df = url_correlation_df[[\n",
    "        ('URL Group', 'Top 100'),\n",
    "        ('URL Group', 'Top 500'),\n",
    "        ('URL Group', 'Top 2000'),\n",
    "        ('URL Group', 'Random'),\n",
    "        ('Stats', 'Diff'),\n",
    "        ('Pct. Tokens in Corpus', 'C4'),\n",
    "        ('Pct. Tokens in Corpus', 'RW'),\n",
    "        ('Pct. Tokens in Corpus', 'Dolma'),\n",
    "    ]]\n",
    "    \n",
    "    url_correlation_df.index = url_correlation_df.index.str.replace('services_', '')\n",
    "    url_correlation_df.index.name = 'Variable'\n",
    "\n",
    "    resamples.index = resamples.index.str.replace('services_', '')\n",
    "    resamples.index.name = 'Variable'\n",
    "\n",
    "    return url_correlation_df, resamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "386f297b-648b-4315-99f3-d06bd48b824e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m url_correlation_df, url_correlation_resamples \u001b[38;5;241m=\u001b[39m \u001b[43murl_variable_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_token_lookup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl_results_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[58], line 198\u001b[0m, in \u001b[0;36murl_variable_instance\u001b[0;34m(url_token_lookup, url_results_df, n_resamples)\u001b[0m\n\u001b[1;32m    195\u001b[0m tmp \u001b[38;5;241m=\u001b[39m url_results_df\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    197\u001b[0m resamples \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_resamples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    199\u001b[0m     keys \u001b[38;5;241m=\u001b[39m tmp\u001b[38;5;241m.\u001b[39mloc[tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    200\u001b[0m     domains \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(keys, \u001b[38;5;28mlen\u001b[39m(keys), replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/research/notebooks/venv/lib/python3.8/site-packages/tqdm/notebook.py:238\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    237\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/research/notebooks/venv/lib/python3.8/site-packages/tqdm/notebook.py:113\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[1;32m    115\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "url_correlation_df, url_correlation_resamples = url_variable_instance(url_token_lookup, url_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9edce5ee-48cb-44cf-9369-16c03240afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sanity-check the resampling results\n",
    "\n",
    "# url_correlation_resamples.T.describe().T\n",
    "\n",
    "# These will usually fail, but it's fine -- exact normality will generally\n",
    "# not happen for large n, the histograms look good and show that there's\n",
    "# nothing wrong with the resampling process\n",
    "# url_correlation_resamples.apply(lambda s: normaltest(s).pvalue, axis=1)\n",
    "\n",
    "# for i in url_correlation_resamples.index:\n",
    "#     fig, ax = plt.subplots()\n",
    "#     url_correlation_resamples.loc[i].hist(ax=ax)\n",
    "#     ax.set_title(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d78ef0b-9011-4828-a5e3-7c6977e3c666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8333333333333334, 0.9444444444444444)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_tests(point, boot, alpha=None):\n",
    "    if alpha is None:\n",
    "        alpha = norm.sf(5) / (3 * point.shape[0]) # 5 sigma level\n",
    "\n",
    "    tests = []\n",
    "    for i in point.index:\n",
    "        upper = boot.loc[i].quantile(1 - alpha / 2)\n",
    "        lower = boot.loc[i].quantile(alpha / 2)\n",
    "        \n",
    "        for col in ['Top 100', 'Top 500', 'Top 2000']:\n",
    "            observed = point.loc[i, ('URL Group', col)]\n",
    "            \n",
    "            tests += [{\n",
    "                'var': i,\n",
    "                'col': col,\n",
    "                'observed': observed,\n",
    "                'upper': upper,\n",
    "                'lower': lower,\n",
    "                'reject': (observed > upper or observed < lower),\n",
    "            }]\n",
    "    \n",
    "    return pd.DataFrame(tests).set_index(['var', 'col'])\n",
    "\n",
    "tests = run_tests(url_correlation_df, url_correlation_resamples)\n",
    "tests_05 = run_tests(url_correlation_df, url_correlation_resamples, alpha=0.05)\n",
    "\n",
    "(\n",
    "    tests['reject'].sum() / tests.shape[0],\n",
    "    tests_05['reject'].sum() / tests_05.shape[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "228074c2-7321-41b7-90d4-68eb0dbe7d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption[\\textbf{Mean incidence rates of web source features across C4, RefinedWeb, and Dolma.}]{\\textbf{Mean incidence rates of web source features across C4, RefinedWeb, and Dolma.} We measure incidence rates for the top 100, 500, and 2000 URLs, ranked by number of tokens, as well as the random sample. The `Diff' column reports the \\% difference between the top 2k and random samples. We test for significant differences between the overall corpus and each of the top-100, top-500 and top-2000 sets with a Bonferroni-corrected two-sided permutation test, where differences significant at the Bonferroni-corrected $5 \\sigma$ level are indicated in bold. 83\\% of differences are significant at this level, while 94\\% are significant at the less strict $p = 0.05$ level. We also estimate the percentage of tokens in each corpus, C4, RefinedWeb, and Dolma, for which the web feature is present.}\n",
      "\\label{tab:correlations}\n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      " & \\multicolumn{4}{c}{URL Group} & Stats & \\multicolumn{3}{c}{Pct. Tokens in Corpus} \\\\\n",
      " & Top 100 & Top 500 & Top 2000 & Random & Diff & C4 & RW & Dolma \\\\\n",
      "Variable &  &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "User Content & \\bfseries 21.3 & 19.0 & 19.3 & 15.1 & {\\cellcolor{green}} 4.2 & 38.2 & 51.0 & 67.4 \\\\\n",
      "Paywall & \\bfseries 33.9 & \\bfseries 34.8 & \\bfseries 27.5 & 1.6 & {\\cellcolor{green}} 25.9 & 3.7 & 4.5 & 2.7 \\\\\n",
      "Ads & \\bfseries 56.7 & \\bfseries 61.4 & \\bfseries 53.1 & 5.4 & {\\cellcolor{green}} 47.7 & 33.7 & 60.9 & 63.6 \\\\\n",
      "Modality: Image & 97.0 & \\bfseries 97.7 & 97.3 & 95.0 & {\\cellcolor{green}} 2.3 & 103.1 & 126.5 & 114.6 \\\\\n",
      "Modality: Video & \\bfseries 88.7 & \\bfseries 83.0 & \\bfseries 62.6 & 18.9 & {\\cellcolor{green}} 43.8 & 41.6 & 31.1 & 60.6 \\\\\n",
      "Modality: Audio & \\bfseries 83.9 & \\bfseries 74.8 & \\bfseries 47.1 & 3.4 & {\\cellcolor{green}} 43.7 & 32.8 & 12.4 & 54.8 \\\\\n",
      "Sensitive Content & 0.0 & 0.7 & \\bfseries 2.1 & 0.6 & {\\cellcolor{green}} 1.5 & 1.4 & 0.4 & 40.6 \\\\\n",
      "Academic & \\bfseries 12.8 & \\bfseries 9.6 & \\bfseries 9.8 & 3.8 & {\\cellcolor{green}} 6.0 & 2.8 & 2.8 & 1.8 \\\\\n",
      "Blogs & \\bfseries 3.1 & \\bfseries 3.0 & \\bfseries 3.9 & 15.1 & {\\cellcolor{red}} -11.2 & 34.1 & 21.0 & 61.8 \\\\\n",
      "E-Commerce & 8.7 & 9.9 & 9.8 & 10.6 & {\\cellcolor{red}} -0.7 & 31.5 & 38.4 & 59.9 \\\\\n",
      "Encyclopedia/Database & \\bfseries 19.3 & \\bfseries 12.8 & \\bfseries 11.0 & 0.4 & {\\cellcolor{green}} 10.6 & 11.4 & 4.0 & 51.1 \\\\\n",
      "Government & \\bfseries 3.0 & \\bfseries 2.9 & \\bfseries 3.0 & 1.1 & {\\cellcolor{green}} 1.8 & 0.8 & 1.0 & 0.6 \\\\\n",
      "News/Periodicals & \\bfseries 44.8 & \\bfseries 53.9 & \\bfseries 50.6 & 5.3 & {\\cellcolor{green}} 45.3 & 13.8 & 16.1 & 61.1 \\\\\n",
      "Organization/Personal Website & \\bfseries 15.6 & \\bfseries 13.1 & \\bfseries 12.2 & 71.2 & {\\cellcolor{red}} -59.0 & 46.9 & 79.1 & 38.1 \\\\\n",
      "Other & \\bfseries 16.1 & \\bfseries 11.2 & \\bfseries 12.1 & 4.3 & {\\cellcolor{green}} 7.8 & 4.4 & 3.1 & 2.6 \\\\\n",
      "Social Media/Forums & \\bfseries 10.6 & \\bfseries 9.3 & \\bfseries 11.4 & 1.6 & {\\cellcolor{green}} 9.8 & 14.6 & 4.9 & 54.5 \\\\\n",
      "Restrictive Robots.txt & \\bfseries 30.1 & \\bfseries 25.2 & \\bfseries 17.1 & 1.5 & {\\cellcolor{green}} 15.7 & 2.1 & 4.1 & 2.1 \\\\\n",
      "Restrictive Terms & \\bfseries 22.9 & \\bfseries 19.9 & \\bfseries 16.1 & 4.1 & {\\cellcolor{green}} 12.0 & 25.8 & 37.3 & 59.9 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    'environment': 'table',\n",
    "    \n",
    "    'label': 'tab:correlations',\n",
    "    'column_format': 'l' + 'r' * url_correlation_df.shape[1],\n",
    "    'multicol_align': 'c',\n",
    "    \n",
    "    'caption': (r'''\n",
    "    \\textbf{Mean incidence rates of web source features across C4, RefinedWeb, and Dolma.} We measure incidence rates for the top 100, 500, and 2000 URLs, ranked by number of tokens, as well as the random sample. The `Diff' column reports the \\% difference between the top 2k and random samples. We test for significant differences between the overall corpus and each of the top-100, top-500 and top-2000 sets with a Bonferroni-corrected two-sided permutation test, where differences significant at the Bonferroni-corrected $5 \\sigma$ level are indicated in bold. 83\\% of differences are significant at this level, while 94\\% are significant at the less strict $p = 0.05$ level. We also estimate the percentage of tokens in each corpus, C4, RefinedWeb, and Dolma, for which the web feature is present.\n",
    "    '''.strip(), r'\\textbf{Mean incidence rates of web source features across C4, RefinedWeb, and Dolma.}'),\n",
    "    \n",
    "    'hrules': True,\n",
    "    'convert_css': True,\n",
    "}\n",
    "\n",
    "def color_values(val):\n",
    "    color = 'red' if val < 0 else 'green' if val > 0 else 'black'\n",
    "    return f'background-color: {color}'\n",
    "\n",
    "def bold_rejects(column):\n",
    "    def style_cell(cell_value, index, column_name):\n",
    "        if column_name[0] != 'URL Group':\n",
    "            return ''\n",
    "        elif column_name[1] not in ('Top 100', 'Top 500', 'Top 2000'):\n",
    "            return ''\n",
    "        else:\n",
    "            reject = tests.loc[(index, column_name[1]), 'reject']\n",
    "            if reject:\n",
    "                return 'font-weight: bold;'\n",
    "            else:\n",
    "                return ''\n",
    "\n",
    "    return [style_cell(cell, idx, column.name) for cell, idx in zip(column, column.index)]\n",
    "\n",
    "print(url_correlation_df \\\n",
    "      .style \\\n",
    "      .apply(bold_rejects, axis=0) \\\n",
    "      .applymap(color_values, subset=[('Stats', 'Diff')]) \\\n",
    "      .format(formatter={\n",
    "          c: lambda s: ('{:+.1f}' if c == ('Stats', 'Diff') else '{:.1f}').format(100*s)\n",
    "          for c in url_correlation_df.columns\n",
    "      }) \\\n",
    "      .to_latex(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de77b84a-3b07-4768-917b-883b559f6b6f",
   "metadata": {},
   "source": [
    "# Overall confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "940ffb99-30e3-4c85-92da-4bed6335a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    df,\n",
    "    yaxis_order=None, \n",
    "    xaxis_order=None,\n",
    "    text_axis=None,\n",
    "    color_axis=None,\n",
    "    color_scale=None,\n",
    "    yaxis_title=\"\",\n",
    "    xaxis_title=\"\",\n",
    "    font_size=20,\n",
    "    text_font_size=None,\n",
    "    font_style='sans-serif',\n",
    "    width=400,\n",
    "    height=400,\n",
    "):\n",
    "    if text_font_size is None:\n",
    "        text_font_size = font_size\n",
    "    \n",
    "    if color_scale is None:\n",
    "        # color_scale = alt.Scale(scheme='blues')\n",
    "        color_scale = alt.Scale(domain=[df[color_axis].min(), df[color_axis].max()], range=['#7ec1be', '#101f5b'])\n",
    "    \n",
    "    if yaxis_order is None:\n",
    "        yaxis_order = df[yaxis_title].unique()\n",
    "    if xaxis_order is None:\n",
    "        xaxis_order = df[xaxis_title].unique()\n",
    "    full_matrix = pd.MultiIndex.from_product([yaxis_order, xaxis_order], names=[yaxis_title, xaxis_title]).to_frame(index=False)\n",
    "    df_full = pd.merge(full_matrix, df, on=[yaxis_title, xaxis_title], how='outer')\n",
    "    df_full[text_axis] = df_full[text_axis].fillna('--')\n",
    "    df_full['text_color'] = df_full[text_axis].astype(str).str.replace('%', '').str.strip().apply(lambda s: float(s) if s != '--' else np.nan) > 10\n",
    "    \n",
    "    # Create the heatmap\n",
    "    heatmap = alt.Chart(df_full).mark_rect(invalid=None).encode(\n",
    "        x=alt.X(f'{xaxis_title}:N', title=xaxis_title, sort=xaxis_order if xaxis_order else None),\n",
    "        y=alt.Y(f'{yaxis_title}:N', title=yaxis_title, sort=yaxis_order if yaxis_order else None),\n",
    "        color=alt.condition(\n",
    "            f\"isValid(datum['{color_axis}'])\",\n",
    "            alt.Color(f'{color_axis}:Q', scale=color_scale),\n",
    "            alt.value('lightgray'),\n",
    "        ),\n",
    "        order=\"order:Q\"\n",
    "    )\n",
    "\n",
    "    text = heatmap.mark_text(\n",
    "        align='center',\n",
    "        baseline='middle',\n",
    "        fontSize=text_font_size,\n",
    "        font=font_style,\n",
    "    ).encode(\n",
    "        text=alt.Text(f'{text_axis}:N'),  # Format the text as \"XX.Y\"\n",
    "        color=alt.condition(\n",
    "            alt.datum.text_color,\n",
    "            alt.value('white'),\n",
    "            alt.value('black')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    final_plot = (heatmap + text).properties(\n",
    "        width=width,\n",
    "        height=height,\n",
    "    ).configure_axis(\n",
    "        labelFontSize=font_size,\n",
    "        labelFont=font_style,\n",
    "        titleFontSize=font_size,\n",
    "        titleFont=font_style,\n",
    "        domain=True,\n",
    "    ).configure_axisX(\n",
    "        labelAngle=0,\n",
    "        domain=True\n",
    "    ).configure_axisY(\n",
    "        domain=True     # Ensure the Y-axis domain line is shown\n",
    "    ).configure_view(\n",
    "        stroke='black'  # Add borders around the entire plot\n",
    "    ).configure_legend(\n",
    "        disable=True,\n",
    "    )\n",
    "    \n",
    "    return final_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55459440-08f8-4445-a4ee-f49f7b6e8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tos_robots_confusion_matrix(\n",
    "    tos_policies,\n",
    "    tos_license_policies,\n",
    "    tos_compete_policies,\n",
    "    url_robots_summary,\n",
    "    companies,\n",
    "    url_token_lookup,\n",
    "    use_token_counts=True,\n",
    "    corpora_choice=\"c4\",\n",
    "    font_size=20,\n",
    "    text_font_size=None,\n",
    "    font_style='sans-serif',\n",
    "    width=400,\n",
    "    height=400,\n",
    "):\n",
    "    recent_url_robots, recent_tos_verdicts = robots_util.prepare_recent_robots_tos_info(\n",
    "        tos_policies, tos_license_policies, tos_compete_policies, url_robots_summary, companies,\n",
    "    )\n",
    "\n",
    "    ROBOTS_LABELS = {\n",
    "        \"none\": \"None\",\n",
    "        \"some\": \"Partial\",\n",
    "        \"all\": \"Restricted\",\n",
    "    }\n",
    "\n",
    "\n",
    "    TOS_LABELS = {\n",
    "        \"Unrestricted Use\": \"None\",\n",
    "        \"Conditional Use\": \"Conditional\",\n",
    "        \"NC Only\": \"NC Only\",\n",
    "        \"No Re-Distribution\": \"No Distribution\",\n",
    "        \"Non-Compete\": \"Non-Compete\",\n",
    "        \"No AI\": \"No AI\",\n",
    "        \"No Scraping\": \"No Scraping\",\n",
    "        \"No Scraping & AI\": \"No Scraping & AI\",\n",
    "    }\n",
    "    \n",
    "    yaxis_order = [\"Restricted\", \"Partial\", \"None\"]\n",
    "    xaxis_order = [TOS_LABELS[\"Unrestricted Use\"],\n",
    "                   TOS_LABELS[\"Conditional Use\"],\n",
    "                   TOS_LABELS[\"No Re-Distribution\"],\n",
    "                   TOS_LABELS[\"Non-Compete\"],\n",
    "                   TOS_LABELS[\"NC Only\"],\n",
    "                   TOS_LABELS[\"No AI\"],\n",
    "                   TOS_LABELS[\"No Scraping\"],\n",
    "                   TOS_LABELS[\"No Scraping & AI\"]\n",
    "                  ]\n",
    "    \n",
    "    # Create a defaultdict to store counts\n",
    "    counts = defaultdict(lambda: defaultdict(int))\n",
    "    token_counts = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    # Count the occurrences of each (status, policy) pair\n",
    "    total_instances, total_tokens = 0, 0\n",
    "    url_token_counts = url_token_lookup.get_url_to_token_map(corpora_choice)\n",
    "    for url in set(recent_url_robots.keys()).intersection(set(recent_tos_verdicts.keys())):\n",
    "        status = ROBOTS_LABELS[recent_url_robots.get(url, \"none\")]\n",
    "        policy = TOS_LABELS[recent_tos_verdicts.get(url, \"No Restrictions\")]\n",
    "        counts[status][policy] += 1\n",
    "        total_instances += 1\n",
    "        token_counts[status][policy] += url_token_counts[url]\n",
    "        total_tokens += url_token_counts[url]\n",
    "    \n",
    "    # Create a list of tuples (status, policy, count)\n",
    "    data = [{\"Robots Restrictions\": status, \"Terms of Service Policies\": policy, \"Count\": count, \"Token Counts\": token_counts[status][policy],\n",
    "             \"Percent\": round(100 * count / total_instances, 2), \n",
    "             \"Percent Tokens\": round(100 * token_counts[status][policy] / total_tokens, 2),}\n",
    "            for status in yaxis_order\n",
    "            for policy in xaxis_order\n",
    "            if (count := counts[status][policy]) > 0]\n",
    "    \n",
    "    # Create a DataFrame from the list of tuples\n",
    "    df = pd.DataFrame(data)\n",
    "    df['Formatted Percent'] = df['Percent'].apply(lambda x: f\"{x:.1f} %\")\n",
    "    df['Formatted Percent Tokens'] = df['Percent Tokens'].apply(lambda x: f\"{x:.1f} %\")\n",
    "    \n",
    "    if use_token_counts:\n",
    "        color_axis, text_axis = \"Percent Tokens\", \"Formatted Percent Tokens\"\n",
    "    else:\n",
    "        color_axis, text_axis = \"Percent\", \"Formatted Percent\"\n",
    "\n",
    "    return plot_confusion_matrix(\n",
    "        df,\n",
    "        yaxis_order=yaxis_order, \n",
    "        xaxis_order=xaxis_order,\n",
    "        text_axis=text_axis,\n",
    "        color_axis=color_axis,\n",
    "        yaxis_title=\"Robots Restrictions\",\n",
    "        xaxis_title=\"Terms of Service Policies\",\n",
    "        font_size=font_size,\n",
    "        text_font_size=text_font_size,\n",
    "        font_style=font_style,\n",
    "        width=width,\n",
    "        height=height,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9fa9195-b1e7-491b-b3b6-3e0cc156058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.defaultdict'>\n",
      "9312\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-5ce01b9bc13b4e2691d5e60619c157d5.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-5ce01b9bc13b4e2691d5e60619c157d5.vega-embed details,\n",
       "  #altair-viz-5ce01b9bc13b4e2691d5e60619c157d5.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-5ce01b9bc13b4e2691d5e60619c157d5\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-5ce01b9bc13b4e2691d5e60619c157d5\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-5ce01b9bc13b4e2691d5e60619c157d5\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"Times New Roman\"}, \"axis\": {\"labelFont\": \"sans-serif\", \"titleFont\": \"sans-serif\", \"domain\": true, \"labelFontSize\": 18, \"titleFontSize\": 18}, \"header\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\"}, \"legend\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\", \"disable\": true}, \"text\": {\"font\": \"Times New Roman\"}, \"axisX\": {\"domain\": true, \"labelAngle\": 0}, \"axisY\": {\"domain\": true}, \"view\": {\"stroke\": \"black\"}}, \"layer\": [{\"mark\": {\"type\": \"rect\", \"invalid\": null}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"isValid(datum['Percent Tokens'])\", \"field\": \"Percent Tokens\", \"scale\": {\"domain\": [0.09, 21.39], \"range\": [\"#7ec1be\", \"#101f5b\"]}, \"type\": \"quantitative\"}, \"value\": \"lightgray\"}, \"order\": {\"field\": \"order\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"Terms of Service Policies\", \"sort\": [\"None\", \"Conditional\", \"No Distribution\", \"Non-Compete\", \"NC Only\", \"No AI\", \"No Scraping\", \"No Scraping & AI\"], \"title\": \"Terms of Service Policies\", \"type\": \"nominal\"}, \"y\": {\"field\": \"Robots Restrictions\", \"sort\": [\"Restricted\", \"Partial\", \"None\"], \"title\": \"Robots Restrictions\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"font\": \"sans-serif\", \"fontSize\": 24}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"datum.text_color\", \"value\": \"white\"}, \"value\": \"black\"}, \"order\": {\"field\": \"order\", \"type\": \"quantitative\"}, \"text\": {\"field\": \"Formatted Percent Tokens\", \"type\": \"nominal\"}, \"x\": {\"field\": \"Terms of Service Policies\", \"sort\": [\"None\", \"Conditional\", \"No Distribution\", \"Non-Compete\", \"NC Only\", \"No AI\", \"No Scraping\", \"No Scraping & AI\"], \"title\": \"Terms of Service Policies\", \"type\": \"nominal\"}, \"y\": {\"field\": \"Robots Restrictions\", \"sort\": [\"Restricted\", \"Partial\", \"None\"], \"title\": \"Robots Restrictions\", \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-c22aea4992a7574427ca72f1a839e849\"}, \"height\": 220, \"width\": 1000, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-c22aea4992a7574427ca72f1a839e849\": [{\"Robots Restrictions\": \"Restricted\", \"Terms of Service Policies\": \"None\", \"Count\": 126.0, \"Token Counts\": 7801182595.0, \"Percent\": 5.86, \"Percent Tokens\": 5.97, \"Formatted Percent\": \"5.9 %\", \"Formatted Percent Tokens\": \"6.0 %\", \"text_color\": false}, {\"Robots Restrictions\": \"Restricted\", \"Terms of Service Policies\": \"Conditional\", \"Count\": 2.0, \"Token Counts\": 555898467.0, \"Percent\": 0.09, \"Percent Tokens\": 0.43, \"Formatted Percent\": \"0.1 %\", \"Formatted Percent Tokens\": \"0.4 %\", \"text_color\": false}, {\"Robots Restrictions\": \"Restricted\", \"Terms of Service Policies\": \"No Distribution\", \"Count\": 9.0, \"Token Counts\": 412020062.0, \"Percent\": 0.42, \"Percent Tokens\": 0.32, \"Formatted Percent\": \"0.4 %\", \"Formatted Percent Tokens\": \"0.3 %\", \"text_color\": false}, {\"Robots Restrictions\": \"Restricted\", \"Terms of Service Policies\": \"Non-Compete\", \"Count\": 20.0, \"Token Counts\": 326303047.0, \"Percent\": 0.93, \"Percent Tokens\": 0.25, \"Formatted Percent\": \"0.9 %\", \"Formatted Percent Tokens\": \"0.2 %\", \"text_color\": false}, {\"Robots Restrictions\": \"Restricted\", \"Terms of Service Policies\": \"NC Only\", \"Count\": 43.0, \"Token Counts\": 3429741708.0, \"Percent\": 2.0, \"Percent Tokens\": 2.62, \"Formatted Percent\": \"2.0 %\", \"Formatted Percent Tokens\": \"2.6 %\", \"text_color\": false}, {\"Robots Restrictions\": \"Restricted\", \"Terms of Service Policies\": \"No AI\", \"Count\": null, \"Token Counts\": null, \"Percent\": null, \"Percent Tokens\": null, \"Formatted Percent\": null, \"Formatted Percent Tokens\": \"--\", \"text_color\": false}, {\"Robots Restrictions\": \"Restricted\", \"Terms of Service Policies\": \"No Scraping\", \"Count\": 150.0, \"Token Counts\": 12892212324.0, \"Percent\": 6.97, \"Percent Tokens\": 9.87, \"Formatted Percent\": \"7.0 %\", \"Formatted Percent Tokens\": \"9.9 %\", \"text_color\": false}, {\"Robots Restrictions\": \"Restricted\", \"Terms of Service Policies\": \"No Scraping & AI\", \"Count\": 48.0, \"Token Counts\": 3696081530.0, \"Percent\": 2.23, \"Percent Tokens\": 2.83, \"Formatted Percent\": \"2.2 %\", \"Formatted Percent Tokens\": \"2.8 %\", \"text_color\": false}, {\"Robots Restrictions\": \"Partial\", \"Terms of Service Policies\": \"None\", \"Count\": 495.0, \"Token Counts\": 27951844513.0, \"Percent\": 23.0, \"Percent Tokens\": 21.39, \"Formatted Percent\": \"23.0 %\", \"Formatted Percent Tokens\": \"21.4 %\", \"text_color\": true}, {\"Robots Restrictions\": \"Partial\", \"Terms of Service Policies\": \"Conditional\", \"Count\": 6.0, \"Token Counts\": 281472821.0, \"Percent\": 0.28, \"Percent Tokens\": 0.22, \"Formatted Percent\": \"0.3 %\", \"Formatted Percent Tokens\": \"0.2 %\", \"text_color\": false}, {\"Robots Restrictions\": \"Partial\", \"Terms of Service Policies\": \"No Distribution\", \"Count\": 31.0, \"Token Counts\": 3319767378.0, \"Percent\": 1.44, \"Percent Tokens\": 2.54, \"Formatted Percent\": \"1.4 %\", \"Formatted Percent Tokens\": \"2.5 %\", \"text_color\": false}, {\"Robots Restrictions\": \"Partial\", \"Terms of Service Policies\": \"Non-Compete\", \"Count\": 29.0, \"Token Counts\": 1918571760.0, \"Percent\": 1.35, \"Percent Tokens\": 1.47, \"Formatted Percent\": \"1.4 %\", \"Formatted Percent Tokens\": \"1.5 %\", \"text_color\": false}, {\"Robots Restrictions\": \"Partial\", \"Terms of Service Policies\": \"NC Only\", \"Count\": 191.0, \"Token Counts\": 9216643438.0, \"Percent\": 8.88, \"Percent Tokens\": 7.05, \"Formatted Percent\": \"8.9 %\", \"Formatted Percent Tokens\": \"7.0 %\", \"text_color\": false}, {\"Robots Restrictions\": \"Partial\", \"Terms of Service Policies\": \"No AI\", \"Count\": 2.0, \"Token Counts\": 122721803.0, \"Percent\": 0.09, \"Percent Tokens\": 0.09, \"Formatted Percent\": \"0.1 %\", \"Formatted Percent Tokens\": \"0.1 %\", \"text_color\": false}, {\"Robots Restrictions\": \"Partial\", \"Terms of Service Policies\": \"No Scraping\", \"Count\": 320.0, \"Token Counts\": 25177356533.0, \"Percent\": 14.87, \"Percent Tokens\": 19.27, \"Formatted Percent\": \"14.9 %\", \"Formatted Percent Tokens\": \"19.3 %\", \"text_color\": true}, {\"Robots Restrictions\": \"Partial\", \"Terms of Service Policies\": \"No Scraping & AI\", \"Count\": 26.0, \"Token Counts\": 2686983742.0, \"Percent\": 1.21, \"Percent Tokens\": 2.06, \"Formatted Percent\": \"1.2 %\", \"Formatted Percent Tokens\": \"2.1 %\", \"text_color\": false}, {\"Robots Restrictions\": \"None\", \"Terms of Service Policies\": \"None\", \"Count\": 297.0, \"Token Counts\": 11484569216.0, \"Percent\": 13.8, \"Percent Tokens\": 8.79, \"Formatted Percent\": \"13.8 %\", \"Formatted Percent Tokens\": \"8.8 %\", \"text_color\": false}, {\"Robots Restrictions\": \"None\", \"Terms of Service Policies\": \"Conditional\", \"Count\": 5.0, \"Token Counts\": 233025861.0, \"Percent\": 0.23, \"Percent Tokens\": 0.18, \"Formatted Percent\": \"0.2 %\", \"Formatted Percent Tokens\": \"0.2 %\", \"text_color\": false}, {\"Robots Restrictions\": \"None\", \"Terms of Service Policies\": \"No Distribution\", \"Count\": 21.0, \"Token Counts\": 728570852.0, \"Percent\": 0.98, \"Percent Tokens\": 0.56, \"Formatted Percent\": \"1.0 %\", \"Formatted Percent Tokens\": \"0.6 %\", \"text_color\": false}, {\"Robots Restrictions\": \"None\", \"Terms of Service Policies\": \"Non-Compete\", \"Count\": 10.0, \"Token Counts\": 1497100989.0, \"Percent\": 0.46, \"Percent Tokens\": 1.15, \"Formatted Percent\": \"0.5 %\", \"Formatted Percent Tokens\": \"1.1 %\", \"text_color\": false}, {\"Robots Restrictions\": \"None\", \"Terms of Service Policies\": \"NC Only\", \"Count\": 91.0, \"Token Counts\": 3661938446.0, \"Percent\": 4.23, \"Percent Tokens\": 2.8, \"Formatted Percent\": \"4.2 %\", \"Formatted Percent Tokens\": \"2.8 %\", \"text_color\": false}, {\"Robots Restrictions\": \"None\", \"Terms of Service Policies\": \"No AI\", \"Count\": null, \"Token Counts\": null, \"Percent\": null, \"Percent Tokens\": null, \"Formatted Percent\": null, \"Formatted Percent Tokens\": \"--\", \"text_color\": false}, {\"Robots Restrictions\": \"None\", \"Terms of Service Policies\": \"No Scraping\", \"Count\": 211.0, \"Token Counts\": 11909696504.0, \"Percent\": 9.8, \"Percent Tokens\": 9.11, \"Formatted Percent\": \"9.8 %\", \"Formatted Percent Tokens\": \"9.1 %\", \"text_color\": false}, {\"Robots Restrictions\": \"None\", \"Terms of Service Policies\": \"No Scraping & AI\", \"Count\": 19.0, \"Token Counts\": 1360629026.0, \"Percent\": 0.88, \"Percent Tokens\": 1.04, \"Formatted Percent\": \"0.9 %\", \"Formatted Percent Tokens\": \"1.0 %\", \"text_color\": false}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_tos_robots_confusion_matrix(\n",
    "    tos_policies,\n",
    "    tos_license_policies,\n",
    "    tos_compete_policies,\n",
    "    url_robots_summary,\n",
    "    COMPANIES_TO_ANALYZE,\n",
    "    url_token_lookup,\n",
    "    corpora_choice=\"dolma\",\n",
    "    font_size=18,\n",
    "    text_font_size=24,\n",
    "    width=1000,\n",
    "    height=220,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb624a-0fb1-4ccb-9241-b5d52261231c",
   "metadata": {},
   "source": [
    "# Company to company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2035e1f7-db57-4ae0-b51c-1df7583c70fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_to_company_restrictions(url_robots_summary, companies, font_size=20, font_style='sans-serif', width=600, height=400):\n",
    "    # Create a dictionary to hold the URL statuses for each company\n",
    "    url_status_dict = {}\n",
    "    \n",
    "    for company in companies:\n",
    "        # Get the latest URL robot statuses for the company\n",
    "        agent_names = robots_util.get_bots(company)\n",
    "        url_status = robots_util.get_latest_url_robot_statuses(url_robots_summary, agent_names)\n",
    "        url_status_dict[company] = url_status\n",
    "\n",
    "    # Create a list to hold the conditional probability data\n",
    "    conditional_prob_data = []\n",
    "    \n",
    "    # Compare each pair of companies\n",
    "    for company_a in companies:\n",
    "        for company_b in companies:\n",
    "            if company_a == company_b:\n",
    "                continue  # Skip self-comparison\n",
    "            \n",
    "            status_a = url_status_dict[company_a]\n",
    "            status_b = url_status_dict[company_b]\n",
    "            \n",
    "            total_restricted_a = sum(1 for status in status_a.values() if status == 'all')\n",
    "            restricted_b_if_a_restricted = sum(1 for url, status in status_a.items() if status == 'all' and status_b.get(url) == 'all')\n",
    "            \n",
    "            if total_restricted_a > 0:\n",
    "                pct_b_restricted_if_a_restricted = round((restricted_b_if_a_restricted / total_restricted_a) * 100, 1)\n",
    "            else:\n",
    "                pct_b_restricted_if_a_restricted = 0\n",
    "            \n",
    "            conditional_prob_data.append({\n",
    "                'Company A': company_a,\n",
    "                'Company B': company_b,\n",
    "                'pct_a_restricted_if_b_restricted': pct_b_restricted_if_a_restricted\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(conditional_prob_data)\n",
    "\n",
    "    COMPANY_MAP = {\n",
    "        'Google': 'Goog.',\n",
    "        'OpenAI': 'OAI',\n",
    "        'Anthropic': 'Anth.',\n",
    "        'Cohere': 'Cohere',\n",
    "        'Common Crawl': 'C.C.',\n",
    "        'Meta': 'Meta',\n",
    "        'Internet Archive': 'I.Arch.',\n",
    "        'Google Search': 'G.S.',\n",
    "        'False Anthropic': 'F.Anth.',\n",
    "    }\n",
    "\n",
    "    df['Company A'] = df['Company A'].map(COMPANY_MAP)\n",
    "    df['Company B'] = df['Company B'].map(COMPANY_MAP)\n",
    "\n",
    "    return plot_confusion_matrix(\n",
    "        df,\n",
    "        yaxis_order=[COMPANY_MAP[c] for c in companies], \n",
    "        xaxis_order=[COMPANY_MAP[c] for c in companies],\n",
    "        text_axis='pct_a_restricted_if_b_restricted',\n",
    "        color_axis='pct_a_restricted_if_b_restricted',\n",
    "        color_scale=alt.Scale(\n",
    "            domain=[\n",
    "                df['pct_a_restricted_if_b_restricted'].min(),\n",
    "                df['pct_a_restricted_if_b_restricted'].max()\n",
    "            ],\n",
    "            range=['#7ec1be', '#101f5b']\n",
    "        ),\n",
    "        yaxis_title=\"Company A\",\n",
    "        xaxis_title=\"Company B\",\n",
    "        font_size=font_size, \n",
    "        font_style=font_style,\n",
    "        width=width,\n",
    "        height=height,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a4dcfe3-423c-42a3-95d2-670590683d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-b800c2297c034c93bb025935c3411f68.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-b800c2297c034c93bb025935c3411f68.vega-embed details,\n",
       "  #altair-viz-b800c2297c034c93bb025935c3411f68.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-b800c2297c034c93bb025935c3411f68\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b800c2297c034c93bb025935c3411f68\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b800c2297c034c93bb025935c3411f68\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"Times New Roman\"}, \"axis\": {\"labelFont\": \"sans-serif\", \"titleFont\": \"sans-serif\", \"domain\": true, \"labelFontSize\": 20, \"titleFontSize\": 20}, \"header\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\"}, \"legend\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\", \"disable\": true}, \"text\": {\"font\": \"Times New Roman\"}, \"axisX\": {\"domain\": true, \"labelAngle\": 0}, \"axisY\": {\"domain\": true}, \"view\": {\"stroke\": \"black\"}}, \"layer\": [{\"mark\": {\"type\": \"rect\", \"invalid\": null}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"isValid(datum['pct_a_restricted_if_b_restricted'])\", \"field\": \"pct_a_restricted_if_b_restricted\", \"scale\": {\"domain\": [4.4, 100.0], \"range\": [\"#7ec1be\", \"#101f5b\"]}, \"type\": \"quantitative\"}, \"value\": \"lightgray\"}, \"order\": {\"field\": \"order\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"Company B\", \"sort\": [\"Goog.\", \"OAI\", \"Anth.\", \"Cohere\", \"C.C.\", \"Meta\", \"I.Arch.\", \"G.S.\", \"F.Anth.\"], \"title\": \"Company B\", \"type\": \"nominal\"}, \"y\": {\"field\": \"Company A\", \"sort\": [\"Goog.\", \"OAI\", \"Anth.\", \"Cohere\", \"C.C.\", \"Meta\", \"I.Arch.\", \"G.S.\", \"F.Anth.\"], \"title\": \"Company A\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"font\": \"sans-serif\", \"fontSize\": 20}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"datum.text_color\", \"value\": \"white\"}, \"value\": \"black\"}, \"order\": {\"field\": \"order\", \"type\": \"quantitative\"}, \"text\": {\"field\": \"pct_a_restricted_if_b_restricted\", \"type\": \"nominal\"}, \"x\": {\"field\": \"Company B\", \"sort\": [\"Goog.\", \"OAI\", \"Anth.\", \"Cohere\", \"C.C.\", \"Meta\", \"I.Arch.\", \"G.S.\", \"F.Anth.\"], \"title\": \"Company B\", \"type\": \"nominal\"}, \"y\": {\"field\": \"Company A\", \"sort\": [\"Goog.\", \"OAI\", \"Anth.\", \"Cohere\", \"C.C.\", \"Meta\", \"I.Arch.\", \"G.S.\", \"F.Anth.\"], \"title\": \"Company A\", \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-b6be4e22d2faeb70016147540b2f03b4\"}, \"height\": 400, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-b6be4e22d2faeb70016147540b2f03b4\": [{\"Company A\": \"Goog.\", \"Company B\": \"Goog.\", \"pct_a_restricted_if_b_restricted\": \"--\", \"text_color\": false}, {\"Company A\": \"Goog.\", \"Company B\": \"OAI\", \"pct_a_restricted_if_b_restricted\": 97.3, \"text_color\": true}, {\"Company A\": \"Goog.\", \"Company B\": \"Anth.\", \"pct_a_restricted_if_b_restricted\": 75.7, \"text_color\": true}, {\"Company A\": \"Goog.\", \"Company B\": \"Cohere\", \"pct_a_restricted_if_b_restricted\": 44.6, \"text_color\": true}, {\"Company A\": \"Goog.\", \"Company B\": \"C.C.\", \"pct_a_restricted_if_b_restricted\": 75.7, \"text_color\": true}, {\"Company A\": \"Goog.\", \"Company B\": \"Meta\", \"pct_a_restricted_if_b_restricted\": 45.9, \"text_color\": true}, {\"Company A\": \"Goog.\", \"Company B\": \"I.Arch.\", \"pct_a_restricted_if_b_restricted\": 18.9, \"text_color\": true}, {\"Company A\": \"Goog.\", \"Company B\": \"G.S.\", \"pct_a_restricted_if_b_restricted\": 12.2, \"text_color\": true}, {\"Company A\": \"Goog.\", \"Company B\": \"F.Anth.\", \"pct_a_restricted_if_b_restricted\": 55.4, \"text_color\": true}, {\"Company A\": \"OAI\", \"Company B\": \"Goog.\", \"pct_a_restricted_if_b_restricted\": 35.5, \"text_color\": true}, {\"Company A\": \"OAI\", \"Company B\": \"OAI\", \"pct_a_restricted_if_b_restricted\": \"--\", \"text_color\": false}, {\"Company A\": \"OAI\", \"Company B\": \"Anth.\", \"pct_a_restricted_if_b_restricted\": 51.2, \"text_color\": true}, {\"Company A\": \"OAI\", \"Company B\": \"Cohere\", \"pct_a_restricted_if_b_restricted\": 16.3, \"text_color\": true}, {\"Company A\": \"OAI\", \"Company B\": \"C.C.\", \"pct_a_restricted_if_b_restricted\": 51.2, \"text_color\": true}, {\"Company A\": \"OAI\", \"Company B\": \"Meta\", \"pct_a_restricted_if_b_restricted\": 16.3, \"text_color\": true}, {\"Company A\": \"OAI\", \"Company B\": \"I.Arch.\", \"pct_a_restricted_if_b_restricted\": 7.4, \"text_color\": false}, {\"Company A\": \"OAI\", \"Company B\": \"G.S.\", \"pct_a_restricted_if_b_restricted\": 4.4, \"text_color\": false}, {\"Company A\": \"OAI\", \"Company B\": \"F.Anth.\", \"pct_a_restricted_if_b_restricted\": 21.2, \"text_color\": true}, {\"Company A\": \"Anth.\", \"Company B\": \"Goog.\", \"pct_a_restricted_if_b_restricted\": 51.9, \"text_color\": true}, {\"Company A\": \"Anth.\", \"Company B\": \"OAI\", \"pct_a_restricted_if_b_restricted\": 96.3, \"text_color\": true}, {\"Company A\": \"Anth.\", \"Company B\": \"Anth.\", \"pct_a_restricted_if_b_restricted\": \"--\", \"text_color\": false}, {\"Company A\": \"Anth.\", \"Company B\": \"Cohere\", \"pct_a_restricted_if_b_restricted\": 29.6, \"text_color\": true}, {\"Company A\": \"Anth.\", \"Company B\": \"C.C.\", \"pct_a_restricted_if_b_restricted\": 100.0, \"text_color\": true}, {\"Company A\": \"Anth.\", \"Company B\": \"Meta\", \"pct_a_restricted_if_b_restricted\": 30.6, \"text_color\": true}, {\"Company A\": \"Anth.\", \"Company B\": \"I.Arch.\", \"pct_a_restricted_if_b_restricted\": 14.8, \"text_color\": true}, {\"Company A\": \"Anth.\", \"Company B\": \"G.S.\", \"pct_a_restricted_if_b_restricted\": 8.3, \"text_color\": false}, {\"Company A\": \"Anth.\", \"Company B\": \"F.Anth.\", \"pct_a_restricted_if_b_restricted\": 38.9, \"text_color\": true}, {\"Company A\": \"Cohere\", \"Company B\": \"Goog.\", \"pct_a_restricted_if_b_restricted\": 100.0, \"text_color\": true}, {\"Company A\": \"Cohere\", \"Company B\": \"OAI\", \"pct_a_restricted_if_b_restricted\": 100.0, \"text_color\": true}, {\"Company A\": \"Cohere\", \"Company B\": \"Anth.\", \"pct_a_restricted_if_b_restricted\": 97.0, \"text_color\": true}, {\"Company A\": \"Cohere\", \"Company B\": \"Cohere\", \"pct_a_restricted_if_b_restricted\": \"--\", \"text_color\": false}, {\"Company A\": \"Cohere\", \"Company B\": \"C.C.\", \"pct_a_restricted_if_b_restricted\": 97.0, \"text_color\": true}, {\"Company A\": \"Cohere\", \"Company B\": \"Meta\", \"pct_a_restricted_if_b_restricted\": 84.8, \"text_color\": true}, {\"Company A\": \"Cohere\", \"Company B\": \"I.Arch.\", \"pct_a_restricted_if_b_restricted\": 39.4, \"text_color\": true}, {\"Company A\": \"Cohere\", \"Company B\": \"G.S.\", \"pct_a_restricted_if_b_restricted\": 27.3, \"text_color\": true}, {\"Company A\": \"Cohere\", \"Company B\": \"F.Anth.\", \"pct_a_restricted_if_b_restricted\": 100.0, \"text_color\": true}, {\"Company A\": \"C.C.\", \"Company B\": \"Goog.\", \"pct_a_restricted_if_b_restricted\": 51.9, \"text_color\": true}, {\"Company A\": \"C.C.\", \"Company B\": \"OAI\", \"pct_a_restricted_if_b_restricted\": 96.3, \"text_color\": true}, {\"Company A\": \"C.C.\", \"Company B\": \"Anth.\", \"pct_a_restricted_if_b_restricted\": 100.0, \"text_color\": true}, {\"Company A\": \"C.C.\", \"Company B\": \"Cohere\", \"pct_a_restricted_if_b_restricted\": 29.6, \"text_color\": true}, {\"Company A\": \"C.C.\", \"Company B\": \"C.C.\", \"pct_a_restricted_if_b_restricted\": \"--\", \"text_color\": false}, {\"Company A\": \"C.C.\", \"Company B\": \"Meta\", \"pct_a_restricted_if_b_restricted\": 30.6, \"text_color\": true}, {\"Company A\": \"C.C.\", \"Company B\": \"I.Arch.\", \"pct_a_restricted_if_b_restricted\": 14.8, \"text_color\": true}, {\"Company A\": \"C.C.\", \"Company B\": \"G.S.\", \"pct_a_restricted_if_b_restricted\": 8.3, \"text_color\": false}, {\"Company A\": \"C.C.\", \"Company B\": \"F.Anth.\", \"pct_a_restricted_if_b_restricted\": 38.9, \"text_color\": true}, {\"Company A\": \"Meta\", \"Company B\": \"Goog.\", \"pct_a_restricted_if_b_restricted\": 97.1, \"text_color\": true}, {\"Company A\": \"Meta\", \"Company B\": \"OAI\", \"pct_a_restricted_if_b_restricted\": 94.3, \"text_color\": true}, {\"Company A\": \"Meta\", \"Company B\": \"Anth.\", \"pct_a_restricted_if_b_restricted\": 94.3, \"text_color\": true}, {\"Company A\": \"Meta\", \"Company B\": \"Cohere\", \"pct_a_restricted_if_b_restricted\": 80.0, \"text_color\": true}, {\"Company A\": \"Meta\", \"Company B\": \"C.C.\", \"pct_a_restricted_if_b_restricted\": 94.3, \"text_color\": true}, {\"Company A\": \"Meta\", \"Company B\": \"Meta\", \"pct_a_restricted_if_b_restricted\": \"--\", \"text_color\": false}, {\"Company A\": \"Meta\", \"Company B\": \"I.Arch.\", \"pct_a_restricted_if_b_restricted\": 31.4, \"text_color\": true}, {\"Company A\": \"Meta\", \"Company B\": \"G.S.\", \"pct_a_restricted_if_b_restricted\": 25.7, \"text_color\": true}, {\"Company A\": \"Meta\", \"Company B\": \"F.Anth.\", \"pct_a_restricted_if_b_restricted\": 91.4, \"text_color\": true}, {\"Company A\": \"I.Arch.\", \"Company B\": \"Goog.\", \"pct_a_restricted_if_b_restricted\": 46.7, \"text_color\": true}, {\"Company A\": \"I.Arch.\", \"Company B\": \"OAI\", \"pct_a_restricted_if_b_restricted\": 50.0, \"text_color\": true}, {\"Company A\": \"I.Arch.\", \"Company B\": \"Anth.\", \"pct_a_restricted_if_b_restricted\": 53.3, \"text_color\": true}, {\"Company A\": \"I.Arch.\", \"Company B\": \"Cohere\", \"pct_a_restricted_if_b_restricted\": 43.3, \"text_color\": true}, {\"Company A\": \"I.Arch.\", \"Company B\": \"C.C.\", \"pct_a_restricted_if_b_restricted\": 53.3, \"text_color\": true}, {\"Company A\": \"I.Arch.\", \"Company B\": \"Meta\", \"pct_a_restricted_if_b_restricted\": 36.7, \"text_color\": true}, {\"Company A\": \"I.Arch.\", \"Company B\": \"I.Arch.\", \"pct_a_restricted_if_b_restricted\": \"--\", \"text_color\": false}, {\"Company A\": \"I.Arch.\", \"Company B\": \"G.S.\", \"pct_a_restricted_if_b_restricted\": 30.0, \"text_color\": true}, {\"Company A\": \"I.Arch.\", \"Company B\": \"F.Anth.\", \"pct_a_restricted_if_b_restricted\": 46.7, \"text_color\": true}, {\"Company A\": \"G.S.\", \"Company B\": \"Goog.\", \"pct_a_restricted_if_b_restricted\": 100.0, \"text_color\": true}, {\"Company A\": \"G.S.\", \"Company B\": \"OAI\", \"pct_a_restricted_if_b_restricted\": 100.0, \"text_color\": true}, {\"Company A\": \"G.S.\", \"Company B\": \"Anth.\", \"pct_a_restricted_if_b_restricted\": 100.0, \"text_color\": true}, {\"Company A\": \"G.S.\", \"Company B\": \"Cohere\", \"pct_a_restricted_if_b_restricted\": 100.0, \"text_color\": true}, {\"Company A\": \"G.S.\", \"Company B\": \"C.C.\", \"pct_a_restricted_if_b_restricted\": 100.0, \"text_color\": true}, {\"Company A\": \"G.S.\", \"Company B\": \"Meta\", \"pct_a_restricted_if_b_restricted\": 100.0, \"text_color\": true}, {\"Company A\": \"G.S.\", \"Company B\": \"I.Arch.\", \"pct_a_restricted_if_b_restricted\": 100.0, \"text_color\": true}, {\"Company A\": \"G.S.\", \"Company B\": \"G.S.\", \"pct_a_restricted_if_b_restricted\": \"--\", \"text_color\": false}, {\"Company A\": \"G.S.\", \"Company B\": \"F.Anth.\", \"pct_a_restricted_if_b_restricted\": 100.0, \"text_color\": true}, {\"Company A\": \"F.Anth.\", \"Company B\": \"Goog.\", \"pct_a_restricted_if_b_restricted\": 93.2, \"text_color\": true}, {\"Company A\": \"F.Anth.\", \"Company B\": \"OAI\", \"pct_a_restricted_if_b_restricted\": 97.7, \"text_color\": true}, {\"Company A\": \"F.Anth.\", \"Company B\": \"Anth.\", \"pct_a_restricted_if_b_restricted\": 95.5, \"text_color\": true}, {\"Company A\": \"F.Anth.\", \"Company B\": \"Cohere\", \"pct_a_restricted_if_b_restricted\": 75.0, \"text_color\": true}, {\"Company A\": \"F.Anth.\", \"Company B\": \"C.C.\", \"pct_a_restricted_if_b_restricted\": 95.5, \"text_color\": true}, {\"Company A\": \"F.Anth.\", \"Company B\": \"Meta\", \"pct_a_restricted_if_b_restricted\": 72.7, \"text_color\": true}, {\"Company A\": \"F.Anth.\", \"Company B\": \"I.Arch.\", \"pct_a_restricted_if_b_restricted\": 31.8, \"text_color\": true}, {\"Company A\": \"F.Anth.\", \"Company B\": \"G.S.\", \"pct_a_restricted_if_b_restricted\": 20.5, \"text_color\": true}, {\"Company A\": \"F.Anth.\", \"Company B\": \"F.Anth.\", \"pct_a_restricted_if_b_restricted\": \"--\", \"text_color\": false}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_to_company_restrictions(url_robots_summary_head, ALL_COMPANIES_TO_TRACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7c2a06-c294-40e2-9a49-86a9633269ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "382f0417249244c2a935b45575d1a6f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8f9a03c0ff3640d98c2572ff53cf5c6e",
       "style": "IPY_MODEL_eeb72bcab3c24534a8bf3d11c37eb76a",
       "value": " 100000/100000 [07:08&lt;00:00, 264.32it/s]"
      }
     },
     "55d6c8db22814272982c3069c4028c4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "591f3bfde65244ea90f3617c48a0c019": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_dace26a5b3144cc185ead0b985d6aed0",
       "style": "IPY_MODEL_ffca6b725d4846cd9569b581f3773ed8",
       "value": "100%"
      }
     },
     "6c38c656fd32406d889e8d4809ab2cf0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6e615f0430f143d7b6a636f63f3d37ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_55d6c8db22814272982c3069c4028c4a",
       "max": 100000,
       "style": "IPY_MODEL_6c38c656fd32406d889e8d4809ab2cf0",
       "value": 100000
      }
     },
     "8f9a03c0ff3640d98c2572ff53cf5c6e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d4df20b113a24fefaf847628eb69060b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dace26a5b3144cc185ead0b985d6aed0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "eeb72bcab3c24534a8bf3d11c37eb76a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f17f7e75ff1241949f0f5066b0f0f9f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_591f3bfde65244ea90f3617c48a0c019",
        "IPY_MODEL_6e615f0430f143d7b6a636f63f3d37ea",
        "IPY_MODEL_382f0417249244c2a935b45575d1a6f2"
       ],
       "layout": "IPY_MODEL_d4df20b113a24fefaf847628eb69060b"
      }
     },
     "ffca6b725d4846cd9569b581f3773ed8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
