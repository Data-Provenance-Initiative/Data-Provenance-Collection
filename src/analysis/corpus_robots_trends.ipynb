{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a1d42b-5f82-4cb3-9ea5-b7e333a81ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Visualization packages\n",
    "import altair as alt\n",
    "\n",
    "# Append system path\n",
    "sys.path = [p for p in sys.path if not p.endswith('../..')]  # Cleans duplicated '../..'\n",
    "sys.path.insert(0, '../')  # This adds `src` to the path\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Append system path\n",
    "sys.path = [p for p in sys.path if not p.endswith('../..')]  # Cleans duplicated '../..'\n",
    "sys.path.insert(0, '../')  # This adds `src` to the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e151984-9a59-47a0-a9c9-cdf7971dc8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(pattern):\n",
    "    \"\"\" Load data from CSV files matching the pattern. \"\"\"\n",
    "    file_paths = glob.glob(pattern)\n",
    "    data = []\n",
    "    for file in file_paths:\n",
    "        df = pd.read_csv(file, index_col=0, parse_dates=True)\n",
    "        # Extract dataset and subset from filename\n",
    "        parts = os.path.basename(file).split('_')\n",
    "        df['Dataset'], df['Domain Type'] = parts[0], parts[1]\n",
    "        df['Dataset'] = df['Dataset'].map({'c4': \"C4\", 'rf': 'RefinedWeb', 'dolma': 'Dolma'})\n",
    "        data.append(df)\n",
    "    \n",
    "    concat_df = pd.concat(data).reset_index().rename(columns={'index': 'Date'})\n",
    "    return concat_df\n",
    "\n",
    "def prepare_data_for_plot1(data):\n",
    "    \"\"\" Prepare data for the first plot. \"\"\"\n",
    "    data = data[data['Domain Type'] == 'all']\n",
    "    # data[['head_frac', 'combined_tokens']] *= 100  # Multiply values by 100\n",
    "    return data.reset_index().melt(id_vars=['Date', 'Dataset'], value_vars=['Head', 'Full Corpus'],\n",
    "                                var_name='Token Sample', value_name='Percent')\n",
    "\n",
    "def prepare_data_for_plot2(data):\n",
    "    # data['subset'] = data['subset'].map(mapping).fillna(data['subset'])\n",
    "    relevant_subsets = {\n",
    "        \"Academic\": \"Acad\", \n",
    "        \"News\": \"News\", \n",
    "        'E': \"E-comm\", \n",
    "        'Encyclopedia': \"Encyc\", \n",
    "        'Government': \"Gov\", \n",
    "        \"Organization\": \"Org/Pers\", \n",
    "        'Social Media': \"Socials/Forum\",\n",
    "    }\n",
    "    data_numeric = data.drop(columns=['Dataset'])  # Drop the 'dataset' column\n",
    "    # data_numeric[['head_frac', 'combined_tokens']] *= 100  # Multiply values by 100\n",
    "    grouped = data_numeric.groupby(['Date', 'Domain Type']).mean().reset_index()\n",
    "    grouped = grouped[grouped[\"Domain Type\"].isin(relevant_subsets.keys())]\n",
    "    grouped[\"Domain Type\"] = grouped['Domain Type'].map(relevant_subsets).fillna(grouped['Domain Type'])\n",
    "    return grouped.melt(id_vars=['Date', 'Domain Type'], value_vars=['Head', 'Full Corpus'],\n",
    "                        var_name='Token Sample', value_name='Percent')\n",
    "\n",
    "def forecast_region(data, forecast_startdate, height, period_col=\"Date\"):\n",
    "    forecast_startdate = pd.to_datetime(forecast_startdate)\n",
    "    shading = alt.Chart(\n",
    "        pd.DataFrame({\"start\": [forecast_startdate], \"end\": [data[period_col].max()]})\n",
    "    ).mark_rect(\n",
    "        opacity=0.1,\n",
    "        color=\"gray\"\n",
    "    ).encode(\n",
    "        x=alt.X(\"start:T\", title=\"\"),\n",
    "        x2=\"end:T\"\n",
    "    )\n",
    "\n",
    "    forecast_rule = alt.Chart(\n",
    "        pd.DataFrame({\"period\": [forecast_startdate]})\n",
    "    ).mark_rule(\n",
    "        color=\"gray\"\n",
    "    ).encode(\n",
    "        x=\"period:T\"\n",
    "    )\n",
    "\n",
    "    # Add a label in the middle of the forecasted region\n",
    "    shading_text = alt.Chart(\n",
    "        pd.DataFrame({\"date\": [forecast_startdate + (data[period_col].max() - forecast_startdate) / 2], \"text\": [\"Forecast\"]})\n",
    "    ).mark_text(\n",
    "        align=\"center\",\n",
    "        baseline=\"middle\",\n",
    "        dx=0,\n",
    "        dy=height - 20,\n",
    "        color=\"black\",\n",
    "        fontWeight=\"bold\"\n",
    "    ).encode(\n",
    "        x=\"date:T\",\n",
    "        y=alt.value(0),\n",
    "        text=\"text:N\"\n",
    "    )\n",
    "\n",
    "    return shading + forecast_rule + shading_text\n",
    "\n",
    "    \n",
    "def temporal_corpus_estimation_plot(\n",
    "    data, title, x_title, y_title, font_style, font_size,\n",
    "    y_max=0.5,\n",
    "    forecast_startdate=\"2022\",\n",
    "    show_legend=True,\n",
    "    height=400,\n",
    "    width=800,\n",
    "):\n",
    "    \"\"\" Create and return an Altair plot. \"\"\"\n",
    "\n",
    "    colorLegend = alt.Legend(orient='none', title='Dataset',\n",
    "        labelFont=font_style, labelFontSize=font_size,\n",
    "        titleFont=font_style, titleFontSize=font_size, direction='horizontal',\n",
    "        legendX=0, legendY=230) if show_legend else None\n",
    "    strokeDashLegend = alt.Legend(orient='none', title='Token Sample',\n",
    "        labelFont=font_style, labelFontSize=font_size,\n",
    "        titleFont=font_style, titleFontSize=font_size, direction='horizontal',\n",
    "        legendX=300, legendY=230) if show_legend else None\n",
    "    \n",
    "    chart = alt.Chart(data).mark_line().encode(\n",
    "        x=alt.X('Date:T', title=x_title, axis=alt.Axis(format='%Y', tickCount={\"interval\": \"year\", \"step\": 1})),  # Yearly labels, data by month\n",
    "        y=alt.Y('Percent:Q', title=y_title, scale=alt.Scale(domain=[0, y_max]), axis=alt.Axis(format=\"%\", orient='right')),\n",
    "        # color='Dataset:N',\n",
    "        # strokeDash='Token Sample:N',\n",
    "        color=alt.Color('Dataset:N', legend=colorLegend),  # Position for color legend\n",
    "        strokeDash=alt.StrokeDash('Token Sample:N', legend=strokeDashLegend))  # Position for strokeDash legend\n",
    "    \n",
    "    ################################################################\n",
    "    # SHADE FORECASTED DATA REGIONS\n",
    "    # Add a shaded region for forecasted data, if needed\n",
    "    ################################################################\n",
    "    if forecast_startdate:\n",
    "        chart = chart + forecast_region(data, forecast_startdate, height)\n",
    "\n",
    "    chart = chart.properties(\n",
    "        width=width,\n",
    "        height=height\n",
    "    ).configure_axis(\n",
    "        labelFontSize=font_size,\n",
    "        titleFontSize=font_size,\n",
    "        labelFont=font_style,\n",
    "        titleFont=font_style,\n",
    "        grid=False  # Remove gridlines\n",
    "    ).configure_legend(\n",
    "        labelFont=font_style,\n",
    "        labelFontSize=font_size,\n",
    "        titleFont=font_style,\n",
    "        titleFontSize=font_size\n",
    "    )\n",
    "    return chart\n",
    "        \n",
    "\n",
    "def temporal_corpus_estimation_by_service_plot(\n",
    "    data, title, x_title, y_title, font_style, font_size,\n",
    "    y_max=0.7,\n",
    "    forecast_startdate=None,\n",
    "    show_legend=True,\n",
    "    height=400,\n",
    "    width=800,\n",
    "):\n",
    "    \"\"\" Ensure 'Date' is a datetime and data is sorted. \"\"\"\n",
    "    data['Date'] = pd.to_datetime(data['Date'])  # Parse 'Date' as datetime if not already\n",
    "    data = data.sort_values('Date')  # Sort data by 'Date'\n",
    "\n",
    "    # Optional settings for legends if they are to be displayed\n",
    "    legend_color = alt.Legend(orient='none', title='Domain Type',\n",
    "                            labelFont=font_style, labelFontSize=font_size,\n",
    "                            titleFont=font_style, titleFontSize=font_size, direction='horizontal', # , columns=7\n",
    "                            legendX=0, legendY=230) if show_legend else None\n",
    "    \n",
    "    legend_stroke_dash = None \n",
    "    # alt.Legend(orient='none', title='Token Sample',\n",
    "    #                                 labelFont=font_style, labelFontSize=font_size,\n",
    "    #                                 titleFont=font_style, titleFontSize=font_size,\n",
    "    #                                 direction='horizontal', legendX=150, legendY=10) if show_legend else None\n",
    "    \n",
    "    # Chart code with conditional legends\n",
    "    chart = alt.Chart(data).mark_line().encode(\n",
    "        x=alt.X('Date:T', title=x_title, axis=alt.Axis(format='%Y', tickCount={\"interval\": \"year\", \"step\": 1})),\n",
    "        y=alt.Y('Percent:Q', title=y_title, scale=alt.Scale(domain=[0, y_max]), axis=alt.Axis(format=\"%\", orient='right')),\n",
    "        color=alt.Color('Domain Type:N', legend=legend_color),\n",
    "        strokeDash=alt.StrokeDash('Token Sample:N', legend=legend_stroke_dash)\n",
    "    )\n",
    "\n",
    "    ################################################################\n",
    "    # SHADE FORECASTED DATA REGIONS\n",
    "    # Add a shaded region for forecasted data, if needed\n",
    "    ################################################################\n",
    "    if forecast_startdate:\n",
    "        chart = chart + forecast_region(data, forecast_startdate, height)\n",
    "\n",
    "    chart = chart.properties(\n",
    "        width=width,\n",
    "        height=height\n",
    "    ).configure_axis(\n",
    "        labelFontSize=font_size,\n",
    "        titleFontSize=font_size,\n",
    "        labelFont=font_style,\n",
    "        titleFont=font_style,\n",
    "        grid=False  # Remove gridlines\n",
    "    )\n",
    "\n",
    "    return chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cfb3bb-1c38-4c53-8b86-63d25fe6b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "robots_df = load_data('data/domain_estimates/robots/*')\n",
    "\n",
    "# Prepare data for plots\n",
    "robots_df_full_plot = prepare_data_for_plot1(robots_df)\n",
    "robots_df_service_plot = prepare_data_for_plot2(robots_df)\n",
    "# print(data_plot2[\"subset\"].unique())\n",
    "\n",
    "# Create plots\n",
    "robots_corpus_plot = temporal_corpus_estimation_plot(\n",
    "    robots_df_full_plot, 'Robots: Head Tokens vs Combined Tokens for each Dataset', '', '', 'Times', 13.5,\n",
    "    y_max=0.5,\n",
    "    forecast_startdate=None,\n",
    "    show_legend=False,\n",
    "    height=200, width=450,\n",
    ")\n",
    "robots_services_plot = temporal_corpus_estimation_by_service_plot(\n",
    "    robots_df_service_plot, 'Robots: Average Percent of Tokens by Subset', '', '', 'Times', 13.5,\n",
    "    y_max=0.5,\n",
    "    forecast_startdate=None,\n",
    "    show_legend=False,\n",
    "    height=200, width=450,\n",
    ")\n",
    "\n",
    "# Display the plots\n",
    "robots_corpus_plot.display()\n",
    "robots_services_plot.display()\n",
    "\n",
    "# Head, Combined\n",
    "# Robots vs ToS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e606f45d-3cf2-4c4b-ad41-51e5c84a3b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "tos_df = load_data('data/domain_estimates/tos/*')\n",
    "\n",
    "# Prepare data for plots\n",
    "tos_df_full_plot = prepare_data_for_plot1(tos_df)\n",
    "tos_df_service_plot = prepare_data_for_plot2(tos_df)\n",
    "# print(data_plot2[\"subset\"].unique())\n",
    "\n",
    "# Create plots\n",
    "tos_corpus_plot = temporal_corpus_estimation_plot(\n",
    "    tos_df_full_plot, 'Robots: Head Tokens vs Combined Tokens for each Dataset', '', '', 'Times', 13.5,\n",
    "    y_max=0.7,\n",
    "    forecast_startdate=None,\n",
    "    show_legend=True,\n",
    "    height=200, width=450,\n",
    ")\n",
    "tos_services_plot = temporal_corpus_estimation_by_service_plot(\n",
    "    tos_df_service_plot, 'Robots: Average Percent of Tokens by Subset', '', '', 'Times', 13.5,\n",
    "    y_max=0.7,\n",
    "    forecast_startdate=None,\n",
    "    show_legend=True,\n",
    "    height=200, width=450,\n",
    ")\n",
    "# Display the plots\n",
    "tos_corpus_plot.display()\n",
    "tos_services_plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f046d-4ce7-4ef3-b5a1-1ef3dc3df495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head == rand for every single one.\n",
    "# E-commerce mean shouldn't be that high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0d560-a8b3-4fbd-aa1c-b925fbabebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.hconcat(robots_corpus_plot, robots_services_plot).configure_axis(\n",
    "#     grid=False\n",
    "# ).configure_view(\n",
    "#     strokeWidth=0 # Remove the frame around the chart\n",
    "# ).resolve_legend(\n",
    "#     color='independent'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5838efd1-5de4-48af-9cba-928129351183",
   "metadata": {},
   "outputs": [],
   "source": [
    "robots_df_full_plot[robots_df_full_plot[\"Date\"] == \"2024-04-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc97edf0-50b7-4d1f-8934-726b4bd43aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "robots_df_full_plot[robots_df_full_plot[\"Date\"] == \"2023-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a09064-4388-488c-9b23-da27f4a8cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "robots_df_service_plot[robots_df_service_plot[\"Date\"] == \"2024-04-01\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b7393-5beb-42b3-b912-f66417a86544",
   "metadata": {},
   "outputs": [],
   "source": [
    "robots_df_service_plot[robots_df_service_plot[\"Date\"] == \"2023-04-01\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f2db6-f5a1-495e-8e0c-6f9dd48db9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tos_df_full_plot[tos_df_full_plot[\"Date\"] == \"2024-04-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8623ca7-6aec-4996-85dc-a2ff312b12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tos_df_full_plot[tos_df_full_plot[\"Date\"] == \"2023-04-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f255d1-2bb1-444b-9a50-579a17c19037",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"C4 Full Corpus: {43 / 28}\")\n",
    "print(f\"Dolma Full Corpus: {52 / 41}\")\n",
    "print(f\"RW Full Corpus: {53 / 42}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68b2aed-69fb-41e3-9e26-fff07bcb1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "tos_df_service_plot[tos_df_service_plot[\"Date\"] == \"2024-04-01\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b847747f-39a9-4ad2-8fae-7246122ada51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tos_df_service_plot[tos_df_service_plot[\"Date\"] == \"2023-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c584b3-aac9-4a2a-acaf-51b567bb8e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
