{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement install (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for install\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: vl-convert-python==1.6.0 in /home/gridsan/ktiwary/.conda/envs/dpi310/lib/python3.10/site-packages (1.6.0)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install -q -U pandas altair langcodes\n",
    "!pip3 install -q -U install semanticscholar\n",
    "!pip install vl-convert-python==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Append system path\n",
    "sys.path = [p for p in sys.path if not p.endswith(\"../..\")]  # Cleans duplicated '../..'\n",
    "sys.path.insert(0, \"../\")  # This adds `src` to the path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows() # Allow using more than 5000 rows, for now\n",
    "import langcodes\n",
    "from collections import defaultdict\n",
    "from helpers import io, filters\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Utility functions to process and transform data summaries:\n",
    "\n",
    "---\n",
    "```python\n",
    "def invert_dict_of_lists(\n",
    "  d: dict[str, list[str]]\n",
    ") -> dict[str, str]\n",
    "```\n",
    "- Inverts a dictionary of lists for easier mapping of constants.\n",
    "---\n",
    "```python\n",
    "def remap_licenses_with_paraphrases(\n",
    "  summaries: list[dict[str, Any]],\n",
    "  paraphrases: dict[str, str]\n",
    ") -> dict[str, Any]\n",
    "``` \n",
    "- Standardizes inconsistent license names in data summaries using predefined paraphrases.\n",
    "---\n",
    "```python\n",
    "def map_license_criteria_multimodal(\n",
    "  data_summary: list[dict[str, Any]],\n",
    "  all_constants: dict[str, dict[str, list[str]]]\n",
    ") -> list[dict[str, Any]]\n",
    "```\n",
    "- Maps license criteria for multimodal datasets, resolving them according to predefined constants.\n",
    "---\n",
    "```python\n",
    "def get_country(x: str) -> list[int]\n",
    "```\n",
    "- Takes a country name as input and returns a list of ISO3166 codes (mostly, of length 1). It handles a special case that appears in some text annotations (\"African Continent\" -> list of ISO codes) and logs a warning for any countries not found in the mapping.\n",
    "---\n",
    "```python\n",
    "def gini(array: np.ndarray) -> float:\n",
    "```\n",
    "- Takes an array of values and computes the Gini coefficient.\n",
    "---\n",
    "```python\n",
    "def factor_year(\n",
    "  df: pd.DataFrame,\n",
    "  column: str = \"Year Released\",\n",
    "  min_year: int = 2013\n",
    ") -> pd.DataFrame:\n",
    "```\n",
    "- Converts the year column into a categorical variable (with years before a given value grouped together).\n",
    "---\n",
    "```python\n",
    "def order_by_grouped_permisiveness(\n",
    "        df: pd.DataFrame,\n",
    "        group_column: str,\n",
    "        licensetype_column: str = \"License Type\",\n",
    "        permissive_licensetypes: list[str] = [\"Commercial\"]\n",
    ") -> pd.Series:\n",
    "```\n",
    "- Computes permisiveness (proportion of license types in a given set, by default only those marked `Commercial`) by a given grouping factor and returns an order for that factor.\n",
    "---\n",
    "```python\n",
    "def reduce_categories_to_topk(\n",
    "    df: pd.DataFrame,\n",
    "    column: str,\n",
    "    k: int = 6\n",
    ") -> pd.DataFrame:\n",
    "```\n",
    "- Reduces the number of categories in a column to `k`, with the rest grouped under `Other`. So returns a `DataFrame` with a version of that column with `k + 1` total categories.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_dict_of_lists(d: dict[str, list[str]]) -> dict[str, str]:\n",
    "    \"\"\"Useful for mapping constants, paraphrases, etc.\n",
    "    These are normally in the form:\n",
    "        { \"Category\": [\"item1\", \"item2\", … ] }\n",
    "    Whereas we want to invert it to:\n",
    "        { \"item1\": \"Category\", \"item2\": \"Category\", … }\n",
    "    \"\"\"\n",
    "    inverted = {}\n",
    "    for k, v in d.items():\n",
    "        for item in v:\n",
    "            inverted[item] = k\n",
    "    return inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_licenses_with_paraphrases(\n",
    "        summaries: list[dict[str, Any]],\n",
    "        paraphrases: dict[str, str]\n",
    "    ) -> dict[str, Any]:\n",
    "    \"\"\"Map inconsistent license names to shared paraphrases using the constants.\n",
    "    E.g. \"CC-BY-SA 4.0\", \"CC BY SA 4.0\" -> \"CC BY-SA 4.0\"\n",
    "    \"\"\"\n",
    "\n",
    "    for i, summary in enumerate(summaries):\n",
    "        for j, license in enumerate(summary[\"Licenses\"]):\n",
    "            license = license[\"License\"]\n",
    "            summaries[i][\"Licenses\"][j][\"License\"] = paraphrases.get(\n",
    "                license,\n",
    "                license\n",
    "            )\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_resolve_licenses(\n",
    "    license_infos: list[tuple[str, str]],\n",
    "    all_constants: dict[str, dict[str, list[str]]]\n",
    ") -> list[str]:\n",
    "    \"\"\"Function taken from `text_ft_plots.ipynb`\"\"\"\n",
    "    classified_licenses = []\n",
    "    for (license_name, license_url) in license_infos:\n",
    "        # Classify an individual license\n",
    "        classifications = filters.classify_license(license_name, license_url, all_constants)\n",
    "        classified_licenses.append(classifications)\n",
    "\n",
    "    # By default, multiple licenses yield to the most restrictive one\n",
    "    resolved_criteria = filters.resolve_multiple_licenses(classified_licenses)\n",
    "    return resolved_criteria\n",
    "\n",
    "\n",
    "def add_license_classes_to_summaries(\n",
    "    data_summary: list[dict[str, Any]],\n",
    "    resolved_classes: dict[str, list[str]],\n",
    "    aggregator: str\n",
    "):\n",
    "    \"\"\"Function taken from `text_ft_plots.ipynb`\"\"\"\n",
    "    # Update DataFrame with columns for use, attribution, share_alike\n",
    "    for row in data_summary:\n",
    "        row[f\"License Use ({aggregator})\"] = resolved_classes[row[\"Unique Dataset Identifier\"]][0]\n",
    "        row[f\"License Attribution ({aggregator})\"] = resolved_classes[row[\"Unique Dataset Identifier\"]][1]\n",
    "        row[f\"License Share Alike ({aggregator})\"] = resolved_classes[row[\"Unique Dataset Identifier\"]][2]\n",
    "    return data_summary\n",
    "\n",
    "\n",
    "def map_license_criteria_multimodal(\n",
    "    data_summary: list[dict[str, Any]],\n",
    "    all_constants: dict[str, dict[str, list[str]]]\n",
    ") -> list[dict[str, Any]]:\n",
    "    \"\"\"Variant of `map_license_criteria` that works with multimodal datasets.\n",
    "    Simplified to only include `Licenses` (not HF, etc.).\n",
    "\n",
    "    Function adapted from `text_ft_plots.ipynb`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack licenses for each dataset. {uid --> (license_name, license_url)}\n",
    "    our_uid_to_license_infos = defaultdict(list)\n",
    "\n",
    "    # Same as ours, but excludes OpenAI Terms:\n",
    "    our_uid_to_license_infos_no_openai = defaultdict(list)\n",
    "\n",
    "    for row in data_summary:\n",
    "        uid = row[\"Unique Dataset Identifier\"]\n",
    "        for license_info in row[\"Licenses\"]:\n",
    "            license_name = license_info[\"License\"]\n",
    "            license_url = license_info.get(\"License URL\", None) # FOR NOW\n",
    "            our_uid_to_license_infos[uid].append((license_name, license_url))\n",
    "            if license_info[\"License\"] != \"OpenAI\":\n",
    "                our_uid_to_license_infos_no_openai[uid].append((license_name, license_url))\n",
    "\n",
    "        # If OpenAI was the only license, we add Unspecified so there isn't nothing there.\n",
    "        if len(our_uid_to_license_infos_no_openai[uid]) == 0:\n",
    "            our_uid_to_license_infos_no_openai[uid].append((\"Unspecified\", None))\n",
    "\n",
    "\n",
    "    # classify and resolve licenses for each dataset and each aggregator\n",
    "    ours_resolved, ours_openai_resolved = {}, {}\n",
    "    for uid in our_uid_to_license_infos.keys():\n",
    "        ours_resolved[uid] = classify_and_resolve_licenses(our_uid_to_license_infos[uid], all_constants)\n",
    "        ours_openai_resolved[uid] = classify_and_resolve_licenses(our_uid_to_license_infos_no_openai[uid], all_constants)\n",
    "\n",
    "\n",
    "    data_summary = add_license_classes_to_summaries(data_summary, ours_resolved, \"DataProvenance\")\n",
    "    data_summary = add_license_classes_to_summaries(data_summary, ours_openai_resolved, \"DataProvenance IgnoreOpenAI\")\n",
    "\n",
    "    return data_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(array: np.ndarray) -> float:\n",
    "    \"\"\"Calculate the Gini coefficient of a numpy array.\n",
    "\n",
    "    Implementation taken from: https://github.com/oliviaguest/gini\n",
    "    \"\"\"\n",
    "    # based on bottom eq:\n",
    "    # http://www.statsdirect.com/help/generatedimages/equations/equation154.svg\n",
    "    # from:\n",
    "    # http://www.statsdirect.com/help/default.htm#nonparametric_methods/gini.htm\n",
    "    # All values are treated equally, arrays must be 1d:\n",
    "    array = array.flatten()\n",
    "    if np.amin(array) < 0:\n",
    "        # Values cannot be negative:\n",
    "        array -= np.amin(array)\n",
    "    # Values cannot be 0:\n",
    "    array = array + 0.0000001\n",
    "    # Values must be sorted:\n",
    "    array = np.sort(array)\n",
    "    # Index per array element:\n",
    "    index = np.arange(1,array.shape[0]+1)\n",
    "    # Number of array elements:\n",
    "    n = array.shape[0]\n",
    "    # Gini coefficient:\n",
    "    return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_cis_for_gini(\n",
    "    data: np.ndarray,\n",
    "    n_samples: int = 1000,\n",
    "    alpha: float = 0.05\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"Calculate the confidence interval for the Gini coefficient using bootstrapping.\n",
    "    \"\"\"\n",
    "\n",
    "    ginis = []\n",
    "    for _ in range(n_samples):\n",
    "        sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        ginis.append(gini(sample))\n",
    "\n",
    "    ginis = np.array(ginis)\n",
    "    lower_bound = np.percentile(ginis, alpha / 2 * 100)\n",
    "    upper_bound = np.percentile(ginis, (1 - alpha / 2) * 100)\n",
    "\n",
    "    return np.mean(ginis), lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_year(\n",
    "    df: pd.DataFrame,\n",
    "    column: str = \"Year Released\",\n",
    "    min_year: int = 2004\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Transform the year column into a categorical column.\n",
    "\n",
    "    Years before `min_year` are grouped into a category, i.e. \"<`min_year`\" (e.g. )\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    min_yeartext = \"<%d\" % min_year\n",
    "    max_year = df[column].max().astype(int)\n",
    "\n",
    "    df[column] = df[column].map(\n",
    "        lambda x: min_yeartext if (x < min_year) else str(x)\n",
    "    )\n",
    "\n",
    "    order = [min_yeartext, *map(str, range(min_year, max_year + 1))]\n",
    "\n",
    "    df[column] = pd.Categorical(\n",
    "        df[column],\n",
    "        categories=order,\n",
    "        ordered=True\n",
    "    )\n",
    "\n",
    "    return df, order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_by_grouped_permisiveness(\n",
    "        df: pd.DataFrame,\n",
    "        group_column: str,\n",
    "        licensetype_column: str = \"License Type\",\n",
    "        permissive_licensetypes: list[str] = [\"Commercial\"]\n",
    ") -> pd.Series:\n",
    "    \"\"\"Given a DataFrame, group it by `group_column` and calculate the permissiveness of each group.\n",
    "\n",
    "    Permisiveness is calculated as the proportion of licenses that are in `permissive_licensetypes`.\n",
    "    \"\"\"\n",
    "    permisiveness = df.groupby(group_column).apply(\n",
    "        lambda x: (x[licensetype_column].isin(permissive_licensetypes)).mean()\n",
    "    ).reset_index(name=\"Permissiveness\")\n",
    "\n",
    "    permisiveness_order = permisiveness.sort_values(by=\"Permissiveness\")[group_column].tolist()\n",
    "\n",
    "    return permisiveness_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_categories_to_topk(\n",
    "    df: pd.DataFrame,\n",
    "    column: str,\n",
    "    k: int = 6\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Reduce the number of categories in a column to the top `k` categories.\n",
    "\n",
    "    The rest are grouped into an \"Other\" category.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    topk = df[column].value_counts().head(k).index.tolist()\n",
    "    df[column] = df[column].map(\n",
    "        lambda x: x if x in topk else \"Other\"\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Constants and Summaries\n",
    "\n",
    "Load constants and data summaries from JSON files. Constants provide mappings and criteria for licenses, creator groups, various other categories. Data summaries contain modality-specific information about datasets.\n",
    "\n",
    "- `all_constants`: Dictionary containing all predefined constants.\n",
    "- `video_summaries`: Data summaries for speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_constants = io.read_all_constants(\"../../constants/\")\n",
    "video_summaries = io.read_data_summary_json(\"../..//data_summaries-video\")\n",
    "license_paraphrases = invert_dict_of_lists(all_constants[\"LICENSE_PARAPHRASES\"])\n",
    "creator_categories = invert_dict_of_lists(all_constants[\"CREATOR_GROUPS\"])\n",
    "\n",
    "\n",
    "video_summaries = map_license_criteria_multimodal(\n",
    "    remap_licenses_with_paraphrases(\n",
    "        video_summaries,\n",
    "        license_paraphrases\n",
    "    ),\n",
    "    all_constants\n",
    ")\n",
    "\n",
    "df_video = pd.DataFrame(video_summaries)\n",
    "# do some checks on the video dataset\n",
    "# raise if there are any missing values in the license, year released, video sources, tasks\n",
    "assert df_video[\"Licenses\"].apply(lambda x: len(x) == 0).sum() == 0, \"print the rows with missing licenses: \\n\" + str(df_video[df_video[\"Licenses\"].apply(lambda x: len(x) == 0)])\n",
    "assert df_video[\"Year Released\"].isna().sum() == 0, \"print the rows with missing year released: \\n\" + str(df_video[df_video[\"Year Released\"].isna()])\n",
    "assert df_video[\"Video Sources\"].apply(lambda x: len(x) == 0).sum() == 0, \"print the rows with missing video sources: \\n\" + str(df_video[df_video[\"Video Sources\"].apply(lambda x: len(x) == 0)])\n",
    "assert df_video[\"Task Categories\"].apply(lambda x: len(x) == 0).sum() == 0, \"print the rows with missing tasks: \\n\" + str(df_video[df_video[\"Tasks\"].apply(lambda x: len(x) == 0)])\n",
    "\n",
    "df_video, YEARS_ORDER = factor_year(df_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9389346359741161"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall Gini coefficient (hours by dataset)\n",
    "gini(df_video[\"Video Hours\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting constants\n",
    "FONT_SIZE = 20\n",
    "LEGEND_POSITION = \"bottom\"\n",
    "PLOT_TOFILE = False # Whether and where to output plots\n",
    "PLOT_DIR = \"/home/gridsan/ktiwary/src/dpi-ktiwary-fork/dpi-plots/video\"\n",
    "PLOT_PPI = 300\n",
    "MAX_LABELLIMIT = 1000 # Large number to avoid label summarization in plots\n",
    "\n",
    "if PLOT_TOFILE:\n",
    "    PLOT_DIR = os.path.expanduser(PLOT_DIR)\n",
    "    os.makedirs(PLOT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThemeRegistry.enable('times_newroman')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def times_newroman():\n",
    "    font = \"Times New Roman\"\n",
    "\n",
    "    return {\n",
    "          \"config\" : {\n",
    "               \"title\": {\"font\": font},\n",
    "               \"axis\": {\n",
    "               \"labelFont\": font,\n",
    "               \"titleFont\": font\n",
    "          },\n",
    "          \"header\": {\n",
    "               \"labelFont\": font,\n",
    "               \"titleFont\": font\n",
    "          },\n",
    "          \"legend\": {\n",
    "               \"labelFont\": font,\n",
    "               \"titleFont\": font\n",
    "          },\n",
    "          \"text\": {\n",
    "               \"font\": font\n",
    "          }\n",
    "     }\n",
    "}\n",
    "\n",
    "alt.themes.register(\"times_newroman\", times_newroman)\n",
    "alt.themes.enable(\"times_newroman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License Use Vs. Source Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting constants\n",
    "LICENSE_ORDER = [\"Non-Commercial/Academic\", \"Unspecified\", \"Commercial\"]\n",
    "LICENSE_PALETTE = [\"#e04c71\", \"#e0cd92\", \"#82b5cf\"]\n",
    "LICENSE_PLOTW = 600\n",
    "LICENSE_PLOTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map to main DPI license types\n",
    "df_video[\"License Type\"] = df_video[\"License Use (DataProvenance)\"].map({\n",
    "    \"academic-only\": \"Non-Commercial/Academic\",\n",
    "    \"non-commercial\": \"Non-Commercial/Academic\",\n",
    "    \"unspecified\": \"Unspecified\",\n",
    "    \"commercial\": \"Commercial\"\n",
    "})\n",
    "\n",
    "df_video[\"License Type\"] = pd.Categorical(\n",
    "    df_video[\"License Type\"],\n",
    "    categories=LICENSE_ORDER,\n",
    "    ordered=True\n",
    ")\n",
    "df_video = df_video.sort_values(by=\"License Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2104418/2109643095.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  permisiveness = df_videosourcelicences.groupby(\"Video Sources\").apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Sources</th>\n",
       "      <th>License Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowdsourced</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>crowdsourced</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>crowdsourced</td>\n",
       "      <td>Non-Commercial/Academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>crowdsourced</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>crowdsourced</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Video Sources             License Type\n",
       "4   crowdsourced              Unspecified\n",
       "79  crowdsourced              Unspecified\n",
       "90  crowdsourced  Non-Commercial/Academic\n",
       "60  crowdsourced              Unspecified\n",
       "37  crowdsourced              Unspecified"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remap language families for condensed plots\n",
    "INCLUDE_TOP_N_CATEGORIES = 8\n",
    "df_videosourcelicences = df_video.explode(\"Video Sources\")\n",
    "df_videosourcelicences = reduce_categories_to_topk(df_videosourcelicences, \"Video Sources\", INCLUDE_TOP_N_CATEGORIES)\n",
    "\n",
    "\n",
    "# Calculate permissiveness by language family (defined as the proportion of commercial licenses)\n",
    "permisiveness = df_videosourcelicences.groupby(\"Video Sources\").apply(\n",
    "    lambda x: (x[\"License Type\"] == \"Commercial\").mean()\n",
    ").reset_index(name=\"Permissiveness\")\n",
    "\n",
    "# Sort by computed permisiveness\n",
    "videosources_order = permisiveness.sort_values(by=\"Permissiveness\")[\"Video Sources\"].tolist()\n",
    "\n",
    "# Make factor\n",
    "df_videosourcelicences[\"Video Sources\"] = pd.Categorical(\n",
    "    df_videosourcelicences[\"Video Sources\"],\n",
    "    categories=videosources_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Sort by Video Sources\n",
    "df_videosourcelicences = df_videosourcelicences.sort_values(by=\"Video Sources\")\n",
    "df_videosourcelicences.head()[['Video Sources', 'License Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-a611ac81614f4ac0a8d2039c9b9e00ba.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-a611ac81614f4ac0a8d2039c9b9e00ba.vega-embed details,\n",
       "  #altair-viz-a611ac81614f4ac0a8d2039c9b9e00ba.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-a611ac81614f4ac0a8d2039c9b9e00ba\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a611ac81614f4ac0a8d2039c9b9e00ba\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a611ac81614f4ac0a8d2039c9b9e00ba\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"Times New Roman\"}, \"axis\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\", \"labelFontSize\": 20, \"titleFontSize\": 20}, \"header\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\"}, \"legend\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\", \"labelFontSize\": 20, \"labelLimit\": 1000, \"orient\": \"bottom\", \"titleFontSize\": 20}, \"text\": {\"font\": \"Times New Roman\"}}, \"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"License Type\", \"scale\": {\"domain\": [\"Non-Commercial/Academic\", \"Unspecified\", \"Commercial\"], \"range\": [\"#e04c71\", \"#e0cd92\", \"#82b5cf\"]}, \"title\": \"License Type\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30}, \"field\": \"Video Sources\", \"sort\": [\"crowdsourced\", \"human\", \"undisclosed web\", \"movies\", \"youtube\", \"metacafe\", \"vine\", \"Other\", \"flickr\"], \"title\": \"Video Sources\", \"type\": \"nominal\"}, \"y\": {\"aggregate\": \"count\", \"axis\": {\"format\": \"%\"}, \"stack\": \"normalize\", \"title\": \"Pct. Datasets\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"top\", \"dy\": -68, \"fontSize\": 12}, \"encoding\": {\"text\": {\"aggregate\": \"count\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"Video Sources\", \"sort\": [\"crowdsourced\", \"human\", \"undisclosed web\", \"movies\", \"youtube\", \"metacafe\", \"vine\", \"Other\", \"flickr\"], \"title\": \"Video Sources\", \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-82198f2da00c4d2fcaf3fdcc880f483a\"}, \"height\": 100, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-82198f2da00c4d2fcaf3fdcc880f483a\": [{\"Unique Dataset Identifier\": \"qfvs\", \"Collection\": \"qfvs\", \"Collection URL\": \"https://arxiv.org/abs/1707.04960\", \"Dataset Name\": \"QFVS: Query-Focused Video Summarization: Dataset, Evaluation, and A Memory Network Based Approach (CVPR 2017)\", \"Paper Title\": \"QFVS: Query-Focused Video Summarization: Dataset, Evaluation, and A Memory Network Based Approach (CVPR 2017)\", \"Paper URL\": \"https://arxiv.org/abs/1707.04960\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/query-focused-video-summarization-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/1707.04960\", \"Semantic Scholar Corpus ID\": 2774608, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Central Florida\", \"University of Alabama\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 20.0, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"multi-moments-in-time-dataset\", \"Collection\": \"multi-moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Dataset Name\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper Title\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Semantic Scholar Corpus ID\": 207780280, \"Year Released\": \"2021\", \"Text Sources\": [\"crowdsourced\", \"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"titan\", \"Collection\": \"titan\", \"Collection URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf\", \"Dataset Name\": \"TITAN: Future Forecast using Action Priors (CVPR 2020)\", \"Paper Title\": \"TITAN: Future Forecast using Action Priors (CVPR 2020)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/titan-future-forecast-using-action-priors\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf\", \"Semantic Scholar Corpus ID\": 214727763, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Non Commercial\", \"License URL\": \"https://usa.honda-ri.com/titan\"}], \"Creators\": [\"Honda Research Institute\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 2.91, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"tiny-virat\", \"Collection\": \"tiny-virat\", \"Collection URL\": \"https://arxiv.org/abs/2007.07355\", \"Dataset Name\": \"TinyVIRAT: Low-resolution Video Action Recognition\", \"Paper Title\": \"TinyVIRAT: Low-resolution Video Action Recognition\", \"Paper URL\": \"https://arxiv.org/abs/2007.07355\", \"GitHub URL\": \"https://github.com/UgurDemir/Tiny-VIRAT\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tinyvirat\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.07355\", \"Semantic Scholar Corpus ID\": 220525685, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Central Florida\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 10.83, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"pku-mmd-dataset\", \"Collection\": \"pku-mmd-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1703.07475\", \"Dataset Name\": \"PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding (ACM Multimedia Workshop)\", \"Paper Title\": \"PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding (ACM Multimedia Workshop)\", \"Paper URL\": \"https://arxiv.org/abs/1703.07475\", \"GitHub URL\": \"https://struct002.github.io/PKUMMD/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/pku-mmd-a-large-scale-benchmark-for\", \"ArXiv URL\": \"https://arxiv.org/abs/1703.07475\", \"Semantic Scholar Corpus ID\": 1904265, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Microsoft Research\", \"Peking University\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 50.0, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"summe\", \"Collection\": \"summe\", \"Collection URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"Dataset Name\": \"SumMe: Creating Summaries from User Videos (ECCV 2014)\", \"Paper Title\": \"SumMe: Creating Summaries from User Videos (ECCV 2014)\", \"Paper URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/summe\", \"ArXiv URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"Semantic Scholar Corpus ID\": 2111093, \"Year Released\": \"2014\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"ETH Z\\u00fcrich\", \"KU Leuven\", \"upicto GmbH\"], \"Countries\": [\"Belgium\", \"Switzerland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1.11, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"lemma-dataset\", \"Collection\": \"lemma-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2007.15781\", \"Dataset Name\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper Title\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2007.15781\", \"GitHub URL\": \"https://github.com/Buzz-Beater/LEMMA\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/lemma\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.15781\", \"Semantic Scholar Corpus ID\": 220634784, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\", \"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"UCLA\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 10.8, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"20BN-jester\", \"Collection\": \"20BN-jester\", \"Collection URL\": \"https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf\", \"Dataset Name\": \"20BN-jester: The Jester Dataset: A Large-Scale Video Dataset of Human Gestures (ICCVW 2019)\", \"Paper Title\": \"20BN-jester: The Jester Dataset: A Large-Scale Video Dataset of Human Gestures (ICCVW 2019)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf\", \"Semantic Scholar Corpus ID\": 208010438, \"Year Released\": \"2019\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://developer.qualcomm.com/software/ai-datasets/jester\"}], \"Creators\": [\"Twenty Billion Neurons GmbH\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13.0, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ntu-rgbd\", \"Collection\": \"ntu-rgbd\", \"Collection URL\": \"https://arxiv.org/pdf/1604.02808.pdf\", \"Dataset Name\": \"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis (CVPR 2016, TPAMI 2019)\", \"Paper Title\": \"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis (CVPR 2016, TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1604.02808.pdf\", \"GitHub URL\": \"https://github.com/shahroudy/NTURGB-D\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ntu-rgbd-a-large-scale-dataset-for-3d-human\", \"ArXiv URL\": \"https://arxiv.org/pdf/1604.02808.pdf\", \"Semantic Scholar Corpus ID\": 15928602, \"Year Released\": \"2016\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://rose1.ntu.edu.sg/dataset/actionRecognition/\"}], \"Creators\": [\"Nanyang Technological University\"], \"Countries\": [\"Singapore\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 74.1, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"20bn-something\", \"Collection\": \"20bn-something\", \"Collection URL\": \"https://arxiv.org/abs/1706.04261\", \"Dataset Name\": \"20BN-SOMETHING-SOMETHING: The \\\"something something\\\" video database for learning and evaluating visual common sense\", \"Paper Title\": \"20BN-SOMETHING-SOMETHING: The \\\"something something\\\" video database for learning and evaluating visual common sense\", \"Paper URL\": \"https://arxiv.org/abs/1706.04261\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/something-something-v2\", \"ArXiv URL\": \"https://arxiv.org/abs/1706.04261\", \"Semantic Scholar Corpus ID\": 834612, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://developer.qualcomm.com/software/ai-datasets/something-something\"}], \"Creators\": [\"Twenty Billion Neurons GmbH\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 121.46, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"cacd\", \"Collection\": \"cacd\", \"Collection URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"Dataset Name\": \"CDAD: A Common Daily Action Dataset with Collected Hard Negative Samples (CVPR 2022)\", \"Paper Title\": \"CDAD: A Common Daily Action Dataset with Collected Hard Negative Samples (CVPR 2022)\", \"Paper URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"GitHub URL\": \"https://github.com/MartinXM/CDAD\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"Semantic Scholar Corpus ID\": 251035434, \"Year Released\": \"2022\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"The Hong Kong Polytechnic University\", \"Alibaba Group\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 215.0, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mpii-cooking2\", \"Collection\": \"mpii-cooking2\", \"Collection URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"Dataset Name\": \"MPII Cooking 2\", \"Paper Title\": \"MPII Cooking 2\", \"Paper URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mpii-cooking-2-dataset\", \"ArXiv URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"Semantic Scholar Corpus ID\": 14036544, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/human-activity-recognition/mpii-cooking-2-dataset/\"}], \"Creators\": [\"Max Planck Institute for Informatics\", \"Saarland University\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 27.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Temporal Action Detection\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"uav-human\", \"Collection\": \"uav-human\", \"Collection URL\": \"https://arxiv.org/abs/2104.00946\", \"Dataset Name\": \"UAV-Human: A Large Benchmark for Human Behavior Understanding with Unmanned Aerial Vehicles\", \"Paper Title\": \"UAV-Human: A Large Benchmark for Human Behavior Understanding with Unmanned Aerial Vehicles\", \"Paper URL\": \"https://arxiv.org/abs/2104.00946\", \"GitHub URL\": \"https://github.com/sutdcv/UAV-Human\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/uav-human-a-large-benchmark-for-human\", \"ArXiv URL\": \"https://arxiv.org/abs/2104.00946\", \"Semantic Scholar Corpus ID\": 233004700, \"Year Released\": \"2021\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://sutdcv.github.io/uav-human-web/\"}], \"Creators\": [\"Shandong University\", \"Singapore University of Technology and Design\"], \"Countries\": [\"Singapore\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 18.34, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"lemma-dataset\", \"Collection\": \"lemma-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2007.15781\", \"Dataset Name\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper Title\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2007.15781\", \"GitHub URL\": \"https://github.com/Buzz-Beater/LEMMA\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/lemma\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.15781\", \"Semantic Scholar Corpus ID\": 220634784, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\", \"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"UCLA\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 10.8, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"homage\", \"Collection\": \"homage\", \"Collection URL\": \"https://arxiv.org/abs/2105.05226\", \"Dataset Name\": \"HOMAGE: Home Action Genome: Cooperative Compositional Action Understanding (CVPR 2021)\", \"Paper Title\": \"HOMAGE: Home Action Genome: Cooperative Compositional Action Understanding (CVPR 2021)\", \"Paper URL\": \"https://arxiv.org/abs/2105.05226\", \"GitHub URL\": \"https://github.com/nishantrai18/homage\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/home-action-genome-cooperative-compositional\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.05226\", \"Semantic Scholar Corpus ID\": 234357543, \"Year Released\": \"2021\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Stanford University\", \"Panasonic Corporation\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 30.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\", \"Temporal Action Segmentation\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"charades-ego\", \"Collection\": \"charades-ego\", \"Collection URL\": \"https://arxiv.org/abs/1804.09627\", \"Dataset Name\": \"Charades-Ego: Actor and Observer: Joint Modeling of First and Third-Person Videos (CVPR 2018)\", \"Paper Title\": \"Charades-Ego: Actor and Observer: Joint Modeling of First and Third-Person Videos (CVPR 2018)\", \"Paper URL\": \"https://arxiv.org/abs/1804.09627\", \"GitHub URL\": \"https://github.com/gsig/actor-observer\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/search?q_meta=&q_type=&q=Actor+and+Observer%3A+Joint+Modeling+of+First+and+Third-Person+Videos\", \"ArXiv URL\": \"https://arxiv.org/abs/1804.09627\", \"Semantic Scholar Corpus ID\": 4562167, \"Year Released\": \"2018\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://prior.allenai.org/projects/data/charades-ego/license.txt\"}], \"Creators\": [\"Allen Institute for AI\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 69.33, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"mpii-cooking\", \"Collection\": \"mpii-cooking\", \"Collection URL\": \"https://arxiv.org/abs/1502.06648\", \"Dataset Name\": \"MPII-Cooking: Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data (IJCV 2015)\", \"Paper Title\": \"MPII-Cooking: Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data (IJCV 2015)\", \"Paper URL\": \"https://arxiv.org/abs/1502.06648\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/recognizing-fine-grained-and-composite\", \"ArXiv URL\": \"https://arxiv.org/abs/1502.06648\", \"Semantic Scholar Corpus ID\": 14036544, \"Year Released\": \"2015\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/human-activity-recognition/mpii-cooking-activities-dataset\"}], \"Creators\": [\"Max Planck Institute for Informatics\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 27.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"egoschema\", \"Collection\": \"egoschema\", \"Collection URL\": \"https://arxiv.org/pdf/2308.09126\", \"Dataset Name\": \"EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding\", \"Paper Title\": \"EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding\", \"Paper URL\": \"https://arxiv.org/pdf/2308.09126\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egoschema-a-diagnostic-benchmark-for-very-1\", \"ArXiv URL\": \"https://arxiv.org/pdf/2308.09126\", \"Semantic Scholar Corpus ID\": 261031047, \"Year Released\": \"2024\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"UC Berkeley\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 250.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"kinetics-400\", \"Collection\": \"kinetics-400\", \"Collection URL\": \"https://arxiv.org/abs/1705.06950\", \"Dataset Name\": \"Kinetics 400\", \"Paper Title\": \"Kinetics 400\", \"Paper URL\": \"https://arxiv.org/abs/1705.06950\", \"GitHub URL\": \"https://github.com/cvdfoundation/kinetics-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/kinetics\", \"ArXiv URL\": \"https://arxiv.org/abs/1705.06950\", \"Semantic Scholar Corpus ID\": 27300853, \"Year Released\": \"2017\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"DeepMind\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 850.68, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mars\", \"Collection\": \"mars\", \"Collection URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Dataset Name\": \"Mars\", \"Paper Title\": \"Mars\", \"Paper URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mars\", \"ArXiv URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Semantic Scholar Corpus ID\": 2214158, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Microsoft\", \"Tsinghua University\", \"The University of Texas at San Antonio\", \"Peking University\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.24, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Segmentation\", \"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"haa500-dataset\", \"Collection\": \"haa500-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2009.05224\", \"Dataset Name\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper Title\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper URL\": \"https://arxiv.org/abs/2009.05224\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/haa500-human-centric-atomic-action-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.05224\", \"Semantic Scholar Corpus ID\": 221640805, \"Year Released\": \"2020\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Carnegie Mellon University\", \"The Hong Kong University of Science and Technology\", \"Princeton University\", \"Kuaishou Technology\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 5.48, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"project-aria-digital-twin-dataset\", \"Collection\": \"project-aria-digital-twin-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2306.06362\", \"Dataset Name\": \"Aria Digital Twin\", \"Paper Title\": \"Aria Digital Twin\", \"Paper URL\": \"https://arxiv.org/abs/2306.06362\", \"GitHub URL\": \"https://github.com/facebookresearch/projectaria_tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/aria-digital-twin-a-new-benchmark-dataset-for\", \"ArXiv URL\": \"https://arxiv.org/abs/2306.06362\", \"Semantic Scholar Corpus ID\": 261243365, \"Year Released\": \"2023\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/facebookresearch/projectaria_tools/blob/main/LICENSE\"}], \"Creators\": [\"Meta\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 6.6, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Object Detection\", \"Video Segmentation\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ego-4d\", \"Collection\": \"ego-4d\", \"Collection URL\": \"https://arxiv.org/abs/2110.07058\", \"Dataset Name\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper Title\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper URL\": \"https://arxiv.org/abs/2110.07058\", \"GitHub URL\": \"https://github.com/EGO4D/forecasting\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego4d-around-the-world-in-3000-hours-of\", \"ArXiv URL\": \"https://arxiv.org/abs/2110.07058\", \"Semantic Scholar Corpus ID\": 238856888, \"Year Released\": \"2022\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://ego4d-data.org/pdfs/Ego4D-Licenses-Draft.pdf\"}], \"Creators\": [\"Facebook AI Research\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3670.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\", \"Temporal Action Segmentation\", \"Video Captioning\", \"Misc\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"breakfast\", \"Collection\": \"breakfast\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"Dataset Name\": \"Breakfast\", \"Paper Title\": \"Breakfast\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/breakfast\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"Semantic Scholar Corpus ID\": 9621856, \"Year Released\": \"2014\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/breakfast-actions-dataset/\"}], \"Creators\": [\"Fraunhofer FKIE\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 77.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Captioning\", \"Action Segmentation\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ego-exo4D\", \"Collection\": \"ego-exo4D\", \"Collection URL\": \"https://arxiv.org/abs/2311.18259\", \"Dataset Name\": \"Ego-Exo4D\", \"Paper Title\": \"Ego-Exo4D\", \"Paper URL\": \"https://arxiv.org/abs/2311.18259\", \"GitHub URL\": \"https://github.com/facebookresearch/Ego4d\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego-exo4d-understanding-skilled-human/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2311.18259\", \"Semantic Scholar Corpus ID\": 265506384, \"Year Released\": \"2023\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/facebookresearch/Ego4d/blob/main/LICENSE\"}], \"Creators\": [\"Meta\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1422.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Pose Estimation\", \"Video Classification\", \"Video Captioning\", \"Misc\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"project-aria-dataset\", \"Collection\": \"project-aria-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/2402.13349\", \"Dataset Name\": \"Aria Everyday Activities Dataset\", \"Paper Title\": \"Aria Everyday Activities Dataset\", \"Paper URL\": \"https://arxiv.org/pdf/2402.13349\", \"GitHub URL\": \"https://github.com/facebookresearch/projectaria_tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/aria-everyday-activities-dataset\", \"ArXiv URL\": \"https://arxiv.org/pdf/2402.13349\", \"Semantic Scholar Corpus ID\": 267770215, \"Year Released\": \"2024\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/facebookresearch/Aria_data_tools/blob/main/LICENSE\"}], \"Creators\": [\"Meta\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1400.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Misc (Scene Reconstruction)\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"collective\", \"Collection\": \"collective\", \"Collection URL\": \"https://cvgl.stanford.edu/papers/Wongun_CollectiveActivityRecognition09.pdf\", \"Dataset Name\": \"Collective: What are they doing? : Collective activity classification using spatio-temporal relationship among people\", \"Paper Title\": \"Collective: What are they doing? : Collective activity classification using spatio-temporal relationship among people\", \"Paper URL\": \"https://cvgl.stanford.edu/papers/Wongun_CollectiveActivityRecognition09.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://cvgl.stanford.edu/papers/Wongun_CollectiveActivityRecognition09.pdf\", \"Semantic Scholar Corpus ID\": 5925915, \"Year Released\": \"2009\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Michigan\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.1, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Group Activity Recognition\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mmact\", \"Collection\": \"mmact\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Dataset Name\": \"MMAct\", \"Paper Title\": \"MMAct\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mmact\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Semantic Scholar Corpus ID\": 207980205, \"Year Released\": \"2019\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://mmact19.github.io/2019/\"}], \"Creators\": [\"The Hong Kong University of Science and Technology\", \"Alibaba Group\"], \"Countries\": [\"Hong Kong\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 100.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Temporal Localization\", \"Action Recognition\", \"Spatial-Temporal Action Localization\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"charades\", \"Collection\": \"charades\", \"Collection URL\": \"https://arxiv.org/abs/1604.01753\", \"Dataset Name\": \"Charades\", \"Paper Title\": \"Charades\", \"Paper URL\": \"https://arxiv.org/abs/1604.01753\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/charades\", \"ArXiv URL\": \"https://arxiv.org/abs/1604.01753\", \"Semantic Scholar Corpus ID\": 18061547, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades#licensing-information\"}], \"Creators\": [\"Carnegie Mellon University\", \"Inria\", \"University of Washington\", \"Allen Institute for AI\"], \"Countries\": [\"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 82.3, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"50salads\", \"Collection\": \"50salads\", \"Collection URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"Dataset Name\": \"50Salads\", \"Paper Title\": \"50Salads\", \"Paper URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/50-salads\", \"ArXiv URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"Semantic Scholar Corpus ID\": 2333743, \"Year Released\": \"2013\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://cvip.computing.dundee.ac.uk/datasets/foodpreparation/50salads/\"}], \"Creators\": [\"University of Dundee\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 40.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Action Segmentation\", \"Action Localization\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"epic-kitchenes\", \"Collection\": \"epic-kitchenes\", \"Collection URL\": \"https://arxiv.org/abs/1804.02748\", \"Dataset Name\": \"EPIC-KITCHENS\", \"Paper Title\": \"EPIC-KITCHENS\", \"Paper URL\": \"https://arxiv.org/abs/1804.02748\", \"GitHub URL\": \"https://github.com/epic-kitchens\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/epic-kitchens-100\", \"ArXiv URL\": \"https://arxiv.org/abs/1804.02748\", \"Semantic Scholar Corpus ID\": 4710439, \"Year Released\": \"2018\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://epic-kitchens.github.io/2024\"}], \"Creators\": [\"University of Toronto\", \"University of Bristol\", \"University of Catania\"], \"Countries\": [\"United Kingdom\", \"Canada\", \"Spain\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 100.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"toyota-smarthome\", \"Collection\": \"toyota-smarthome\", \"Collection URL\": \"https://openaccess.thecvf.com/content_ICCV_2019/papers/Das_Toyota_Smarthome_Real-World_Activities_of_Daily_Living_ICCV_2019_paper.pdf\", \"Dataset Name\": \"Toyota Smarthome: Real-World Activities of Daily Living (ICCV 2019)\", \"Paper Title\": \"Toyota Smarthome: Real-World Activities of Daily Living (ICCV 2019)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_ICCV_2019/papers/Das_Toyota_Smarthome_Real-World_Activities_of_Daily_Living_ICCV_2019_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_ICCV_2019/papers/Das_Toyota_Smarthome_Real-World_Activities_of_Daily_Living_ICCV_2019_paper.pdf\", \"Semantic Scholar Corpus ID\": 207971208, \"Year Released\": \"2019\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://project.inria.fr/toyotasmarthome/files/2020/12/License_v2.pdf\"}], \"Creators\": [\"Toyota\"], \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 268.58, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"vtw\", \"Collection\": \"vtw\", \"Collection URL\": \"https://arxiv.org/abs/1608.07068\", \"Dataset Name\": \"VTW\", \"Paper Title\": \"VTW\", \"Paper URL\": \"https://arxiv.org/abs/1608.07068\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/title-generation-for-user-generated-videos\", \"ArXiv URL\": \"https://arxiv.org/abs/1608.07068\", \"Semantic Scholar Corpus ID\": 6155397, \"Year Released\": \"2016\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Tsinghua University\", \"Stanford University\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 213.2, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"eev-dataset\", \"Collection\": \"eev-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2001.05488\", \"Dataset Name\": \"EEV: A Large-Scale Dataset for Studying Evoked Expressions from Video\", \"Paper Title\": \"EEV: A Large-Scale Dataset for Studying Evoked Expressions from Video\", \"Paper URL\": \"https://arxiv.org/abs/2001.05488\", \"GitHub URL\": \"https://github.com/google-research-datasets/eev\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/abs/2001.05488\", \"Semantic Scholar Corpus ID\": 210701992, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://github.com/google-research-datasets/eev?tab=readme-ov-file#license\"}], \"Creators\": [\"Google Research\", \"California Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 370.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"msr-vtt\", \"Collection\": \"msr-vtt\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7780940\", \"Dataset Name\": \"MSR-VTT\", \"Paper Title\": \"MSR-VTT\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7780940\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/msr-vtt\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7780940\", \"Semantic Scholar Corpus ID\": 206594535, \"Year Released\": \"2016\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Microsoft Research\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 41.2, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"davis\", \"Collection\": \"davis\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"Dataset Name\": \"Davis\", \"Paper Title\": \"Davis\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"GitHub URL\": \"https://github.com/fperazzi/davis\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-benchmark-dataset-and-evaluation\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"Semantic Scholar Corpus ID\": 3619941, \"Year Released\": \"2017\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/fperazzi/davis/blob/main/LICENSE\"}], \"Creators\": [\"ETH Z\\u00fcrich\", \"Disney Research\"], \"Countries\": [\"Switzerland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.04, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Segmentation\", \"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"rare-act-dataset\", \"Collection\": \"rare-act-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Dataset Name\": \"RareAct: A video dataset of unusual interactions\", \"Paper Title\": \"RareAct: A video dataset of unusual interactions\", \"Paper URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"GitHub URL\": \"https://github.com/antoine77340/RareAct\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/rareact\", \"ArXiv URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Semantic Scholar Corpus ID\": 220936243, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Oxford\", \"Ecole Normale Sup\\u00e9rieure\", \"Inria\", \"CIIRC\", \"Czech Technical University\"], \"Countries\": [\"United Kingdom\", \"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 21.13, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"multi-moments-in-time-dataset\", \"Collection\": \"multi-moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Dataset Name\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper Title\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Semantic Scholar Corpus ID\": 207780280, \"Year Released\": \"2021\", \"Text Sources\": [\"crowdsourced\", \"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"trecvid\", \"Collection\": \"trecvid\", \"Collection URL\": \"https://arxiv.org/abs/2009.09984\", \"Dataset Name\": \"TRECVID\", \"Paper Title\": \"TRECVID\", \"Paper URL\": \"https://arxiv.org/abs/2009.09984\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/trecvid-2019-an-evaluation-campaign-to/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.09984\", \"Semantic Scholar Corpus ID\": 212694843, \"Year Released\": \"2019\", \"Text Sources\": [\"undisclosed web\", \"bbc\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://trecvid.nist.gov/\"}], \"Creators\": [\"National Institute of Standards and Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1000.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\", \"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"ferv39k-dataset\", \"Collection\": \"ferv39k-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2203.09463\", \"Dataset Name\": \"FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos (CVPR 2022)\", \"Paper Title\": \"FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos (CVPR 2022)\", \"Paper URL\": \"https://arxiv.org/abs/2203.09463\", \"GitHub URL\": \"https://github.com/wangyanckxx/FERV39k\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ferv39k-a-large-scale-multi-scene-dataset-for\", \"ArXiv URL\": \"https://arxiv.org/abs/2203.09463\", \"Semantic Scholar Corpus ID\": 247518747, \"Year Released\": \"2022\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://wangyanckxx.github.io/Proj_CVPR2022_FERV39k.html\"}], \"Creators\": [\"Fudan University\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 16.47, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"mad\", \"Collection\": \"mad\", \"Collection URL\": \"https://arxiv.org/abs/2112.00431\", \"Dataset Name\": \"MAD: A Scalable Dataset for Language Grounding in Videos from Movie Audio Descriptions\", \"Paper Title\": \"MAD: A Scalable Dataset for Language Grounding in Videos from Movie Audio Descriptions\", \"Paper URL\": \"https://arxiv.org/abs/2112.00431\", \"GitHub URL\": \"https://github.com/Soldelli/MAD\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mad\", \"ArXiv URL\": \"https://arxiv.org/abs/2112.00431\", \"Semantic Scholar Corpus ID\": 244773187, \"Year Released\": \"2022\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdtUV3uweS0u7AHAMIJAL_dRRdZ5MHpJS3fdZVbhnVt-Yb4NA/viewform\"}], \"Creators\": [\"King Abdullah University of Science and Technology (KAUST)\"], \"Countries\": [\"Saudi Arabia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1207.3, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"activitynet\", \"Collection\": \"activitynet\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"Dataset Name\": \"ActivityNet\", \"Paper Title\": \"ActivityNet\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/Leyo/ActivityNet_Captions\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/activitynet\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"Semantic Scholar Corpus ID\": 1710722, \"Year Released\": \"2015\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/facebookresearch/ActivityNet-Entities/blob/main/LICENSE\"}], \"Creators\": [\"Universidad del Norte\", \"King Abdullah University of Science and Technology (KAUST)\"], \"Countries\": [\"Saudi Arabia\", \"Colombia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 849.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"imagenet-vid\", \"Collection\": \"imagenet-vid\", \"Collection URL\": \"https://link.springer.com/article/10.1007/s11263-015-0816-y?sa_campaign=email/event/articleAuthor/onlineFirst#\", \"Dataset Name\": \"ImageNet VID\", \"Paper Title\": \"ImageNet VID\", \"Paper URL\": \"https://link.springer.com/article/10.1007/s11263-015-0816-y?sa_campaign=email/event/articleAuthor/onlineFirst#\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/sota/video-object-detection-on-imagenet-vid\", \"ArXiv URL\": \"https://link.springer.com/article/10.1007/s11263-015-0816-y?sa_campaign=email/event/articleAuthor/onlineFirst#\", \"Semantic Scholar Corpus ID\": 2930547, \"Year Released\": \"2017\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://www.image-net.org/challenges/LSVRC/2017/index.php\"}], \"Creators\": [\"Stanford University\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 9.26, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"WebVid\", \"Collection\": \"WebVid\", \"Collection URL\": \"https://arxiv.org/abs/2104.00650\", \"Dataset Name\": \"WebVid\", \"Paper Title\": \"WebVid\", \"Paper URL\": \"https://arxiv.org/abs/2104.00650\", \"GitHub URL\": \"https://github.com/m-bain/webvid\", \"Hugging Face URL\": \"https://huggingface.co/datasets/TempoFunk/webvid-10M\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/webvid\", \"ArXiv URL\": \"https://arxiv.org/abs/2104.00650\", \"Semantic Scholar Corpus ID\": 232478955, \"Year Released\": \"2021\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/m-bain/webvid/blob/main/TERMS.md\"}], \"Creators\": [\"University of Oxford\", \"CNRS\"], \"Countries\": [\"United Kingdom\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13000.0, \"Taken Down\": \"True\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"finegym-dataset\", \"Collection\": \"finegym-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2004.06704\", \"Dataset Name\": \"FineGym: A Hierarchical Video Dataset for Fine-grained Action Understanding (CVPR 2020)\", \"Paper Title\": \"FineGym: A Hierarchical Video Dataset for Fine-grained Action Understanding (CVPR 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2004.06704\", \"GitHub URL\": \"https://github.com/SDOlivia/FineGym/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/finegym\", \"ArXiv URL\": \"https://arxiv.org/abs/2004.06704\", \"Semantic Scholar Corpus ID\": 215754360, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://sdolivia.github.io/FineGym/\"}], \"Creators\": [\"The Chinese University of Hong Kong\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 708.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"lsmdc\", \"Collection\": \"lsmdc\", \"Collection URL\": \"https://arxiv.org/pdf/1605.03705\", \"Dataset Name\": \"LSMDC\", \"Paper Title\": \"LSMDC\", \"Paper URL\": \"https://arxiv.org/pdf/1605.03705\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/movie-description\", \"ArXiv URL\": \"https://arxiv.org/pdf/1605.03705\", \"Semantic Scholar Corpus ID\": 18217052, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://datasets.d2.mpi-inf.mpg.de/movieDescription/protected/lsmdc2016/README.txt\"}], \"Creators\": [\"UC Berkeley\", \"Disney Research\", \"Universite de Montreal\", \"Polytechnique Montr\\u00e9al\", \"Universit\\u00e9 de Sherbrooke\", \"Twitter\"], \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Summarization\", \"Misc\", \"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"apes\", \"Collection\": \"apes\", \"Collection URL\": \"https://arxiv.org/pdf/2106.01667\", \"Dataset Name\": \"Apes\", \"Paper Title\": \"Apes\", \"Paper URL\": \"https://arxiv.org/pdf/2106.01667\", \"GitHub URL\": \"https://github.com/fuankarion/audiovisual-person-search\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/apes-audiovisual-person-search-in-untrimmed/review/\", \"ArXiv URL\": \"https://arxiv.org/pdf/2106.01667\", \"Semantic Scholar Corpus ID\": 235313698, \"Year Released\": \"2021\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Universidad de los Andes\", \"Adobe Research\", \"King Abdullah University of Science and Technology (KAUST)\"], \"Countries\": [\"Chile\", \"United States of America\", \"Saudi Arabia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 36.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"moviescenes\", \"Collection\": \"moviescenes\", \"Collection URL\": \"https://arxiv.org/abs/2004.02678\", \"Dataset Name\": \"MovieScenes\", \"Paper Title\": \"MovieScenes\", \"Paper URL\": \"https://arxiv.org/abs/2004.02678\", \"GitHub URL\": \"https://github.com/AnyiRao/SceneSeg\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-local-to-global-approach-to-multi-modal\", \"ArXiv URL\": \"https://arxiv.org/abs/2004.02678\", \"Semantic Scholar Corpus ID\": 214802984, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"The Chinese University of Hong Kong\", \"UC Berkeley\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 250.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Misc (Scene Segmentation)\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hollywood-extended\", \"Collection\": \"hollywood-extended\", \"Collection URL\": \"https://arxiv.org/pdf/1407.1208\", \"Dataset Name\": \"Hollywood Extended\", \"Paper Title\": \"Hollywood Extended\", \"Paper URL\": \"https://arxiv.org/pdf/1407.1208\", \"GitHub URL\": \"https://github.com/piotr-bojanowski/action-ordering\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/weakly-supervised-action-labeling-in-videos\", \"ArXiv URL\": \"https://arxiv.org/pdf/1407.1208\", \"Semantic Scholar Corpus ID\": 9342651, \"Year Released\": \"2014\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/piotr-bojanowski/action-ordering/blob/master/LICENSE\"}], \"Creators\": [\"Inria\"], \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 8.75, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Temporal Action Detection\", \"Action Recognition\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"msa\", \"Collection\": \"msa\", \"Collection URL\": \"https://arxiv.org/abs/1910.11009\", \"Dataset Name\": \"MSA\", \"Paper Title\": \"MSA\", \"Paper URL\": \"https://arxiv.org/abs/1910.11009\", \"GitHub URL\": \"https://github.com/ycxioooong/MovieSynopsisAssociation\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-graph-based-framework-to-bridge-movies-and-1\", \"ArXiv URL\": \"https://arxiv.org/abs/1910.11009\", \"Semantic Scholar Corpus ID\": 204852218, \"Year Released\": \"2019\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"The Chinese University of Hong Kong\", \"UC Berkeley\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 516.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"condensed-movies\", \"Collection\": \"condensed-movies\", \"Collection URL\": \"https://arxiv.org/pdf/2005.04208\", \"Dataset Name\": \"Condensed Movies\", \"Paper Title\": \"Condensed Movies\", \"Paper URL\": \"https://arxiv.org/pdf/2005.04208\", \"GitHub URL\": \"https://github.com/m-bain/CondensedMovies\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/condensed-movies\", \"ArXiv URL\": \"https://arxiv.org/pdf/2005.04208\", \"Semantic Scholar Corpus ID\": 218571391, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://www.robots.ox.ac.uk/~vgg/data/condensed-movies/#download\"}], \"Creators\": [\"University of Oxford\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1270.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"stroygraphs\", \"Collection\": \"stroygraphs\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/papers/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.pdf\", \"Dataset Name\": \"StoryGraphs\", \"Paper Title\": \"StoryGraphs\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/papers/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.pdf\", \"GitHub URL\": \"https://github.com/makarandtapaswi/StoryGraphs_CVPR2014\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/storygraphs-visualizing-character\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/papers/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.pdf\", \"Semantic Scholar Corpus ID\": 1055956, \"Year Released\": \"2014\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Karlsruhe Institute of Technology\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7.3, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Misc\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hollywood2-dataset\", \"Collection\": \"hollywood2-dataset\", \"Collection URL\": \"https://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf\", \"Dataset Name\": \"HOLLYWOOD2: Actions in Context (CVPR 2009)\", \"Paper Title\": \"HOLLYWOOD2: Actions in Context (CVPR 2009)\", \"Paper URL\": \"https://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf\", \"Semantic Scholar Corpus ID\": 3155054, \"Year Released\": \"2009\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Inria\"], \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 20.1, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"movieqa\", \"Collection\": \"movieqa\", \"Collection URL\": \"https://arxiv.org/abs/1512.02902\", \"Dataset Name\": \"MovieQA\", \"Paper Title\": \"MovieQA\", \"Paper URL\": \"https://arxiv.org/abs/1512.02902\", \"GitHub URL\": \"https://github.com/makarandtapaswi/MovieQA_CVPR2016/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/movieqa\", \"ArXiv URL\": \"https://arxiv.org/abs/1512.02902\", \"Semantic Scholar Corpus ID\": 1017389, \"Year Released\": \"2015\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"University of Toronto\"], \"Countries\": [\"Germany\", \"Canada\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 381.0, \"Taken Down\": \"True\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Question Answering\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"cinepile\", \"Collection\": \"cinepile\", \"Collection URL\": \"https://arxiv.org/pdf/2405.08813\", \"Dataset Name\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper Title\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper URL\": \"https://arxiv.org/pdf/2405.08813\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/tomg-group-umd/cinepile\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/cinepile\", \"ArXiv URL\": \"https://arxiv.org/pdf/2405.08813\", \"Semantic Scholar Corpus ID\": 269761335, \"Year Released\": \"2024\", \"Text Sources\": [\"youtube\", \"movies\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://creativecommons.org/licenses/by/4.0/\"}], \"Creators\": [\"University of Maryland\", \"Weizmann Institute of Science\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 417.6, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"movie-net\", \"Collection\": \"movie-net\", \"Collection URL\": \"https://arxiv.org/abs/2007.10937\", \"Dataset Name\": \"MovieNet\", \"Paper Title\": \"MovieNet\", \"Paper URL\": \"https://arxiv.org/abs/2007.10937\", \"GitHub URL\": \"https://github.com/movienet/movienet-tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/movienet\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.10937\", \"Semantic Scholar Corpus ID\": 220665753, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"The Chinese University of Hong Kong\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3000.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Summarization\", \"Misc\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"moviegraphs\", \"Collection\": \"moviegraphs\", \"Collection URL\": \"https://arxiv.org/pdf/1712.06761\", \"Dataset Name\": \"MovieGraphs\", \"Paper Title\": \"MovieGraphs\", \"Paper URL\": \"https://arxiv.org/pdf/1712.06761\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/moviegraphs\", \"ArXiv URL\": \"https://arxiv.org/pdf/1712.06761\", \"Semantic Scholar Corpus ID\": 4856028, \"Year Released\": \"2018\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moviegraphs.cs.toronto.edu/download.html\"}], \"Creators\": [\"Vector Institute for Artificial Intelligence\", \"Montreal Institute of Learning Algorithms (Mila)\", \"University of Toronto\"], \"Countries\": [\"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 93.9, \"Taken Down\": \"True\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Misc (video retrieval\", \"interaction understanding via ordering\", \"reason prediction)\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"lsmdc-ordering\", \"Collection\": \"lsmdc-ordering\", \"Collection URL\": \"https://arxiv.org/pdf/2004.02205\", \"Dataset Name\": \"LSMDC Ordering\", \"Paper Title\": \"LSMDC Ordering\", \"Paper URL\": \"https://arxiv.org/pdf/2004.02205\", \"GitHub URL\": \"https://github.com/vivoutlaw/TCBP\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/deep-multimodal-feature-encoding-for-video\", \"ArXiv URL\": \"https://arxiv.org/pdf/2004.02205\", \"Semantic Scholar Corpus ID\": 214802821, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/vivoutlaw/tcbp/blob/master/LICENSE\"}], \"Creators\": [\"University of Toronto\", \"Karlsruhe Institute of Technology\", \"Inria\", \"Massachusetts Institute of Technology\"], \"Countries\": [\"Germany\", \"Canada\", \"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"mpii-md\", \"Collection\": \"mpii-md\", \"Collection URL\": \"https://arxiv.org/pdf/1501.02530.pdf\", \"Dataset Name\": \"MPII-MD: A Dataset for Movie Description\", \"Paper Title\": \"MPII-MD: A Dataset for Movie Description\", \"Paper URL\": \"https://arxiv.org/pdf/1501.02530.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1501.02530.pdf\", \"Semantic Scholar Corpus ID\": 15184723, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Max Planck Institute for Informatics\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 56.5, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"cinepile\", \"Collection\": \"cinepile\", \"Collection URL\": \"https://arxiv.org/pdf/2405.08813\", \"Dataset Name\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper Title\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper URL\": \"https://arxiv.org/pdf/2405.08813\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/tomg-group-umd/cinepile\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/cinepile\", \"ArXiv URL\": \"https://arxiv.org/pdf/2405.08813\", \"Semantic Scholar Corpus ID\": 269761335, \"Year Released\": \"2024\", \"Text Sources\": [\"youtube\", \"movies\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://creativecommons.org/licenses/by/4.0/\"}], \"Creators\": [\"University of Maryland\", \"Weizmann Institute of Science\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 417.6, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"thumos-challenge\", \"Collection\": \"thumos-challenge\", \"Collection URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Dataset Name\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper Title\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/thumos14-1\", \"ArXiv URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Semantic Scholar Corpus ID\": 14049355, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLScs9davISAtYQS7SEF5qQNu0jUpLzNH3aHmPfuqk2q1VYDkmw/viewform\"}], \"Creators\": [\"Stanford University\", \"University of Central Florida\", \"Fudan University\", \"Inria\"], \"Countries\": [\"United States of America\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 254.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"vatex\", \"Collection\": \"vatex\", \"Collection URL\": \"https://arxiv.org/abs/1904.03493\", \"Dataset Name\": \"VaTeX\", \"Paper Title\": \"VaTeX\", \"Paper URL\": \"https://arxiv.org/abs/1904.03493\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/vatex\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/vatex\", \"ArXiv URL\": \"https://arxiv.org/abs/1904.03493\", \"Semantic Scholar Corpus ID\": 102352148, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://eric-xw.github.io/vatex-website/index.html\"}], \"Creators\": [\"ByteDance AI Lab\", \"UC Santa Barbara\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 114.58, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"how2\", \"Collection\": \"how2\", \"Collection URL\": \"https://arxiv.org/abs/1811.00347\", \"Dataset Name\": \"How2: A Large-scale Dataset for Multimodal Language Understanding (NeurIPS 2018)\", \"Paper Title\": \"How2: A Large-scale Dataset for Multimodal Language Understanding (NeurIPS 2018)\", \"Paper URL\": \"https://arxiv.org/abs/1811.00347\", \"GitHub URL\": \"https://github.com/srvk/how2-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/abs/1811.00347\", \"Semantic Scholar Corpus ID\": 53186236, \"Year Released\": \"2018\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Various\", \"License URL\": \"https://github.com/srvk/how2-dataset?tab=readme-ov-file#how2-license\"}], \"Creators\": [\"Carnegie Mellon University\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 2300.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"ucf101-dataset\", \"Collection\": \"ucf101-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1212.0402\", \"Dataset Name\": \"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\", \"Paper Title\": \"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\", \"Paper URL\": \"https://arxiv.org/abs/1212.0402\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/ucf101\", \"ArXiv URL\": \"https://arxiv.org/abs/1212.0402\", \"Semantic Scholar Corpus ID\": 7197134, \"Year Released\": \"2012\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Central Florida\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 26.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"narrated-instruction-vids\", \"Collection\": \"narrated-instruction-vids\", \"Collection URL\": \"https://arxiv.org/abs/1506.09215\", \"Dataset Name\": \"Narrated Instruction Videos\", \"Paper Title\": \"Narrated Instruction Videos\", \"Paper URL\": \"https://arxiv.org/abs/1506.09215\", \"GitHub URL\": \"https://github.com/jalayrac/instructionVideos\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youtube-inria-instructional\", \"ArXiv URL\": \"https://arxiv.org/abs/1506.09215\", \"Semantic Scholar Corpus ID\": 2617244, \"Year Released\": \"2016\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/jalayrac/instructionVideos?tab=readme-ov-file#license\"}], \"Creators\": [\"CNRS\", \"Ecole Normale Sup\\u00e9rieure\", \"Inria\", \"International Institute of Information Technology - Hyderabad\"], \"Countries\": [\"United States of America\", \"India\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"YT-Temporal-180m\", \"Collection\": \"YT-Temporal-180m\", \"Collection URL\": \"https://arxiv.org/pdf/2106.02636\", \"Dataset Name\": \"MERLOT: Multimodal Neural Script Knowledge Models\", \"Paper Title\": \"MERLOT: Multimodal Neural Script Knowledge Models\", \"Paper URL\": \"https://arxiv.org/pdf/2106.02636\", \"GitHub URL\": \"https://github.com/rowanz/merlot\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/yttemporal180m\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/merlot-multimodal-neural-script-knowledge\", \"ArXiv URL\": \"https://arxiv.org/pdf/2106.02636\", \"Semantic Scholar Corpus ID\": 235352775, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/rowanz/merlot/blob/main/LICENSE\"}], \"Creators\": [\"University of Washington\", \"Allen Institute for AI\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1515.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"multi-thumos-challenge\", \"Collection\": \"multi-thumos-challenge\", \"Collection URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"Dataset Name\": \"MultiTHUMOS: Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos (IJCV 2017)\", \"Paper Title\": \"MultiTHUMOS: Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos (IJCV 2017)\", \"Paper URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/multithumos\", \"ArXiv URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"Semantic Scholar Corpus ID\": 3337929, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://ai.stanford.edu/~syyeung/resources/multithumos.zip\"}], \"Creators\": [\"Stanford University\", \"Carnegie Mellon University\", \"Simon Fraser University\"], \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 30.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"youcook-2\", \"Collection\": \"youcook-2\", \"Collection URL\": \"https://arxiv.org/abs/1703.09788\", \"Dataset Name\": \"YouCook2\", \"Paper Title\": \"YouCook2\", \"Paper URL\": \"https://arxiv.org/abs/1703.09788\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youcook2\", \"ArXiv URL\": \"https://arxiv.org/abs/1703.09788\", \"Semantic Scholar Corpus ID\": 19713015, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"http://youcook2.eecs.umich.edu/static/YouCookII/LICENSE_YOUCOOK2.txt\"}], \"Creators\": [\"University of Rochester\", \"University of Michigan\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 175.6, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"videolt-dataset\", \"Collection\": \"videolt-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2105.02668\", \"Dataset Name\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper Title\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper URL\": \"https://arxiv.org/abs/2105.02668\", \"GitHub URL\": \"https://github.com/17Skye17/VideoLT\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/videolt\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.02668\", \"Semantic Scholar Corpus ID\": 233864776, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Non Commercial\", \"License URL\": \"https://github.com/17Skye17/VideoLT?tab=readme-ov-file#data-preparation\"}], \"Creators\": [\"Fudan University\", \"Shanghai Collaborative Innovation Center of Intelligent Visual Computing\", \"Inception Institute of Artificial Intelligence\", \"University of Maryland\"], \"Countries\": [\"China\", \"UAE\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13664.96, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"vlog-vids\", \"Collection\": \"vlog-vids\", \"Collection URL\": \"https://arxiv.org/abs/1712.02310\", \"Dataset Name\": \"VLOG: From Lifestyle Vlogs to Everyday Interactions (CVPR 2018)\", \"Paper Title\": \"VLOG: From Lifestyle Vlogs to Everyday Interactions (CVPR 2018)\", \"Paper URL\": \"https://arxiv.org/abs/1712.02310\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/vlog-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/1712.02310\", \"Semantic Scholar Corpus ID\": 22264672, \"Year Released\": \"2018\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://web.eecs.umich.edu/~fouhey/2017/VLOG/index.html\"}], \"Creators\": [\"UC Berkeley\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 336.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"ava\", \"Collection\": \"ava\", \"Collection URL\": \"https://arxiv.org/pdf/1705.08421\", \"Dataset Name\": \"AVA\", \"Paper Title\": \"AVA\", \"Paper URL\": \"https://arxiv.org/pdf/1705.08421\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ava-a-video-dataset-of-spatio-temporally\", \"ArXiv URL\": \"https://arxiv.org/pdf/1705.08421\", \"Semantic Scholar Corpus ID\": 688013, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://research.google.com/ava/\"}], \"Creators\": [\"Google Research\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 107.5, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Temporal Localization\", \"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"tvsum\", \"Collection\": \"tvsum\", \"Collection URL\": \"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\", \"Dataset Name\": \"TVSum: Summarizing web videos using titles (CVPR 2015)\", \"Paper Title\": \"TVSum: Summarizing web videos using titles (CVPR 2015)\", \"Paper URL\": \"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\", \"GitHub URL\": \"https://github.com/yalesong/tvsum\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tvsum-1\", \"ArXiv URL\": \"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\", \"Semantic Scholar Corpus ID\": 7675635, \"Year Released\": \"2015\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 3.0\", \"License URL\": \"https://github.com/yalesong/tvsum\"}], \"Creators\": [\"Yahoo Labs\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3.5, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"YT-Temporal-1B\", \"Collection\": \"YT-Temporal-1B\", \"Collection URL\": \"https://arxiv.org/pdf/2201.02639\", \"Dataset Name\": \"MERLOT Reserve: Multimodal Neural Script Knowledge through Vision and Language and Sound\", \"Paper Title\": \"MERLOT Reserve: Multimodal Neural Script Knowledge through Vision and Language and Sound\", \"Paper URL\": \"https://arxiv.org/pdf/2201.02639\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/merlot-reserve-neural-script-knowledge\", \"ArXiv URL\": \"https://arxiv.org/pdf/2201.02639\", \"Semantic Scholar Corpus ID\": 245837609, \"Year Released\": \"2022\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/rowanz/merlot_reserve/blob/main/LICENSE\"}], \"Creators\": [\"University of Washington\", \"Allen Institute for AI\", \"University of Edinburgh\"], \"Countries\": [\"United States of America\", \"Scotland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 55555.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"omnisource-web-dataset\", \"Collection\": \"omnisource-web-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2003.13042\", \"Dataset Name\": \"OmniSource Web Dataset\", \"Paper Title\": \"OmniSource Web Dataset\", \"Paper URL\": \"https://arxiv.org/abs/2003.13042\", \"GitHub URL\": \"https://github.com/open-mmlab/mmaction\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/omni-sourced-webly-supervised-learning-for#code\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.13042\", \"Semantic Scholar Corpus ID\": 214714240, \"Year Released\": \"2020\", \"Text Sources\": [\"google videos\", \"instagram\", \"youtube\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/open-mmlab/mmaction?tab=readme-ov-file#license\"}], \"Creators\": [\"The Chinese University of Hong Kong\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13333.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"sports1M-dataset\", \"Collection\": \"sports1M-dataset\", \"Collection URL\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\", \"Dataset Name\": \"Sports-1M: Large-scale Video Classification with Convolutional Neural Networks\", \"Paper Title\": \"Sports-1M: Large-scale Video Classification with Convolutional Neural Networks\", \"Paper URL\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\", \"GitHub URL\": \"https://github.com/gtoderici/sports-1m-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/large-scale-video-classification-with-1\", \"ArXiv URL\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\", \"Semantic Scholar Corpus ID\": 206592218, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 3.0\", \"License URL\": \"https://github.com/gtoderici/sports-1m-dataset\"}], \"Creators\": [\"Stanford University\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 105761.41, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"kinetics-600\", \"Collection\": \"kinetics-600\", \"Collection URL\": \"https://arxiv.org/abs/1808.01340\", \"Dataset Name\": \"Kinetics 600\", \"Paper Title\": \"Kinetics 600\", \"Paper URL\": \"https://arxiv.org/abs/1808.01340\", \"GitHub URL\": \"https://github.com/cvdfoundation/kinetics-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/kinetics-600\", \"ArXiv URL\": \"https://arxiv.org/abs/1808.01340\", \"Semantic Scholar Corpus ID\": 51927456, \"Year Released\": \"2018\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"DeepMind\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1376.52, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"100doh\", \"Collection\": \"100doh\", \"Collection URL\": \"https://arxiv.org/abs/2006.06669\", \"Dataset Name\": \"100DOH: Understanding Human Hands in Contact at Internet Scale (CVPR 2020)\", \"Paper Title\": \"100DOH: Understanding Human Hands in Contact at Internet Scale (CVPR 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2006.06669\", \"GitHub URL\": \"https://github.com/ddshan/hand_object_detector\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/understanding-human-hands-in-contact-at-1\", \"ArXiv URL\": \"https://arxiv.org/abs/2006.06669\", \"Semantic Scholar Corpus ID\": 215413188, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://fouheylab.eecs.umich.edu/~dandans/projects/100DOH/download.html\"}], \"Creators\": [\"University of Michigan\", \"Johns Hopkins University\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 4577.3, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Misc (Hand/Object Detection)\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"queryd\", \"Collection\": \"queryd\", \"Collection URL\": \"https://arxiv.org/abs/2011.11071\", \"Dataset Name\": \"QuerYD\", \"Paper Title\": \"QuerYD\", \"Paper URL\": \"https://arxiv.org/abs/2011.11071\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/queryd\", \"ArXiv URL\": \"https://arxiv.org/abs/2011.11071\", \"Semantic Scholar Corpus ID\": 261006321, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"youdescribe\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Oxford\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 207.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"violin\", \"Collection\": \"violin\", \"Collection URL\": \"https://arxiv.org/abs/2003.11618\", \"Dataset Name\": \"VIOLIN\", \"Paper Title\": \"VIOLIN\", \"Paper URL\": \"https://arxiv.org/abs/2003.11618\", \"GitHub URL\": \"https://github.com/jimmy646/violin\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/violin\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.11618\", \"Semantic Scholar Corpus ID\": 214668012, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Microsoft\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 582.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"kinetics-700\", \"Collection\": \"kinetics-700\", \"Collection URL\": \"https://arxiv.org/pdf/2010.10864.pdf\", \"Dataset Name\": \"Kinetics-700\", \"Paper Title\": \"Kinetics-700\", \"Paper URL\": \"https://arxiv.org/pdf/2010.10864.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/kinetics-700\", \"ArXiv URL\": \"https://arxiv.org/pdf/2010.10864.pdf\", \"Semantic Scholar Corpus ID\": 196831809, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"DeepMind\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1805.56, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask\", \"Paper Title\": \"CrossTask\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Middle East Technical University\", \"Inria\", \"PSL University - Universit\\u00e9 PSL\", \"University of Michigan\", \"CIIRC\"], \"Countries\": [\"Czech Republic\", \"France\", \"Turkey\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hacs-dataset\", \"Collection\": \"hacs-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1712.09374\", \"Dataset Name\": \"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\", \"Paper Title\": \"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\", \"Paper URL\": \"https://arxiv.org/abs/1712.09374\", \"GitHub URL\": \"https://github.com/hangzhaomit/HACS-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hacs\", \"ArXiv URL\": \"https://arxiv.org/abs/1712.09374\", \"Semantic Scholar Corpus ID\": 68049510, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/hangzhaomit/HACS-dataset?tab=readme-ov-file#request-testing-videos-and-missing-videos-new\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"Dartmouth University\", \"UIUC\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hd-vila-100m\", \"Collection\": \"hd-vila-100m\", \"Collection URL\": \"https://arxiv.org/abs/2111.10337\", \"Dataset Name\": \"Advancing High-Resolution Video-Language Representation with Large-Scale Video Transcriptions\", \"Paper Title\": \"Advancing High-Resolution Video-Language Representation with Large-Scale Video Transcriptions\", \"Paper URL\": \"https://arxiv.org/abs/2111.10337\", \"GitHub URL\": \"https://github.com/microsoft/XPretrain/blob/main/hd-vila-100m/README.md\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/advancing-high-resolution-video-language/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2111.10337\", \"Semantic Scholar Corpus ID\": 244462849, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/microsoft/XPretrain/blob/main/hd-vila-100m/README.md\"}], \"Creators\": [\"Microsoft\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 371.5, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"oops-dataset\", \"Collection\": \"oops-dataset\", \"Collection URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Epstein_Oops_Predicting_Unintentional_Action_in_Video_CVPR_2020_paper.pdf\", \"Dataset Name\": \"Oops!: Predicting Unintentional Action in Video (CVPR 2020)\", \"Paper Title\": \"Oops!: Predicting Unintentional Action in Video (CVPR 2020)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Epstein_Oops_Predicting_Unintentional_Action_in_Video_CVPR_2020_paper.pdf\", \"GitHub URL\": \"https://github.com/cvlab-columbia/oops\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/oops-predicting-unintentional-action-in-video\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Epstein_Oops_Predicting_Unintentional_Action_in_Video_CVPR_2020_paper.pdf\", \"Semantic Scholar Corpus ID\": 208291335, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://oops.cs.columbia.edu/data/\"}], \"Creators\": [\"Columbia University\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 50.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"youtube-8m\", \"Collection\": \"youtube-8m\", \"Collection URL\": \"https://arxiv.org/abs/1609.08675\", \"Dataset Name\": \"Youtube-8M: A Large-Scale Video Classification Benchmark\", \"Paper Title\": \"Youtube-8M: A Large-Scale Video Classification Benchmark\", \"Paper URL\": \"https://arxiv.org/abs/1609.08675\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youtube-8m\", \"ArXiv URL\": \"https://arxiv.org/abs/1609.08675\", \"Semantic Scholar Corpus ID\": 11241677, \"Year Released\": \"2016\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Google Research\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 350000.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"voxceleb\", \"Collection\": \"voxceleb\", \"Collection URL\": \"https://arxiv.org/abs/1706.08612\", \"Dataset Name\": \"VoxCeleb\", \"Paper Title\": \"VoxCeleb\", \"Paper URL\": \"https://arxiv.org/abs/1706.08612\", \"GitHub URL\": \"https://github.com/a-nagrani/VGGVox\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://cs.paperswithcode.com/paper/voxceleb-a-large-scale-speaker-identification\", \"ArXiv URL\": \"https://arxiv.org/abs/1706.08612\", \"Semantic Scholar Corpus ID\": 10475843, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/\"}], \"Creators\": [\"University of Oxford\"], \"Countries\": [\"United Kingdom\", \"South Korea\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 2000.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"coin-dataset\", \"Collection\": \"coin-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1903.02874\", \"Dataset Name\": \"COIN: A Large-scale Dataset for Comprehensive Instructional Video Analysis (CVPR 2019)\", \"Paper Title\": \"COIN: A Large-scale Dataset for Comprehensive Instructional Video Analysis (CVPR 2019)\", \"Paper URL\": \"https://arxiv.org/abs/1903.02874\", \"GitHub URL\": \"https://github.com/coin-dataset/annotations\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/coin#:~:text=The%20COIN%20dataset%20(a%20large,are%20all%20collected%20from%20YouTube.\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.02874\", \"Semantic Scholar Corpus ID\": 71147568, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/coin-dataset/annotations?tab=readme-ov-file#license\"}], \"Creators\": [\"Tsinghua University\", \"Meitu Inc.\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 476.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"howto100m\", \"Collection\": \"howto100m\", \"Collection URL\": \"https://arxiv.org/abs/1906.03327\", \"Dataset Name\": \"HowTo100M\", \"Paper Title\": \"HowTo100M\", \"Paper URL\": \"https://arxiv.org/abs/1906.03327\", \"GitHub URL\": \"https://github.com/antoine77340/howto100m\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/howto100m\", \"ArXiv URL\": \"https://arxiv.org/abs/1906.03327\", \"Semantic Scholar Corpus ID\": 182952863, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Ecole Normale Sup\\u00e9rieure\", \"Inria\", \"CIIRC\", \"Czech Technical University\"], \"Countries\": [\"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 134472.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper Title\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Ecole Normale Sup\\u00e9rieure\", \"Inria\", \"CIIRC\", \"Czech Technical University\", \"University of Michigan\"], \"Countries\": [\"France\", \"Turkey\", \"United States of America\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Temporal Action Localization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hyu-vids\", \"Collection\": \"hyu-vids\", \"Collection URL\": \"https://arxiv.org/abs/1904.11451\", \"Dataset Name\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper Title\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/1904.11451\", \"GitHub URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/holistic-large-scale-video-understanding\", \"ArXiv URL\": \"https://arxiv.org/abs/1904.11451\", \"Semantic Scholar Corpus ID\": 131777079, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"ETH Z\\u00fcrich\", \"KU Leuven\", \"University of Bonn\", \"Sensifai\"], \"Countries\": [\"Switzerland\", \"Belgium\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 96166.67, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"videostory\", \"Collection\": \"videostory\", \"Collection URL\": \"https://isis-data.science.uva.nl/cgmsnoek/pub/habibian-videostory-mm2014.pdf\", \"Dataset Name\": \"VideoStory: A New Multimedia Embedding for Few-Example Recognition and Translation of Events\", \"Paper Title\": \"VideoStory: A New Multimedia Embedding for Few-Example Recognition and Translation of Events\", \"Paper URL\": \"https://isis-data.science.uva.nl/cgmsnoek/pub/habibian-videostory-mm2014.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://isis-data.science.uva.nl/cgmsnoek/pub/habibian-videostory-mm2014.pdf\", \"Semantic Scholar Corpus ID\": 28203, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Amsterdam\"], \"Countries\": [\"Netherlands\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 743.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mimetics-dataset\", \"Collection\": \"mimetics-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1912.07249\", \"Dataset Name\": \"Mimetics: Towards Understanding Human Actions Out of Context\", \"Paper Title\": \"Mimetics: Towards Understanding Human Actions Out of Context\", \"Paper URL\": \"https://arxiv.org/abs/1912.07249\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/mimetics-towards-understanding-human-actions\", \"ArXiv URL\": \"https://arxiv.org/abs/1912.07249\", \"Semantic Scholar Corpus ID\": 209376248, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Naver\"], \"Countries\": [\"South Korea\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.99, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"volleyball-vids\", \"Collection\": \"volleyball-vids\", \"Collection URL\": \"https://arxiv.org/abs/1511.06040\", \"Dataset Name\": \"Volleyball: A Hierarchical Deep Temporal Model for Group Activity Recognition\", \"Paper Title\": \"Volleyball: A Hierarchical Deep Temporal Model for Group Activity Recognition\", \"Paper URL\": \"https://arxiv.org/abs/1511.06040\", \"GitHub URL\": \"https://github.com/mostafa-saad/deep-activity-rec#dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/volleyball\", \"ArXiv URL\": \"https://arxiv.org/abs/1511.06040\", \"Semantic Scholar Corpus ID\": 8483403, \"Year Released\": \"2015\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Simon Fraser University\"], \"Countries\": [\"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.1, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Group Activity Recognition\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"youcook\", \"Collection\": \"youcook\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2013/papers/Das_A_Thousand_Frames_2013_CVPR_paper.pdf\", \"Dataset Name\": \"YouCook: A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching (CVPR 2013)\", \"Paper Title\": \"YouCook: A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching (CVPR 2013)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2013/papers/Das_A_Thousand_Frames_2013_CVPR_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youcook\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2013/papers/Das_A_Thousand_Frames_2013_CVPR_paper.pdf\", \"Semantic Scholar Corpus ID\": 12284555, \"Year Released\": \"2013\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University at Buffalo\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1000.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"egopet\", \"Collection\": \"egopet\", \"Collection URL\": \"https://arxiv.org/pdf/2404.09991\", \"Dataset Name\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper Title\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper URL\": \"https://arxiv.org/pdf/2404.09991\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egopet-egomotion-and-interaction-data-from-an\", \"ArXiv URL\": \"https://arxiv.org/pdf/2404.09991\", \"Semantic Scholar Corpus ID\": 269148727, \"Year Released\": \"2024\", \"Text Sources\": [\"tiktok\", \"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://github.com/DannyTran123/egopet/blob/main/LICENSE\"}], \"Creators\": [\"Tel Aviv University\", \"UC Berkeley\", \"New York University\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 84.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Misc (Locomotion Prediction\", \"Visual Interaction Prediction\", \"Vision to Proprioception Prediction)\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"metacafe\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"metacafe\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"vine\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"vine\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"tgif\", \"Collection\": \"tgif\", \"Collection URL\": \"https://arxiv.org/abs/1604.02748\", \"Dataset Name\": \"TGIF\", \"Paper Title\": \"TGIF\", \"Paper URL\": \"https://arxiv.org/abs/1604.02748\", \"GitHub URL\": \"https://github.com/raingo/TGIF-Release\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/TGIF\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tgif\", \"ArXiv URL\": \"https://arxiv.org/abs/1604.02748\", \"Semantic Scholar Corpus ID\": 6262415, \"Year Released\": \"2016\", \"Text Sources\": [\"tumblr\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/raingo/TGIF-Release\"}], \"Creators\": [\"University of Rochester\", \"Yahoo! Inc.\", \"AiCure\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 86.1, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"ava-dataset\", \"Collection\": \"ava-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1901.01342\", \"Dataset Name\": \"AVA Active Speaker\", \"Paper Title\": \"AVA Active Speaker\", \"Paper URL\": \"https://arxiv.org/abs/1901.01342\", \"GitHub URL\": \"https://github.com/cvdfoundation/ava-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/ava-activespeaker\", \"ArXiv URL\": \"https://arxiv.org/abs/1901.01342\", \"Semantic Scholar Corpus ID\": 216211909, \"Year Released\": \"2019\", \"Text Sources\": [\"Not Prohibited\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://research.google.com/ava/download.html#ava_active_speaker_download\"}], \"Creators\": [\"Google Research\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 38.5, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"omnisource-web-dataset\", \"Collection\": \"omnisource-web-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2003.13042\", \"Dataset Name\": \"OmniSource Web Dataset\", \"Paper Title\": \"OmniSource Web Dataset\", \"Paper URL\": \"https://arxiv.org/abs/2003.13042\", \"GitHub URL\": \"https://github.com/open-mmlab/mmaction\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/omni-sourced-webly-supervised-learning-for#code\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.13042\", \"Semantic Scholar Corpus ID\": 214714240, \"Year Released\": \"2020\", \"Text Sources\": [\"google videos\", \"instagram\", \"youtube\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/open-mmlab/mmaction?tab=readme-ov-file#license\"}], \"Creators\": [\"The Chinese University of Hong Kong\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13333.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"omnisource-web-dataset\", \"Collection\": \"omnisource-web-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2003.13042\", \"Dataset Name\": \"OmniSource Web Dataset\", \"Paper Title\": \"OmniSource Web Dataset\", \"Paper URL\": \"https://arxiv.org/abs/2003.13042\", \"GitHub URL\": \"https://github.com/open-mmlab/mmaction\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/omni-sourced-webly-supervised-learning-for#code\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.13042\", \"Semantic Scholar Corpus ID\": 214714240, \"Year Released\": \"2020\", \"Text Sources\": [\"google videos\", \"instagram\", \"youtube\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/open-mmlab/mmaction?tab=readme-ov-file#license\"}], \"Creators\": [\"The Chinese University of Hong Kong\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13333.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"egopet\", \"Collection\": \"egopet\", \"Collection URL\": \"https://arxiv.org/pdf/2404.09991\", \"Dataset Name\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper Title\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper URL\": \"https://arxiv.org/pdf/2404.09991\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egopet-egomotion-and-interaction-data-from-an\", \"ArXiv URL\": \"https://arxiv.org/pdf/2404.09991\", \"Semantic Scholar Corpus ID\": 269148727, \"Year Released\": \"2024\", \"Text Sources\": [\"tiktok\", \"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://github.com/DannyTran123/egopet/blob/main/LICENSE\"}], \"Creators\": [\"Tel Aviv University\", \"UC Berkeley\", \"New York University\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 84.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Misc (Locomotion Prediction\", \"Visual Interaction Prediction\", \"Vision to Proprioception Prediction)\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"soa-dataset\", \"Collection\": \"soa-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1904.11451\", \"Dataset Name\": \"Scenes-objects-actions: A multi-task, multi-label video dataset\", \"Paper Title\": \"Scenes-objects-actions: A multi-task, multi-label video dataset\", \"Paper URL\": \"https://arxiv.org/pdf/1904.11451\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/scenes-objects-actions-a-multi-task-multi\", \"ArXiv URL\": \"https://arxiv.org/pdf/1904.11451\", \"Semantic Scholar Corpus ID\": 52968009, \"Year Released\": \"2018\", \"Text Sources\": [\"facebook\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Meta\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1561.1, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"trecvid\", \"Collection\": \"trecvid\", \"Collection URL\": \"https://arxiv.org/abs/2009.09984\", \"Dataset Name\": \"TRECVID\", \"Paper Title\": \"TRECVID\", \"Paper URL\": \"https://arxiv.org/abs/2009.09984\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/trecvid-2019-an-evaluation-campaign-to/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.09984\", \"Semantic Scholar Corpus ID\": 212694843, \"Year Released\": \"2019\", \"Text Sources\": [\"undisclosed web\", \"bbc\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://trecvid.nist.gov/\"}], \"Creators\": [\"National Institute of Standards and Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1000.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\", \"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"queryd\", \"Collection\": \"queryd\", \"Collection URL\": \"https://arxiv.org/abs/2011.11071\", \"Dataset Name\": \"QuerYD\", \"Paper Title\": \"QuerYD\", \"Paper URL\": \"https://arxiv.org/abs/2011.11071\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/queryd\", \"ArXiv URL\": \"https://arxiv.org/abs/2011.11071\", \"Semantic Scholar Corpus ID\": 261006321, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"youdescribe\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Oxford\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 207.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"flickr\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"didemo\", \"Collection\": \"didemo\", \"Collection URL\": \"https://paperswithcode.com/dataset/didemo\", \"Dataset Name\": \"DiDeMo: Localizing Moments in Video with Temporal Language (EMNLP 2018)\", \"Paper Title\": \"DiDeMo: Localizing Moments in Video with Temporal Language (EMNLP 2018)\", \"Paper URL\": \"https://paperswithcode.com/dataset/didemo\", \"GitHub URL\": \"https://github.com/LisaAnne/TemporalLanguageRelease\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://paperswithcode.com/dataset/didemo\", \"Semantic Scholar Corpus ID\": 52164739, \"Year Released\": \"2018\", \"Text Sources\": [\"flickr\"], \"Licenses\": [{\"License\": \"BSD 2-Clause License\", \"License URL\": \"https://github.com/LisaAnne/TemporalLanguageRelease\"}], \"Creators\": [\"UC Berkeley\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 275.0, \"Taken Down\": \"False\", \"Video Sources\": \"flickr\", \"Task Categories\": [\"Temporal Action Localization\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"flickr\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = alt.Chart(df_videosourcelicences).mark_bar().encode(\n",
    "    x=alt.X(\n",
    "        \"Video Sources:N\",\n",
    "        title=\"Video Sources\",\n",
    "        sort=videosources_order,\n",
    "        axis=alt.Axis(labelAngle=-30)\n",
    "    ),\n",
    "    y=alt.Y(\n",
    "        \"count():Q\",\n",
    "        stack=\"normalize\",\n",
    "        axis=alt.Axis(format=\"%\"),\n",
    "        title=\"Pct. Datasets\"\n",
    "    ),\n",
    "    color=alt.Color(\n",
    "        \"License Type:N\",\n",
    "        scale=alt.Scale(\n",
    "            domain=LICENSE_ORDER,\n",
    "            range=LICENSE_PALETTE\n",
    "        ),\n",
    "        title=\"License Type\"\n",
    "    )\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=100\n",
    ")\n",
    "\n",
    "text = alt.Chart(df_videosourcelicences).mark_text(\n",
    "    dy=-68,\n",
    "    align=\"center\",\n",
    "    baseline=\"top\",\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    x=alt.X(\n",
    "        \"Video Sources:N\",\n",
    "        title=\"Video Sources\",\n",
    "        sort=videosources_order\n",
    "    ),\n",
    "    text=\"count():Q\"\n",
    ")\n",
    "\n",
    "chart = (base + text).configure_axis(\n",
    "    labelFontSize=FONT_SIZE,\n",
    "    titleFontSize=FONT_SIZE\n",
    ").configure_legend(\n",
    "    labelFontSize=FONT_SIZE,\n",
    "    titleFontSize=FONT_SIZE,\n",
    "    orient=LEGEND_POSITION,\n",
    "    labelLimit=MAX_LABELLIMIT\n",
    ")\n",
    "\n",
    "if PLOT_TOFILE:\n",
    "    chart.save(\n",
    "        os.path.join(PLOT_DIR, \"video_sources-licenses.png\"),\n",
    "        ppi=PLOT_PPI\n",
    "    )\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Category by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     2009\n",
       "3     2009\n",
       "68    2011\n",
       "68    2011\n",
       "68    2011\n",
       "Name: Year Released, dtype: category\n",
       "Categories (22, object): ['<2004' < '2004' < '2005' < '2006' ... '2021' < '2022' < '2023' < '2024']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INCLUDE_TOP_N_CATEGORIES = 6\n",
    "df_videosourceyears = df_video.explode(\"Video Sources\")\n",
    "df_videosourceyears = reduce_categories_to_topk(df_videosourceyears, \"Video Sources\", INCLUDE_TOP_N_CATEGORIES)\n",
    "\n",
    "df_videosourceyears = df_videosourceyears.sort_values(by=\"Year Released\")\n",
    "df_videosourceyears.head()['Year Released']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-fc21cdf2e9a546399fb4086c443a3467.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-fc21cdf2e9a546399fb4086c443a3467.vega-embed details,\n",
       "  #altair-viz-fc21cdf2e9a546399fb4086c443a3467.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-fc21cdf2e9a546399fb4086c443a3467\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-fc21cdf2e9a546399fb4086c443a3467\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-fc21cdf2e9a546399fb4086c443a3467\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"Times New Roman\"}, \"axis\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\", \"labelFontSize\": 20, \"titleFontSize\": 20}, \"header\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\"}, \"legend\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\", \"columns\": 4, \"labelFontSize\": 20, \"labelLimit\": 1000, \"orient\": \"bottom\", \"titleFontSize\": 20}, \"text\": {\"font\": \"Times New Roman\"}}, \"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"Video Sources\", \"title\": \"Video Sources\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30}, \"field\": \"Year Released\", \"sort\": [\"<2004\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"], \"title\": \"Year Released\", \"type\": \"nominal\"}, \"y\": {\"aggregate\": \"count\", \"axis\": {\"format\": \"%\"}, \"stack\": \"normalize\", \"title\": \"Pct. Datasets\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"top\", \"dy\": -90, \"fontSize\": 12}, \"encoding\": {\"text\": {\"aggregate\": \"count\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"Year Released\", \"sort\": [\"<2004\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"], \"title\": \"Year Released\", \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-610ef9b6a1a90cfbc51ccfe6ad38f17b\"}, \"height\": 160, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-610ef9b6a1a90cfbc51ccfe6ad38f17b\": [{\"Unique Dataset Identifier\": \"hollywood2-dataset\", \"Collection\": \"hollywood2-dataset\", \"Collection URL\": \"https://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf\", \"Dataset Name\": \"HOLLYWOOD2: Actions in Context (CVPR 2009)\", \"Paper Title\": \"HOLLYWOOD2: Actions in Context (CVPR 2009)\", \"Paper URL\": \"https://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf\", \"Semantic Scholar Corpus ID\": 3155054, \"Year Released\": \"2009\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Inria\"], \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 20.1, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"collective\", \"Collection\": \"collective\", \"Collection URL\": \"https://cvgl.stanford.edu/papers/Wongun_CollectiveActivityRecognition09.pdf\", \"Dataset Name\": \"Collective: What are they doing? : Collective activity classification using spatio-temporal relationship among people\", \"Paper Title\": \"Collective: What are they doing? : Collective activity classification using spatio-temporal relationship among people\", \"Paper URL\": \"https://cvgl.stanford.edu/papers/Wongun_CollectiveActivityRecognition09.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://cvgl.stanford.edu/papers/Wongun_CollectiveActivityRecognition09.pdf\", \"Semantic Scholar Corpus ID\": 5925915, \"Year Released\": \"2009\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Michigan\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.1, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Group Activity Recognition\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ucf101-dataset\", \"Collection\": \"ucf101-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1212.0402\", \"Dataset Name\": \"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\", \"Paper Title\": \"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\", \"Paper URL\": \"https://arxiv.org/abs/1212.0402\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/ucf101\", \"ArXiv URL\": \"https://arxiv.org/abs/1212.0402\", \"Semantic Scholar Corpus ID\": 7197134, \"Year Released\": \"2012\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Central Florida\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 26.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"youcook\", \"Collection\": \"youcook\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2013/papers/Das_A_Thousand_Frames_2013_CVPR_paper.pdf\", \"Dataset Name\": \"YouCook: A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching (CVPR 2013)\", \"Paper Title\": \"YouCook: A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching (CVPR 2013)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2013/papers/Das_A_Thousand_Frames_2013_CVPR_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youcook\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2013/papers/Das_A_Thousand_Frames_2013_CVPR_paper.pdf\", \"Semantic Scholar Corpus ID\": 12284555, \"Year Released\": \"2013\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University at Buffalo\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1000.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"50salads\", \"Collection\": \"50salads\", \"Collection URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"Dataset Name\": \"50Salads\", \"Paper Title\": \"50Salads\", \"Paper URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/50-salads\", \"ArXiv URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"Semantic Scholar Corpus ID\": 2333743, \"Year Released\": \"2013\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://cvip.computing.dundee.ac.uk/datasets/foodpreparation/50salads/\"}], \"Creators\": [\"University of Dundee\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 40.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Action Segmentation\", \"Action Localization\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"summe\", \"Collection\": \"summe\", \"Collection URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"Dataset Name\": \"SumMe: Creating Summaries from User Videos (ECCV 2014)\", \"Paper Title\": \"SumMe: Creating Summaries from User Videos (ECCV 2014)\", \"Paper URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/summe\", \"ArXiv URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"Semantic Scholar Corpus ID\": 2111093, \"Year Released\": \"2014\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"ETH Z\\u00fcrich\", \"KU Leuven\", \"upicto GmbH\"], \"Countries\": [\"Belgium\", \"Switzerland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1.11, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"stroygraphs\", \"Collection\": \"stroygraphs\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/papers/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.pdf\", \"Dataset Name\": \"StoryGraphs\", \"Paper Title\": \"StoryGraphs\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/papers/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.pdf\", \"GitHub URL\": \"https://github.com/makarandtapaswi/StoryGraphs_CVPR2014\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/storygraphs-visualizing-character\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/papers/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.pdf\", \"Semantic Scholar Corpus ID\": 1055956, \"Year Released\": \"2014\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Karlsruhe Institute of Technology\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7.3, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Misc\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"videostory\", \"Collection\": \"videostory\", \"Collection URL\": \"https://isis-data.science.uva.nl/cgmsnoek/pub/habibian-videostory-mm2014.pdf\", \"Dataset Name\": \"VideoStory: A New Multimedia Embedding for Few-Example Recognition and Translation of Events\", \"Paper Title\": \"VideoStory: A New Multimedia Embedding for Few-Example Recognition and Translation of Events\", \"Paper URL\": \"https://isis-data.science.uva.nl/cgmsnoek/pub/habibian-videostory-mm2014.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://isis-data.science.uva.nl/cgmsnoek/pub/habibian-videostory-mm2014.pdf\", \"Semantic Scholar Corpus ID\": 28203, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Amsterdam\"], \"Countries\": [\"Netherlands\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 743.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"breakfast\", \"Collection\": \"breakfast\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"Dataset Name\": \"Breakfast\", \"Paper Title\": \"Breakfast\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/breakfast\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"Semantic Scholar Corpus ID\": 9621856, \"Year Released\": \"2014\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/breakfast-actions-dataset/\"}], \"Creators\": [\"Fraunhofer FKIE\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 77.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Captioning\", \"Action Segmentation\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"thumos-challenge\", \"Collection\": \"thumos-challenge\", \"Collection URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Dataset Name\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper Title\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/thumos14-1\", \"ArXiv URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Semantic Scholar Corpus ID\": 14049355, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLScs9davISAtYQS7SEF5qQNu0jUpLzNH3aHmPfuqk2q1VYDkmw/viewform\"}], \"Creators\": [\"Stanford University\", \"University of Central Florida\", \"Fudan University\", \"Inria\"], \"Countries\": [\"United States of America\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 254.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hollywood-extended\", \"Collection\": \"hollywood-extended\", \"Collection URL\": \"https://arxiv.org/pdf/1407.1208\", \"Dataset Name\": \"Hollywood Extended\", \"Paper Title\": \"Hollywood Extended\", \"Paper URL\": \"https://arxiv.org/pdf/1407.1208\", \"GitHub URL\": \"https://github.com/piotr-bojanowski/action-ordering\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/weakly-supervised-action-labeling-in-videos\", \"ArXiv URL\": \"https://arxiv.org/pdf/1407.1208\", \"Semantic Scholar Corpus ID\": 9342651, \"Year Released\": \"2014\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/piotr-bojanowski/action-ordering/blob/master/LICENSE\"}], \"Creators\": [\"Inria\"], \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 8.75, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Temporal Action Detection\", \"Action Recognition\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"sports1M-dataset\", \"Collection\": \"sports1M-dataset\", \"Collection URL\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\", \"Dataset Name\": \"Sports-1M: Large-scale Video Classification with Convolutional Neural Networks\", \"Paper Title\": \"Sports-1M: Large-scale Video Classification with Convolutional Neural Networks\", \"Paper URL\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\", \"GitHub URL\": \"https://github.com/gtoderici/sports-1m-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/large-scale-video-classification-with-1\", \"ArXiv URL\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\", \"Semantic Scholar Corpus ID\": 206592218, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 3.0\", \"License URL\": \"https://github.com/gtoderici/sports-1m-dataset\"}], \"Creators\": [\"Stanford University\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 105761.41, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"volleyball-vids\", \"Collection\": \"volleyball-vids\", \"Collection URL\": \"https://arxiv.org/abs/1511.06040\", \"Dataset Name\": \"Volleyball: A Hierarchical Deep Temporal Model for Group Activity Recognition\", \"Paper Title\": \"Volleyball: A Hierarchical Deep Temporal Model for Group Activity Recognition\", \"Paper URL\": \"https://arxiv.org/abs/1511.06040\", \"GitHub URL\": \"https://github.com/mostafa-saad/deep-activity-rec#dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/volleyball\", \"ArXiv URL\": \"https://arxiv.org/abs/1511.06040\", \"Semantic Scholar Corpus ID\": 8483403, \"Year Released\": \"2015\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Simon Fraser University\"], \"Countries\": [\"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.1, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Group Activity Recognition\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"activitynet\", \"Collection\": \"activitynet\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"Dataset Name\": \"ActivityNet\", \"Paper Title\": \"ActivityNet\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/Leyo/ActivityNet_Captions\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/activitynet\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"Semantic Scholar Corpus ID\": 1710722, \"Year Released\": \"2015\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/facebookresearch/ActivityNet-Entities/blob/main/LICENSE\"}], \"Creators\": [\"Universidad del Norte\", \"King Abdullah University of Science and Technology (KAUST)\"], \"Countries\": [\"Saudi Arabia\", \"Colombia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 849.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"tvsum\", \"Collection\": \"tvsum\", \"Collection URL\": \"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\", \"Dataset Name\": \"TVSum: Summarizing web videos using titles (CVPR 2015)\", \"Paper Title\": \"TVSum: Summarizing web videos using titles (CVPR 2015)\", \"Paper URL\": \"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\", \"GitHub URL\": \"https://github.com/yalesong/tvsum\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tvsum-1\", \"ArXiv URL\": \"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\", \"Semantic Scholar Corpus ID\": 7675635, \"Year Released\": \"2015\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 3.0\", \"License URL\": \"https://github.com/yalesong/tvsum\"}], \"Creators\": [\"Yahoo Labs\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3.5, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"mpii-cooking\", \"Collection\": \"mpii-cooking\", \"Collection URL\": \"https://arxiv.org/abs/1502.06648\", \"Dataset Name\": \"MPII-Cooking: Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data (IJCV 2015)\", \"Paper Title\": \"MPII-Cooking: Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data (IJCV 2015)\", \"Paper URL\": \"https://arxiv.org/abs/1502.06648\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/recognizing-fine-grained-and-composite\", \"ArXiv URL\": \"https://arxiv.org/abs/1502.06648\", \"Semantic Scholar Corpus ID\": 14036544, \"Year Released\": \"2015\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/human-activity-recognition/mpii-cooking-activities-dataset\"}], \"Creators\": [\"Max Planck Institute for Informatics\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 27.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"movieqa\", \"Collection\": \"movieqa\", \"Collection URL\": \"https://arxiv.org/abs/1512.02902\", \"Dataset Name\": \"MovieQA\", \"Paper Title\": \"MovieQA\", \"Paper URL\": \"https://arxiv.org/abs/1512.02902\", \"GitHub URL\": \"https://github.com/makarandtapaswi/MovieQA_CVPR2016/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/movieqa\", \"ArXiv URL\": \"https://arxiv.org/abs/1512.02902\", \"Semantic Scholar Corpus ID\": 1017389, \"Year Released\": \"2015\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"University of Toronto\"], \"Countries\": [\"Germany\", \"Canada\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 381.0, \"Taken Down\": \"True\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Question Answering\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"ntu-rgbd\", \"Collection\": \"ntu-rgbd\", \"Collection URL\": \"https://arxiv.org/pdf/1604.02808.pdf\", \"Dataset Name\": \"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis (CVPR 2016, TPAMI 2019)\", \"Paper Title\": \"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis (CVPR 2016, TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1604.02808.pdf\", \"GitHub URL\": \"https://github.com/shahroudy/NTURGB-D\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ntu-rgbd-a-large-scale-dataset-for-3d-human\", \"ArXiv URL\": \"https://arxiv.org/pdf/1604.02808.pdf\", \"Semantic Scholar Corpus ID\": 15928602, \"Year Released\": \"2016\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://rose1.ntu.edu.sg/dataset/actionRecognition/\"}], \"Creators\": [\"Nanyang Technological University\"], \"Countries\": [\"Singapore\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 74.1, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"mpii-cooking2\", \"Collection\": \"mpii-cooking2\", \"Collection URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"Dataset Name\": \"MPII Cooking 2\", \"Paper Title\": \"MPII Cooking 2\", \"Paper URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mpii-cooking-2-dataset\", \"ArXiv URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"Semantic Scholar Corpus ID\": 14036544, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/human-activity-recognition/mpii-cooking-2-dataset/\"}], \"Creators\": [\"Max Planck Institute for Informatics\", \"Saarland University\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 27.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Temporal Action Detection\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"mars\", \"Collection\": \"mars\", \"Collection URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Dataset Name\": \"Mars\", \"Paper Title\": \"Mars\", \"Paper URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mars\", \"ArXiv URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Semantic Scholar Corpus ID\": 2214158, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Microsoft\", \"Tsinghua University\", \"The University of Texas at San Antonio\", \"Peking University\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.24, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Segmentation\", \"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"charades\", \"Collection\": \"charades\", \"Collection URL\": \"https://arxiv.org/abs/1604.01753\", \"Dataset Name\": \"Charades\", \"Paper Title\": \"Charades\", \"Paper URL\": \"https://arxiv.org/abs/1604.01753\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/charades\", \"ArXiv URL\": \"https://arxiv.org/abs/1604.01753\", \"Semantic Scholar Corpus ID\": 18061547, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades#licensing-information\"}], \"Creators\": [\"Carnegie Mellon University\", \"Inria\", \"University of Washington\", \"Allen Institute for AI\"], \"Countries\": [\"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 82.3, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"youtube-8m\", \"Collection\": \"youtube-8m\", \"Collection URL\": \"https://arxiv.org/abs/1609.08675\", \"Dataset Name\": \"Youtube-8M: A Large-Scale Video Classification Benchmark\", \"Paper Title\": \"Youtube-8M: A Large-Scale Video Classification Benchmark\", \"Paper URL\": \"https://arxiv.org/abs/1609.08675\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youtube-8m\", \"ArXiv URL\": \"https://arxiv.org/abs/1609.08675\", \"Semantic Scholar Corpus ID\": 11241677, \"Year Released\": \"2016\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Google Research\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 350000.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"msr-vtt\", \"Collection\": \"msr-vtt\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7780940\", \"Dataset Name\": \"MSR-VTT\", \"Paper Title\": \"MSR-VTT\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7780940\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/msr-vtt\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7780940\", \"Semantic Scholar Corpus ID\": 206594535, \"Year Released\": \"2016\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Microsoft Research\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 41.2, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"narrated-instruction-vids\", \"Collection\": \"narrated-instruction-vids\", \"Collection URL\": \"https://arxiv.org/abs/1506.09215\", \"Dataset Name\": \"Narrated Instruction Videos\", \"Paper Title\": \"Narrated Instruction Videos\", \"Paper URL\": \"https://arxiv.org/abs/1506.09215\", \"GitHub URL\": \"https://github.com/jalayrac/instructionVideos\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youtube-inria-instructional\", \"ArXiv URL\": \"https://arxiv.org/abs/1506.09215\", \"Semantic Scholar Corpus ID\": 2617244, \"Year Released\": \"2016\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/jalayrac/instructionVideos?tab=readme-ov-file#license\"}], \"Creators\": [\"CNRS\", \"Ecole Normale Sup\\u00e9rieure\", \"Inria\", \"International Institute of Information Technology - Hyderabad\"], \"Countries\": [\"United States of America\", \"India\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"vtw\", \"Collection\": \"vtw\", \"Collection URL\": \"https://arxiv.org/abs/1608.07068\", \"Dataset Name\": \"VTW\", \"Paper Title\": \"VTW\", \"Paper URL\": \"https://arxiv.org/abs/1608.07068\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/title-generation-for-user-generated-videos\", \"ArXiv URL\": \"https://arxiv.org/abs/1608.07068\", \"Semantic Scholar Corpus ID\": 6155397, \"Year Released\": \"2016\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Tsinghua University\", \"Stanford University\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 213.2, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"tgif\", \"Collection\": \"tgif\", \"Collection URL\": \"https://arxiv.org/abs/1604.02748\", \"Dataset Name\": \"TGIF\", \"Paper Title\": \"TGIF\", \"Paper URL\": \"https://arxiv.org/abs/1604.02748\", \"GitHub URL\": \"https://github.com/raingo/TGIF-Release\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/TGIF\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tgif\", \"ArXiv URL\": \"https://arxiv.org/abs/1604.02748\", \"Semantic Scholar Corpus ID\": 6262415, \"Year Released\": \"2016\", \"Text Sources\": [\"tumblr\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/raingo/TGIF-Release\"}], \"Creators\": [\"University of Rochester\", \"Yahoo! Inc.\", \"AiCure\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 86.1, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"youcook-2\", \"Collection\": \"youcook-2\", \"Collection URL\": \"https://arxiv.org/abs/1703.09788\", \"Dataset Name\": \"YouCook2\", \"Paper Title\": \"YouCook2\", \"Paper URL\": \"https://arxiv.org/abs/1703.09788\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youcook2\", \"ArXiv URL\": \"https://arxiv.org/abs/1703.09788\", \"Semantic Scholar Corpus ID\": 19713015, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"http://youcook2.eecs.umich.edu/static/YouCookII/LICENSE_YOUCOOK2.txt\"}], \"Creators\": [\"University of Rochester\", \"University of Michigan\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 175.6, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"qfvs\", \"Collection\": \"qfvs\", \"Collection URL\": \"https://arxiv.org/abs/1707.04960\", \"Dataset Name\": \"QFVS: Query-Focused Video Summarization: Dataset, Evaluation, and A Memory Network Based Approach (CVPR 2017)\", \"Paper Title\": \"QFVS: Query-Focused Video Summarization: Dataset, Evaluation, and A Memory Network Based Approach (CVPR 2017)\", \"Paper URL\": \"https://arxiv.org/abs/1707.04960\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/query-focused-video-summarization-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/1707.04960\", \"Semantic Scholar Corpus ID\": 2774608, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Central Florida\", \"University of Alabama\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 20.0, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"davis\", \"Collection\": \"davis\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"Dataset Name\": \"Davis\", \"Paper Title\": \"Davis\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"GitHub URL\": \"https://github.com/fperazzi/davis\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-benchmark-dataset-and-evaluation\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"Semantic Scholar Corpus ID\": 3619941, \"Year Released\": \"2017\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/fperazzi/davis/blob/main/LICENSE\"}], \"Creators\": [\"ETH Z\\u00fcrich\", \"Disney Research\"], \"Countries\": [\"Switzerland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.04, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Segmentation\", \"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"pku-mmd-dataset\", \"Collection\": \"pku-mmd-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1703.07475\", \"Dataset Name\": \"PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding (ACM Multimedia Workshop)\", \"Paper Title\": \"PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding (ACM Multimedia Workshop)\", \"Paper URL\": \"https://arxiv.org/abs/1703.07475\", \"GitHub URL\": \"https://struct002.github.io/PKUMMD/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/pku-mmd-a-large-scale-benchmark-for\", \"ArXiv URL\": \"https://arxiv.org/abs/1703.07475\", \"Semantic Scholar Corpus ID\": 1904265, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Microsoft Research\", \"Peking University\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 50.0, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"kinetics-400\", \"Collection\": \"kinetics-400\", \"Collection URL\": \"https://arxiv.org/abs/1705.06950\", \"Dataset Name\": \"Kinetics 400\", \"Paper Title\": \"Kinetics 400\", \"Paper URL\": \"https://arxiv.org/abs/1705.06950\", \"GitHub URL\": \"https://github.com/cvdfoundation/kinetics-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/kinetics\", \"ArXiv URL\": \"https://arxiv.org/abs/1705.06950\", \"Semantic Scholar Corpus ID\": 27300853, \"Year Released\": \"2017\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"DeepMind\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 850.68, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mpii-md\", \"Collection\": \"mpii-md\", \"Collection URL\": \"https://arxiv.org/pdf/1501.02530.pdf\", \"Dataset Name\": \"MPII-MD: A Dataset for Movie Description\", \"Paper Title\": \"MPII-MD: A Dataset for Movie Description\", \"Paper URL\": \"https://arxiv.org/pdf/1501.02530.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1501.02530.pdf\", \"Semantic Scholar Corpus ID\": 15184723, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Max Planck Institute for Informatics\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 56.5, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"multi-thumos-challenge\", \"Collection\": \"multi-thumos-challenge\", \"Collection URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"Dataset Name\": \"MultiTHUMOS: Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos (IJCV 2017)\", \"Paper Title\": \"MultiTHUMOS: Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos (IJCV 2017)\", \"Paper URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/multithumos\", \"ArXiv URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"Semantic Scholar Corpus ID\": 3337929, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://ai.stanford.edu/~syyeung/resources/multithumos.zip\"}], \"Creators\": [\"Stanford University\", \"Carnegie Mellon University\", \"Simon Fraser University\"], \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 30.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ava\", \"Collection\": \"ava\", \"Collection URL\": \"https://arxiv.org/pdf/1705.08421\", \"Dataset Name\": \"AVA\", \"Paper Title\": \"AVA\", \"Paper URL\": \"https://arxiv.org/pdf/1705.08421\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ava-a-video-dataset-of-spatio-temporally\", \"ArXiv URL\": \"https://arxiv.org/pdf/1705.08421\", \"Semantic Scholar Corpus ID\": 688013, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://research.google.com/ava/\"}], \"Creators\": [\"Google Research\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 107.5, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Temporal Localization\", \"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"lsmdc\", \"Collection\": \"lsmdc\", \"Collection URL\": \"https://arxiv.org/pdf/1605.03705\", \"Dataset Name\": \"LSMDC\", \"Paper Title\": \"LSMDC\", \"Paper URL\": \"https://arxiv.org/pdf/1605.03705\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/movie-description\", \"ArXiv URL\": \"https://arxiv.org/pdf/1605.03705\", \"Semantic Scholar Corpus ID\": 18217052, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://datasets.d2.mpi-inf.mpg.de/movieDescription/protected/lsmdc2016/README.txt\"}], \"Creators\": [\"UC Berkeley\", \"Disney Research\", \"Universite de Montreal\", \"Polytechnique Montr\\u00e9al\", \"Universit\\u00e9 de Sherbrooke\", \"Twitter\"], \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Summarization\", \"Misc\", \"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"20bn-something\", \"Collection\": \"20bn-something\", \"Collection URL\": \"https://arxiv.org/abs/1706.04261\", \"Dataset Name\": \"20BN-SOMETHING-SOMETHING: The \\\"something something\\\" video database for learning and evaluating visual common sense\", \"Paper Title\": \"20BN-SOMETHING-SOMETHING: The \\\"something something\\\" video database for learning and evaluating visual common sense\", \"Paper URL\": \"https://arxiv.org/abs/1706.04261\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/something-something-v2\", \"ArXiv URL\": \"https://arxiv.org/abs/1706.04261\", \"Semantic Scholar Corpus ID\": 834612, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://developer.qualcomm.com/software/ai-datasets/something-something\"}], \"Creators\": [\"Twenty Billion Neurons GmbH\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 121.46, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"voxceleb\", \"Collection\": \"voxceleb\", \"Collection URL\": \"https://arxiv.org/abs/1706.08612\", \"Dataset Name\": \"VoxCeleb\", \"Paper Title\": \"VoxCeleb\", \"Paper URL\": \"https://arxiv.org/abs/1706.08612\", \"GitHub URL\": \"https://github.com/a-nagrani/VGGVox\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://cs.paperswithcode.com/paper/voxceleb-a-large-scale-speaker-identification\", \"ArXiv URL\": \"https://arxiv.org/abs/1706.08612\", \"Semantic Scholar Corpus ID\": 10475843, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/\"}], \"Creators\": [\"University of Oxford\"], \"Countries\": [\"United Kingdom\", \"South Korea\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 2000.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"imagenet-vid\", \"Collection\": \"imagenet-vid\", \"Collection URL\": \"https://link.springer.com/article/10.1007/s11263-015-0816-y?sa_campaign=email/event/articleAuthor/onlineFirst#\", \"Dataset Name\": \"ImageNet VID\", \"Paper Title\": \"ImageNet VID\", \"Paper URL\": \"https://link.springer.com/article/10.1007/s11263-015-0816-y?sa_campaign=email/event/articleAuthor/onlineFirst#\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/sota/video-object-detection-on-imagenet-vid\", \"ArXiv URL\": \"https://link.springer.com/article/10.1007/s11263-015-0816-y?sa_campaign=email/event/articleAuthor/onlineFirst#\", \"Semantic Scholar Corpus ID\": 2930547, \"Year Released\": \"2017\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://www.image-net.org/challenges/LSVRC/2017/index.php\"}], \"Creators\": [\"Stanford University\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 9.26, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"kinetics-600\", \"Collection\": \"kinetics-600\", \"Collection URL\": \"https://arxiv.org/abs/1808.01340\", \"Dataset Name\": \"Kinetics 600\", \"Paper Title\": \"Kinetics 600\", \"Paper URL\": \"https://arxiv.org/abs/1808.01340\", \"GitHub URL\": \"https://github.com/cvdfoundation/kinetics-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/kinetics-600\", \"ArXiv URL\": \"https://arxiv.org/abs/1808.01340\", \"Semantic Scholar Corpus ID\": 51927456, \"Year Released\": \"2018\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"DeepMind\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1376.52, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"didemo\", \"Collection\": \"didemo\", \"Collection URL\": \"https://paperswithcode.com/dataset/didemo\", \"Dataset Name\": \"DiDeMo: Localizing Moments in Video with Temporal Language (EMNLP 2018)\", \"Paper Title\": \"DiDeMo: Localizing Moments in Video with Temporal Language (EMNLP 2018)\", \"Paper URL\": \"https://paperswithcode.com/dataset/didemo\", \"GitHub URL\": \"https://github.com/LisaAnne/TemporalLanguageRelease\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://paperswithcode.com/dataset/didemo\", \"Semantic Scholar Corpus ID\": 52164739, \"Year Released\": \"2018\", \"Text Sources\": [\"flickr\"], \"Licenses\": [{\"License\": \"BSD 2-Clause License\", \"License URL\": \"https://github.com/LisaAnne/TemporalLanguageRelease\"}], \"Creators\": [\"UC Berkeley\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 275.0, \"Taken Down\": \"False\", \"Video Sources\": \"flickr\", \"Task Categories\": [\"Temporal Action Localization\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"epic-kitchenes\", \"Collection\": \"epic-kitchenes\", \"Collection URL\": \"https://arxiv.org/abs/1804.02748\", \"Dataset Name\": \"EPIC-KITCHENS\", \"Paper Title\": \"EPIC-KITCHENS\", \"Paper URL\": \"https://arxiv.org/abs/1804.02748\", \"GitHub URL\": \"https://github.com/epic-kitchens\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/epic-kitchens-100\", \"ArXiv URL\": \"https://arxiv.org/abs/1804.02748\", \"Semantic Scholar Corpus ID\": 4710439, \"Year Released\": \"2018\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://epic-kitchens.github.io/2024\"}], \"Creators\": [\"University of Toronto\", \"University of Bristol\", \"University of Catania\"], \"Countries\": [\"United Kingdom\", \"Canada\", \"Spain\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 100.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"vlog-vids\", \"Collection\": \"vlog-vids\", \"Collection URL\": \"https://arxiv.org/abs/1712.02310\", \"Dataset Name\": \"VLOG: From Lifestyle Vlogs to Everyday Interactions (CVPR 2018)\", \"Paper Title\": \"VLOG: From Lifestyle Vlogs to Everyday Interactions (CVPR 2018)\", \"Paper URL\": \"https://arxiv.org/abs/1712.02310\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/vlog-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/1712.02310\", \"Semantic Scholar Corpus ID\": 22264672, \"Year Released\": \"2018\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://web.eecs.umich.edu/~fouhey/2017/VLOG/index.html\"}], \"Creators\": [\"UC Berkeley\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 336.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"charades-ego\", \"Collection\": \"charades-ego\", \"Collection URL\": \"https://arxiv.org/abs/1804.09627\", \"Dataset Name\": \"Charades-Ego: Actor and Observer: Joint Modeling of First and Third-Person Videos (CVPR 2018)\", \"Paper Title\": \"Charades-Ego: Actor and Observer: Joint Modeling of First and Third-Person Videos (CVPR 2018)\", \"Paper URL\": \"https://arxiv.org/abs/1804.09627\", \"GitHub URL\": \"https://github.com/gsig/actor-observer\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/search?q_meta=&q_type=&q=Actor+and+Observer%3A+Joint+Modeling+of+First+and+Third-Person+Videos\", \"ArXiv URL\": \"https://arxiv.org/abs/1804.09627\", \"Semantic Scholar Corpus ID\": 4562167, \"Year Released\": \"2018\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://prior.allenai.org/projects/data/charades-ego/license.txt\"}], \"Creators\": [\"Allen Institute for AI\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 69.33, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"soa-dataset\", \"Collection\": \"soa-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1904.11451\", \"Dataset Name\": \"Scenes-objects-actions: A multi-task, multi-label video dataset\", \"Paper Title\": \"Scenes-objects-actions: A multi-task, multi-label video dataset\", \"Paper URL\": \"https://arxiv.org/pdf/1904.11451\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/scenes-objects-actions-a-multi-task-multi\", \"ArXiv URL\": \"https://arxiv.org/pdf/1904.11451\", \"Semantic Scholar Corpus ID\": 52968009, \"Year Released\": \"2018\", \"Text Sources\": [\"facebook\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Meta\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1561.1, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"moviegraphs\", \"Collection\": \"moviegraphs\", \"Collection URL\": \"https://arxiv.org/pdf/1712.06761\", \"Dataset Name\": \"MovieGraphs\", \"Paper Title\": \"MovieGraphs\", \"Paper URL\": \"https://arxiv.org/pdf/1712.06761\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/moviegraphs\", \"ArXiv URL\": \"https://arxiv.org/pdf/1712.06761\", \"Semantic Scholar Corpus ID\": 4856028, \"Year Released\": \"2018\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moviegraphs.cs.toronto.edu/download.html\"}], \"Creators\": [\"Vector Institute for Artificial Intelligence\", \"Montreal Institute of Learning Algorithms (Mila)\", \"University of Toronto\"], \"Countries\": [\"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 93.9, \"Taken Down\": \"True\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Misc (video retrieval\", \"interaction understanding via ordering\", \"reason prediction)\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"how2\", \"Collection\": \"how2\", \"Collection URL\": \"https://arxiv.org/abs/1811.00347\", \"Dataset Name\": \"How2: A Large-scale Dataset for Multimodal Language Understanding (NeurIPS 2018)\", \"Paper Title\": \"How2: A Large-scale Dataset for Multimodal Language Understanding (NeurIPS 2018)\", \"Paper URL\": \"https://arxiv.org/abs/1811.00347\", \"GitHub URL\": \"https://github.com/srvk/how2-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/abs/1811.00347\", \"Semantic Scholar Corpus ID\": 53186236, \"Year Released\": \"2018\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Various\", \"License URL\": \"https://github.com/srvk/how2-dataset?tab=readme-ov-file#how2-license\"}], \"Creators\": [\"Carnegie Mellon University\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 2300.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"trecvid\", \"Collection\": \"trecvid\", \"Collection URL\": \"https://arxiv.org/abs/2009.09984\", \"Dataset Name\": \"TRECVID\", \"Paper Title\": \"TRECVID\", \"Paper URL\": \"https://arxiv.org/abs/2009.09984\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/trecvid-2019-an-evaluation-campaign-to/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.09984\", \"Semantic Scholar Corpus ID\": 212694843, \"Year Released\": \"2019\", \"Text Sources\": [\"undisclosed web\", \"bbc\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://trecvid.nist.gov/\"}], \"Creators\": [\"National Institute of Standards and Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1000.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\", \"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper Title\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Ecole Normale Sup\\u00e9rieure\", \"Inria\", \"CIIRC\", \"Czech Technical University\", \"University of Michigan\"], \"Countries\": [\"France\", \"Turkey\", \"United States of America\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Temporal Action Localization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"flickr\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"vatex\", \"Collection\": \"vatex\", \"Collection URL\": \"https://arxiv.org/abs/1904.03493\", \"Dataset Name\": \"VaTeX\", \"Paper Title\": \"VaTeX\", \"Paper URL\": \"https://arxiv.org/abs/1904.03493\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/vatex\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/vatex\", \"ArXiv URL\": \"https://arxiv.org/abs/1904.03493\", \"Semantic Scholar Corpus ID\": 102352148, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://eric-xw.github.io/vatex-website/index.html\"}], \"Creators\": [\"ByteDance AI Lab\", \"UC Santa Barbara\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 114.58, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ava-dataset\", \"Collection\": \"ava-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1901.01342\", \"Dataset Name\": \"AVA Active Speaker\", \"Paper Title\": \"AVA Active Speaker\", \"Paper URL\": \"https://arxiv.org/abs/1901.01342\", \"GitHub URL\": \"https://github.com/cvdfoundation/ava-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/ava-activespeaker\", \"ArXiv URL\": \"https://arxiv.org/abs/1901.01342\", \"Semantic Scholar Corpus ID\": 216211909, \"Year Released\": \"2019\", \"Text Sources\": [\"Not Prohibited\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://research.google.com/ava/download.html#ava_active_speaker_download\"}], \"Creators\": [\"Google Research\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 38.5, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"msa\", \"Collection\": \"msa\", \"Collection URL\": \"https://arxiv.org/abs/1910.11009\", \"Dataset Name\": \"MSA\", \"Paper Title\": \"MSA\", \"Paper URL\": \"https://arxiv.org/abs/1910.11009\", \"GitHub URL\": \"https://github.com/ycxioooong/MovieSynopsisAssociation\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-graph-based-framework-to-bridge-movies-and-1\", \"ArXiv URL\": \"https://arxiv.org/abs/1910.11009\", \"Semantic Scholar Corpus ID\": 204852218, \"Year Released\": \"2019\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"The Chinese University of Hong Kong\", \"UC Berkeley\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 516.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"howto100m\", \"Collection\": \"howto100m\", \"Collection URL\": \"https://arxiv.org/abs/1906.03327\", \"Dataset Name\": \"HowTo100M\", \"Paper Title\": \"HowTo100M\", \"Paper URL\": \"https://arxiv.org/abs/1906.03327\", \"GitHub URL\": \"https://github.com/antoine77340/howto100m\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/howto100m\", \"ArXiv URL\": \"https://arxiv.org/abs/1906.03327\", \"Semantic Scholar Corpus ID\": 182952863, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Ecole Normale Sup\\u00e9rieure\", \"Inria\", \"CIIRC\", \"Czech Technical University\"], \"Countries\": [\"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 134472.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"toyota-smarthome\", \"Collection\": \"toyota-smarthome\", \"Collection URL\": \"https://openaccess.thecvf.com/content_ICCV_2019/papers/Das_Toyota_Smarthome_Real-World_Activities_of_Daily_Living_ICCV_2019_paper.pdf\", \"Dataset Name\": \"Toyota Smarthome: Real-World Activities of Daily Living (ICCV 2019)\", \"Paper Title\": \"Toyota Smarthome: Real-World Activities of Daily Living (ICCV 2019)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_ICCV_2019/papers/Das_Toyota_Smarthome_Real-World_Activities_of_Daily_Living_ICCV_2019_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_ICCV_2019/papers/Das_Toyota_Smarthome_Real-World_Activities_of_Daily_Living_ICCV_2019_paper.pdf\", \"Semantic Scholar Corpus ID\": 207971208, \"Year Released\": \"2019\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://project.inria.fr/toyotasmarthome/files/2020/12/License_v2.pdf\"}], \"Creators\": [\"Toyota\"], \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 268.58, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"trecvid\", \"Collection\": \"trecvid\", \"Collection URL\": \"https://arxiv.org/abs/2009.09984\", \"Dataset Name\": \"TRECVID\", \"Paper Title\": \"TRECVID\", \"Paper URL\": \"https://arxiv.org/abs/2009.09984\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/trecvid-2019-an-evaluation-campaign-to/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.09984\", \"Semantic Scholar Corpus ID\": 212694843, \"Year Released\": \"2019\", \"Text Sources\": [\"undisclosed web\", \"bbc\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://trecvid.nist.gov/\"}], \"Creators\": [\"National Institute of Standards and Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1000.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\", \"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"coin-dataset\", \"Collection\": \"coin-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1903.02874\", \"Dataset Name\": \"COIN: A Large-scale Dataset for Comprehensive Instructional Video Analysis (CVPR 2019)\", \"Paper Title\": \"COIN: A Large-scale Dataset for Comprehensive Instructional Video Analysis (CVPR 2019)\", \"Paper URL\": \"https://arxiv.org/abs/1903.02874\", \"GitHub URL\": \"https://github.com/coin-dataset/annotations\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/coin#:~:text=The%20COIN%20dataset%20(a%20large,are%20all%20collected%20from%20YouTube.\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.02874\", \"Semantic Scholar Corpus ID\": 71147568, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/coin-dataset/annotations?tab=readme-ov-file#license\"}], \"Creators\": [\"Tsinghua University\", \"Meitu Inc.\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 476.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"20BN-jester\", \"Collection\": \"20BN-jester\", \"Collection URL\": \"https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf\", \"Dataset Name\": \"20BN-jester: The Jester Dataset: A Large-Scale Video Dataset of Human Gestures (ICCVW 2019)\", \"Paper Title\": \"20BN-jester: The Jester Dataset: A Large-Scale Video Dataset of Human Gestures (ICCVW 2019)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf\", \"Semantic Scholar Corpus ID\": 208010438, \"Year Released\": \"2019\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://developer.qualcomm.com/software/ai-datasets/jester\"}], \"Creators\": [\"Twenty Billion Neurons GmbH\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13.0, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"mmact\", \"Collection\": \"mmact\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Dataset Name\": \"MMAct\", \"Paper Title\": \"MMAct\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mmact\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Semantic Scholar Corpus ID\": 207980205, \"Year Released\": \"2019\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://mmact19.github.io/2019/\"}], \"Creators\": [\"The Hong Kong University of Science and Technology\", \"Alibaba Group\"], \"Countries\": [\"Hong Kong\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 100.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Temporal Localization\", \"Action Recognition\", \"Spatial-Temporal Action Localization\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hacs-dataset\", \"Collection\": \"hacs-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1712.09374\", \"Dataset Name\": \"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\", \"Paper Title\": \"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\", \"Paper URL\": \"https://arxiv.org/abs/1712.09374\", \"GitHub URL\": \"https://github.com/hangzhaomit/HACS-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hacs\", \"ArXiv URL\": \"https://arxiv.org/abs/1712.09374\", \"Semantic Scholar Corpus ID\": 68049510, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/hangzhaomit/HACS-dataset?tab=readme-ov-file#request-testing-videos-and-missing-videos-new\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"Dartmouth University\", \"UIUC\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask\", \"Paper Title\": \"CrossTask\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Middle East Technical University\", \"Inria\", \"PSL University - Universit\\u00e9 PSL\", \"University of Michigan\", \"CIIRC\"], \"Countries\": [\"Czech Republic\", \"France\", \"Turkey\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"eev-dataset\", \"Collection\": \"eev-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2001.05488\", \"Dataset Name\": \"EEV: A Large-Scale Dataset for Studying Evoked Expressions from Video\", \"Paper Title\": \"EEV: A Large-Scale Dataset for Studying Evoked Expressions from Video\", \"Paper URL\": \"https://arxiv.org/abs/2001.05488\", \"GitHub URL\": \"https://github.com/google-research-datasets/eev\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/abs/2001.05488\", \"Semantic Scholar Corpus ID\": 210701992, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://github.com/google-research-datasets/eev?tab=readme-ov-file#license\"}], \"Creators\": [\"Google Research\", \"California Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 370.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"omnisource-web-dataset\", \"Collection\": \"omnisource-web-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2003.13042\", \"Dataset Name\": \"OmniSource Web Dataset\", \"Paper Title\": \"OmniSource Web Dataset\", \"Paper URL\": \"https://arxiv.org/abs/2003.13042\", \"GitHub URL\": \"https://github.com/open-mmlab/mmaction\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/omni-sourced-webly-supervised-learning-for#code\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.13042\", \"Semantic Scholar Corpus ID\": 214714240, \"Year Released\": \"2020\", \"Text Sources\": [\"google videos\", \"instagram\", \"youtube\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/open-mmlab/mmaction?tab=readme-ov-file#license\"}], \"Creators\": [\"The Chinese University of Hong Kong\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13333.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"omnisource-web-dataset\", \"Collection\": \"omnisource-web-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2003.13042\", \"Dataset Name\": \"OmniSource Web Dataset\", \"Paper Title\": \"OmniSource Web Dataset\", \"Paper URL\": \"https://arxiv.org/abs/2003.13042\", \"GitHub URL\": \"https://github.com/open-mmlab/mmaction\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/omni-sourced-webly-supervised-learning-for#code\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.13042\", \"Semantic Scholar Corpus ID\": 214714240, \"Year Released\": \"2020\", \"Text Sources\": [\"google videos\", \"instagram\", \"youtube\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/open-mmlab/mmaction?tab=readme-ov-file#license\"}], \"Creators\": [\"The Chinese University of Hong Kong\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13333.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"condensed-movies\", \"Collection\": \"condensed-movies\", \"Collection URL\": \"https://arxiv.org/pdf/2005.04208\", \"Dataset Name\": \"Condensed Movies\", \"Paper Title\": \"Condensed Movies\", \"Paper URL\": \"https://arxiv.org/pdf/2005.04208\", \"GitHub URL\": \"https://github.com/m-bain/CondensedMovies\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/condensed-movies\", \"ArXiv URL\": \"https://arxiv.org/pdf/2005.04208\", \"Semantic Scholar Corpus ID\": 218571391, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://www.robots.ox.ac.uk/~vgg/data/condensed-movies/#download\"}], \"Creators\": [\"University of Oxford\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1270.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"lsmdc-ordering\", \"Collection\": \"lsmdc-ordering\", \"Collection URL\": \"https://arxiv.org/pdf/2004.02205\", \"Dataset Name\": \"LSMDC Ordering\", \"Paper Title\": \"LSMDC Ordering\", \"Paper URL\": \"https://arxiv.org/pdf/2004.02205\", \"GitHub URL\": \"https://github.com/vivoutlaw/TCBP\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/deep-multimodal-feature-encoding-for-video\", \"ArXiv URL\": \"https://arxiv.org/pdf/2004.02205\", \"Semantic Scholar Corpus ID\": 214802821, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/vivoutlaw/tcbp/blob/master/LICENSE\"}], \"Creators\": [\"University of Toronto\", \"Karlsruhe Institute of Technology\", \"Inria\", \"Massachusetts Institute of Technology\"], \"Countries\": [\"Germany\", \"Canada\", \"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"haa500-dataset\", \"Collection\": \"haa500-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2009.05224\", \"Dataset Name\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper Title\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper URL\": \"https://arxiv.org/abs/2009.05224\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/haa500-human-centric-atomic-action-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.05224\", \"Semantic Scholar Corpus ID\": 221640805, \"Year Released\": \"2020\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Carnegie Mellon University\", \"The Hong Kong University of Science and Technology\", \"Princeton University\", \"Kuaishou Technology\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 5.48, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"omnisource-web-dataset\", \"Collection\": \"omnisource-web-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2003.13042\", \"Dataset Name\": \"OmniSource Web Dataset\", \"Paper Title\": \"OmniSource Web Dataset\", \"Paper URL\": \"https://arxiv.org/abs/2003.13042\", \"GitHub URL\": \"https://github.com/open-mmlab/mmaction\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/omni-sourced-webly-supervised-learning-for#code\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.13042\", \"Semantic Scholar Corpus ID\": 214714240, \"Year Released\": \"2020\", \"Text Sources\": [\"google videos\", \"instagram\", \"youtube\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/open-mmlab/mmaction?tab=readme-ov-file#license\"}], \"Creators\": [\"The Chinese University of Hong Kong\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13333.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"100doh\", \"Collection\": \"100doh\", \"Collection URL\": \"https://arxiv.org/abs/2006.06669\", \"Dataset Name\": \"100DOH: Understanding Human Hands in Contact at Internet Scale (CVPR 2020)\", \"Paper Title\": \"100DOH: Understanding Human Hands in Contact at Internet Scale (CVPR 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2006.06669\", \"GitHub URL\": \"https://github.com/ddshan/hand_object_detector\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/understanding-human-hands-in-contact-at-1\", \"ArXiv URL\": \"https://arxiv.org/abs/2006.06669\", \"Semantic Scholar Corpus ID\": 215413188, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://fouheylab.eecs.umich.edu/~dandans/projects/100DOH/download.html\"}], \"Creators\": [\"University of Michigan\", \"Johns Hopkins University\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 4577.3, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Misc (Hand/Object Detection)\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"kinetics-700\", \"Collection\": \"kinetics-700\", \"Collection URL\": \"https://arxiv.org/pdf/2010.10864.pdf\", \"Dataset Name\": \"Kinetics-700\", \"Paper Title\": \"Kinetics-700\", \"Paper URL\": \"https://arxiv.org/pdf/2010.10864.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/kinetics-700\", \"ArXiv URL\": \"https://arxiv.org/pdf/2010.10864.pdf\", \"Semantic Scholar Corpus ID\": 196831809, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"DeepMind\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1805.56, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"finegym-dataset\", \"Collection\": \"finegym-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2004.06704\", \"Dataset Name\": \"FineGym: A Hierarchical Video Dataset for Fine-grained Action Understanding (CVPR 2020)\", \"Paper Title\": \"FineGym: A Hierarchical Video Dataset for Fine-grained Action Understanding (CVPR 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2004.06704\", \"GitHub URL\": \"https://github.com/SDOlivia/FineGym/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/finegym\", \"ArXiv URL\": \"https://arxiv.org/abs/2004.06704\", \"Semantic Scholar Corpus ID\": 215754360, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://sdolivia.github.io/FineGym/\"}], \"Creators\": [\"The Chinese University of Hong Kong\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 708.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"tiny-virat\", \"Collection\": \"tiny-virat\", \"Collection URL\": \"https://arxiv.org/abs/2007.07355\", \"Dataset Name\": \"TinyVIRAT: Low-resolution Video Action Recognition\", \"Paper Title\": \"TinyVIRAT: Low-resolution Video Action Recognition\", \"Paper URL\": \"https://arxiv.org/abs/2007.07355\", \"GitHub URL\": \"https://github.com/UgurDemir/Tiny-VIRAT\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tinyvirat\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.07355\", \"Semantic Scholar Corpus ID\": 220525685, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Central Florida\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 10.83, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hyu-vids\", \"Collection\": \"hyu-vids\", \"Collection URL\": \"https://arxiv.org/abs/1904.11451\", \"Dataset Name\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper Title\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/1904.11451\", \"GitHub URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/holistic-large-scale-video-understanding\", \"ArXiv URL\": \"https://arxiv.org/abs/1904.11451\", \"Semantic Scholar Corpus ID\": 131777079, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"ETH Z\\u00fcrich\", \"KU Leuven\", \"University of Bonn\", \"Sensifai\"], \"Countries\": [\"Switzerland\", \"Belgium\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 96166.67, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moviescenes\", \"Collection\": \"moviescenes\", \"Collection URL\": \"https://arxiv.org/abs/2004.02678\", \"Dataset Name\": \"MovieScenes\", \"Paper Title\": \"MovieScenes\", \"Paper URL\": \"https://arxiv.org/abs/2004.02678\", \"GitHub URL\": \"https://github.com/AnyiRao/SceneSeg\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-local-to-global-approach-to-multi-modal\", \"ArXiv URL\": \"https://arxiv.org/abs/2004.02678\", \"Semantic Scholar Corpus ID\": 214802984, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"The Chinese University of Hong Kong\", \"UC Berkeley\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 250.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Misc (Scene Segmentation)\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"rare-act-dataset\", \"Collection\": \"rare-act-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Dataset Name\": \"RareAct: A video dataset of unusual interactions\", \"Paper Title\": \"RareAct: A video dataset of unusual interactions\", \"Paper URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"GitHub URL\": \"https://github.com/antoine77340/RareAct\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/rareact\", \"ArXiv URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Semantic Scholar Corpus ID\": 220936243, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Oxford\", \"Ecole Normale Sup\\u00e9rieure\", \"Inria\", \"CIIRC\", \"Czech Technical University\"], \"Countries\": [\"United Kingdom\", \"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 21.13, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"oops-dataset\", \"Collection\": \"oops-dataset\", \"Collection URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Epstein_Oops_Predicting_Unintentional_Action_in_Video_CVPR_2020_paper.pdf\", \"Dataset Name\": \"Oops!: Predicting Unintentional Action in Video (CVPR 2020)\", \"Paper Title\": \"Oops!: Predicting Unintentional Action in Video (CVPR 2020)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Epstein_Oops_Predicting_Unintentional_Action_in_Video_CVPR_2020_paper.pdf\", \"GitHub URL\": \"https://github.com/cvlab-columbia/oops\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/oops-predicting-unintentional-action-in-video\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Epstein_Oops_Predicting_Unintentional_Action_in_Video_CVPR_2020_paper.pdf\", \"Semantic Scholar Corpus ID\": 208291335, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://oops.cs.columbia.edu/data/\"}], \"Creators\": [\"Columbia University\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 50.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"violin\", \"Collection\": \"violin\", \"Collection URL\": \"https://arxiv.org/abs/2003.11618\", \"Dataset Name\": \"VIOLIN\", \"Paper Title\": \"VIOLIN\", \"Paper URL\": \"https://arxiv.org/abs/2003.11618\", \"GitHub URL\": \"https://github.com/jimmy646/violin\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/violin\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.11618\", \"Semantic Scholar Corpus ID\": 214668012, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Microsoft\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 582.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"titan\", \"Collection\": \"titan\", \"Collection URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf\", \"Dataset Name\": \"TITAN: Future Forecast using Action Priors (CVPR 2020)\", \"Paper Title\": \"TITAN: Future Forecast using Action Priors (CVPR 2020)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/titan-future-forecast-using-action-priors\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf\", \"Semantic Scholar Corpus ID\": 214727763, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Non Commercial\", \"License URL\": \"https://usa.honda-ri.com/titan\"}], \"Creators\": [\"Honda Research Institute\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 2.91, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"movie-net\", \"Collection\": \"movie-net\", \"Collection URL\": \"https://arxiv.org/abs/2007.10937\", \"Dataset Name\": \"MovieNet\", \"Paper Title\": \"MovieNet\", \"Paper URL\": \"https://arxiv.org/abs/2007.10937\", \"GitHub URL\": \"https://github.com/movienet/movienet-tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/movienet\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.10937\", \"Semantic Scholar Corpus ID\": 220665753, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"The Chinese University of Hong Kong\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3000.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Summarization\", \"Misc\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"lemma-dataset\", \"Collection\": \"lemma-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2007.15781\", \"Dataset Name\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper Title\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2007.15781\", \"GitHub URL\": \"https://github.com/Buzz-Beater/LEMMA\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/lemma\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.15781\", \"Semantic Scholar Corpus ID\": 220634784, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\", \"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"UCLA\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 10.8, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"lemma-dataset\", \"Collection\": \"lemma-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2007.15781\", \"Dataset Name\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper Title\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2007.15781\", \"GitHub URL\": \"https://github.com/Buzz-Beater/LEMMA\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/lemma\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.15781\", \"Semantic Scholar Corpus ID\": 220634784, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\", \"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"UCLA\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 10.8, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"homage\", \"Collection\": \"homage\", \"Collection URL\": \"https://arxiv.org/abs/2105.05226\", \"Dataset Name\": \"HOMAGE: Home Action Genome: Cooperative Compositional Action Understanding (CVPR 2021)\", \"Paper Title\": \"HOMAGE: Home Action Genome: Cooperative Compositional Action Understanding (CVPR 2021)\", \"Paper URL\": \"https://arxiv.org/abs/2105.05226\", \"GitHub URL\": \"https://github.com/nishantrai18/homage\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/home-action-genome-cooperative-compositional\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.05226\", \"Semantic Scholar Corpus ID\": 234357543, \"Year Released\": \"2021\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Stanford University\", \"Panasonic Corporation\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 30.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\", \"Temporal Action Segmentation\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"WebVid\", \"Collection\": \"WebVid\", \"Collection URL\": \"https://arxiv.org/abs/2104.00650\", \"Dataset Name\": \"WebVid\", \"Paper Title\": \"WebVid\", \"Paper URL\": \"https://arxiv.org/abs/2104.00650\", \"GitHub URL\": \"https://github.com/m-bain/webvid\", \"Hugging Face URL\": \"https://huggingface.co/datasets/TempoFunk/webvid-10M\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/webvid\", \"ArXiv URL\": \"https://arxiv.org/abs/2104.00650\", \"Semantic Scholar Corpus ID\": 232478955, \"Year Released\": \"2021\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/m-bain/webvid/blob/main/TERMS.md\"}], \"Creators\": [\"University of Oxford\", \"CNRS\"], \"Countries\": [\"United Kingdom\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13000.0, \"Taken Down\": \"True\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"uav-human\", \"Collection\": \"uav-human\", \"Collection URL\": \"https://arxiv.org/abs/2104.00946\", \"Dataset Name\": \"UAV-Human: A Large Benchmark for Human Behavior Understanding with Unmanned Aerial Vehicles\", \"Paper Title\": \"UAV-Human: A Large Benchmark for Human Behavior Understanding with Unmanned Aerial Vehicles\", \"Paper URL\": \"https://arxiv.org/abs/2104.00946\", \"GitHub URL\": \"https://github.com/sutdcv/UAV-Human\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/uav-human-a-large-benchmark-for-human\", \"ArXiv URL\": \"https://arxiv.org/abs/2104.00946\", \"Semantic Scholar Corpus ID\": 233004700, \"Year Released\": \"2021\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://sutdcv.github.io/uav-human-web/\"}], \"Creators\": [\"Shandong University\", \"Singapore University of Technology and Design\"], \"Countries\": [\"Singapore\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 18.34, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hd-vila-100m\", \"Collection\": \"hd-vila-100m\", \"Collection URL\": \"https://arxiv.org/abs/2111.10337\", \"Dataset Name\": \"Advancing High-Resolution Video-Language Representation with Large-Scale Video Transcriptions\", \"Paper Title\": \"Advancing High-Resolution Video-Language Representation with Large-Scale Video Transcriptions\", \"Paper URL\": \"https://arxiv.org/abs/2111.10337\", \"GitHub URL\": \"https://github.com/microsoft/XPretrain/blob/main/hd-vila-100m/README.md\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/advancing-high-resolution-video-language/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2111.10337\", \"Semantic Scholar Corpus ID\": 244462849, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/microsoft/XPretrain/blob/main/hd-vila-100m/README.md\"}], \"Creators\": [\"Microsoft\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 371.5, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"videolt-dataset\", \"Collection\": \"videolt-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2105.02668\", \"Dataset Name\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper Title\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper URL\": \"https://arxiv.org/abs/2105.02668\", \"GitHub URL\": \"https://github.com/17Skye17/VideoLT\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/videolt\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.02668\", \"Semantic Scholar Corpus ID\": 233864776, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Non Commercial\", \"License URL\": \"https://github.com/17Skye17/VideoLT?tab=readme-ov-file#data-preparation\"}], \"Creators\": [\"Fudan University\", \"Shanghai Collaborative Innovation Center of Intelligent Visual Computing\", \"Inception Institute of Artificial Intelligence\", \"University of Maryland\"], \"Countries\": [\"China\", \"UAE\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13664.96, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"YT-Temporal-180m\", \"Collection\": \"YT-Temporal-180m\", \"Collection URL\": \"https://arxiv.org/pdf/2106.02636\", \"Dataset Name\": \"MERLOT: Multimodal Neural Script Knowledge Models\", \"Paper Title\": \"MERLOT: Multimodal Neural Script Knowledge Models\", \"Paper URL\": \"https://arxiv.org/pdf/2106.02636\", \"GitHub URL\": \"https://github.com/rowanz/merlot\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/yttemporal180m\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/merlot-multimodal-neural-script-knowledge\", \"ArXiv URL\": \"https://arxiv.org/pdf/2106.02636\", \"Semantic Scholar Corpus ID\": 235352775, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/rowanz/merlot/blob/main/LICENSE\"}], \"Creators\": [\"University of Washington\", \"Allen Institute for AI\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1515.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"queryd\", \"Collection\": \"queryd\", \"Collection URL\": \"https://arxiv.org/abs/2011.11071\", \"Dataset Name\": \"QuerYD\", \"Paper Title\": \"QuerYD\", \"Paper URL\": \"https://arxiv.org/abs/2011.11071\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/queryd\", \"ArXiv URL\": \"https://arxiv.org/abs/2011.11071\", \"Semantic Scholar Corpus ID\": 261006321, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"youdescribe\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Oxford\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 207.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"queryd\", \"Collection\": \"queryd\", \"Collection URL\": \"https://arxiv.org/abs/2011.11071\", \"Dataset Name\": \"QuerYD\", \"Paper Title\": \"QuerYD\", \"Paper URL\": \"https://arxiv.org/abs/2011.11071\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/queryd\", \"ArXiv URL\": \"https://arxiv.org/abs/2011.11071\", \"Semantic Scholar Corpus ID\": 261006321, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"youdescribe\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Oxford\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 207.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"multi-moments-in-time-dataset\", \"Collection\": \"multi-moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Dataset Name\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper Title\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Semantic Scholar Corpus ID\": 207780280, \"Year Released\": \"2021\", \"Text Sources\": [\"crowdsourced\", \"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"flickr\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"multi-moments-in-time-dataset\", \"Collection\": \"multi-moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Dataset Name\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper Title\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Semantic Scholar Corpus ID\": 207780280, \"Year Released\": \"2021\", \"Text Sources\": [\"crowdsourced\", \"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"apes\", \"Collection\": \"apes\", \"Collection URL\": \"https://arxiv.org/pdf/2106.01667\", \"Dataset Name\": \"Apes\", \"Paper Title\": \"Apes\", \"Paper URL\": \"https://arxiv.org/pdf/2106.01667\", \"GitHub URL\": \"https://github.com/fuankarion/audiovisual-person-search\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/apes-audiovisual-person-search-in-untrimmed/review/\", \"ArXiv URL\": \"https://arxiv.org/pdf/2106.01667\", \"Semantic Scholar Corpus ID\": 235313698, \"Year Released\": \"2021\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Universidad de los Andes\", \"Adobe Research\", \"King Abdullah University of Science and Technology (KAUST)\"], \"Countries\": [\"Chile\", \"United States of America\", \"Saudi Arabia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 36.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"mimetics-dataset\", \"Collection\": \"mimetics-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1912.07249\", \"Dataset Name\": \"Mimetics: Towards Understanding Human Actions Out of Context\", \"Paper Title\": \"Mimetics: Towards Understanding Human Actions Out of Context\", \"Paper URL\": \"https://arxiv.org/abs/1912.07249\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/mimetics-towards-understanding-human-actions\", \"ArXiv URL\": \"https://arxiv.org/abs/1912.07249\", \"Semantic Scholar Corpus ID\": 209376248, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Naver\"], \"Countries\": [\"South Korea\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.99, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"ego-4d\", \"Collection\": \"ego-4d\", \"Collection URL\": \"https://arxiv.org/abs/2110.07058\", \"Dataset Name\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper Title\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper URL\": \"https://arxiv.org/abs/2110.07058\", \"GitHub URL\": \"https://github.com/EGO4D/forecasting\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego4d-around-the-world-in-3000-hours-of\", \"ArXiv URL\": \"https://arxiv.org/abs/2110.07058\", \"Semantic Scholar Corpus ID\": 238856888, \"Year Released\": \"2022\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://ego4d-data.org/pdfs/Ego4D-Licenses-Draft.pdf\"}], \"Creators\": [\"Facebook AI Research\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3670.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\", \"Temporal Action Segmentation\", \"Video Captioning\", \"Misc\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"YT-Temporal-1B\", \"Collection\": \"YT-Temporal-1B\", \"Collection URL\": \"https://arxiv.org/pdf/2201.02639\", \"Dataset Name\": \"MERLOT Reserve: Multimodal Neural Script Knowledge through Vision and Language and Sound\", \"Paper Title\": \"MERLOT Reserve: Multimodal Neural Script Knowledge through Vision and Language and Sound\", \"Paper URL\": \"https://arxiv.org/pdf/2201.02639\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/merlot-reserve-neural-script-knowledge\", \"ArXiv URL\": \"https://arxiv.org/pdf/2201.02639\", \"Semantic Scholar Corpus ID\": 245837609, \"Year Released\": \"2022\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/rowanz/merlot_reserve/blob/main/LICENSE\"}], \"Creators\": [\"University of Washington\", \"Allen Institute for AI\", \"University of Edinburgh\"], \"Countries\": [\"United States of America\", \"Scotland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 55555.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"mad\", \"Collection\": \"mad\", \"Collection URL\": \"https://arxiv.org/abs/2112.00431\", \"Dataset Name\": \"MAD: A Scalable Dataset for Language Grounding in Videos from Movie Audio Descriptions\", \"Paper Title\": \"MAD: A Scalable Dataset for Language Grounding in Videos from Movie Audio Descriptions\", \"Paper URL\": \"https://arxiv.org/abs/2112.00431\", \"GitHub URL\": \"https://github.com/Soldelli/MAD\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mad\", \"ArXiv URL\": \"https://arxiv.org/abs/2112.00431\", \"Semantic Scholar Corpus ID\": 244773187, \"Year Released\": \"2022\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdtUV3uweS0u7AHAMIJAL_dRRdZ5MHpJS3fdZVbhnVt-Yb4NA/viewform\"}], \"Creators\": [\"King Abdullah University of Science and Technology (KAUST)\"], \"Countries\": [\"Saudi Arabia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1207.3, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"cacd\", \"Collection\": \"cacd\", \"Collection URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"Dataset Name\": \"CDAD: A Common Daily Action Dataset with Collected Hard Negative Samples (CVPR 2022)\", \"Paper Title\": \"CDAD: A Common Daily Action Dataset with Collected Hard Negative Samples (CVPR 2022)\", \"Paper URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"GitHub URL\": \"https://github.com/MartinXM/CDAD\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"Semantic Scholar Corpus ID\": 251035434, \"Year Released\": \"2022\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"The Hong Kong Polytechnic University\", \"Alibaba Group\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 215.0, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"ferv39k-dataset\", \"Collection\": \"ferv39k-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2203.09463\", \"Dataset Name\": \"FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos (CVPR 2022)\", \"Paper Title\": \"FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos (CVPR 2022)\", \"Paper URL\": \"https://arxiv.org/abs/2203.09463\", \"GitHub URL\": \"https://github.com/wangyanckxx/FERV39k\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ferv39k-a-large-scale-multi-scene-dataset-for\", \"ArXiv URL\": \"https://arxiv.org/abs/2203.09463\", \"Semantic Scholar Corpus ID\": 247518747, \"Year Released\": \"2022\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://wangyanckxx.github.io/Proj_CVPR2022_FERV39k.html\"}], \"Creators\": [\"Fudan University\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 16.47, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"ego-exo4D\", \"Collection\": \"ego-exo4D\", \"Collection URL\": \"https://arxiv.org/abs/2311.18259\", \"Dataset Name\": \"Ego-Exo4D\", \"Paper Title\": \"Ego-Exo4D\", \"Paper URL\": \"https://arxiv.org/abs/2311.18259\", \"GitHub URL\": \"https://github.com/facebookresearch/Ego4d\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego-exo4d-understanding-skilled-human/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2311.18259\", \"Semantic Scholar Corpus ID\": 265506384, \"Year Released\": \"2023\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/facebookresearch/Ego4d/blob/main/LICENSE\"}], \"Creators\": [\"Meta\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1422.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Pose Estimation\", \"Video Classification\", \"Video Captioning\", \"Misc\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"project-aria-digital-twin-dataset\", \"Collection\": \"project-aria-digital-twin-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2306.06362\", \"Dataset Name\": \"Aria Digital Twin\", \"Paper Title\": \"Aria Digital Twin\", \"Paper URL\": \"https://arxiv.org/abs/2306.06362\", \"GitHub URL\": \"https://github.com/facebookresearch/projectaria_tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/aria-digital-twin-a-new-benchmark-dataset-for\", \"ArXiv URL\": \"https://arxiv.org/abs/2306.06362\", \"Semantic Scholar Corpus ID\": 261243365, \"Year Released\": \"2023\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/facebookresearch/projectaria_tools/blob/main/LICENSE\"}], \"Creators\": [\"Meta\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 6.6, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Object Detection\", \"Video Segmentation\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"cinepile\", \"Collection\": \"cinepile\", \"Collection URL\": \"https://arxiv.org/pdf/2405.08813\", \"Dataset Name\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper Title\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper URL\": \"https://arxiv.org/pdf/2405.08813\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/tomg-group-umd/cinepile\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/cinepile\", \"ArXiv URL\": \"https://arxiv.org/pdf/2405.08813\", \"Semantic Scholar Corpus ID\": 269761335, \"Year Released\": \"2024\", \"Text Sources\": [\"youtube\", \"movies\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://creativecommons.org/licenses/by/4.0/\"}], \"Creators\": [\"University of Maryland\", \"Weizmann Institute of Science\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 417.6, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"egopet\", \"Collection\": \"egopet\", \"Collection URL\": \"https://arxiv.org/pdf/2404.09991\", \"Dataset Name\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper Title\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper URL\": \"https://arxiv.org/pdf/2404.09991\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egopet-egomotion-and-interaction-data-from-an\", \"ArXiv URL\": \"https://arxiv.org/pdf/2404.09991\", \"Semantic Scholar Corpus ID\": 269148727, \"Year Released\": \"2024\", \"Text Sources\": [\"tiktok\", \"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://github.com/DannyTran123/egopet/blob/main/LICENSE\"}], \"Creators\": [\"Tel Aviv University\", \"UC Berkeley\", \"New York University\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 84.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Misc (Locomotion Prediction\", \"Visual Interaction Prediction\", \"Vision to Proprioception Prediction)\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"project-aria-dataset\", \"Collection\": \"project-aria-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/2402.13349\", \"Dataset Name\": \"Aria Everyday Activities Dataset\", \"Paper Title\": \"Aria Everyday Activities Dataset\", \"Paper URL\": \"https://arxiv.org/pdf/2402.13349\", \"GitHub URL\": \"https://github.com/facebookresearch/projectaria_tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/aria-everyday-activities-dataset\", \"ArXiv URL\": \"https://arxiv.org/pdf/2402.13349\", \"Semantic Scholar Corpus ID\": 267770215, \"Year Released\": \"2024\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/facebookresearch/Aria_data_tools/blob/main/LICENSE\"}], \"Creators\": [\"Meta\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1400.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Misc (Scene Reconstruction)\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"cinepile\", \"Collection\": \"cinepile\", \"Collection URL\": \"https://arxiv.org/pdf/2405.08813\", \"Dataset Name\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper Title\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper URL\": \"https://arxiv.org/pdf/2405.08813\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/tomg-group-umd/cinepile\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/cinepile\", \"ArXiv URL\": \"https://arxiv.org/pdf/2405.08813\", \"Semantic Scholar Corpus ID\": 269761335, \"Year Released\": \"2024\", \"Text Sources\": [\"youtube\", \"movies\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://creativecommons.org/licenses/by/4.0/\"}], \"Creators\": [\"University of Maryland\", \"Weizmann Institute of Science\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 417.6, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"egopet\", \"Collection\": \"egopet\", \"Collection URL\": \"https://arxiv.org/pdf/2404.09991\", \"Dataset Name\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper Title\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper URL\": \"https://arxiv.org/pdf/2404.09991\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egopet-egomotion-and-interaction-data-from-an\", \"ArXiv URL\": \"https://arxiv.org/pdf/2404.09991\", \"Semantic Scholar Corpus ID\": 269148727, \"Year Released\": \"2024\", \"Text Sources\": [\"tiktok\", \"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://github.com/DannyTran123/egopet/blob/main/LICENSE\"}], \"Creators\": [\"Tel Aviv University\", \"UC Berkeley\", \"New York University\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 84.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Misc (Locomotion Prediction\", \"Visual Interaction Prediction\", \"Vision to Proprioception Prediction)\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"egoschema\", \"Collection\": \"egoschema\", \"Collection URL\": \"https://arxiv.org/pdf/2308.09126\", \"Dataset Name\": \"EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding\", \"Paper Title\": \"EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding\", \"Paper URL\": \"https://arxiv.org/pdf/2308.09126\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egoschema-a-diagnostic-benchmark-for-very-1\", \"ArXiv URL\": \"https://arxiv.org/pdf/2308.09126\", \"Semantic Scholar Corpus ID\": 261031047, \"Year Released\": \"2024\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"UC Berkeley\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 250.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_sourceyear = alt.Chart(\n",
    "    df_videosourceyears\n",
    ").mark_bar().encode(\n",
    "    x=alt.X(\n",
    "        \"Year Released:N\",\n",
    "        title=\"Year Released\",\n",
    "        sort=YEARS_ORDER,\n",
    "        axis=alt.Axis(labelAngle=-30)\n",
    "    ),\n",
    "    y=alt.Y(\n",
    "        \"count():Q\",\n",
    "        stack=\"normalize\",\n",
    "        axis=alt.Axis(format=\"%\"),\n",
    "        title=\"Pct. Datasets\"\n",
    "    ),\n",
    "    color=alt.Color(\n",
    "        \"Video Sources:N\",\n",
    "        title=\"Video Sources\"\n",
    "    )\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=160\n",
    ")\n",
    "\n",
    "text_sourceyear = alt.Chart(df_videosourceyears).mark_text(\n",
    "    dy=-90,\n",
    "    align=\"center\",\n",
    "    baseline=\"top\",\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    x=alt.X(\n",
    "        \"Year Released:N\",\n",
    "        title=\"Year Released\",\n",
    "        sort=YEARS_ORDER\n",
    "    ),\n",
    "    text=\"count():Q\"\n",
    ")\n",
    "\n",
    "chart_sourceyear = (base_sourceyear + text_sourceyear).configure_axis(\n",
    "    labelFontSize=FONT_SIZE,\n",
    "    titleFontSize=FONT_SIZE\n",
    ").configure_legend(\n",
    "    labelFontSize=FONT_SIZE,\n",
    "    titleFontSize=FONT_SIZE,\n",
    "    orient=LEGEND_POSITION,\n",
    "    columns=4,\n",
    "    labelLimit=MAX_LABELLIMIT\n",
    ")\n",
    "\n",
    "\n",
    "if PLOT_TOFILE:\n",
    "    chart_sourceyear.save(\n",
    "        os.path.join(PLOT_DIR, \"video_sourcecategories-years.png\"),\n",
    "        ppi=PLOT_PPI\n",
    "    )\n",
    "\n",
    "chart_sourceyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creator Category by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creators\n",
      "Academic          132\n",
      "Corporation        20\n",
      "Industry Lab       17\n",
      "Research Group     12\n",
      "Other               6\n",
      "Government          1\n",
      "Startup             1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Creators</th>\n",
       "      <th>Year Released</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Research Group</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Creators Year Released\n",
       "3         Academic          2009\n",
       "5   Research Group          2009\n",
       "68        Academic          2011\n",
       "68        Academic          2011\n",
       "68        Academic          2011"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video['Creators'] = df_video['Creators'].apply(\n",
    "    lambda x: [creator_categories.get(item, item) for item in x]\n",
    ")\n",
    "\n",
    "print(df_video['Creators'].explode().value_counts())\n",
    "\n",
    "INCLUDE_TOP_N_CATEGORIES = 6\n",
    "df_videocreatoryears = df_video.explode(\"Creators\")\n",
    "df_videocreatoryears = reduce_categories_to_topk(df_videocreatoryears, \"Creators\", INCLUDE_TOP_N_CATEGORIES)\n",
    "\n",
    "df_videocreatoryears = df_videocreatoryears.sort_values(by=\"Year Released\")\n",
    "df_videocreatoryears.head()[['Creators', 'Year Released']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-9c964aed7c3844a0ae27f58bb87868e4.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-9c964aed7c3844a0ae27f58bb87868e4.vega-embed details,\n",
       "  #altair-viz-9c964aed7c3844a0ae27f58bb87868e4.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-9c964aed7c3844a0ae27f58bb87868e4\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-9c964aed7c3844a0ae27f58bb87868e4\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-9c964aed7c3844a0ae27f58bb87868e4\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"Times New Roman\"}, \"axis\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\", \"labelFontSize\": 20, \"titleFontSize\": 20}, \"header\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\"}, \"legend\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\", \"columns\": 4, \"labelFontSize\": 20, \"labelLimit\": 1000, \"orient\": \"bottom\", \"titleFontSize\": 20}, \"text\": {\"font\": \"Times New Roman\"}}, \"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"Creators\", \"title\": \"Video Creator Cateogies\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30}, \"field\": \"Year Released\", \"sort\": [\"<2004\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"], \"title\": \"Year Released\", \"type\": \"nominal\"}, \"y\": {\"aggregate\": \"count\", \"axis\": {\"format\": \"%\"}, \"stack\": \"normalize\", \"title\": \"Pct. Datasets\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"top\", \"dy\": -90, \"fontSize\": 12}, \"encoding\": {\"text\": {\"aggregate\": \"count\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"Year Released\", \"sort\": [\"<2004\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"], \"title\": \"Year Released\", \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-6bf519bf71a63f824c0ec5b1506b7ef4\"}, \"height\": 160, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-6bf519bf71a63f824c0ec5b1506b7ef4\": [{\"Unique Dataset Identifier\": \"collective\", \"Collection\": \"collective\", \"Collection URL\": \"https://cvgl.stanford.edu/papers/Wongun_CollectiveActivityRecognition09.pdf\", \"Dataset Name\": \"Collective: What are they doing? : Collective activity classification using spatio-temporal relationship among people\", \"Paper Title\": \"Collective: What are they doing? : Collective activity classification using spatio-temporal relationship among people\", \"Paper URL\": \"https://cvgl.stanford.edu/papers/Wongun_CollectiveActivityRecognition09.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://cvgl.stanford.edu/papers/Wongun_CollectiveActivityRecognition09.pdf\", \"Semantic Scholar Corpus ID\": 5925915, \"Year Released\": \"2009\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.1, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Group Activity Recognition\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hollywood2-dataset\", \"Collection\": \"hollywood2-dataset\", \"Collection URL\": \"https://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf\", \"Dataset Name\": \"HOLLYWOOD2: Actions in Context (CVPR 2009)\", \"Paper Title\": \"HOLLYWOOD2: Actions in Context (CVPR 2009)\", \"Paper URL\": \"https://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf\", \"Semantic Scholar Corpus ID\": 3155054, \"Year Released\": \"2009\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Research Group\", \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 20.1, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ucf101-dataset\", \"Collection\": \"ucf101-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1212.0402\", \"Dataset Name\": \"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\", \"Paper Title\": \"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\", \"Paper URL\": \"https://arxiv.org/abs/1212.0402\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/ucf101\", \"ArXiv URL\": \"https://arxiv.org/abs/1212.0402\", \"Semantic Scholar Corpus ID\": 7197134, \"Year Released\": \"2012\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 26.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"youcook\", \"Collection\": \"youcook\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2013/papers/Das_A_Thousand_Frames_2013_CVPR_paper.pdf\", \"Dataset Name\": \"YouCook: A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching (CVPR 2013)\", \"Paper Title\": \"YouCook: A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching (CVPR 2013)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2013/papers/Das_A_Thousand_Frames_2013_CVPR_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youcook\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2013/papers/Das_A_Thousand_Frames_2013_CVPR_paper.pdf\", \"Semantic Scholar Corpus ID\": 12284555, \"Year Released\": \"2013\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"50salads\", \"Collection\": \"50salads\", \"Collection URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"Dataset Name\": \"50Salads\", \"Paper Title\": \"50Salads\", \"Paper URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/50-salads\", \"ArXiv URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"Semantic Scholar Corpus ID\": 2333743, \"Year Released\": \"2013\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://cvip.computing.dundee.ac.uk/datasets/foodpreparation/50salads/\"}], \"Creators\": \"Academic\", \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 40.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Action Segmentation\", \"Action Localization\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"summe\", \"Collection\": \"summe\", \"Collection URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"Dataset Name\": \"SumMe: Creating Summaries from User Videos (ECCV 2014)\", \"Paper Title\": \"SumMe: Creating Summaries from User Videos (ECCV 2014)\", \"Paper URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/summe\", \"ArXiv URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"Semantic Scholar Corpus ID\": 2111093, \"Year Released\": \"2014\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Corporation\", \"Countries\": [\"Belgium\", \"Switzerland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1.11, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"videostory\", \"Collection\": \"videostory\", \"Collection URL\": \"https://isis-data.science.uva.nl/cgmsnoek/pub/habibian-videostory-mm2014.pdf\", \"Dataset Name\": \"VideoStory: A New Multimedia Embedding for Few-Example Recognition and Translation of Events\", \"Paper Title\": \"VideoStory: A New Multimedia Embedding for Few-Example Recognition and Translation of Events\", \"Paper URL\": \"https://isis-data.science.uva.nl/cgmsnoek/pub/habibian-videostory-mm2014.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://isis-data.science.uva.nl/cgmsnoek/pub/habibian-videostory-mm2014.pdf\", \"Semantic Scholar Corpus ID\": 28203, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"Netherlands\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 743.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"stroygraphs\", \"Collection\": \"stroygraphs\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/papers/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.pdf\", \"Dataset Name\": \"StoryGraphs\", \"Paper Title\": \"StoryGraphs\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/papers/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.pdf\", \"GitHub URL\": \"https://github.com/makarandtapaswi/StoryGraphs_CVPR2014\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/storygraphs-visualizing-character\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/papers/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.pdf\", \"Semantic Scholar Corpus ID\": 1055956, \"Year Released\": \"2014\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7.3, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Misc\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hollywood-extended\", \"Collection\": \"hollywood-extended\", \"Collection URL\": \"https://arxiv.org/pdf/1407.1208\", \"Dataset Name\": \"Hollywood Extended\", \"Paper Title\": \"Hollywood Extended\", \"Paper URL\": \"https://arxiv.org/pdf/1407.1208\", \"GitHub URL\": \"https://github.com/piotr-bojanowski/action-ordering\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/weakly-supervised-action-labeling-in-videos\", \"ArXiv URL\": \"https://arxiv.org/pdf/1407.1208\", \"Semantic Scholar Corpus ID\": 9342651, \"Year Released\": \"2014\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/piotr-bojanowski/action-ordering/blob/master/LICENSE\"}], \"Creators\": \"Research Group\", \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 8.75, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Temporal Action Detection\", \"Action Recognition\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"sports1M-dataset\", \"Collection\": \"sports1M-dataset\", \"Collection URL\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\", \"Dataset Name\": \"Sports-1M: Large-scale Video Classification with Convolutional Neural Networks\", \"Paper Title\": \"Sports-1M: Large-scale Video Classification with Convolutional Neural Networks\", \"Paper URL\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\", \"GitHub URL\": \"https://github.com/gtoderici/sports-1m-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/large-scale-video-classification-with-1\", \"ArXiv URL\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\", \"Semantic Scholar Corpus ID\": 206592218, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 3.0\", \"License URL\": \"https://github.com/gtoderici/sports-1m-dataset\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 105761.41, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"summe\", \"Collection\": \"summe\", \"Collection URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"Dataset Name\": \"SumMe: Creating Summaries from User Videos (ECCV 2014)\", \"Paper Title\": \"SumMe: Creating Summaries from User Videos (ECCV 2014)\", \"Paper URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/summe\", \"ArXiv URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"Semantic Scholar Corpus ID\": 2111093, \"Year Released\": \"2014\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"Belgium\", \"Switzerland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1.11, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"thumos-challenge\", \"Collection\": \"thumos-challenge\", \"Collection URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Dataset Name\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper Title\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/thumos14-1\", \"ArXiv URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Semantic Scholar Corpus ID\": 14049355, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLScs9davISAtYQS7SEF5qQNu0jUpLzNH3aHmPfuqk2q1VYDkmw/viewform\"}], \"Creators\": \"Research Group\", \"Countries\": [\"United States of America\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 254.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"thumos-challenge\", \"Collection\": \"thumos-challenge\", \"Collection URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Dataset Name\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper Title\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/thumos14-1\", \"ArXiv URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Semantic Scholar Corpus ID\": 14049355, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLScs9davISAtYQS7SEF5qQNu0jUpLzNH3aHmPfuqk2q1VYDkmw/viewform\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 254.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"thumos-challenge\", \"Collection\": \"thumos-challenge\", \"Collection URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Dataset Name\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper Title\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/thumos14-1\", \"ArXiv URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Semantic Scholar Corpus ID\": 14049355, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLScs9davISAtYQS7SEF5qQNu0jUpLzNH3aHmPfuqk2q1VYDkmw/viewform\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 254.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"thumos-challenge\", \"Collection\": \"thumos-challenge\", \"Collection URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Dataset Name\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper Title\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/thumos14-1\", \"ArXiv URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Semantic Scholar Corpus ID\": 14049355, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLScs9davISAtYQS7SEF5qQNu0jUpLzNH3aHmPfuqk2q1VYDkmw/viewform\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 254.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"breakfast\", \"Collection\": \"breakfast\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"Dataset Name\": \"Breakfast\", \"Paper Title\": \"Breakfast\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/breakfast\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"Semantic Scholar Corpus ID\": 9621856, \"Year Released\": \"2014\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/breakfast-actions-dataset/\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 77.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Captioning\", \"Action Segmentation\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"summe\", \"Collection\": \"summe\", \"Collection URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"Dataset Name\": \"SumMe: Creating Summaries from User Videos (ECCV 2014)\", \"Paper Title\": \"SumMe: Creating Summaries from User Videos (ECCV 2014)\", \"Paper URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/summe\", \"ArXiv URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"Semantic Scholar Corpus ID\": 2111093, \"Year Released\": \"2014\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"Belgium\", \"Switzerland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1.11, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"breakfast\", \"Collection\": \"breakfast\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"Dataset Name\": \"Breakfast\", \"Paper Title\": \"Breakfast\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/breakfast\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"Semantic Scholar Corpus ID\": 9621856, \"Year Released\": \"2014\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/breakfast-actions-dataset/\"}], \"Creators\": \"Research Group\", \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 77.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Captioning\", \"Action Segmentation\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"volleyball-vids\", \"Collection\": \"volleyball-vids\", \"Collection URL\": \"https://arxiv.org/abs/1511.06040\", \"Dataset Name\": \"Volleyball: A Hierarchical Deep Temporal Model for Group Activity Recognition\", \"Paper Title\": \"Volleyball: A Hierarchical Deep Temporal Model for Group Activity Recognition\", \"Paper URL\": \"https://arxiv.org/abs/1511.06040\", \"GitHub URL\": \"https://github.com/mostafa-saad/deep-activity-rec#dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/volleyball\", \"ArXiv URL\": \"https://arxiv.org/abs/1511.06040\", \"Semantic Scholar Corpus ID\": 8483403, \"Year Released\": \"2015\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.1, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Group Activity Recognition\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"movieqa\", \"Collection\": \"movieqa\", \"Collection URL\": \"https://arxiv.org/abs/1512.02902\", \"Dataset Name\": \"MovieQA\", \"Paper Title\": \"MovieQA\", \"Paper URL\": \"https://arxiv.org/abs/1512.02902\", \"GitHub URL\": \"https://github.com/makarandtapaswi/MovieQA_CVPR2016/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/movieqa\", \"ArXiv URL\": \"https://arxiv.org/abs/1512.02902\", \"Semantic Scholar Corpus ID\": 1017389, \"Year Released\": \"2015\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"Germany\", \"Canada\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 381.0, \"Taken Down\": \"True\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Question Answering\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"movieqa\", \"Collection\": \"movieqa\", \"Collection URL\": \"https://arxiv.org/abs/1512.02902\", \"Dataset Name\": \"MovieQA\", \"Paper Title\": \"MovieQA\", \"Paper URL\": \"https://arxiv.org/abs/1512.02902\", \"GitHub URL\": \"https://github.com/makarandtapaswi/MovieQA_CVPR2016/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/movieqa\", \"ArXiv URL\": \"https://arxiv.org/abs/1512.02902\", \"Semantic Scholar Corpus ID\": 1017389, \"Year Released\": \"2015\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"Germany\", \"Canada\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 381.0, \"Taken Down\": \"True\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Question Answering\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"movieqa\", \"Collection\": \"movieqa\", \"Collection URL\": \"https://arxiv.org/abs/1512.02902\", \"Dataset Name\": \"MovieQA\", \"Paper Title\": \"MovieQA\", \"Paper URL\": \"https://arxiv.org/abs/1512.02902\", \"GitHub URL\": \"https://github.com/makarandtapaswi/MovieQA_CVPR2016/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/movieqa\", \"ArXiv URL\": \"https://arxiv.org/abs/1512.02902\", \"Semantic Scholar Corpus ID\": 1017389, \"Year Released\": \"2015\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"Germany\", \"Canada\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 381.0, \"Taken Down\": \"True\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Question Answering\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mpii-cooking\", \"Collection\": \"mpii-cooking\", \"Collection URL\": \"https://arxiv.org/abs/1502.06648\", \"Dataset Name\": \"MPII-Cooking: Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data (IJCV 2015)\", \"Paper Title\": \"MPII-Cooking: Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data (IJCV 2015)\", \"Paper URL\": \"https://arxiv.org/abs/1502.06648\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/recognizing-fine-grained-and-composite\", \"ArXiv URL\": \"https://arxiv.org/abs/1502.06648\", \"Semantic Scholar Corpus ID\": 14036544, \"Year Released\": \"2015\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/human-activity-recognition/mpii-cooking-activities-dataset\"}], \"Creators\": \"Academic\", \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 27.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"tvsum\", \"Collection\": \"tvsum\", \"Collection URL\": \"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\", \"Dataset Name\": \"TVSum: Summarizing web videos using titles (CVPR 2015)\", \"Paper Title\": \"TVSum: Summarizing web videos using titles (CVPR 2015)\", \"Paper URL\": \"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\", \"GitHub URL\": \"https://github.com/yalesong/tvsum\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tvsum-1\", \"ArXiv URL\": \"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\", \"Semantic Scholar Corpus ID\": 7675635, \"Year Released\": \"2015\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 3.0\", \"License URL\": \"https://github.com/yalesong/tvsum\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3.5, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"activitynet\", \"Collection\": \"activitynet\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"Dataset Name\": \"ActivityNet\", \"Paper Title\": \"ActivityNet\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/Leyo/ActivityNet_Captions\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/activitynet\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"Semantic Scholar Corpus ID\": 1710722, \"Year Released\": \"2015\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/facebookresearch/ActivityNet-Entities/blob/main/LICENSE\"}], \"Creators\": \"Academic\", \"Countries\": [\"Saudi Arabia\", \"Colombia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 849.0, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"activitynet\", \"Collection\": \"activitynet\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"Dataset Name\": \"ActivityNet\", \"Paper Title\": \"ActivityNet\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/Leyo/ActivityNet_Captions\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/activitynet\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"Semantic Scholar Corpus ID\": 1710722, \"Year Released\": \"2015\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/facebookresearch/ActivityNet-Entities/blob/main/LICENSE\"}], \"Creators\": \"Academic\", \"Countries\": [\"Saudi Arabia\", \"Colombia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 849.0, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"mpii-cooking2\", \"Collection\": \"mpii-cooking2\", \"Collection URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"Dataset Name\": \"MPII Cooking 2\", \"Paper Title\": \"MPII Cooking 2\", \"Paper URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mpii-cooking-2-dataset\", \"ArXiv URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"Semantic Scholar Corpus ID\": 14036544, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/human-activity-recognition/mpii-cooking-2-dataset/\"}], \"Creators\": \"Academic\", \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 27.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Temporal Action Detection\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"charades\", \"Collection\": \"charades\", \"Collection URL\": \"https://arxiv.org/abs/1604.01753\", \"Dataset Name\": \"Charades\", \"Paper Title\": \"Charades\", \"Paper URL\": \"https://arxiv.org/abs/1604.01753\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/charades\", \"ArXiv URL\": \"https://arxiv.org/abs/1604.01753\", \"Semantic Scholar Corpus ID\": 18061547, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades#licensing-information\"}], \"Creators\": \"Research Group\", \"Countries\": [\"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 82.3, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"charades\", \"Collection\": \"charades\", \"Collection URL\": \"https://arxiv.org/abs/1604.01753\", \"Dataset Name\": \"Charades\", \"Paper Title\": \"Charades\", \"Paper URL\": \"https://arxiv.org/abs/1604.01753\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/charades\", \"ArXiv URL\": \"https://arxiv.org/abs/1604.01753\", \"Semantic Scholar Corpus ID\": 18061547, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades#licensing-information\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 82.3, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"tgif\", \"Collection\": \"tgif\", \"Collection URL\": \"https://arxiv.org/abs/1604.02748\", \"Dataset Name\": \"TGIF\", \"Paper Title\": \"TGIF\", \"Paper URL\": \"https://arxiv.org/abs/1604.02748\", \"GitHub URL\": \"https://github.com/raingo/TGIF-Release\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/TGIF\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tgif\", \"ArXiv URL\": \"https://arxiv.org/abs/1604.02748\", \"Semantic Scholar Corpus ID\": 6262415, \"Year Released\": \"2016\", \"Text Sources\": [\"tumblr\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/raingo/TGIF-Release\"}], \"Creators\": \"Corporation\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 86.1, \"Taken Down\": \"False\", \"Video Sources\": [\"tumblr\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"tgif\", \"Collection\": \"tgif\", \"Collection URL\": \"https://arxiv.org/abs/1604.02748\", \"Dataset Name\": \"TGIF\", \"Paper Title\": \"TGIF\", \"Paper URL\": \"https://arxiv.org/abs/1604.02748\", \"GitHub URL\": \"https://github.com/raingo/TGIF-Release\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/TGIF\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tgif\", \"ArXiv URL\": \"https://arxiv.org/abs/1604.02748\", \"Semantic Scholar Corpus ID\": 6262415, \"Year Released\": \"2016\", \"Text Sources\": [\"tumblr\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/raingo/TGIF-Release\"}], \"Creators\": \"Corporation\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 86.1, \"Taken Down\": \"False\", \"Video Sources\": [\"tumblr\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"youtube-8m\", \"Collection\": \"youtube-8m\", \"Collection URL\": \"https://arxiv.org/abs/1609.08675\", \"Dataset Name\": \"Youtube-8M: A Large-Scale Video Classification Benchmark\", \"Paper Title\": \"Youtube-8M: A Large-Scale Video Classification Benchmark\", \"Paper URL\": \"https://arxiv.org/abs/1609.08675\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youtube-8m\", \"ArXiv URL\": \"https://arxiv.org/abs/1609.08675\", \"Semantic Scholar Corpus ID\": 11241677, \"Year Released\": \"2016\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 350000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"tgif\", \"Collection\": \"tgif\", \"Collection URL\": \"https://arxiv.org/abs/1604.02748\", \"Dataset Name\": \"TGIF\", \"Paper Title\": \"TGIF\", \"Paper URL\": \"https://arxiv.org/abs/1604.02748\", \"GitHub URL\": \"https://github.com/raingo/TGIF-Release\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/TGIF\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tgif\", \"ArXiv URL\": \"https://arxiv.org/abs/1604.02748\", \"Semantic Scholar Corpus ID\": 6262415, \"Year Released\": \"2016\", \"Text Sources\": [\"tumblr\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/raingo/TGIF-Release\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 86.1, \"Taken Down\": \"False\", \"Video Sources\": [\"tumblr\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"mpii-cooking2\", \"Collection\": \"mpii-cooking2\", \"Collection URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"Dataset Name\": \"MPII Cooking 2\", \"Paper Title\": \"MPII Cooking 2\", \"Paper URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mpii-cooking-2-dataset\", \"ArXiv URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"Semantic Scholar Corpus ID\": 14036544, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/human-activity-recognition/mpii-cooking-2-dataset/\"}], \"Creators\": \"Academic\", \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 27.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Temporal Action Detection\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"mars\", \"Collection\": \"mars\", \"Collection URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Dataset Name\": \"Mars\", \"Paper Title\": \"Mars\", \"Paper URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mars\", \"ArXiv URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Semantic Scholar Corpus ID\": 2214158, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.24, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Segmentation\", \"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"narrated-instruction-vids\", \"Collection\": \"narrated-instruction-vids\", \"Collection URL\": \"https://arxiv.org/abs/1506.09215\", \"Dataset Name\": \"Narrated Instruction Videos\", \"Paper Title\": \"Narrated Instruction Videos\", \"Paper URL\": \"https://arxiv.org/abs/1506.09215\", \"GitHub URL\": \"https://github.com/jalayrac/instructionVideos\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youtube-inria-instructional\", \"ArXiv URL\": \"https://arxiv.org/abs/1506.09215\", \"Semantic Scholar Corpus ID\": 2617244, \"Year Released\": \"2016\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/jalayrac/instructionVideos?tab=readme-ov-file#license\"}], \"Creators\": \"Research Group\", \"Countries\": [\"United States of America\", \"India\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"charades\", \"Collection\": \"charades\", \"Collection URL\": \"https://arxiv.org/abs/1604.01753\", \"Dataset Name\": \"Charades\", \"Paper Title\": \"Charades\", \"Paper URL\": \"https://arxiv.org/abs/1604.01753\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/charades\", \"ArXiv URL\": \"https://arxiv.org/abs/1604.01753\", \"Semantic Scholar Corpus ID\": 18061547, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades#licensing-information\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 82.3, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"msr-vtt\", \"Collection\": \"msr-vtt\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7780940\", \"Dataset Name\": \"MSR-VTT\", \"Paper Title\": \"MSR-VTT\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7780940\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/msr-vtt\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7780940\", \"Semantic Scholar Corpus ID\": 206594535, \"Year Released\": \"2016\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 41.2, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"narrated-instruction-vids\", \"Collection\": \"narrated-instruction-vids\", \"Collection URL\": \"https://arxiv.org/abs/1506.09215\", \"Dataset Name\": \"Narrated Instruction Videos\", \"Paper Title\": \"Narrated Instruction Videos\", \"Paper URL\": \"https://arxiv.org/abs/1506.09215\", \"GitHub URL\": \"https://github.com/jalayrac/instructionVideos\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youtube-inria-instructional\", \"ArXiv URL\": \"https://arxiv.org/abs/1506.09215\", \"Semantic Scholar Corpus ID\": 2617244, \"Year Released\": \"2016\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/jalayrac/instructionVideos?tab=readme-ov-file#license\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"India\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"vtw\", \"Collection\": \"vtw\", \"Collection URL\": \"https://arxiv.org/abs/1608.07068\", \"Dataset Name\": \"VTW\", \"Paper Title\": \"VTW\", \"Paper URL\": \"https://arxiv.org/abs/1608.07068\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/title-generation-for-user-generated-videos\", \"ArXiv URL\": \"https://arxiv.org/abs/1608.07068\", \"Semantic Scholar Corpus ID\": 6155397, \"Year Released\": \"2016\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 213.2, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"vtw\", \"Collection\": \"vtw\", \"Collection URL\": \"https://arxiv.org/abs/1608.07068\", \"Dataset Name\": \"VTW\", \"Paper Title\": \"VTW\", \"Paper URL\": \"https://arxiv.org/abs/1608.07068\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/title-generation-for-user-generated-videos\", \"ArXiv URL\": \"https://arxiv.org/abs/1608.07068\", \"Semantic Scholar Corpus ID\": 6155397, \"Year Released\": \"2016\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 213.2, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mars\", \"Collection\": \"mars\", \"Collection URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Dataset Name\": \"Mars\", \"Paper Title\": \"Mars\", \"Paper URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mars\", \"ArXiv URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Semantic Scholar Corpus ID\": 2214158, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.24, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Segmentation\", \"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mars\", \"Collection\": \"mars\", \"Collection URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Dataset Name\": \"Mars\", \"Paper Title\": \"Mars\", \"Paper URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mars\", \"ArXiv URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Semantic Scholar Corpus ID\": 2214158, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.24, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Segmentation\", \"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mars\", \"Collection\": \"mars\", \"Collection URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Dataset Name\": \"Mars\", \"Paper Title\": \"Mars\", \"Paper URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mars\", \"ArXiv URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Semantic Scholar Corpus ID\": 2214158, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.24, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Segmentation\", \"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"narrated-instruction-vids\", \"Collection\": \"narrated-instruction-vids\", \"Collection URL\": \"https://arxiv.org/abs/1506.09215\", \"Dataset Name\": \"Narrated Instruction Videos\", \"Paper Title\": \"Narrated Instruction Videos\", \"Paper URL\": \"https://arxiv.org/abs/1506.09215\", \"GitHub URL\": \"https://github.com/jalayrac/instructionVideos\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youtube-inria-instructional\", \"ArXiv URL\": \"https://arxiv.org/abs/1506.09215\", \"Semantic Scholar Corpus ID\": 2617244, \"Year Released\": \"2016\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/jalayrac/instructionVideos?tab=readme-ov-file#license\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"India\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"narrated-instruction-vids\", \"Collection\": \"narrated-instruction-vids\", \"Collection URL\": \"https://arxiv.org/abs/1506.09215\", \"Dataset Name\": \"Narrated Instruction Videos\", \"Paper Title\": \"Narrated Instruction Videos\", \"Paper URL\": \"https://arxiv.org/abs/1506.09215\", \"GitHub URL\": \"https://github.com/jalayrac/instructionVideos\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youtube-inria-instructional\", \"ArXiv URL\": \"https://arxiv.org/abs/1506.09215\", \"Semantic Scholar Corpus ID\": 2617244, \"Year Released\": \"2016\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/jalayrac/instructionVideos?tab=readme-ov-file#license\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"India\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"charades\", \"Collection\": \"charades\", \"Collection URL\": \"https://arxiv.org/abs/1604.01753\", \"Dataset Name\": \"Charades\", \"Paper Title\": \"Charades\", \"Paper URL\": \"https://arxiv.org/abs/1604.01753\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/charades\", \"ArXiv URL\": \"https://arxiv.org/abs/1604.01753\", \"Semantic Scholar Corpus ID\": 18061547, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades#licensing-information\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 82.3, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ntu-rgbd\", \"Collection\": \"ntu-rgbd\", \"Collection URL\": \"https://arxiv.org/pdf/1604.02808.pdf\", \"Dataset Name\": \"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis (CVPR 2016, TPAMI 2019)\", \"Paper Title\": \"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis (CVPR 2016, TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1604.02808.pdf\", \"GitHub URL\": \"https://github.com/shahroudy/NTURGB-D\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ntu-rgbd-a-large-scale-dataset-for-3d-human\", \"ArXiv URL\": \"https://arxiv.org/pdf/1604.02808.pdf\", \"Semantic Scholar Corpus ID\": 15928602, \"Year Released\": \"2016\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://rose1.ntu.edu.sg/dataset/actionRecognition/\"}], \"Creators\": \"Academic\", \"Countries\": [\"Singapore\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 74.1, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"lsmdc\", \"Collection\": \"lsmdc\", \"Collection URL\": \"https://arxiv.org/pdf/1605.03705\", \"Dataset Name\": \"LSMDC\", \"Paper Title\": \"LSMDC\", \"Paper URL\": \"https://arxiv.org/pdf/1605.03705\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/movie-description\", \"ArXiv URL\": \"https://arxiv.org/pdf/1605.03705\", \"Semantic Scholar Corpus ID\": 18217052, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://datasets.d2.mpi-inf.mpg.de/movieDescription/protected/lsmdc2016/README.txt\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Summarization\", \"Misc\", \"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"youcook-2\", \"Collection\": \"youcook-2\", \"Collection URL\": \"https://arxiv.org/abs/1703.09788\", \"Dataset Name\": \"YouCook2\", \"Paper Title\": \"YouCook2\", \"Paper URL\": \"https://arxiv.org/abs/1703.09788\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youcook2\", \"ArXiv URL\": \"https://arxiv.org/abs/1703.09788\", \"Semantic Scholar Corpus ID\": 19713015, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"http://youcook2.eecs.umich.edu/static/YouCookII/LICENSE_YOUCOOK2.txt\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 175.6, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"youcook-2\", \"Collection\": \"youcook-2\", \"Collection URL\": \"https://arxiv.org/abs/1703.09788\", \"Dataset Name\": \"YouCook2\", \"Paper Title\": \"YouCook2\", \"Paper URL\": \"https://arxiv.org/abs/1703.09788\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youcook2\", \"ArXiv URL\": \"https://arxiv.org/abs/1703.09788\", \"Semantic Scholar Corpus ID\": 19713015, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"http://youcook2.eecs.umich.edu/static/YouCookII/LICENSE_YOUCOOK2.txt\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 175.6, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"lsmdc\", \"Collection\": \"lsmdc\", \"Collection URL\": \"https://arxiv.org/pdf/1605.03705\", \"Dataset Name\": \"LSMDC\", \"Paper Title\": \"LSMDC\", \"Paper URL\": \"https://arxiv.org/pdf/1605.03705\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/movie-description\", \"ArXiv URL\": \"https://arxiv.org/pdf/1605.03705\", \"Semantic Scholar Corpus ID\": 18217052, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://datasets.d2.mpi-inf.mpg.de/movieDescription/protected/lsmdc2016/README.txt\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Summarization\", \"Misc\", \"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"ava\", \"Collection\": \"ava\", \"Collection URL\": \"https://arxiv.org/pdf/1705.08421\", \"Dataset Name\": \"AVA\", \"Paper Title\": \"AVA\", \"Paper URL\": \"https://arxiv.org/pdf/1705.08421\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ava-a-video-dataset-of-spatio-temporally\", \"ArXiv URL\": \"https://arxiv.org/pdf/1705.08421\", \"Semantic Scholar Corpus ID\": 688013, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://research.google.com/ava/\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 107.5, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Temporal Localization\", \"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"kinetics-400\", \"Collection\": \"kinetics-400\", \"Collection URL\": \"https://arxiv.org/abs/1705.06950\", \"Dataset Name\": \"Kinetics 400\", \"Paper Title\": \"Kinetics 400\", \"Paper URL\": \"https://arxiv.org/abs/1705.06950\", \"GitHub URL\": \"https://github.com/cvdfoundation/kinetics-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/kinetics\", \"ArXiv URL\": \"https://arxiv.org/abs/1705.06950\", \"Semantic Scholar Corpus ID\": 27300853, \"Year Released\": \"2017\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 850.68, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"pku-mmd-dataset\", \"Collection\": \"pku-mmd-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1703.07475\", \"Dataset Name\": \"PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding (ACM Multimedia Workshop)\", \"Paper Title\": \"PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding (ACM Multimedia Workshop)\", \"Paper URL\": \"https://arxiv.org/abs/1703.07475\", \"GitHub URL\": \"https://struct002.github.io/PKUMMD/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/pku-mmd-a-large-scale-benchmark-for\", \"ArXiv URL\": \"https://arxiv.org/abs/1703.07475\", \"Semantic Scholar Corpus ID\": 1904265, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 50.0, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"pku-mmd-dataset\", \"Collection\": \"pku-mmd-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1703.07475\", \"Dataset Name\": \"PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding (ACM Multimedia Workshop)\", \"Paper Title\": \"PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding (ACM Multimedia Workshop)\", \"Paper URL\": \"https://arxiv.org/abs/1703.07475\", \"GitHub URL\": \"https://struct002.github.io/PKUMMD/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/pku-mmd-a-large-scale-benchmark-for\", \"ArXiv URL\": \"https://arxiv.org/abs/1703.07475\", \"Semantic Scholar Corpus ID\": 1904265, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 50.0, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"multi-thumos-challenge\", \"Collection\": \"multi-thumos-challenge\", \"Collection URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"Dataset Name\": \"MultiTHUMOS: Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos (IJCV 2017)\", \"Paper Title\": \"MultiTHUMOS: Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos (IJCV 2017)\", \"Paper URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/multithumos\", \"ArXiv URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"Semantic Scholar Corpus ID\": 3337929, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://ai.stanford.edu/~syyeung/resources/multithumos.zip\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 30.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"qfvs\", \"Collection\": \"qfvs\", \"Collection URL\": \"https://arxiv.org/abs/1707.04960\", \"Dataset Name\": \"QFVS: Query-Focused Video Summarization: Dataset, Evaluation, and A Memory Network Based Approach (CVPR 2017)\", \"Paper Title\": \"QFVS: Query-Focused Video Summarization: Dataset, Evaluation, and A Memory Network Based Approach (CVPR 2017)\", \"Paper URL\": \"https://arxiv.org/abs/1707.04960\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/query-focused-video-summarization-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/1707.04960\", \"Semantic Scholar Corpus ID\": 2774608, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 20.0, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"multi-thumos-challenge\", \"Collection\": \"multi-thumos-challenge\", \"Collection URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"Dataset Name\": \"MultiTHUMOS: Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos (IJCV 2017)\", \"Paper Title\": \"MultiTHUMOS: Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos (IJCV 2017)\", \"Paper URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/multithumos\", \"ArXiv URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"Semantic Scholar Corpus ID\": 3337929, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://ai.stanford.edu/~syyeung/resources/multithumos.zip\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 30.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"multi-thumos-challenge\", \"Collection\": \"multi-thumos-challenge\", \"Collection URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"Dataset Name\": \"MultiTHUMOS: Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos (IJCV 2017)\", \"Paper Title\": \"MultiTHUMOS: Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos (IJCV 2017)\", \"Paper URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/multithumos\", \"ArXiv URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"Semantic Scholar Corpus ID\": 3337929, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://ai.stanford.edu/~syyeung/resources/multithumos.zip\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 30.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"imagenet-vid\", \"Collection\": \"imagenet-vid\", \"Collection URL\": \"https://link.springer.com/article/10.1007/s11263-015-0816-y?sa_campaign=email/event/articleAuthor/onlineFirst#\", \"Dataset Name\": \"ImageNet VID\", \"Paper Title\": \"ImageNet VID\", \"Paper URL\": \"https://link.springer.com/article/10.1007/s11263-015-0816-y?sa_campaign=email/event/articleAuthor/onlineFirst#\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/sota/video-object-detection-on-imagenet-vid\", \"ArXiv URL\": \"https://link.springer.com/article/10.1007/s11263-015-0816-y?sa_campaign=email/event/articleAuthor/onlineFirst#\", \"Semantic Scholar Corpus ID\": 2930547, \"Year Released\": \"2017\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://www.image-net.org/challenges/LSVRC/2017/index.php\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 9.26, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"voxceleb\", \"Collection\": \"voxceleb\", \"Collection URL\": \"https://arxiv.org/abs/1706.08612\", \"Dataset Name\": \"VoxCeleb\", \"Paper Title\": \"VoxCeleb\", \"Paper URL\": \"https://arxiv.org/abs/1706.08612\", \"GitHub URL\": \"https://github.com/a-nagrani/VGGVox\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://cs.paperswithcode.com/paper/voxceleb-a-large-scale-speaker-identification\", \"ArXiv URL\": \"https://arxiv.org/abs/1706.08612\", \"Semantic Scholar Corpus ID\": 10475843, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/\"}], \"Creators\": \"Academic\", \"Countries\": [\"United Kingdom\", \"South Korea\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 2000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"20bn-something\", \"Collection\": \"20bn-something\", \"Collection URL\": \"https://arxiv.org/abs/1706.04261\", \"Dataset Name\": \"20BN-SOMETHING-SOMETHING: The \\\"something something\\\" video database for learning and evaluating visual common sense\", \"Paper Title\": \"20BN-SOMETHING-SOMETHING: The \\\"something something\\\" video database for learning and evaluating visual common sense\", \"Paper URL\": \"https://arxiv.org/abs/1706.04261\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/something-something-v2\", \"ArXiv URL\": \"https://arxiv.org/abs/1706.04261\", \"Semantic Scholar Corpus ID\": 834612, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://developer.qualcomm.com/software/ai-datasets/something-something\"}], \"Creators\": \"Corporation\", \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 121.46, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"qfvs\", \"Collection\": \"qfvs\", \"Collection URL\": \"https://arxiv.org/abs/1707.04960\", \"Dataset Name\": \"QFVS: Query-Focused Video Summarization: Dataset, Evaluation, and A Memory Network Based Approach (CVPR 2017)\", \"Paper Title\": \"QFVS: Query-Focused Video Summarization: Dataset, Evaluation, and A Memory Network Based Approach (CVPR 2017)\", \"Paper URL\": \"https://arxiv.org/abs/1707.04960\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/query-focused-video-summarization-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/1707.04960\", \"Semantic Scholar Corpus ID\": 2774608, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 20.0, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mpii-md\", \"Collection\": \"mpii-md\", \"Collection URL\": \"https://arxiv.org/pdf/1501.02530.pdf\", \"Dataset Name\": \"MPII-MD: A Dataset for Movie Description\", \"Paper Title\": \"MPII-MD: A Dataset for Movie Description\", \"Paper URL\": \"https://arxiv.org/pdf/1501.02530.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1501.02530.pdf\", \"Semantic Scholar Corpus ID\": 15184723, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 56.5, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"lsmdc\", \"Collection\": \"lsmdc\", \"Collection URL\": \"https://arxiv.org/pdf/1605.03705\", \"Dataset Name\": \"LSMDC\", \"Paper Title\": \"LSMDC\", \"Paper URL\": \"https://arxiv.org/pdf/1605.03705\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/movie-description\", \"ArXiv URL\": \"https://arxiv.org/pdf/1605.03705\", \"Semantic Scholar Corpus ID\": 18217052, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://datasets.d2.mpi-inf.mpg.de/movieDescription/protected/lsmdc2016/README.txt\"}], \"Creators\": \"Corporation\", \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Summarization\", \"Misc\", \"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"davis\", \"Collection\": \"davis\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"Dataset Name\": \"Davis\", \"Paper Title\": \"Davis\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"GitHub URL\": \"https://github.com/fperazzi/davis\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-benchmark-dataset-and-evaluation\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"Semantic Scholar Corpus ID\": 3619941, \"Year Released\": \"2017\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/fperazzi/davis/blob/main/LICENSE\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"Switzerland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.04, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Segmentation\", \"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"lsmdc\", \"Collection\": \"lsmdc\", \"Collection URL\": \"https://arxiv.org/pdf/1605.03705\", \"Dataset Name\": \"LSMDC\", \"Paper Title\": \"LSMDC\", \"Paper URL\": \"https://arxiv.org/pdf/1605.03705\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/movie-description\", \"ArXiv URL\": \"https://arxiv.org/pdf/1605.03705\", \"Semantic Scholar Corpus ID\": 18217052, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://datasets.d2.mpi-inf.mpg.de/movieDescription/protected/lsmdc2016/README.txt\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Summarization\", \"Misc\", \"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"lsmdc\", \"Collection\": \"lsmdc\", \"Collection URL\": \"https://arxiv.org/pdf/1605.03705\", \"Dataset Name\": \"LSMDC\", \"Paper Title\": \"LSMDC\", \"Paper URL\": \"https://arxiv.org/pdf/1605.03705\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/movie-description\", \"ArXiv URL\": \"https://arxiv.org/pdf/1605.03705\", \"Semantic Scholar Corpus ID\": 18217052, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://datasets.d2.mpi-inf.mpg.de/movieDescription/protected/lsmdc2016/README.txt\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Summarization\", \"Misc\", \"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"davis\", \"Collection\": \"davis\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"Dataset Name\": \"Davis\", \"Paper Title\": \"Davis\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"GitHub URL\": \"https://github.com/fperazzi/davis\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-benchmark-dataset-and-evaluation\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"Semantic Scholar Corpus ID\": 3619941, \"Year Released\": \"2017\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/fperazzi/davis/blob/main/LICENSE\"}], \"Creators\": \"Academic\", \"Countries\": [\"Switzerland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.04, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Segmentation\", \"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"lsmdc\", \"Collection\": \"lsmdc\", \"Collection URL\": \"https://arxiv.org/pdf/1605.03705\", \"Dataset Name\": \"LSMDC\", \"Paper Title\": \"LSMDC\", \"Paper URL\": \"https://arxiv.org/pdf/1605.03705\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/movie-description\", \"ArXiv URL\": \"https://arxiv.org/pdf/1605.03705\", \"Semantic Scholar Corpus ID\": 18217052, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://datasets.d2.mpi-inf.mpg.de/movieDescription/protected/lsmdc2016/README.txt\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Summarization\", \"Misc\", \"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"soa-dataset\", \"Collection\": \"soa-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1904.11451\", \"Dataset Name\": \"Scenes-objects-actions: A multi-task, multi-label video dataset\", \"Paper Title\": \"Scenes-objects-actions: A multi-task, multi-label video dataset\", \"Paper URL\": \"https://arxiv.org/pdf/1904.11451\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/scenes-objects-actions-a-multi-task-multi\", \"ArXiv URL\": \"https://arxiv.org/pdf/1904.11451\", \"Semantic Scholar Corpus ID\": 52968009, \"Year Released\": \"2018\", \"Text Sources\": [\"facebook\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Corporation\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1561.1, \"Taken Down\": \"False\", \"Video Sources\": [\"facebook\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"charades-ego\", \"Collection\": \"charades-ego\", \"Collection URL\": \"https://arxiv.org/abs/1804.09627\", \"Dataset Name\": \"Charades-Ego: Actor and Observer: Joint Modeling of First and Third-Person Videos (CVPR 2018)\", \"Paper Title\": \"Charades-Ego: Actor and Observer: Joint Modeling of First and Third-Person Videos (CVPR 2018)\", \"Paper URL\": \"https://arxiv.org/abs/1804.09627\", \"GitHub URL\": \"https://github.com/gsig/actor-observer\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/search?q_meta=&q_type=&q=Actor+and+Observer%3A+Joint+Modeling+of+First+and+Third-Person+Videos\", \"ArXiv URL\": \"https://arxiv.org/abs/1804.09627\", \"Semantic Scholar Corpus ID\": 4562167, \"Year Released\": \"2018\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://prior.allenai.org/projects/data/charades-ego/license.txt\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 69.33, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"kinetics-600\", \"Collection\": \"kinetics-600\", \"Collection URL\": \"https://arxiv.org/abs/1808.01340\", \"Dataset Name\": \"Kinetics 600\", \"Paper Title\": \"Kinetics 600\", \"Paper URL\": \"https://arxiv.org/abs/1808.01340\", \"GitHub URL\": \"https://github.com/cvdfoundation/kinetics-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/kinetics-600\", \"ArXiv URL\": \"https://arxiv.org/abs/1808.01340\", \"Semantic Scholar Corpus ID\": 51927456, \"Year Released\": \"2018\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1376.52, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"how2\", \"Collection\": \"how2\", \"Collection URL\": \"https://arxiv.org/abs/1811.00347\", \"Dataset Name\": \"How2: A Large-scale Dataset for Multimodal Language Understanding (NeurIPS 2018)\", \"Paper Title\": \"How2: A Large-scale Dataset for Multimodal Language Understanding (NeurIPS 2018)\", \"Paper URL\": \"https://arxiv.org/abs/1811.00347\", \"GitHub URL\": \"https://github.com/srvk/how2-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/abs/1811.00347\", \"Semantic Scholar Corpus ID\": 53186236, \"Year Released\": \"2018\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Various\", \"License URL\": \"https://github.com/srvk/how2-dataset?tab=readme-ov-file#how2-license\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 2300.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"vlog-vids\", \"Collection\": \"vlog-vids\", \"Collection URL\": \"https://arxiv.org/abs/1712.02310\", \"Dataset Name\": \"VLOG: From Lifestyle Vlogs to Everyday Interactions (CVPR 2018)\", \"Paper Title\": \"VLOG: From Lifestyle Vlogs to Everyday Interactions (CVPR 2018)\", \"Paper URL\": \"https://arxiv.org/abs/1712.02310\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/vlog-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/1712.02310\", \"Semantic Scholar Corpus ID\": 22264672, \"Year Released\": \"2018\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://web.eecs.umich.edu/~fouhey/2017/VLOG/index.html\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 336.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"didemo\", \"Collection\": \"didemo\", \"Collection URL\": \"https://paperswithcode.com/dataset/didemo\", \"Dataset Name\": \"DiDeMo: Localizing Moments in Video with Temporal Language (EMNLP 2018)\", \"Paper Title\": \"DiDeMo: Localizing Moments in Video with Temporal Language (EMNLP 2018)\", \"Paper URL\": \"https://paperswithcode.com/dataset/didemo\", \"GitHub URL\": \"https://github.com/LisaAnne/TemporalLanguageRelease\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://paperswithcode.com/dataset/didemo\", \"Semantic Scholar Corpus ID\": 52164739, \"Year Released\": \"2018\", \"Text Sources\": [\"flickr\"], \"Licenses\": [{\"License\": \"BSD 2-Clause License\", \"License URL\": \"https://github.com/LisaAnne/TemporalLanguageRelease\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 275.0, \"Taken Down\": \"False\", \"Video Sources\": [\"flickr\"], \"Task Categories\": [\"Temporal Action Localization\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"epic-kitchenes\", \"Collection\": \"epic-kitchenes\", \"Collection URL\": \"https://arxiv.org/abs/1804.02748\", \"Dataset Name\": \"EPIC-KITCHENS\", \"Paper Title\": \"EPIC-KITCHENS\", \"Paper URL\": \"https://arxiv.org/abs/1804.02748\", \"GitHub URL\": \"https://github.com/epic-kitchens\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/epic-kitchens-100\", \"ArXiv URL\": \"https://arxiv.org/abs/1804.02748\", \"Semantic Scholar Corpus ID\": 4710439, \"Year Released\": \"2018\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://epic-kitchens.github.io/2024\"}], \"Creators\": \"Academic\", \"Countries\": [\"United Kingdom\", \"Canada\", \"Spain\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 100.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"epic-kitchenes\", \"Collection\": \"epic-kitchenes\", \"Collection URL\": \"https://arxiv.org/abs/1804.02748\", \"Dataset Name\": \"EPIC-KITCHENS\", \"Paper Title\": \"EPIC-KITCHENS\", \"Paper URL\": \"https://arxiv.org/abs/1804.02748\", \"GitHub URL\": \"https://github.com/epic-kitchens\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/epic-kitchens-100\", \"ArXiv URL\": \"https://arxiv.org/abs/1804.02748\", \"Semantic Scholar Corpus ID\": 4710439, \"Year Released\": \"2018\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://epic-kitchens.github.io/2024\"}], \"Creators\": \"Academic\", \"Countries\": [\"United Kingdom\", \"Canada\", \"Spain\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 100.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moviegraphs\", \"Collection\": \"moviegraphs\", \"Collection URL\": \"https://arxiv.org/pdf/1712.06761\", \"Dataset Name\": \"MovieGraphs\", \"Paper Title\": \"MovieGraphs\", \"Paper URL\": \"https://arxiv.org/pdf/1712.06761\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/moviegraphs\", \"ArXiv URL\": \"https://arxiv.org/pdf/1712.06761\", \"Semantic Scholar Corpus ID\": 4856028, \"Year Released\": \"2018\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moviegraphs.cs.toronto.edu/download.html\"}], \"Creators\": \"Academic\", \"Countries\": [\"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 93.9, \"Taken Down\": \"True\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Misc (video retrieval\", \"interaction understanding via ordering\", \"reason prediction)\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moviegraphs\", \"Collection\": \"moviegraphs\", \"Collection URL\": \"https://arxiv.org/pdf/1712.06761\", \"Dataset Name\": \"MovieGraphs\", \"Paper Title\": \"MovieGraphs\", \"Paper URL\": \"https://arxiv.org/pdf/1712.06761\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/moviegraphs\", \"ArXiv URL\": \"https://arxiv.org/pdf/1712.06761\", \"Semantic Scholar Corpus ID\": 4856028, \"Year Released\": \"2018\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moviegraphs.cs.toronto.edu/download.html\"}], \"Creators\": \"Academic\", \"Countries\": [\"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 93.9, \"Taken Down\": \"True\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Misc (video retrieval\", \"interaction understanding via ordering\", \"reason prediction)\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"epic-kitchenes\", \"Collection\": \"epic-kitchenes\", \"Collection URL\": \"https://arxiv.org/abs/1804.02748\", \"Dataset Name\": \"EPIC-KITCHENS\", \"Paper Title\": \"EPIC-KITCHENS\", \"Paper URL\": \"https://arxiv.org/abs/1804.02748\", \"GitHub URL\": \"https://github.com/epic-kitchens\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/epic-kitchens-100\", \"ArXiv URL\": \"https://arxiv.org/abs/1804.02748\", \"Semantic Scholar Corpus ID\": 4710439, \"Year Released\": \"2018\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://epic-kitchens.github.io/2024\"}], \"Creators\": \"Academic\", \"Countries\": [\"United Kingdom\", \"Canada\", \"Spain\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 100.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moviegraphs\", \"Collection\": \"moviegraphs\", \"Collection URL\": \"https://arxiv.org/pdf/1712.06761\", \"Dataset Name\": \"MovieGraphs\", \"Paper Title\": \"MovieGraphs\", \"Paper URL\": \"https://arxiv.org/pdf/1712.06761\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/moviegraphs\", \"ArXiv URL\": \"https://arxiv.org/pdf/1712.06761\", \"Semantic Scholar Corpus ID\": 4856028, \"Year Released\": \"2018\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moviegraphs.cs.toronto.edu/download.html\"}], \"Creators\": \"Other\", \"Countries\": [\"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 93.9, \"Taken Down\": \"True\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Misc (video retrieval\", \"interaction understanding via ordering\", \"reason prediction)\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"msa\", \"Collection\": \"msa\", \"Collection URL\": \"https://arxiv.org/abs/1910.11009\", \"Dataset Name\": \"MSA\", \"Paper Title\": \"MSA\", \"Paper URL\": \"https://arxiv.org/abs/1910.11009\", \"GitHub URL\": \"https://github.com/ycxioooong/MovieSynopsisAssociation\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-graph-based-framework-to-bridge-movies-and-1\", \"ArXiv URL\": \"https://arxiv.org/abs/1910.11009\", \"Semantic Scholar Corpus ID\": 204852218, \"Year Released\": \"2019\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 516.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hacs-dataset\", \"Collection\": \"hacs-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1712.09374\", \"Dataset Name\": \"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\", \"Paper Title\": \"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\", \"Paper URL\": \"https://arxiv.org/abs/1712.09374\", \"GitHub URL\": \"https://github.com/hangzhaomit/HACS-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hacs\", \"ArXiv URL\": \"https://arxiv.org/abs/1712.09374\", \"Semantic Scholar Corpus ID\": 68049510, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/hangzhaomit/HACS-dataset?tab=readme-ov-file#request-testing-videos-and-missing-videos-new\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"ava-dataset\", \"Collection\": \"ava-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1901.01342\", \"Dataset Name\": \"AVA Active Speaker\", \"Paper Title\": \"AVA Active Speaker\", \"Paper URL\": \"https://arxiv.org/abs/1901.01342\", \"GitHub URL\": \"https://github.com/cvdfoundation/ava-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/ava-activespeaker\", \"ArXiv URL\": \"https://arxiv.org/abs/1901.01342\", \"Semantic Scholar Corpus ID\": 216211909, \"Year Released\": \"2019\", \"Text Sources\": [\"Not Prohibited\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://research.google.com/ava/download.html#ava_active_speaker_download\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 38.5, \"Taken Down\": \"False\", \"Video Sources\": [\"Not Prohibited\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper Title\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Research Group\", \"Countries\": [\"France\", \"Turkey\", \"United States of America\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Temporal Action Localization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper Title\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Other\", \"Countries\": [\"France\", \"Turkey\", \"United States of America\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Temporal Action Localization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper Title\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"France\", \"Turkey\", \"United States of America\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Temporal Action Localization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper Title\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"France\", \"Turkey\", \"United States of America\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Temporal Action Localization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"msa\", \"Collection\": \"msa\", \"Collection URL\": \"https://arxiv.org/abs/1910.11009\", \"Dataset Name\": \"MSA\", \"Paper Title\": \"MSA\", \"Paper URL\": \"https://arxiv.org/abs/1910.11009\", \"GitHub URL\": \"https://github.com/ycxioooong/MovieSynopsisAssociation\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-graph-based-framework-to-bridge-movies-and-1\", \"ArXiv URL\": \"https://arxiv.org/abs/1910.11009\", \"Semantic Scholar Corpus ID\": 204852218, \"Year Released\": \"2019\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 516.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hacs-dataset\", \"Collection\": \"hacs-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1712.09374\", \"Dataset Name\": \"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\", \"Paper Title\": \"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\", \"Paper URL\": \"https://arxiv.org/abs/1712.09374\", \"GitHub URL\": \"https://github.com/hangzhaomit/HACS-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hacs\", \"ArXiv URL\": \"https://arxiv.org/abs/1712.09374\", \"Semantic Scholar Corpus ID\": 68049510, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/hangzhaomit/HACS-dataset?tab=readme-ov-file#request-testing-videos-and-missing-videos-new\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"toyota-smarthome\", \"Collection\": \"toyota-smarthome\", \"Collection URL\": \"https://openaccess.thecvf.com/content_ICCV_2019/papers/Das_Toyota_Smarthome_Real-World_Activities_of_Daily_Living_ICCV_2019_paper.pdf\", \"Dataset Name\": \"Toyota Smarthome: Real-World Activities of Daily Living (ICCV 2019)\", \"Paper Title\": \"Toyota Smarthome: Real-World Activities of Daily Living (ICCV 2019)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_ICCV_2019/papers/Das_Toyota_Smarthome_Real-World_Activities_of_Daily_Living_ICCV_2019_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_ICCV_2019/papers/Das_Toyota_Smarthome_Real-World_Activities_of_Daily_Living_ICCV_2019_paper.pdf\", \"Semantic Scholar Corpus ID\": 207971208, \"Year Released\": \"2019\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://project.inria.fr/toyotasmarthome/files/2020/12/License_v2.pdf\"}], \"Creators\": \"Corporation\", \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 268.58, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper Title\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"France\", \"Turkey\", \"United States of America\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Temporal Action Localization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hacs-dataset\", \"Collection\": \"hacs-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1712.09374\", \"Dataset Name\": \"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\", \"Paper Title\": \"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\", \"Paper URL\": \"https://arxiv.org/abs/1712.09374\", \"GitHub URL\": \"https://github.com/hangzhaomit/HACS-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hacs\", \"ArXiv URL\": \"https://arxiv.org/abs/1712.09374\", \"Semantic Scholar Corpus ID\": 68049510, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/hangzhaomit/HACS-dataset?tab=readme-ov-file#request-testing-videos-and-missing-videos-new\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"howto100m\", \"Collection\": \"howto100m\", \"Collection URL\": \"https://arxiv.org/abs/1906.03327\", \"Dataset Name\": \"HowTo100M\", \"Paper Title\": \"HowTo100M\", \"Paper URL\": \"https://arxiv.org/abs/1906.03327\", \"GitHub URL\": \"https://github.com/antoine77340/howto100m\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/howto100m\", \"ArXiv URL\": \"https://arxiv.org/abs/1906.03327\", \"Semantic Scholar Corpus ID\": 182952863, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Other\", \"Countries\": [\"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 134472.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"trecvid\", \"Collection\": \"trecvid\", \"Collection URL\": \"https://arxiv.org/abs/2009.09984\", \"Dataset Name\": \"TRECVID\", \"Paper Title\": \"TRECVID\", \"Paper URL\": \"https://arxiv.org/abs/2009.09984\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/trecvid-2019-an-evaluation-campaign-to/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.09984\", \"Semantic Scholar Corpus ID\": 212694843, \"Year Released\": \"2019\", \"Text Sources\": [\"undisclosed web\", \"bbc\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://trecvid.nist.gov/\"}], \"Creators\": \"Government\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\", \"bbc\"], \"Task Categories\": [\"Video Captioning\", \"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"vatex\", \"Collection\": \"vatex\", \"Collection URL\": \"https://arxiv.org/abs/1904.03493\", \"Dataset Name\": \"VaTeX\", \"Paper Title\": \"VaTeX\", \"Paper URL\": \"https://arxiv.org/abs/1904.03493\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/vatex\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/vatex\", \"ArXiv URL\": \"https://arxiv.org/abs/1904.03493\", \"Semantic Scholar Corpus ID\": 102352148, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://eric-xw.github.io/vatex-website/index.html\"}], \"Creators\": \"Corporation\", \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 114.58, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask\", \"Paper Title\": \"CrossTask\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Other\", \"Countries\": [\"Czech Republic\", \"France\", \"Turkey\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"howto100m\", \"Collection\": \"howto100m\", \"Collection URL\": \"https://arxiv.org/abs/1906.03327\", \"Dataset Name\": \"HowTo100M\", \"Paper Title\": \"HowTo100M\", \"Paper URL\": \"https://arxiv.org/abs/1906.03327\", \"GitHub URL\": \"https://github.com/antoine77340/howto100m\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/howto100m\", \"ArXiv URL\": \"https://arxiv.org/abs/1906.03327\", \"Semantic Scholar Corpus ID\": 182952863, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 134472.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"vatex\", \"Collection\": \"vatex\", \"Collection URL\": \"https://arxiv.org/abs/1904.03493\", \"Dataset Name\": \"VaTeX\", \"Paper Title\": \"VaTeX\", \"Paper URL\": \"https://arxiv.org/abs/1904.03493\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/vatex\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/vatex\", \"ArXiv URL\": \"https://arxiv.org/abs/1904.03493\", \"Semantic Scholar Corpus ID\": 102352148, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://eric-xw.github.io/vatex-website/index.html\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 114.58, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask\", \"Paper Title\": \"CrossTask\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"Czech Republic\", \"France\", \"Turkey\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask\", \"Paper Title\": \"CrossTask\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"Czech Republic\", \"France\", \"Turkey\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask\", \"Paper Title\": \"CrossTask\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Research Group\", \"Countries\": [\"Czech Republic\", \"France\", \"Turkey\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"coin-dataset\", \"Collection\": \"coin-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1903.02874\", \"Dataset Name\": \"COIN: A Large-scale Dataset for Comprehensive Instructional Video Analysis (CVPR 2019)\", \"Paper Title\": \"COIN: A Large-scale Dataset for Comprehensive Instructional Video Analysis (CVPR 2019)\", \"Paper URL\": \"https://arxiv.org/abs/1903.02874\", \"GitHub URL\": \"https://github.com/coin-dataset/annotations\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/coin#:~:text=The%20COIN%20dataset%20(a%20large,are%20all%20collected%20from%20YouTube.\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.02874\", \"Semantic Scholar Corpus ID\": 71147568, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/coin-dataset/annotations?tab=readme-ov-file#license\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 476.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask\", \"Paper Title\": \"CrossTask\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"Czech Republic\", \"France\", \"Turkey\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mmact\", \"Collection\": \"mmact\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Dataset Name\": \"MMAct\", \"Paper Title\": \"MMAct\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mmact\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Semantic Scholar Corpus ID\": 207980205, \"Year Released\": \"2019\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://mmact19.github.io/2019/\"}], \"Creators\": \"Corporation\", \"Countries\": [\"Hong Kong\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 100.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Temporal Localization\", \"Action Recognition\", \"Spatial-Temporal Action Localization\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"mmact\", \"Collection\": \"mmact\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Dataset Name\": \"MMAct\", \"Paper Title\": \"MMAct\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mmact\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Semantic Scholar Corpus ID\": 207980205, \"Year Released\": \"2019\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://mmact19.github.io/2019/\"}], \"Creators\": \"Academic\", \"Countries\": [\"Hong Kong\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 100.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Temporal Localization\", \"Action Recognition\", \"Spatial-Temporal Action Localization\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"20BN-jester\", \"Collection\": \"20BN-jester\", \"Collection URL\": \"https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf\", \"Dataset Name\": \"20BN-jester: The Jester Dataset: A Large-Scale Video Dataset of Human Gestures (ICCVW 2019)\", \"Paper Title\": \"20BN-jester: The Jester Dataset: A Large-Scale Video Dataset of Human Gestures (ICCVW 2019)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf\", \"Semantic Scholar Corpus ID\": 208010438, \"Year Released\": \"2019\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://developer.qualcomm.com/software/ai-datasets/jester\"}], \"Creators\": \"Corporation\", \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13.0, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"howto100m\", \"Collection\": \"howto100m\", \"Collection URL\": \"https://arxiv.org/abs/1906.03327\", \"Dataset Name\": \"HowTo100M\", \"Paper Title\": \"HowTo100M\", \"Paper URL\": \"https://arxiv.org/abs/1906.03327\", \"GitHub URL\": \"https://github.com/antoine77340/howto100m\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/howto100m\", \"ArXiv URL\": \"https://arxiv.org/abs/1906.03327\", \"Semantic Scholar Corpus ID\": 182952863, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 134472.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"howto100m\", \"Collection\": \"howto100m\", \"Collection URL\": \"https://arxiv.org/abs/1906.03327\", \"Dataset Name\": \"HowTo100M\", \"Paper Title\": \"HowTo100M\", \"Paper URL\": \"https://arxiv.org/abs/1906.03327\", \"GitHub URL\": \"https://github.com/antoine77340/howto100m\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/howto100m\", \"ArXiv URL\": \"https://arxiv.org/abs/1906.03327\", \"Semantic Scholar Corpus ID\": 182952863, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Research Group\", \"Countries\": [\"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 134472.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"coin-dataset\", \"Collection\": \"coin-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1903.02874\", \"Dataset Name\": \"COIN: A Large-scale Dataset for Comprehensive Instructional Video Analysis (CVPR 2019)\", \"Paper Title\": \"COIN: A Large-scale Dataset for Comprehensive Instructional Video Analysis (CVPR 2019)\", \"Paper URL\": \"https://arxiv.org/abs/1903.02874\", \"GitHub URL\": \"https://github.com/coin-dataset/annotations\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/coin#:~:text=The%20COIN%20dataset%20(a%20large,are%20all%20collected%20from%20YouTube.\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.02874\", \"Semantic Scholar Corpus ID\": 71147568, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/coin-dataset/annotations?tab=readme-ov-file#license\"}], \"Creators\": \"Corporation\", \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 476.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hyu-vids\", \"Collection\": \"hyu-vids\", \"Collection URL\": \"https://arxiv.org/abs/1904.11451\", \"Dataset Name\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper Title\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/1904.11451\", \"GitHub URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/holistic-large-scale-video-understanding\", \"ArXiv URL\": \"https://arxiv.org/abs/1904.11451\", \"Semantic Scholar Corpus ID\": 131777079, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\"}], \"Creators\": \"Academic\", \"Countries\": [\"Switzerland\", \"Belgium\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 96166.67, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"eev-dataset\", \"Collection\": \"eev-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2001.05488\", \"Dataset Name\": \"EEV: A Large-Scale Dataset for Studying Evoked Expressions from Video\", \"Paper Title\": \"EEV: A Large-Scale Dataset for Studying Evoked Expressions from Video\", \"Paper URL\": \"https://arxiv.org/abs/2001.05488\", \"GitHub URL\": \"https://github.com/google-research-datasets/eev\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/abs/2001.05488\", \"Semantic Scholar Corpus ID\": 210701992, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://github.com/google-research-datasets/eev?tab=readme-ov-file#license\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 370.0, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"eev-dataset\", \"Collection\": \"eev-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2001.05488\", \"Dataset Name\": \"EEV: A Large-Scale Dataset for Studying Evoked Expressions from Video\", \"Paper Title\": \"EEV: A Large-Scale Dataset for Studying Evoked Expressions from Video\", \"Paper URL\": \"https://arxiv.org/abs/2001.05488\", \"GitHub URL\": \"https://github.com/google-research-datasets/eev\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/abs/2001.05488\", \"Semantic Scholar Corpus ID\": 210701992, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://github.com/google-research-datasets/eev?tab=readme-ov-file#license\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 370.0, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"condensed-movies\", \"Collection\": \"condensed-movies\", \"Collection URL\": \"https://arxiv.org/pdf/2005.04208\", \"Dataset Name\": \"Condensed Movies\", \"Paper Title\": \"Condensed Movies\", \"Paper URL\": \"https://arxiv.org/pdf/2005.04208\", \"GitHub URL\": \"https://github.com/m-bain/CondensedMovies\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/condensed-movies\", \"ArXiv URL\": \"https://arxiv.org/pdf/2005.04208\", \"Semantic Scholar Corpus ID\": 218571391, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://www.robots.ox.ac.uk/~vgg/data/condensed-movies/#download\"}], \"Creators\": \"Academic\", \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1270.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"omnisource-web-dataset\", \"Collection\": \"omnisource-web-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2003.13042\", \"Dataset Name\": \"OmniSource Web Dataset\", \"Paper Title\": \"OmniSource Web Dataset\", \"Paper URL\": \"https://arxiv.org/abs/2003.13042\", \"GitHub URL\": \"https://github.com/open-mmlab/mmaction\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/omni-sourced-webly-supervised-learning-for#code\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.13042\", \"Semantic Scholar Corpus ID\": 214714240, \"Year Released\": \"2020\", \"Text Sources\": [\"google videos\", \"instagram\", \"youtube\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/open-mmlab/mmaction?tab=readme-ov-file#license\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13333.0, \"Taken Down\": \"False\", \"Video Sources\": [\"google videos\", \"instagram\", \"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"lsmdc-ordering\", \"Collection\": \"lsmdc-ordering\", \"Collection URL\": \"https://arxiv.org/pdf/2004.02205\", \"Dataset Name\": \"LSMDC Ordering\", \"Paper Title\": \"LSMDC Ordering\", \"Paper URL\": \"https://arxiv.org/pdf/2004.02205\", \"GitHub URL\": \"https://github.com/vivoutlaw/TCBP\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/deep-multimodal-feature-encoding-for-video\", \"ArXiv URL\": \"https://arxiv.org/pdf/2004.02205\", \"Semantic Scholar Corpus ID\": 214802821, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/vivoutlaw/tcbp/blob/master/LICENSE\"}], \"Creators\": \"Academic\", \"Countries\": [\"Germany\", \"Canada\", \"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"lsmdc-ordering\", \"Collection\": \"lsmdc-ordering\", \"Collection URL\": \"https://arxiv.org/pdf/2004.02205\", \"Dataset Name\": \"LSMDC Ordering\", \"Paper Title\": \"LSMDC Ordering\", \"Paper URL\": \"https://arxiv.org/pdf/2004.02205\", \"GitHub URL\": \"https://github.com/vivoutlaw/TCBP\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/deep-multimodal-feature-encoding-for-video\", \"ArXiv URL\": \"https://arxiv.org/pdf/2004.02205\", \"Semantic Scholar Corpus ID\": 214802821, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/vivoutlaw/tcbp/blob/master/LICENSE\"}], \"Creators\": \"Research Group\", \"Countries\": [\"Germany\", \"Canada\", \"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"lsmdc-ordering\", \"Collection\": \"lsmdc-ordering\", \"Collection URL\": \"https://arxiv.org/pdf/2004.02205\", \"Dataset Name\": \"LSMDC Ordering\", \"Paper Title\": \"LSMDC Ordering\", \"Paper URL\": \"https://arxiv.org/pdf/2004.02205\", \"GitHub URL\": \"https://github.com/vivoutlaw/TCBP\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/deep-multimodal-feature-encoding-for-video\", \"ArXiv URL\": \"https://arxiv.org/pdf/2004.02205\", \"Semantic Scholar Corpus ID\": 214802821, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/vivoutlaw/tcbp/blob/master/LICENSE\"}], \"Creators\": \"Academic\", \"Countries\": [\"Germany\", \"Canada\", \"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"lsmdc-ordering\", \"Collection\": \"lsmdc-ordering\", \"Collection URL\": \"https://arxiv.org/pdf/2004.02205\", \"Dataset Name\": \"LSMDC Ordering\", \"Paper Title\": \"LSMDC Ordering\", \"Paper URL\": \"https://arxiv.org/pdf/2004.02205\", \"GitHub URL\": \"https://github.com/vivoutlaw/TCBP\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/deep-multimodal-feature-encoding-for-video\", \"ArXiv URL\": \"https://arxiv.org/pdf/2004.02205\", \"Semantic Scholar Corpus ID\": 214802821, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/vivoutlaw/tcbp/blob/master/LICENSE\"}], \"Creators\": \"Academic\", \"Countries\": [\"Germany\", \"Canada\", \"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"100doh\", \"Collection\": \"100doh\", \"Collection URL\": \"https://arxiv.org/abs/2006.06669\", \"Dataset Name\": \"100DOH: Understanding Human Hands in Contact at Internet Scale (CVPR 2020)\", \"Paper Title\": \"100DOH: Understanding Human Hands in Contact at Internet Scale (CVPR 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2006.06669\", \"GitHub URL\": \"https://github.com/ddshan/hand_object_detector\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/understanding-human-hands-in-contact-at-1\", \"ArXiv URL\": \"https://arxiv.org/abs/2006.06669\", \"Semantic Scholar Corpus ID\": 215413188, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://fouheylab.eecs.umich.edu/~dandans/projects/100DOH/download.html\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 4577.3, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Misc (Hand/Object Detection)\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hyu-vids\", \"Collection\": \"hyu-vids\", \"Collection URL\": \"https://arxiv.org/abs/1904.11451\", \"Dataset Name\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper Title\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/1904.11451\", \"GitHub URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/holistic-large-scale-video-understanding\", \"ArXiv URL\": \"https://arxiv.org/abs/1904.11451\", \"Semantic Scholar Corpus ID\": 131777079, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\"}], \"Creators\": \"Academic\", \"Countries\": [\"Switzerland\", \"Belgium\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 96166.67, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hyu-vids\", \"Collection\": \"hyu-vids\", \"Collection URL\": \"https://arxiv.org/abs/1904.11451\", \"Dataset Name\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper Title\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/1904.11451\", \"GitHub URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/holistic-large-scale-video-understanding\", \"ArXiv URL\": \"https://arxiv.org/abs/1904.11451\", \"Semantic Scholar Corpus ID\": 131777079, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\"}], \"Creators\": \"Academic\", \"Countries\": [\"Switzerland\", \"Belgium\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 96166.67, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"finegym-dataset\", \"Collection\": \"finegym-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2004.06704\", \"Dataset Name\": \"FineGym: A Hierarchical Video Dataset for Fine-grained Action Understanding (CVPR 2020)\", \"Paper Title\": \"FineGym: A Hierarchical Video Dataset for Fine-grained Action Understanding (CVPR 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2004.06704\", \"GitHub URL\": \"https://github.com/SDOlivia/FineGym/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/finegym\", \"ArXiv URL\": \"https://arxiv.org/abs/2004.06704\", \"Semantic Scholar Corpus ID\": 215754360, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://sdolivia.github.io/FineGym/\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 708.0, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hyu-vids\", \"Collection\": \"hyu-vids\", \"Collection URL\": \"https://arxiv.org/abs/1904.11451\", \"Dataset Name\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper Title\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/1904.11451\", \"GitHub URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/holistic-large-scale-video-understanding\", \"ArXiv URL\": \"https://arxiv.org/abs/1904.11451\", \"Semantic Scholar Corpus ID\": 131777079, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\"}], \"Creators\": \"Academic\", \"Countries\": [\"Switzerland\", \"Belgium\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 96166.67, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hyu-vids\", \"Collection\": \"hyu-vids\", \"Collection URL\": \"https://arxiv.org/abs/1904.11451\", \"Dataset Name\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper Title\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/1904.11451\", \"GitHub URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/holistic-large-scale-video-understanding\", \"ArXiv URL\": \"https://arxiv.org/abs/1904.11451\", \"Semantic Scholar Corpus ID\": 131777079, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\"}], \"Creators\": \"Other\", \"Countries\": [\"Switzerland\", \"Belgium\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 96166.67, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"100doh\", \"Collection\": \"100doh\", \"Collection URL\": \"https://arxiv.org/abs/2006.06669\", \"Dataset Name\": \"100DOH: Understanding Human Hands in Contact at Internet Scale (CVPR 2020)\", \"Paper Title\": \"100DOH: Understanding Human Hands in Contact at Internet Scale (CVPR 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2006.06669\", \"GitHub URL\": \"https://github.com/ddshan/hand_object_detector\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/understanding-human-hands-in-contact-at-1\", \"ArXiv URL\": \"https://arxiv.org/abs/2006.06669\", \"Semantic Scholar Corpus ID\": 215413188, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://fouheylab.eecs.umich.edu/~dandans/projects/100DOH/download.html\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 4577.3, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Misc (Hand/Object Detection)\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"rare-act-dataset\", \"Collection\": \"rare-act-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Dataset Name\": \"RareAct: A video dataset of unusual interactions\", \"Paper Title\": \"RareAct: A video dataset of unusual interactions\", \"Paper URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"GitHub URL\": \"https://github.com/antoine77340/RareAct\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/rareact\", \"ArXiv URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Semantic Scholar Corpus ID\": 220936243, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"United Kingdom\", \"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 21.13, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"rare-act-dataset\", \"Collection\": \"rare-act-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Dataset Name\": \"RareAct: A video dataset of unusual interactions\", \"Paper Title\": \"RareAct: A video dataset of unusual interactions\", \"Paper URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"GitHub URL\": \"https://github.com/antoine77340/RareAct\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/rareact\", \"ArXiv URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Semantic Scholar Corpus ID\": 220936243, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"United Kingdom\", \"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 21.13, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"rare-act-dataset\", \"Collection\": \"rare-act-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Dataset Name\": \"RareAct: A video dataset of unusual interactions\", \"Paper Title\": \"RareAct: A video dataset of unusual interactions\", \"Paper URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"GitHub URL\": \"https://github.com/antoine77340/RareAct\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/rareact\", \"ArXiv URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Semantic Scholar Corpus ID\": 220936243, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"United Kingdom\", \"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 21.13, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"rare-act-dataset\", \"Collection\": \"rare-act-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Dataset Name\": \"RareAct: A video dataset of unusual interactions\", \"Paper Title\": \"RareAct: A video dataset of unusual interactions\", \"Paper URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"GitHub URL\": \"https://github.com/antoine77340/RareAct\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/rareact\", \"ArXiv URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Semantic Scholar Corpus ID\": 220936243, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Research Group\", \"Countries\": [\"United Kingdom\", \"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 21.13, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"rare-act-dataset\", \"Collection\": \"rare-act-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Dataset Name\": \"RareAct: A video dataset of unusual interactions\", \"Paper Title\": \"RareAct: A video dataset of unusual interactions\", \"Paper URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"GitHub URL\": \"https://github.com/antoine77340/RareAct\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/rareact\", \"ArXiv URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Semantic Scholar Corpus ID\": 220936243, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Other\", \"Countries\": [\"United Kingdom\", \"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 21.13, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"titan\", \"Collection\": \"titan\", \"Collection URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf\", \"Dataset Name\": \"TITAN: Future Forecast using Action Priors (CVPR 2020)\", \"Paper Title\": \"TITAN: Future Forecast using Action Priors (CVPR 2020)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/titan-future-forecast-using-action-priors\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf\", \"Semantic Scholar Corpus ID\": 214727763, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Non Commercial\", \"License URL\": \"https://usa.honda-ri.com/titan\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 2.91, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"kinetics-700\", \"Collection\": \"kinetics-700\", \"Collection URL\": \"https://arxiv.org/pdf/2010.10864.pdf\", \"Dataset Name\": \"Kinetics-700\", \"Paper Title\": \"Kinetics-700\", \"Paper URL\": \"https://arxiv.org/pdf/2010.10864.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/kinetics-700\", \"ArXiv URL\": \"https://arxiv.org/pdf/2010.10864.pdf\", \"Semantic Scholar Corpus ID\": 196831809, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1805.56, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"moviescenes\", \"Collection\": \"moviescenes\", \"Collection URL\": \"https://arxiv.org/abs/2004.02678\", \"Dataset Name\": \"MovieScenes\", \"Paper Title\": \"MovieScenes\", \"Paper URL\": \"https://arxiv.org/abs/2004.02678\", \"GitHub URL\": \"https://github.com/AnyiRao/SceneSeg\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-local-to-global-approach-to-multi-modal\", \"ArXiv URL\": \"https://arxiv.org/abs/2004.02678\", \"Semantic Scholar Corpus ID\": 214802984, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 250.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Misc (Scene Segmentation)\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"moviescenes\", \"Collection\": \"moviescenes\", \"Collection URL\": \"https://arxiv.org/abs/2004.02678\", \"Dataset Name\": \"MovieScenes\", \"Paper Title\": \"MovieScenes\", \"Paper URL\": \"https://arxiv.org/abs/2004.02678\", \"GitHub URL\": \"https://github.com/AnyiRao/SceneSeg\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-local-to-global-approach-to-multi-modal\", \"ArXiv URL\": \"https://arxiv.org/abs/2004.02678\", \"Semantic Scholar Corpus ID\": 214802984, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 250.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Misc (Scene Segmentation)\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"movie-net\", \"Collection\": \"movie-net\", \"Collection URL\": \"https://arxiv.org/abs/2007.10937\", \"Dataset Name\": \"MovieNet\", \"Paper Title\": \"MovieNet\", \"Paper URL\": \"https://arxiv.org/abs/2007.10937\", \"GitHub URL\": \"https://github.com/movienet/movienet-tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/movienet\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.10937\", \"Semantic Scholar Corpus ID\": 220665753, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Summarization\", \"Misc\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"violin\", \"Collection\": \"violin\", \"Collection URL\": \"https://arxiv.org/abs/2003.11618\", \"Dataset Name\": \"VIOLIN\", \"Paper Title\": \"VIOLIN\", \"Paper URL\": \"https://arxiv.org/abs/2003.11618\", \"GitHub URL\": \"https://github.com/jimmy646/violin\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/violin\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.11618\", \"Semantic Scholar Corpus ID\": 214668012, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 582.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"tiny-virat\", \"Collection\": \"tiny-virat\", \"Collection URL\": \"https://arxiv.org/abs/2007.07355\", \"Dataset Name\": \"TinyVIRAT: Low-resolution Video Action Recognition\", \"Paper Title\": \"TinyVIRAT: Low-resolution Video Action Recognition\", \"Paper URL\": \"https://arxiv.org/abs/2007.07355\", \"GitHub URL\": \"https://github.com/UgurDemir/Tiny-VIRAT\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tinyvirat\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.07355\", \"Semantic Scholar Corpus ID\": 220525685, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 10.83, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"haa500-dataset\", \"Collection\": \"haa500-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2009.05224\", \"Dataset Name\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper Title\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper URL\": \"https://arxiv.org/abs/2009.05224\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/haa500-human-centric-atomic-action-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.05224\", \"Semantic Scholar Corpus ID\": 221640805, \"Year Released\": \"2020\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 5.48, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"lemma-dataset\", \"Collection\": \"lemma-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2007.15781\", \"Dataset Name\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper Title\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2007.15781\", \"GitHub URL\": \"https://github.com/Buzz-Beater/LEMMA\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/lemma\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.15781\", \"Semantic Scholar Corpus ID\": 220634784, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\", \"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 10.8, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\", \"human\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"haa500-dataset\", \"Collection\": \"haa500-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2009.05224\", \"Dataset Name\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper Title\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper URL\": \"https://arxiv.org/abs/2009.05224\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/haa500-human-centric-atomic-action-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.05224\", \"Semantic Scholar Corpus ID\": 221640805, \"Year Released\": \"2020\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Corporation\", \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 5.48, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"haa500-dataset\", \"Collection\": \"haa500-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2009.05224\", \"Dataset Name\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper Title\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper URL\": \"https://arxiv.org/abs/2009.05224\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/haa500-human-centric-atomic-action-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.05224\", \"Semantic Scholar Corpus ID\": 221640805, \"Year Released\": \"2020\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 5.48, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"oops-dataset\", \"Collection\": \"oops-dataset\", \"Collection URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Epstein_Oops_Predicting_Unintentional_Action_in_Video_CVPR_2020_paper.pdf\", \"Dataset Name\": \"Oops!: Predicting Unintentional Action in Video (CVPR 2020)\", \"Paper Title\": \"Oops!: Predicting Unintentional Action in Video (CVPR 2020)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Epstein_Oops_Predicting_Unintentional_Action_in_Video_CVPR_2020_paper.pdf\", \"GitHub URL\": \"https://github.com/cvlab-columbia/oops\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/oops-predicting-unintentional-action-in-video\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Epstein_Oops_Predicting_Unintentional_Action_in_Video_CVPR_2020_paper.pdf\", \"Semantic Scholar Corpus ID\": 208291335, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://oops.cs.columbia.edu/data/\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 50.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"haa500-dataset\", \"Collection\": \"haa500-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2009.05224\", \"Dataset Name\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper Title\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper URL\": \"https://arxiv.org/abs/2009.05224\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/haa500-human-centric-atomic-action-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.05224\", \"Semantic Scholar Corpus ID\": 221640805, \"Year Released\": \"2020\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 5.48, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"videolt-dataset\", \"Collection\": \"videolt-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2105.02668\", \"Dataset Name\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper Title\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper URL\": \"https://arxiv.org/abs/2105.02668\", \"GitHub URL\": \"https://github.com/17Skye17/VideoLT\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/videolt\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.02668\", \"Semantic Scholar Corpus ID\": 233864776, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Non Commercial\", \"License URL\": \"https://github.com/17Skye17/VideoLT?tab=readme-ov-file#data-preparation\"}], \"Creators\": \"Research Group\", \"Countries\": [\"China\", \"UAE\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13664.96, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"videolt-dataset\", \"Collection\": \"videolt-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2105.02668\", \"Dataset Name\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper Title\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper URL\": \"https://arxiv.org/abs/2105.02668\", \"GitHub URL\": \"https://github.com/17Skye17/VideoLT\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/videolt\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.02668\", \"Semantic Scholar Corpus ID\": 233864776, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Non Commercial\", \"License URL\": \"https://github.com/17Skye17/VideoLT?tab=readme-ov-file#data-preparation\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\", \"UAE\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13664.96, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"WebVid\", \"Collection\": \"WebVid\", \"Collection URL\": \"https://arxiv.org/abs/2104.00650\", \"Dataset Name\": \"WebVid\", \"Paper Title\": \"WebVid\", \"Paper URL\": \"https://arxiv.org/abs/2104.00650\", \"GitHub URL\": \"https://github.com/m-bain/webvid\", \"Hugging Face URL\": \"https://huggingface.co/datasets/TempoFunk/webvid-10M\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/webvid\", \"ArXiv URL\": \"https://arxiv.org/abs/2104.00650\", \"Semantic Scholar Corpus ID\": 232478955, \"Year Released\": \"2021\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/m-bain/webvid/blob/main/TERMS.md\"}], \"Creators\": \"Academic\", \"Countries\": [\"United Kingdom\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13000.0, \"Taken Down\": \"True\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"multi-moments-in-time-dataset\", \"Collection\": \"multi-moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Dataset Name\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper Title\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Semantic Scholar Corpus ID\": 207780280, \"Year Released\": \"2021\", \"Text Sources\": [\"crowdsourced\", \"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\", \"undisclosed web\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"YT-Temporal-180m\", \"Collection\": \"YT-Temporal-180m\", \"Collection URL\": \"https://arxiv.org/pdf/2106.02636\", \"Dataset Name\": \"MERLOT: Multimodal Neural Script Knowledge Models\", \"Paper Title\": \"MERLOT: Multimodal Neural Script Knowledge Models\", \"Paper URL\": \"https://arxiv.org/pdf/2106.02636\", \"GitHub URL\": \"https://github.com/rowanz/merlot\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/yttemporal180m\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/merlot-multimodal-neural-script-knowledge\", \"ArXiv URL\": \"https://arxiv.org/pdf/2106.02636\", \"Semantic Scholar Corpus ID\": 235352775, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/rowanz/merlot/blob/main/LICENSE\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1515.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"YT-Temporal-180m\", \"Collection\": \"YT-Temporal-180m\", \"Collection URL\": \"https://arxiv.org/pdf/2106.02636\", \"Dataset Name\": \"MERLOT: Multimodal Neural Script Knowledge Models\", \"Paper Title\": \"MERLOT: Multimodal Neural Script Knowledge Models\", \"Paper URL\": \"https://arxiv.org/pdf/2106.02636\", \"GitHub URL\": \"https://github.com/rowanz/merlot\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/yttemporal180m\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/merlot-multimodal-neural-script-knowledge\", \"ArXiv URL\": \"https://arxiv.org/pdf/2106.02636\", \"Semantic Scholar Corpus ID\": 235352775, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/rowanz/merlot/blob/main/LICENSE\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1515.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"videolt-dataset\", \"Collection\": \"videolt-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2105.02668\", \"Dataset Name\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper Title\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper URL\": \"https://arxiv.org/abs/2105.02668\", \"GitHub URL\": \"https://github.com/17Skye17/VideoLT\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/videolt\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.02668\", \"Semantic Scholar Corpus ID\": 233864776, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Non Commercial\", \"License URL\": \"https://github.com/17Skye17/VideoLT?tab=readme-ov-file#data-preparation\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\", \"UAE\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13664.96, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"uav-human\", \"Collection\": \"uav-human\", \"Collection URL\": \"https://arxiv.org/abs/2104.00946\", \"Dataset Name\": \"UAV-Human: A Large Benchmark for Human Behavior Understanding with Unmanned Aerial Vehicles\", \"Paper Title\": \"UAV-Human: A Large Benchmark for Human Behavior Understanding with Unmanned Aerial Vehicles\", \"Paper URL\": \"https://arxiv.org/abs/2104.00946\", \"GitHub URL\": \"https://github.com/sutdcv/UAV-Human\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/uav-human-a-large-benchmark-for-human\", \"ArXiv URL\": \"https://arxiv.org/abs/2104.00946\", \"Semantic Scholar Corpus ID\": 233004700, \"Year Released\": \"2021\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://sutdcv.github.io/uav-human-web/\"}], \"Creators\": \"Academic\", \"Countries\": [\"Singapore\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 18.34, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"uav-human\", \"Collection\": \"uav-human\", \"Collection URL\": \"https://arxiv.org/abs/2104.00946\", \"Dataset Name\": \"UAV-Human: A Large Benchmark for Human Behavior Understanding with Unmanned Aerial Vehicles\", \"Paper Title\": \"UAV-Human: A Large Benchmark for Human Behavior Understanding with Unmanned Aerial Vehicles\", \"Paper URL\": \"https://arxiv.org/abs/2104.00946\", \"GitHub URL\": \"https://github.com/sutdcv/UAV-Human\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/uav-human-a-large-benchmark-for-human\", \"ArXiv URL\": \"https://arxiv.org/abs/2104.00946\", \"Semantic Scholar Corpus ID\": 233004700, \"Year Released\": \"2021\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://sutdcv.github.io/uav-human-web/\"}], \"Creators\": \"Academic\", \"Countries\": [\"Singapore\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 18.34, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"apes\", \"Collection\": \"apes\", \"Collection URL\": \"https://arxiv.org/pdf/2106.01667\", \"Dataset Name\": \"Apes\", \"Paper Title\": \"Apes\", \"Paper URL\": \"https://arxiv.org/pdf/2106.01667\", \"GitHub URL\": \"https://github.com/fuankarion/audiovisual-person-search\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/apes-audiovisual-person-search-in-untrimmed/review/\", \"ArXiv URL\": \"https://arxiv.org/pdf/2106.01667\", \"Semantic Scholar Corpus ID\": 235313698, \"Year Released\": \"2021\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"Chile\", \"United States of America\", \"Saudi Arabia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 36.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hd-vila-100m\", \"Collection\": \"hd-vila-100m\", \"Collection URL\": \"https://arxiv.org/abs/2111.10337\", \"Dataset Name\": \"Advancing High-Resolution Video-Language Representation with Large-Scale Video Transcriptions\", \"Paper Title\": \"Advancing High-Resolution Video-Language Representation with Large-Scale Video Transcriptions\", \"Paper URL\": \"https://arxiv.org/abs/2111.10337\", \"GitHub URL\": \"https://github.com/microsoft/XPretrain/blob/main/hd-vila-100m/README.md\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/advancing-high-resolution-video-language/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2111.10337\", \"Semantic Scholar Corpus ID\": 244462849, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/microsoft/XPretrain/blob/main/hd-vila-100m/README.md\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 371.5, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"mimetics-dataset\", \"Collection\": \"mimetics-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1912.07249\", \"Dataset Name\": \"Mimetics: Towards Understanding Human Actions Out of Context\", \"Paper Title\": \"Mimetics: Towards Understanding Human Actions Out of Context\", \"Paper URL\": \"https://arxiv.org/abs/1912.07249\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/mimetics-towards-understanding-human-actions\", \"ArXiv URL\": \"https://arxiv.org/abs/1912.07249\", \"Semantic Scholar Corpus ID\": 209376248, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Corporation\", \"Countries\": [\"South Korea\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.99, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"queryd\", \"Collection\": \"queryd\", \"Collection URL\": \"https://arxiv.org/abs/2011.11071\", \"Dataset Name\": \"QuerYD\", \"Paper Title\": \"QuerYD\", \"Paper URL\": \"https://arxiv.org/abs/2011.11071\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/queryd\", \"ArXiv URL\": \"https://arxiv.org/abs/2011.11071\", \"Semantic Scholar Corpus ID\": 261006321, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"youdescribe\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 207.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\", \"youdescribe\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"WebVid\", \"Collection\": \"WebVid\", \"Collection URL\": \"https://arxiv.org/abs/2104.00650\", \"Dataset Name\": \"WebVid\", \"Paper Title\": \"WebVid\", \"Paper URL\": \"https://arxiv.org/abs/2104.00650\", \"GitHub URL\": \"https://github.com/m-bain/webvid\", \"Hugging Face URL\": \"https://huggingface.co/datasets/TempoFunk/webvid-10M\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/webvid\", \"ArXiv URL\": \"https://arxiv.org/abs/2104.00650\", \"Semantic Scholar Corpus ID\": 232478955, \"Year Released\": \"2021\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/m-bain/webvid/blob/main/TERMS.md\"}], \"Creators\": \"Academic\", \"Countries\": [\"United Kingdom\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13000.0, \"Taken Down\": \"True\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"apes\", \"Collection\": \"apes\", \"Collection URL\": \"https://arxiv.org/pdf/2106.01667\", \"Dataset Name\": \"Apes\", \"Paper Title\": \"Apes\", \"Paper URL\": \"https://arxiv.org/pdf/2106.01667\", \"GitHub URL\": \"https://github.com/fuankarion/audiovisual-person-search\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/apes-audiovisual-person-search-in-untrimmed/review/\", \"ArXiv URL\": \"https://arxiv.org/pdf/2106.01667\", \"Semantic Scholar Corpus ID\": 235313698, \"Year Released\": \"2021\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"Chile\", \"United States of America\", \"Saudi Arabia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 36.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"homage\", \"Collection\": \"homage\", \"Collection URL\": \"https://arxiv.org/abs/2105.05226\", \"Dataset Name\": \"HOMAGE: Home Action Genome: Cooperative Compositional Action Understanding (CVPR 2021)\", \"Paper Title\": \"HOMAGE: Home Action Genome: Cooperative Compositional Action Understanding (CVPR 2021)\", \"Paper URL\": \"https://arxiv.org/abs/2105.05226\", \"GitHub URL\": \"https://github.com/nishantrai18/homage\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/home-action-genome-cooperative-compositional\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.05226\", \"Semantic Scholar Corpus ID\": 234357543, \"Year Released\": \"2021\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Corporation\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 30.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Classification\", \"Temporal Action Segmentation\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"homage\", \"Collection\": \"homage\", \"Collection URL\": \"https://arxiv.org/abs/2105.05226\", \"Dataset Name\": \"HOMAGE: Home Action Genome: Cooperative Compositional Action Understanding (CVPR 2021)\", \"Paper Title\": \"HOMAGE: Home Action Genome: Cooperative Compositional Action Understanding (CVPR 2021)\", \"Paper URL\": \"https://arxiv.org/abs/2105.05226\", \"GitHub URL\": \"https://github.com/nishantrai18/homage\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/home-action-genome-cooperative-compositional\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.05226\", \"Semantic Scholar Corpus ID\": 234357543, \"Year Released\": \"2021\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 30.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Classification\", \"Temporal Action Segmentation\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"apes\", \"Collection\": \"apes\", \"Collection URL\": \"https://arxiv.org/pdf/2106.01667\", \"Dataset Name\": \"Apes\", \"Paper Title\": \"Apes\", \"Paper URL\": \"https://arxiv.org/pdf/2106.01667\", \"GitHub URL\": \"https://github.com/fuankarion/audiovisual-person-search\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/apes-audiovisual-person-search-in-untrimmed/review/\", \"ArXiv URL\": \"https://arxiv.org/pdf/2106.01667\", \"Semantic Scholar Corpus ID\": 235313698, \"Year Released\": \"2021\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Corporation\", \"Countries\": [\"Chile\", \"United States of America\", \"Saudi Arabia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 36.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": \"Corporation\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"videolt-dataset\", \"Collection\": \"videolt-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2105.02668\", \"Dataset Name\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper Title\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper URL\": \"https://arxiv.org/abs/2105.02668\", \"GitHub URL\": \"https://github.com/17Skye17/VideoLT\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/videolt\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.02668\", \"Semantic Scholar Corpus ID\": 233864776, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Non Commercial\", \"License URL\": \"https://github.com/17Skye17/VideoLT?tab=readme-ov-file#data-preparation\"}], \"Creators\": \"Other\", \"Countries\": [\"China\", \"UAE\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13664.96, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"cacd\", \"Collection\": \"cacd\", \"Collection URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"Dataset Name\": \"CDAD: A Common Daily Action Dataset with Collected Hard Negative Samples (CVPR 2022)\", \"Paper Title\": \"CDAD: A Common Daily Action Dataset with Collected Hard Negative Samples (CVPR 2022)\", \"Paper URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"GitHub URL\": \"https://github.com/MartinXM/CDAD\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"Semantic Scholar Corpus ID\": 251035434, \"Year Released\": \"2022\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Corporation\", \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 215.0, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"cacd\", \"Collection\": \"cacd\", \"Collection URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"Dataset Name\": \"CDAD: A Common Daily Action Dataset with Collected Hard Negative Samples (CVPR 2022)\", \"Paper Title\": \"CDAD: A Common Daily Action Dataset with Collected Hard Negative Samples (CVPR 2022)\", \"Paper URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"GitHub URL\": \"https://github.com/MartinXM/CDAD\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"Semantic Scholar Corpus ID\": 251035434, \"Year Released\": \"2022\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 215.0, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"ferv39k-dataset\", \"Collection\": \"ferv39k-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2203.09463\", \"Dataset Name\": \"FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos (CVPR 2022)\", \"Paper Title\": \"FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos (CVPR 2022)\", \"Paper URL\": \"https://arxiv.org/abs/2203.09463\", \"GitHub URL\": \"https://github.com/wangyanckxx/FERV39k\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ferv39k-a-large-scale-multi-scene-dataset-for\", \"ArXiv URL\": \"https://arxiv.org/abs/2203.09463\", \"Semantic Scholar Corpus ID\": 247518747, \"Year Released\": \"2022\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://wangyanckxx.github.io/Proj_CVPR2022_FERV39k.html\"}], \"Creators\": \"Academic\", \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 16.47, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"mad\", \"Collection\": \"mad\", \"Collection URL\": \"https://arxiv.org/abs/2112.00431\", \"Dataset Name\": \"MAD: A Scalable Dataset for Language Grounding in Videos from Movie Audio Descriptions\", \"Paper Title\": \"MAD: A Scalable Dataset for Language Grounding in Videos from Movie Audio Descriptions\", \"Paper URL\": \"https://arxiv.org/abs/2112.00431\", \"GitHub URL\": \"https://github.com/Soldelli/MAD\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mad\", \"ArXiv URL\": \"https://arxiv.org/abs/2112.00431\", \"Semantic Scholar Corpus ID\": 244773187, \"Year Released\": \"2022\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdtUV3uweS0u7AHAMIJAL_dRRdZ5MHpJS3fdZVbhnVt-Yb4NA/viewform\"}], \"Creators\": \"Academic\", \"Countries\": [\"Saudi Arabia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1207.3, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"YT-Temporal-1B\", \"Collection\": \"YT-Temporal-1B\", \"Collection URL\": \"https://arxiv.org/pdf/2201.02639\", \"Dataset Name\": \"MERLOT Reserve: Multimodal Neural Script Knowledge through Vision and Language and Sound\", \"Paper Title\": \"MERLOT Reserve: Multimodal Neural Script Knowledge through Vision and Language and Sound\", \"Paper URL\": \"https://arxiv.org/pdf/2201.02639\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/merlot-reserve-neural-script-knowledge\", \"ArXiv URL\": \"https://arxiv.org/pdf/2201.02639\", \"Semantic Scholar Corpus ID\": 245837609, \"Year Released\": \"2022\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/rowanz/merlot_reserve/blob/main/LICENSE\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Scotland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 55555.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"YT-Temporal-1B\", \"Collection\": \"YT-Temporal-1B\", \"Collection URL\": \"https://arxiv.org/pdf/2201.02639\", \"Dataset Name\": \"MERLOT Reserve: Multimodal Neural Script Knowledge through Vision and Language and Sound\", \"Paper Title\": \"MERLOT Reserve: Multimodal Neural Script Knowledge through Vision and Language and Sound\", \"Paper URL\": \"https://arxiv.org/pdf/2201.02639\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/merlot-reserve-neural-script-knowledge\", \"ArXiv URL\": \"https://arxiv.org/pdf/2201.02639\", \"Semantic Scholar Corpus ID\": 245837609, \"Year Released\": \"2022\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/rowanz/merlot_reserve/blob/main/LICENSE\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Scotland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 55555.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"YT-Temporal-1B\", \"Collection\": \"YT-Temporal-1B\", \"Collection URL\": \"https://arxiv.org/pdf/2201.02639\", \"Dataset Name\": \"MERLOT Reserve: Multimodal Neural Script Knowledge through Vision and Language and Sound\", \"Paper Title\": \"MERLOT Reserve: Multimodal Neural Script Knowledge through Vision and Language and Sound\", \"Paper URL\": \"https://arxiv.org/pdf/2201.02639\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/merlot-reserve-neural-script-knowledge\", \"ArXiv URL\": \"https://arxiv.org/pdf/2201.02639\", \"Semantic Scholar Corpus ID\": 245837609, \"Year Released\": \"2022\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/rowanz/merlot_reserve/blob/main/LICENSE\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Scotland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 55555.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ego-4d\", \"Collection\": \"ego-4d\", \"Collection URL\": \"https://arxiv.org/abs/2110.07058\", \"Dataset Name\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper Title\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper URL\": \"https://arxiv.org/abs/2110.07058\", \"GitHub URL\": \"https://github.com/EGO4D/forecasting\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego4d-around-the-world-in-3000-hours-of\", \"ArXiv URL\": \"https://arxiv.org/abs/2110.07058\", \"Semantic Scholar Corpus ID\": 238856888, \"Year Released\": \"2022\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://ego4d-data.org/pdfs/Ego4D-Licenses-Draft.pdf\"}], \"Creators\": \"Industry Lab\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3670.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Classification\", \"Temporal Action Segmentation\", \"Video Captioning\", \"Misc\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ego-exo4D\", \"Collection\": \"ego-exo4D\", \"Collection URL\": \"https://arxiv.org/abs/2311.18259\", \"Dataset Name\": \"Ego-Exo4D\", \"Paper Title\": \"Ego-Exo4D\", \"Paper URL\": \"https://arxiv.org/abs/2311.18259\", \"GitHub URL\": \"https://github.com/facebookresearch/Ego4d\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego-exo4d-understanding-skilled-human/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2311.18259\", \"Semantic Scholar Corpus ID\": 265506384, \"Year Released\": \"2023\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/facebookresearch/Ego4d/blob/main/LICENSE\"}], \"Creators\": \"Corporation\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1422.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Pose Estimation\", \"Video Classification\", \"Video Captioning\", \"Misc\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"project-aria-digital-twin-dataset\", \"Collection\": \"project-aria-digital-twin-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2306.06362\", \"Dataset Name\": \"Aria Digital Twin\", \"Paper Title\": \"Aria Digital Twin\", \"Paper URL\": \"https://arxiv.org/abs/2306.06362\", \"GitHub URL\": \"https://github.com/facebookresearch/projectaria_tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/aria-digital-twin-a-new-benchmark-dataset-for\", \"ArXiv URL\": \"https://arxiv.org/abs/2306.06362\", \"Semantic Scholar Corpus ID\": 261243365, \"Year Released\": \"2023\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/facebookresearch/projectaria_tools/blob/main/LICENSE\"}], \"Creators\": \"Corporation\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 6.6, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Object Detection\", \"Video Segmentation\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"egopet\", \"Collection\": \"egopet\", \"Collection URL\": \"https://arxiv.org/pdf/2404.09991\", \"Dataset Name\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper Title\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper URL\": \"https://arxiv.org/pdf/2404.09991\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egopet-egomotion-and-interaction-data-from-an\", \"ArXiv URL\": \"https://arxiv.org/pdf/2404.09991\", \"Semantic Scholar Corpus ID\": 269148727, \"Year Released\": \"2024\", \"Text Sources\": [\"tiktok\", \"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://github.com/DannyTran123/egopet/blob/main/LICENSE\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 84.0, \"Taken Down\": \"False\", \"Video Sources\": [\"tiktok\", \"youtube\"], \"Task Categories\": [\"Misc (Locomotion Prediction\", \"Visual Interaction Prediction\", \"Vision to Proprioception Prediction)\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"egoschema\", \"Collection\": \"egoschema\", \"Collection URL\": \"https://arxiv.org/pdf/2308.09126\", \"Dataset Name\": \"EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding\", \"Paper Title\": \"EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding\", \"Paper URL\": \"https://arxiv.org/pdf/2308.09126\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egoschema-a-diagnostic-benchmark-for-very-1\", \"ArXiv URL\": \"https://arxiv.org/pdf/2308.09126\", \"Semantic Scholar Corpus ID\": 261031047, \"Year Released\": \"2024\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 250.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"cinepile\", \"Collection\": \"cinepile\", \"Collection URL\": \"https://arxiv.org/pdf/2405.08813\", \"Dataset Name\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper Title\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper URL\": \"https://arxiv.org/pdf/2405.08813\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/tomg-group-umd/cinepile\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/cinepile\", \"ArXiv URL\": \"https://arxiv.org/pdf/2405.08813\", \"Semantic Scholar Corpus ID\": 269761335, \"Year Released\": \"2024\", \"Text Sources\": [\"youtube\", \"movies\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://creativecommons.org/licenses/by/4.0/\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 417.6, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\", \"movies\"], \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"cinepile\", \"Collection\": \"cinepile\", \"Collection URL\": \"https://arxiv.org/pdf/2405.08813\", \"Dataset Name\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper Title\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper URL\": \"https://arxiv.org/pdf/2405.08813\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/tomg-group-umd/cinepile\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/cinepile\", \"ArXiv URL\": \"https://arxiv.org/pdf/2405.08813\", \"Semantic Scholar Corpus ID\": 269761335, \"Year Released\": \"2024\", \"Text Sources\": [\"youtube\", \"movies\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://creativecommons.org/licenses/by/4.0/\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 417.6, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\", \"movies\"], \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"egopet\", \"Collection\": \"egopet\", \"Collection URL\": \"https://arxiv.org/pdf/2404.09991\", \"Dataset Name\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper Title\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper URL\": \"https://arxiv.org/pdf/2404.09991\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egopet-egomotion-and-interaction-data-from-an\", \"ArXiv URL\": \"https://arxiv.org/pdf/2404.09991\", \"Semantic Scholar Corpus ID\": 269148727, \"Year Released\": \"2024\", \"Text Sources\": [\"tiktok\", \"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://github.com/DannyTran123/egopet/blob/main/LICENSE\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 84.0, \"Taken Down\": \"False\", \"Video Sources\": [\"tiktok\", \"youtube\"], \"Task Categories\": [\"Misc (Locomotion Prediction\", \"Visual Interaction Prediction\", \"Vision to Proprioception Prediction)\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"project-aria-dataset\", \"Collection\": \"project-aria-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/2402.13349\", \"Dataset Name\": \"Aria Everyday Activities Dataset\", \"Paper Title\": \"Aria Everyday Activities Dataset\", \"Paper URL\": \"https://arxiv.org/pdf/2402.13349\", \"GitHub URL\": \"https://github.com/facebookresearch/projectaria_tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/aria-everyday-activities-dataset\", \"ArXiv URL\": \"https://arxiv.org/pdf/2402.13349\", \"Semantic Scholar Corpus ID\": 267770215, \"Year Released\": \"2024\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/facebookresearch/Aria_data_tools/blob/main/LICENSE\"}], \"Creators\": \"Corporation\", \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1400.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": [\"Misc (Scene Reconstruction)\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"egopet\", \"Collection\": \"egopet\", \"Collection URL\": \"https://arxiv.org/pdf/2404.09991\", \"Dataset Name\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper Title\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper URL\": \"https://arxiv.org/pdf/2404.09991\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egopet-egomotion-and-interaction-data-from-an\", \"ArXiv URL\": \"https://arxiv.org/pdf/2404.09991\", \"Semantic Scholar Corpus ID\": 269148727, \"Year Released\": \"2024\", \"Text Sources\": [\"tiktok\", \"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://github.com/DannyTran123/egopet/blob/main/LICENSE\"}], \"Creators\": \"Academic\", \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 84.0, \"Taken Down\": \"False\", \"Video Sources\": [\"tiktok\", \"youtube\"], \"Task Categories\": [\"Misc (Locomotion Prediction\", \"Visual Interaction Prediction\", \"Vision to Proprioception Prediction)\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_creatoryear = alt.Chart(\n",
    "    df_videocreatoryears\n",
    ").mark_bar().encode(\n",
    "    x=alt.X(\n",
    "        \"Year Released:N\",\n",
    "        title=\"Year Released\",\n",
    "        sort=YEARS_ORDER,\n",
    "        axis=alt.Axis(labelAngle=-30)\n",
    "    ),\n",
    "    y=alt.Y(\n",
    "        \"count():Q\",\n",
    "        stack=\"normalize\",\n",
    "        axis=alt.Axis(format=\"%\"),\n",
    "        title=\"Pct. Datasets\"\n",
    "    ),\n",
    "    color=alt.Color(\n",
    "        \"Creators:N\",\n",
    "        title=\"Video Creator Cateogies\"\n",
    "    )\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=160\n",
    ")\n",
    "\n",
    "text_creatoryear = alt.Chart(df_videocreatoryears).mark_text(\n",
    "    dy=-90,\n",
    "    align=\"center\",\n",
    "    baseline=\"top\",\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    x=alt.X(\n",
    "        \"Year Released:N\",\n",
    "        title=\"Year Released\",\n",
    "        sort=YEARS_ORDER\n",
    "    ),\n",
    "    text=\"count():Q\"\n",
    ")\n",
    "\n",
    "chart_creatoryear = (base_creatoryear + text_creatoryear).configure_axis(\n",
    "    labelFontSize=FONT_SIZE,\n",
    "    titleFontSize=FONT_SIZE\n",
    ").configure_legend(\n",
    "    labelFontSize=FONT_SIZE,\n",
    "    titleFontSize=FONT_SIZE,\n",
    "    orient=LEGEND_POSITION,\n",
    "    columns=4,\n",
    "    labelLimit=MAX_LABELLIMIT\n",
    ")\n",
    "\n",
    "\n",
    "if PLOT_TOFILE:\n",
    "    chart_creatoryear.save(\n",
    "        os.path.join(PLOT_DIR, \"video_creatorcategories-years.png\"),\n",
    "        ppi=PLOT_PPI\n",
    "    )\n",
    "\n",
    "chart_creatoryear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Hours by Source Category (Cumulative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2104418/3555095109.py:6: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_speechsourceyearscumulativehours = df_speechsourceyears.groupby(\n"
     ]
    }
   ],
   "source": [
    "INCLUDE_TOP_N_CATEGORIES = 6\n",
    "\n",
    "df_speechsourceyears = df_video.explode(\"Video Sources\")\n",
    "df_speechsourceyears = reduce_categories_to_topk(df_speechsourceyears, \"Video Sources\", INCLUDE_TOP_N_CATEGORIES)\n",
    "\n",
    "df_speechsourceyearscumulativehours = df_speechsourceyears.groupby(\n",
    "    [\"Year Released\", \"Video Sources\"]\n",
    ")[\"Video Hours\"].sum().groupby(\n",
    "    \"Video Sources\"\n",
    ").cumsum().reset_index(name=\"Cumulative Hours\")\n",
    "\n",
    "df_speechsourceyearscumulativehours = df_speechsourceyearscumulativehours.sort_values(by=\"Year Released\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-a2e95aefcfb649b09f9dfdbfcf5afb03.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-a2e95aefcfb649b09f9dfdbfcf5afb03.vega-embed details,\n",
       "  #altair-viz-a2e95aefcfb649b09f9dfdbfcf5afb03.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-a2e95aefcfb649b09f9dfdbfcf5afb03\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a2e95aefcfb649b09f9dfdbfcf5afb03\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a2e95aefcfb649b09f9dfdbfcf5afb03\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"Times New Roman\"}, \"axis\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\"}, \"header\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\"}, \"legend\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\"}, \"text\": {\"font\": \"Times New Roman\"}}, \"data\": {\"name\": \"data-dd5c5a2a31ed97d4549b517cbef49661\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"Video Sources\", \"title\": \"Video Sources\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30}, \"field\": \"Year Released\", \"sort\": [\"<2004\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"], \"title\": \"Year Released\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"labelExpr\": \"datum.value >= 1000000 ? datum.value / 1000000 + 'M' : datum.value >= 1000 ? datum.value / 1000 + 'K' : datum.value\", \"values\": [0, 1, 1000, 10000, 100000, 1000000]}, \"field\": \"Cumulative Hours\", \"scale\": {\"constant\": 1000, \"domain\": [1, 1000000], \"type\": \"symlog\"}, \"title\": \"Cumulative Hours\", \"type\": \"quantitative\"}}, \"height\": 160, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-dd5c5a2a31ed97d4549b517cbef49661\": [{\"Year Released\": \"<2004\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"<2004\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"<2004\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"<2004\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"<2004\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"<2004\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"<2004\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2004\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2004\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2004\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2004\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2004\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2004\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2004\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2005\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2005\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2005\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2005\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2005\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2005\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2005\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2006\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2006\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2006\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2006\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2006\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2006\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2006\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2007\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2007\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2007\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2007\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2007\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2007\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2007\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2008\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2008\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2008\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2008\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2008\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2008\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2008\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2009\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2009\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2009\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2009\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.1}, {\"Year Released\": \"2009\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 20.1}, {\"Year Released\": \"2009\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2009\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2010\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2010\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 20.1}, {\"Year Released\": \"2010\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.1}, {\"Year Released\": \"2010\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2010\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2010\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2010\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2011\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 7000.0}, {\"Year Released\": \"2011\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7020.1}, {\"Year Released\": \"2011\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.1}, {\"Year Released\": \"2011\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 7000.0}, {\"Year Released\": \"2011\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2011\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 14000.0}, {\"Year Released\": \"2011\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2012\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 14000.0}, {\"Year Released\": \"2012\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2012\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2012\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.1}, {\"Year Released\": \"2012\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7020.1}, {\"Year Released\": \"2012\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 7000.0}, {\"Year Released\": \"2012\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 7026.0}, {\"Year Released\": \"2013\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7020.1}, {\"Year Released\": \"2013\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 7000.0}, {\"Year Released\": \"2013\", \"Video Sources\": \"human\", \"Cumulative Hours\": 40.1}, {\"Year Released\": \"2013\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 8026.0}, {\"Year Released\": \"2013\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2013\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2013\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 14000.0}, {\"Year Released\": \"2014\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 114784.41}, {\"Year Released\": \"2014\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 14000.0}, {\"Year Released\": \"2014\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 1.11}, {\"Year Released\": \"2014\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2014\", \"Video Sources\": \"human\", \"Cumulative Hours\": 117.1}, {\"Year Released\": \"2014\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7036.150000000001}, {\"Year Released\": \"2014\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 7000.0}, {\"Year Released\": \"2015\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 114788.01000000001}, {\"Year Released\": \"2015\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 7849.0}, {\"Year Released\": \"2015\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7417.150000000001}, {\"Year Released\": \"2015\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 14000.0}, {\"Year Released\": \"2015\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2015\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 1.11}, {\"Year Released\": \"2015\", \"Video Sources\": \"human\", \"Cumulative Hours\": 144.1}, {\"Year Released\": \"2016\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7417.150000000001}, {\"Year Released\": \"2016\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 8103.4}, {\"Year Released\": \"2016\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 464795.01}, {\"Year Released\": \"2016\", \"Video Sources\": \"human\", \"Cumulative Hours\": 253.64}, {\"Year Released\": \"2016\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 75.21}, {\"Year Released\": \"2016\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 14086.1}, {\"Year Released\": \"2016\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2017\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 8112.7}, {\"Year Released\": \"2017\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7631.650000000001}, {\"Year Released\": \"2017\", \"Video Sources\": \"human\", \"Cumulative Hours\": 1104.32}, {\"Year Released\": \"2017\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 467108.11}, {\"Year Released\": \"2017\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 266.66999999999996}, {\"Year Released\": \"2017\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 14086.1}, {\"Year Released\": \"2017\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2018\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 15647.2}, {\"Year Released\": \"2018\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 266.66999999999996}, {\"Year Released\": \"2018\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 275.0}, {\"Year Released\": \"2018\", \"Video Sources\": \"human\", \"Cumulative Hours\": 1273.6499999999999}, {\"Year Released\": \"2018\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7725.55}, {\"Year Released\": \"2018\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 8112.7}, {\"Year Released\": \"2018\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 471120.63}, {\"Year Released\": \"2019\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 608601.21}, {\"Year Released\": \"2019\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 9112.7}, {\"Year Released\": \"2019\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 8241.550000000001}, {\"Year Released\": \"2019\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 279.66999999999996}, {\"Year Released\": \"2019\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 1108.0}, {\"Year Released\": \"2019\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 24182.7}, {\"Year Released\": \"2019\", \"Video Sources\": \"human\", \"Cumulative Hours\": 1642.23}, {\"Year Released\": \"2020\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 10211.83}, {\"Year Released\": \"2020\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 12919.55}, {\"Year Released\": \"2020\", \"Video Sources\": \"human\", \"Cumulative Hours\": 1658.51}, {\"Year Released\": \"2020\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 725115.74}, {\"Year Released\": \"2020\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 304.21}, {\"Year Released\": \"2020\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 50848.7}, {\"Year Released\": \"2020\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 1108.0}, {\"Year Released\": \"2021\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 54805.73}, {\"Year Released\": \"2021\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 1137.21}, {\"Year Released\": \"2021\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 1524.67}, {\"Year Released\": \"2021\", \"Video Sources\": \"human\", \"Cumulative Hours\": 1706.85}, {\"Year Released\": \"2021\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 12955.55}, {\"Year Released\": \"2021\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 24044.83}, {\"Year Released\": \"2021\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 741291.86}, {\"Year Released\": \"2022\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 796846.86}, {\"Year Released\": \"2022\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 25268.6}, {\"Year Released\": \"2022\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 12955.55}, {\"Year Released\": \"2022\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 1352.21}, {\"Year Released\": \"2022\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 1524.67}, {\"Year Released\": \"2022\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 54805.73}, {\"Year Released\": \"2022\", \"Video Sources\": \"human\", \"Cumulative Hours\": 5376.85}, {\"Year Released\": \"2023\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 796846.86}, {\"Year Released\": \"2023\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 12955.55}, {\"Year Released\": \"2023\", \"Video Sources\": \"human\", \"Cumulative Hours\": 6805.45}, {\"Year Released\": \"2023\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 25268.6}, {\"Year Released\": \"2023\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 1352.21}, {\"Year Released\": \"2023\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 54805.73}, {\"Year Released\": \"2023\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 1524.67}, {\"Year Released\": \"2024\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 25268.6}, {\"Year Released\": \"2024\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 54889.73}, {\"Year Released\": \"2024\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 1352.21}, {\"Year Released\": \"2024\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 1524.67}, {\"Year Released\": \"2024\", \"Video Sources\": \"human\", \"Cumulative Hours\": 8455.45}, {\"Year Released\": \"2024\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 13373.15}, {\"Year Released\": \"2024\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 797348.46}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart_sourceyearhours = alt.Chart(\n",
    "    df_speechsourceyearscumulativehours\n",
    ").mark_line().encode(\n",
    "    x=alt.X(\n",
    "        \"Year Released:N\",\n",
    "        title=\"Year Released\",\n",
    "        sort=YEARS_ORDER,\n",
    "        axis=alt.Axis(labelAngle=-30)\n",
    "    ),\n",
    "    y=alt.Y(\n",
    "        \"Cumulative Hours:Q\",\n",
    "        title=\"Cumulative Hours\",\n",
    "        scale=alt.Scale(\n",
    "            type=\"symlog\",\n",
    "            constant=1000,\n",
    "            domain=[1, 1000000]\n",
    "        ),\n",
    "        axis=alt.Axis(\n",
    "            values=[0, 1, 1000, 10000, 100000, 1000000],\n",
    "            labelExpr=\"datum.value >= 1000000 ? datum.value / 1000000 + 'M' : datum.value >= 1000 ? datum.value / 1000 + 'K' : datum.value\"\n",
    "        )\n",
    "    ),\n",
    "    color=alt.Color(\n",
    "        \"Video Sources:N\",\n",
    "        title=\"Video Sources\"\n",
    "    )\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=160\n",
    ")\n",
    "\n",
    "if PLOT_TOFILE:\n",
    "    chart_sourceyearhours.save(\n",
    "        os.path.join(PLOT_DIR, \"video_sourcecategories-cumulativehours.png\"),\n",
    "        ppi=PLOT_PPI\n",
    "    )\n",
    "\n",
    "chart_sourceyearhours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Source Years-Based Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-9257eb43cdd5414ead90e065ab111f72.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-9257eb43cdd5414ead90e065ab111f72.vega-embed details,\n",
       "  #altair-viz-9257eb43cdd5414ead90e065ab111f72.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-9257eb43cdd5414ead90e065ab111f72\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-9257eb43cdd5414ead90e065ab111f72\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-9257eb43cdd5414ead90e065ab111f72\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"Times New Roman\", \"fontSize\": 20}, \"axis\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\", \"grid\": false, \"labelFontSize\": 20, \"titleFontSize\": 20}, \"header\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\", \"labelFontSize\": 20, \"titleFontSize\": 20}, \"legend\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\", \"labelFontSize\": 20, \"labelLimit\": 1000, \"titleFontSize\": 20}, \"text\": {\"font\": \"Times New Roman\"}}, \"hconcat\": [{\"data\": {\"name\": \"data-610ef9b6a1a90cfbc51ccfe6ad38f17b\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"Video Sources\", \"title\": \"Video Sources\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30}, \"field\": \"Year Released\", \"sort\": [\"<2004\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"], \"title\": \"Year Released\", \"type\": \"nominal\"}, \"y\": {\"aggregate\": \"count\", \"axis\": {\"format\": \"%\"}, \"stack\": \"normalize\", \"title\": \"Pct. Datasets\", \"type\": \"quantitative\"}}, \"height\": 160, \"width\": 600}, {\"data\": {\"name\": \"data-dd5c5a2a31ed97d4549b517cbef49661\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"Video Sources\", \"title\": \"Video Sources\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30}, \"field\": \"Year Released\", \"sort\": [\"<2004\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"], \"title\": \"Year Released\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"labelExpr\": \"datum.value >= 1000000 ? datum.value / 1000000 + 'M' : datum.value >= 1000 ? datum.value / 1000 + 'K' : datum.value\", \"values\": [0, 1, 1000, 10000, 100000, 1000000]}, \"field\": \"Cumulative Hours\", \"scale\": {\"constant\": 1000, \"domain\": [1, 1000000], \"type\": \"symlog\"}, \"title\": \"Cumulative Hours\", \"type\": \"quantitative\"}}, \"height\": 160, \"width\": 400}], \"resolve\": {\"scale\": {\"x\": \"independent\", \"y\": \"independent\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-610ef9b6a1a90cfbc51ccfe6ad38f17b\": [{\"Unique Dataset Identifier\": \"hollywood2-dataset\", \"Collection\": \"hollywood2-dataset\", \"Collection URL\": \"https://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf\", \"Dataset Name\": \"HOLLYWOOD2: Actions in Context (CVPR 2009)\", \"Paper Title\": \"HOLLYWOOD2: Actions in Context (CVPR 2009)\", \"Paper URL\": \"https://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf\", \"Semantic Scholar Corpus ID\": 3155054, \"Year Released\": \"2009\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Inria\"], \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 20.1, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"collective\", \"Collection\": \"collective\", \"Collection URL\": \"https://cvgl.stanford.edu/papers/Wongun_CollectiveActivityRecognition09.pdf\", \"Dataset Name\": \"Collective: What are they doing? : Collective activity classification using spatio-temporal relationship among people\", \"Paper Title\": \"Collective: What are they doing? : Collective activity classification using spatio-temporal relationship among people\", \"Paper URL\": \"https://cvgl.stanford.edu/papers/Wongun_CollectiveActivityRecognition09.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://cvgl.stanford.edu/papers/Wongun_CollectiveActivityRecognition09.pdf\", \"Semantic Scholar Corpus ID\": 5925915, \"Year Released\": \"2009\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Michigan\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.1, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Group Activity Recognition\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ucf101-dataset\", \"Collection\": \"ucf101-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1212.0402\", \"Dataset Name\": \"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\", \"Paper Title\": \"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\", \"Paper URL\": \"https://arxiv.org/abs/1212.0402\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/ucf101\", \"ArXiv URL\": \"https://arxiv.org/abs/1212.0402\", \"Semantic Scholar Corpus ID\": 7197134, \"Year Released\": \"2012\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Central Florida\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 26.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"youcook\", \"Collection\": \"youcook\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2013/papers/Das_A_Thousand_Frames_2013_CVPR_paper.pdf\", \"Dataset Name\": \"YouCook: A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching (CVPR 2013)\", \"Paper Title\": \"YouCook: A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching (CVPR 2013)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2013/papers/Das_A_Thousand_Frames_2013_CVPR_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youcook\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2013/papers/Das_A_Thousand_Frames_2013_CVPR_paper.pdf\", \"Semantic Scholar Corpus ID\": 12284555, \"Year Released\": \"2013\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University at Buffalo\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1000.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"50salads\", \"Collection\": \"50salads\", \"Collection URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"Dataset Name\": \"50Salads\", \"Paper Title\": \"50Salads\", \"Paper URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/50-salads\", \"ArXiv URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"Semantic Scholar Corpus ID\": 2333743, \"Year Released\": \"2013\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://cvip.computing.dundee.ac.uk/datasets/foodpreparation/50salads/\"}], \"Creators\": [\"University of Dundee\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 40.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Action Segmentation\", \"Action Localization\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"summe\", \"Collection\": \"summe\", \"Collection URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"Dataset Name\": \"SumMe: Creating Summaries from User Videos (ECCV 2014)\", \"Paper Title\": \"SumMe: Creating Summaries from User Videos (ECCV 2014)\", \"Paper URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/summe\", \"ArXiv URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"Semantic Scholar Corpus ID\": 2111093, \"Year Released\": \"2014\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"ETH Z\\u00fcrich\", \"KU Leuven\", \"upicto GmbH\"], \"Countries\": [\"Belgium\", \"Switzerland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1.11, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"stroygraphs\", \"Collection\": \"stroygraphs\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/papers/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.pdf\", \"Dataset Name\": \"StoryGraphs\", \"Paper Title\": \"StoryGraphs\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/papers/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.pdf\", \"GitHub URL\": \"https://github.com/makarandtapaswi/StoryGraphs_CVPR2014\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/storygraphs-visualizing-character\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/papers/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.pdf\", \"Semantic Scholar Corpus ID\": 1055956, \"Year Released\": \"2014\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Karlsruhe Institute of Technology\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7.3, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Misc\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"videostory\", \"Collection\": \"videostory\", \"Collection URL\": \"https://isis-data.science.uva.nl/cgmsnoek/pub/habibian-videostory-mm2014.pdf\", \"Dataset Name\": \"VideoStory: A New Multimedia Embedding for Few-Example Recognition and Translation of Events\", \"Paper Title\": \"VideoStory: A New Multimedia Embedding for Few-Example Recognition and Translation of Events\", \"Paper URL\": \"https://isis-data.science.uva.nl/cgmsnoek/pub/habibian-videostory-mm2014.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://isis-data.science.uva.nl/cgmsnoek/pub/habibian-videostory-mm2014.pdf\", \"Semantic Scholar Corpus ID\": 28203, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Amsterdam\"], \"Countries\": [\"Netherlands\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 743.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"breakfast\", \"Collection\": \"breakfast\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"Dataset Name\": \"Breakfast\", \"Paper Title\": \"Breakfast\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/breakfast\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"Semantic Scholar Corpus ID\": 9621856, \"Year Released\": \"2014\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/breakfast-actions-dataset/\"}], \"Creators\": [\"Fraunhofer FKIE\", \"Brown University\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 77.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Captioning\", \"Action Segmentation\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"thumos-challenge\", \"Collection\": \"thumos-challenge\", \"Collection URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Dataset Name\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper Title\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/thumos14-1\", \"ArXiv URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Semantic Scholar Corpus ID\": 14049355, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLScs9davISAtYQS7SEF5qQNu0jUpLzNH3aHmPfuqk2q1VYDkmw/viewform\"}], \"Creators\": [\"Stanford University\", \"University of Central Florida\", \"Fudan University\", \"Inria\"], \"Countries\": [\"United States of America\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 254.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hollywood-extended\", \"Collection\": \"hollywood-extended\", \"Collection URL\": \"https://arxiv.org/pdf/1407.1208\", \"Dataset Name\": \"Hollywood Extended\", \"Paper Title\": \"Hollywood Extended\", \"Paper URL\": \"https://arxiv.org/pdf/1407.1208\", \"GitHub URL\": \"https://github.com/piotr-bojanowski/action-ordering\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/weakly-supervised-action-labeling-in-videos\", \"ArXiv URL\": \"https://arxiv.org/pdf/1407.1208\", \"Semantic Scholar Corpus ID\": 9342651, \"Year Released\": \"2014\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/piotr-bojanowski/action-ordering/blob/master/LICENSE\"}], \"Creators\": [\"Inria\"], \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 8.75, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Temporal Action Detection\", \"Action Recognition\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"sports1M-dataset\", \"Collection\": \"sports1M-dataset\", \"Collection URL\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\", \"Dataset Name\": \"Sports-1M: Large-scale Video Classification with Convolutional Neural Networks\", \"Paper Title\": \"Sports-1M: Large-scale Video Classification with Convolutional Neural Networks\", \"Paper URL\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\", \"GitHub URL\": \"https://github.com/gtoderici/sports-1m-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/large-scale-video-classification-with-1\", \"ArXiv URL\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\", \"Semantic Scholar Corpus ID\": 206592218, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 3.0\", \"License URL\": \"https://github.com/gtoderici/sports-1m-dataset\"}], \"Creators\": [\"Stanford University\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 105761.41, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"volleyball-vids\", \"Collection\": \"volleyball-vids\", \"Collection URL\": \"https://arxiv.org/abs/1511.06040\", \"Dataset Name\": \"Volleyball: A Hierarchical Deep Temporal Model for Group Activity Recognition\", \"Paper Title\": \"Volleyball: A Hierarchical Deep Temporal Model for Group Activity Recognition\", \"Paper URL\": \"https://arxiv.org/abs/1511.06040\", \"GitHub URL\": \"https://github.com/mostafa-saad/deep-activity-rec#dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/volleyball\", \"ArXiv URL\": \"https://arxiv.org/abs/1511.06040\", \"Semantic Scholar Corpus ID\": 8483403, \"Year Released\": \"2015\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Simon Fraser University\"], \"Countries\": [\"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.1, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Group Activity Recognition\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"activitynet\", \"Collection\": \"activitynet\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"Dataset Name\": \"ActivityNet\", \"Paper Title\": \"ActivityNet\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/Leyo/ActivityNet_Captions\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/activitynet\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"Semantic Scholar Corpus ID\": 1710722, \"Year Released\": \"2015\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/facebookresearch/ActivityNet-Entities/blob/main/LICENSE\"}], \"Creators\": [\"Universidad del Norte\", \"King Abdullah University of Science and Technology (KAUST)\"], \"Countries\": [\"Saudi Arabia\", \"Colombia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 849.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"tvsum\", \"Collection\": \"tvsum\", \"Collection URL\": \"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\", \"Dataset Name\": \"TVSum: Summarizing web videos using titles (CVPR 2015)\", \"Paper Title\": \"TVSum: Summarizing web videos using titles (CVPR 2015)\", \"Paper URL\": \"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\", \"GitHub URL\": \"https://github.com/yalesong/tvsum\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tvsum-1\", \"ArXiv URL\": \"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\", \"Semantic Scholar Corpus ID\": 7675635, \"Year Released\": \"2015\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 3.0\", \"License URL\": \"https://github.com/yalesong/tvsum\"}], \"Creators\": [\"Yahoo Labs\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3.5, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"mpii-cooking\", \"Collection\": \"mpii-cooking\", \"Collection URL\": \"https://arxiv.org/abs/1502.06648\", \"Dataset Name\": \"MPII-Cooking: Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data (IJCV 2015)\", \"Paper Title\": \"MPII-Cooking: Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data (IJCV 2015)\", \"Paper URL\": \"https://arxiv.org/abs/1502.06648\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/recognizing-fine-grained-and-composite\", \"ArXiv URL\": \"https://arxiv.org/abs/1502.06648\", \"Semantic Scholar Corpus ID\": 14036544, \"Year Released\": \"2015\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/human-activity-recognition/mpii-cooking-activities-dataset\"}], \"Creators\": [\"Max Planck Institute for Informatics\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 27.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"movieqa\", \"Collection\": \"movieqa\", \"Collection URL\": \"https://arxiv.org/abs/1512.02902\", \"Dataset Name\": \"MovieQA\", \"Paper Title\": \"MovieQA\", \"Paper URL\": \"https://arxiv.org/abs/1512.02902\", \"GitHub URL\": \"https://github.com/makarandtapaswi/MovieQA_CVPR2016/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/movieqa\", \"ArXiv URL\": \"https://arxiv.org/abs/1512.02902\", \"Semantic Scholar Corpus ID\": 1017389, \"Year Released\": \"2015\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"Massachusetts Institute of Technology\", \"University of Toronto\"], \"Countries\": [\"Germany\", \"Canada\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 381.0, \"Taken Down\": \"True\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Question Answering\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"ntu-rgbd\", \"Collection\": \"ntu-rgbd\", \"Collection URL\": \"https://arxiv.org/pdf/1604.02808.pdf\", \"Dataset Name\": \"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis (CVPR 2016, TPAMI 2019)\", \"Paper Title\": \"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis (CVPR 2016, TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1604.02808.pdf\", \"GitHub URL\": \"https://github.com/shahroudy/NTURGB-D\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ntu-rgbd-a-large-scale-dataset-for-3d-human\", \"ArXiv URL\": \"https://arxiv.org/pdf/1604.02808.pdf\", \"Semantic Scholar Corpus ID\": 15928602, \"Year Released\": \"2016\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://rose1.ntu.edu.sg/dataset/actionRecognition/\"}], \"Creators\": [\"Nanyang Technological University\"], \"Countries\": [\"Singapore\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 74.1, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"mpii-cooking2\", \"Collection\": \"mpii-cooking2\", \"Collection URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"Dataset Name\": \"MPII Cooking 2\", \"Paper Title\": \"MPII Cooking 2\", \"Paper URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mpii-cooking-2-dataset\", \"ArXiv URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"Semantic Scholar Corpus ID\": 14036544, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/human-activity-recognition/mpii-cooking-2-dataset/\"}], \"Creators\": [\"Max Planck Institute for Informatics\", \"Saarland University\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 27.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Temporal Action Detection\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"mars\", \"Collection\": \"mars\", \"Collection URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Dataset Name\": \"Mars\", \"Paper Title\": \"Mars\", \"Paper URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mars\", \"ArXiv URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Semantic Scholar Corpus ID\": 2214158, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Microsoft\", \"Tsinghua University\", \"The University of Texas at San Antonio\", \"Peking University\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.24, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Segmentation\", \"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"charades\", \"Collection\": \"charades\", \"Collection URL\": \"https://arxiv.org/abs/1604.01753\", \"Dataset Name\": \"Charades\", \"Paper Title\": \"Charades\", \"Paper URL\": \"https://arxiv.org/abs/1604.01753\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/charades\", \"ArXiv URL\": \"https://arxiv.org/abs/1604.01753\", \"Semantic Scholar Corpus ID\": 18061547, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades#licensing-information\"}], \"Creators\": [\"Carnegie Mellon University\", \"Inria\", \"University of Washington\", \"Allen Institute for AI\"], \"Countries\": [\"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 82.3, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"youtube-8m\", \"Collection\": \"youtube-8m\", \"Collection URL\": \"https://arxiv.org/abs/1609.08675\", \"Dataset Name\": \"Youtube-8M: A Large-Scale Video Classification Benchmark\", \"Paper Title\": \"Youtube-8M: A Large-Scale Video Classification Benchmark\", \"Paper URL\": \"https://arxiv.org/abs/1609.08675\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youtube-8m\", \"ArXiv URL\": \"https://arxiv.org/abs/1609.08675\", \"Semantic Scholar Corpus ID\": 11241677, \"Year Released\": \"2016\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Google Research\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 350000.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"msr-vtt\", \"Collection\": \"msr-vtt\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7780940\", \"Dataset Name\": \"MSR-VTT\", \"Paper Title\": \"MSR-VTT\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7780940\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/msr-vtt\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7780940\", \"Semantic Scholar Corpus ID\": 206594535, \"Year Released\": \"2016\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Microsoft Research\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 41.2, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"narrated-instruction-vids\", \"Collection\": \"narrated-instruction-vids\", \"Collection URL\": \"https://arxiv.org/abs/1506.09215\", \"Dataset Name\": \"Narrated Instruction Videos\", \"Paper Title\": \"Narrated Instruction Videos\", \"Paper URL\": \"https://arxiv.org/abs/1506.09215\", \"GitHub URL\": \"https://github.com/jalayrac/instructionVideos\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youtube-inria-instructional\", \"ArXiv URL\": \"https://arxiv.org/abs/1506.09215\", \"Semantic Scholar Corpus ID\": 2617244, \"Year Released\": \"2016\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/jalayrac/instructionVideos?tab=readme-ov-file#license\"}], \"Creators\": [\"CNRS\", \"Ecole Normale Sup\\u00e9rieure\", \"Inria\", \"International Institute of Information Technology - Hyderabad\"], \"Countries\": [\"United States of America\", \"India\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"vtw\", \"Collection\": \"vtw\", \"Collection URL\": \"https://arxiv.org/abs/1608.07068\", \"Dataset Name\": \"VTW\", \"Paper Title\": \"VTW\", \"Paper URL\": \"https://arxiv.org/abs/1608.07068\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/title-generation-for-user-generated-videos\", \"ArXiv URL\": \"https://arxiv.org/abs/1608.07068\", \"Semantic Scholar Corpus ID\": 6155397, \"Year Released\": \"2016\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Tsinghua University\", \"Stanford University\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 213.2, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"tgif\", \"Collection\": \"tgif\", \"Collection URL\": \"https://arxiv.org/abs/1604.02748\", \"Dataset Name\": \"TGIF\", \"Paper Title\": \"TGIF\", \"Paper URL\": \"https://arxiv.org/abs/1604.02748\", \"GitHub URL\": \"https://github.com/raingo/TGIF-Release\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/TGIF\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tgif\", \"ArXiv URL\": \"https://arxiv.org/abs/1604.02748\", \"Semantic Scholar Corpus ID\": 6262415, \"Year Released\": \"2016\", \"Text Sources\": [\"tumblr\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/raingo/TGIF-Release\"}], \"Creators\": [\"University of Rochester\", \"Yahoo! Inc.\", \"AiCure\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 86.1, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"youcook-2\", \"Collection\": \"youcook-2\", \"Collection URL\": \"https://arxiv.org/abs/1703.09788\", \"Dataset Name\": \"YouCook2\", \"Paper Title\": \"YouCook2\", \"Paper URL\": \"https://arxiv.org/abs/1703.09788\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youcook2\", \"ArXiv URL\": \"https://arxiv.org/abs/1703.09788\", \"Semantic Scholar Corpus ID\": 19713015, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"http://youcook2.eecs.umich.edu/static/YouCookII/LICENSE_YOUCOOK2.txt\"}], \"Creators\": [\"University of Rochester\", \"University of Michigan\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 175.6, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"qfvs\", \"Collection\": \"qfvs\", \"Collection URL\": \"https://arxiv.org/abs/1707.04960\", \"Dataset Name\": \"QFVS: Query-Focused Video Summarization: Dataset, Evaluation, and A Memory Network Based Approach (CVPR 2017)\", \"Paper Title\": \"QFVS: Query-Focused Video Summarization: Dataset, Evaluation, and A Memory Network Based Approach (CVPR 2017)\", \"Paper URL\": \"https://arxiv.org/abs/1707.04960\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/query-focused-video-summarization-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/1707.04960\", \"Semantic Scholar Corpus ID\": 2774608, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Central Florida\", \"University of Alabama\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 20.0, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"davis\", \"Collection\": \"davis\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"Dataset Name\": \"Davis\", \"Paper Title\": \"Davis\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"GitHub URL\": \"https://github.com/fperazzi/davis\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-benchmark-dataset-and-evaluation\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"Semantic Scholar Corpus ID\": 3619941, \"Year Released\": \"2017\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/fperazzi/davis/blob/main/LICENSE\"}], \"Creators\": [\"ETH Z\\u00fcrich\", \"Disney Research\"], \"Countries\": [\"Switzerland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.04, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Segmentation\", \"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"pku-mmd-dataset\", \"Collection\": \"pku-mmd-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1703.07475\", \"Dataset Name\": \"PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding (ACM Multimedia Workshop)\", \"Paper Title\": \"PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding (ACM Multimedia Workshop)\", \"Paper URL\": \"https://arxiv.org/abs/1703.07475\", \"GitHub URL\": \"https://struct002.github.io/PKUMMD/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/pku-mmd-a-large-scale-benchmark-for\", \"ArXiv URL\": \"https://arxiv.org/abs/1703.07475\", \"Semantic Scholar Corpus ID\": 1904265, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Microsoft Research\", \"Peking University\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 50.0, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"kinetics-400\", \"Collection\": \"kinetics-400\", \"Collection URL\": \"https://arxiv.org/abs/1705.06950\", \"Dataset Name\": \"Kinetics 400\", \"Paper Title\": \"Kinetics 400\", \"Paper URL\": \"https://arxiv.org/abs/1705.06950\", \"GitHub URL\": \"https://github.com/cvdfoundation/kinetics-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/kinetics\", \"ArXiv URL\": \"https://arxiv.org/abs/1705.06950\", \"Semantic Scholar Corpus ID\": 27300853, \"Year Released\": \"2017\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"DeepMind\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 850.68, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mpii-md\", \"Collection\": \"mpii-md\", \"Collection URL\": \"https://arxiv.org/pdf/1501.02530.pdf\", \"Dataset Name\": \"MPII-MD: A Dataset for Movie Description\", \"Paper Title\": \"MPII-MD: A Dataset for Movie Description\", \"Paper URL\": \"https://arxiv.org/pdf/1501.02530.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1501.02530.pdf\", \"Semantic Scholar Corpus ID\": 15184723, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Max Planck Institute for Informatics\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 56.5, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"multi-thumos-challenge\", \"Collection\": \"multi-thumos-challenge\", \"Collection URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"Dataset Name\": \"MultiTHUMOS: Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos (IJCV 2017)\", \"Paper Title\": \"MultiTHUMOS: Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos (IJCV 2017)\", \"Paper URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/multithumos\", \"ArXiv URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"Semantic Scholar Corpus ID\": 3337929, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://ai.stanford.edu/~syyeung/resources/multithumos.zip\"}], \"Creators\": [\"Stanford University\", \"Carnegie Mellon University\", \"Simon Fraser University\"], \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 30.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ava\", \"Collection\": \"ava\", \"Collection URL\": \"https://arxiv.org/pdf/1705.08421\", \"Dataset Name\": \"AVA\", \"Paper Title\": \"AVA\", \"Paper URL\": \"https://arxiv.org/pdf/1705.08421\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ava-a-video-dataset-of-spatio-temporally\", \"ArXiv URL\": \"https://arxiv.org/pdf/1705.08421\", \"Semantic Scholar Corpus ID\": 688013, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://research.google.com/ava/\"}], \"Creators\": [\"Google Research\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 107.5, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Temporal Localization\", \"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"lsmdc\", \"Collection\": \"lsmdc\", \"Collection URL\": \"https://arxiv.org/pdf/1605.03705\", \"Dataset Name\": \"LSMDC\", \"Paper Title\": \"LSMDC\", \"Paper URL\": \"https://arxiv.org/pdf/1605.03705\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/movie-description\", \"ArXiv URL\": \"https://arxiv.org/pdf/1605.03705\", \"Semantic Scholar Corpus ID\": 18217052, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://datasets.d2.mpi-inf.mpg.de/movieDescription/protected/lsmdc2016/README.txt\"}], \"Creators\": [\"UC Berkeley\", \"Disney Research\", \"Universite de Montreal\", \"Polytechnique Montr\\u00e9al\", \"Universit\\u00e9 de Sherbrooke\", \"Twitter\"], \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Summarization\", \"Misc\", \"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"20bn-something\", \"Collection\": \"20bn-something\", \"Collection URL\": \"https://arxiv.org/abs/1706.04261\", \"Dataset Name\": \"20BN-SOMETHING-SOMETHING: The \\\"something something\\\" video database for learning and evaluating visual common sense\", \"Paper Title\": \"20BN-SOMETHING-SOMETHING: The \\\"something something\\\" video database for learning and evaluating visual common sense\", \"Paper URL\": \"https://arxiv.org/abs/1706.04261\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/something-something-v2\", \"ArXiv URL\": \"https://arxiv.org/abs/1706.04261\", \"Semantic Scholar Corpus ID\": 834612, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://developer.qualcomm.com/software/ai-datasets/something-something\"}], \"Creators\": [\"Twenty Billion Neurons GmbH\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 121.46, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"voxceleb\", \"Collection\": \"voxceleb\", \"Collection URL\": \"https://arxiv.org/abs/1706.08612\", \"Dataset Name\": \"VoxCeleb\", \"Paper Title\": \"VoxCeleb\", \"Paper URL\": \"https://arxiv.org/abs/1706.08612\", \"GitHub URL\": \"https://github.com/a-nagrani/VGGVox\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://cs.paperswithcode.com/paper/voxceleb-a-large-scale-speaker-identification\", \"ArXiv URL\": \"https://arxiv.org/abs/1706.08612\", \"Semantic Scholar Corpus ID\": 10475843, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/\"}], \"Creators\": [\"University of Oxford\"], \"Countries\": [\"United Kingdom\", \"South Korea\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 2000.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"imagenet-vid\", \"Collection\": \"imagenet-vid\", \"Collection URL\": \"https://link.springer.com/article/10.1007/s11263-015-0816-y?sa_campaign=email/event/articleAuthor/onlineFirst#\", \"Dataset Name\": \"ImageNet VID\", \"Paper Title\": \"ImageNet VID\", \"Paper URL\": \"https://link.springer.com/article/10.1007/s11263-015-0816-y?sa_campaign=email/event/articleAuthor/onlineFirst#\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/sota/video-object-detection-on-imagenet-vid\", \"ArXiv URL\": \"https://link.springer.com/article/10.1007/s11263-015-0816-y?sa_campaign=email/event/articleAuthor/onlineFirst#\", \"Semantic Scholar Corpus ID\": 2930547, \"Year Released\": \"2017\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://www.image-net.org/challenges/LSVRC/2017/index.php\"}], \"Creators\": [\"Stanford University\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 9.26, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"kinetics-600\", \"Collection\": \"kinetics-600\", \"Collection URL\": \"https://arxiv.org/abs/1808.01340\", \"Dataset Name\": \"Kinetics 600\", \"Paper Title\": \"Kinetics 600\", \"Paper URL\": \"https://arxiv.org/abs/1808.01340\", \"GitHub URL\": \"https://github.com/cvdfoundation/kinetics-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/kinetics-600\", \"ArXiv URL\": \"https://arxiv.org/abs/1808.01340\", \"Semantic Scholar Corpus ID\": 51927456, \"Year Released\": \"2018\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"DeepMind\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1376.52, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"didemo\", \"Collection\": \"didemo\", \"Collection URL\": \"https://paperswithcode.com/dataset/didemo\", \"Dataset Name\": \"DiDeMo: Localizing Moments in Video with Temporal Language (EMNLP 2018)\", \"Paper Title\": \"DiDeMo: Localizing Moments in Video with Temporal Language (EMNLP 2018)\", \"Paper URL\": \"https://paperswithcode.com/dataset/didemo\", \"GitHub URL\": \"https://github.com/LisaAnne/TemporalLanguageRelease\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://paperswithcode.com/dataset/didemo\", \"Semantic Scholar Corpus ID\": 52164739, \"Year Released\": \"2018\", \"Text Sources\": [\"flickr\"], \"Licenses\": [{\"License\": \"BSD 2-Clause License\", \"License URL\": \"https://github.com/LisaAnne/TemporalLanguageRelease\"}], \"Creators\": [\"UC Berkeley\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 275.0, \"Taken Down\": \"False\", \"Video Sources\": \"flickr\", \"Task Categories\": [\"Temporal Action Localization\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"epic-kitchenes\", \"Collection\": \"epic-kitchenes\", \"Collection URL\": \"https://arxiv.org/abs/1804.02748\", \"Dataset Name\": \"EPIC-KITCHENS\", \"Paper Title\": \"EPIC-KITCHENS\", \"Paper URL\": \"https://arxiv.org/abs/1804.02748\", \"GitHub URL\": \"https://github.com/epic-kitchens\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/epic-kitchens-100\", \"ArXiv URL\": \"https://arxiv.org/abs/1804.02748\", \"Semantic Scholar Corpus ID\": 4710439, \"Year Released\": \"2018\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://epic-kitchens.github.io/2024\"}], \"Creators\": [\"University of Toronto\", \"University of Bristol\", \"University of Catania\"], \"Countries\": [\"United Kingdom\", \"Canada\", \"Spain\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 100.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"vlog-vids\", \"Collection\": \"vlog-vids\", \"Collection URL\": \"https://arxiv.org/abs/1712.02310\", \"Dataset Name\": \"VLOG: From Lifestyle Vlogs to Everyday Interactions (CVPR 2018)\", \"Paper Title\": \"VLOG: From Lifestyle Vlogs to Everyday Interactions (CVPR 2018)\", \"Paper URL\": \"https://arxiv.org/abs/1712.02310\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/vlog-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/1712.02310\", \"Semantic Scholar Corpus ID\": 22264672, \"Year Released\": \"2018\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://web.eecs.umich.edu/~fouhey/2017/VLOG/index.html\"}], \"Creators\": [\"UC Berkeley\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 336.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"charades-ego\", \"Collection\": \"charades-ego\", \"Collection URL\": \"https://arxiv.org/abs/1804.09627\", \"Dataset Name\": \"Charades-Ego: Actor and Observer: Joint Modeling of First and Third-Person Videos (CVPR 2018)\", \"Paper Title\": \"Charades-Ego: Actor and Observer: Joint Modeling of First and Third-Person Videos (CVPR 2018)\", \"Paper URL\": \"https://arxiv.org/abs/1804.09627\", \"GitHub URL\": \"https://github.com/gsig/actor-observer\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/search?q_meta=&q_type=&q=Actor+and+Observer%3A+Joint+Modeling+of+First+and+Third-Person+Videos\", \"ArXiv URL\": \"https://arxiv.org/abs/1804.09627\", \"Semantic Scholar Corpus ID\": 4562167, \"Year Released\": \"2018\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://prior.allenai.org/projects/data/charades-ego/license.txt\"}], \"Creators\": [\"Allen Institute for AI\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 69.33, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"soa-dataset\", \"Collection\": \"soa-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1904.11451\", \"Dataset Name\": \"Scenes-objects-actions: A multi-task, multi-label video dataset\", \"Paper Title\": \"Scenes-objects-actions: A multi-task, multi-label video dataset\", \"Paper URL\": \"https://arxiv.org/pdf/1904.11451\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/scenes-objects-actions-a-multi-task-multi\", \"ArXiv URL\": \"https://arxiv.org/pdf/1904.11451\", \"Semantic Scholar Corpus ID\": 52968009, \"Year Released\": \"2018\", \"Text Sources\": [\"facebook\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Meta\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1561.1, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"moviegraphs\", \"Collection\": \"moviegraphs\", \"Collection URL\": \"https://arxiv.org/pdf/1712.06761\", \"Dataset Name\": \"MovieGraphs\", \"Paper Title\": \"MovieGraphs\", \"Paper URL\": \"https://arxiv.org/pdf/1712.06761\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/moviegraphs\", \"ArXiv URL\": \"https://arxiv.org/pdf/1712.06761\", \"Semantic Scholar Corpus ID\": 4856028, \"Year Released\": \"2018\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moviegraphs.cs.toronto.edu/download.html\"}], \"Creators\": [\"Vector Institute for Artificial Intelligence\", \"Montreal Institute of Learning Algorithms (Mila)\", \"University of Toronto\"], \"Countries\": [\"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 93.9, \"Taken Down\": \"True\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Misc (video retrieval\", \"interaction understanding via ordering\", \"reason prediction)\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"how2\", \"Collection\": \"how2\", \"Collection URL\": \"https://arxiv.org/abs/1811.00347\", \"Dataset Name\": \"How2: A Large-scale Dataset for Multimodal Language Understanding (NeurIPS 2018)\", \"Paper Title\": \"How2: A Large-scale Dataset for Multimodal Language Understanding (NeurIPS 2018)\", \"Paper URL\": \"https://arxiv.org/abs/1811.00347\", \"GitHub URL\": \"https://github.com/srvk/how2-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/abs/1811.00347\", \"Semantic Scholar Corpus ID\": 53186236, \"Year Released\": \"2018\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Various\", \"License URL\": \"https://github.com/srvk/how2-dataset?tab=readme-ov-file#how2-license\"}], \"Creators\": [\"Carnegie Mellon University\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 2300.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"trecvid\", \"Collection\": \"trecvid\", \"Collection URL\": \"https://arxiv.org/abs/2009.09984\", \"Dataset Name\": \"TRECVID\", \"Paper Title\": \"TRECVID\", \"Paper URL\": \"https://arxiv.org/abs/2009.09984\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/trecvid-2019-an-evaluation-campaign-to/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.09984\", \"Semantic Scholar Corpus ID\": 212694843, \"Year Released\": \"2019\", \"Text Sources\": [\"undisclosed web\", \"bbc\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://trecvid.nist.gov/\"}], \"Creators\": [\"National Institute of Standards and Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1000.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\", \"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper Title\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Ecole Normale Sup\\u00e9rieure\", \"Inria\", \"CIIRC\", \"Czech Technical University\", \"University of Michigan\"], \"Countries\": [\"France\", \"Turkey\", \"United States of America\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Temporal Action Localization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"flickr\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"vatex\", \"Collection\": \"vatex\", \"Collection URL\": \"https://arxiv.org/abs/1904.03493\", \"Dataset Name\": \"VaTeX\", \"Paper Title\": \"VaTeX\", \"Paper URL\": \"https://arxiv.org/abs/1904.03493\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/vatex\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/vatex\", \"ArXiv URL\": \"https://arxiv.org/abs/1904.03493\", \"Semantic Scholar Corpus ID\": 102352148, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://eric-xw.github.io/vatex-website/index.html\"}], \"Creators\": [\"ByteDance AI Lab\", \"UC Santa Barbara\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 114.58, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ava-dataset\", \"Collection\": \"ava-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1901.01342\", \"Dataset Name\": \"AVA Active Speaker\", \"Paper Title\": \"AVA Active Speaker\", \"Paper URL\": \"https://arxiv.org/abs/1901.01342\", \"GitHub URL\": \"https://github.com/cvdfoundation/ava-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/ava-activespeaker\", \"ArXiv URL\": \"https://arxiv.org/abs/1901.01342\", \"Semantic Scholar Corpus ID\": 216211909, \"Year Released\": \"2019\", \"Text Sources\": [\"Not Prohibited\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://research.google.com/ava/download.html#ava_active_speaker_download\"}], \"Creators\": [\"Google Research\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 38.5, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"msa\", \"Collection\": \"msa\", \"Collection URL\": \"https://arxiv.org/abs/1910.11009\", \"Dataset Name\": \"MSA\", \"Paper Title\": \"MSA\", \"Paper URL\": \"https://arxiv.org/abs/1910.11009\", \"GitHub URL\": \"https://github.com/ycxioooong/MovieSynopsisAssociation\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-graph-based-framework-to-bridge-movies-and-1\", \"ArXiv URL\": \"https://arxiv.org/abs/1910.11009\", \"Semantic Scholar Corpus ID\": 204852218, \"Year Released\": \"2019\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"The Chinese University of Hong Kong\", \"UC Berkeley\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 516.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"howto100m\", \"Collection\": \"howto100m\", \"Collection URL\": \"https://arxiv.org/abs/1906.03327\", \"Dataset Name\": \"HowTo100M\", \"Paper Title\": \"HowTo100M\", \"Paper URL\": \"https://arxiv.org/abs/1906.03327\", \"GitHub URL\": \"https://github.com/antoine77340/howto100m\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/howto100m\", \"ArXiv URL\": \"https://arxiv.org/abs/1906.03327\", \"Semantic Scholar Corpus ID\": 182952863, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Ecole Normale Sup\\u00e9rieure\", \"Inria\", \"CIIRC\", \"Czech Technical University\"], \"Countries\": [\"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 134472.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"toyota-smarthome\", \"Collection\": \"toyota-smarthome\", \"Collection URL\": \"https://openaccess.thecvf.com/content_ICCV_2019/papers/Das_Toyota_Smarthome_Real-World_Activities_of_Daily_Living_ICCV_2019_paper.pdf\", \"Dataset Name\": \"Toyota Smarthome: Real-World Activities of Daily Living (ICCV 2019)\", \"Paper Title\": \"Toyota Smarthome: Real-World Activities of Daily Living (ICCV 2019)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_ICCV_2019/papers/Das_Toyota_Smarthome_Real-World_Activities_of_Daily_Living_ICCV_2019_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_ICCV_2019/papers/Das_Toyota_Smarthome_Real-World_Activities_of_Daily_Living_ICCV_2019_paper.pdf\", \"Semantic Scholar Corpus ID\": 207971208, \"Year Released\": \"2019\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://project.inria.fr/toyotasmarthome/files/2020/12/License_v2.pdf\"}], \"Creators\": [\"Toyota\"], \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 268.58, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"trecvid\", \"Collection\": \"trecvid\", \"Collection URL\": \"https://arxiv.org/abs/2009.09984\", \"Dataset Name\": \"TRECVID\", \"Paper Title\": \"TRECVID\", \"Paper URL\": \"https://arxiv.org/abs/2009.09984\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/trecvid-2019-an-evaluation-campaign-to/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.09984\", \"Semantic Scholar Corpus ID\": 212694843, \"Year Released\": \"2019\", \"Text Sources\": [\"undisclosed web\", \"bbc\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://trecvid.nist.gov/\"}], \"Creators\": [\"National Institute of Standards and Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1000.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\", \"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"coin-dataset\", \"Collection\": \"coin-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1903.02874\", \"Dataset Name\": \"COIN: A Large-scale Dataset for Comprehensive Instructional Video Analysis (CVPR 2019)\", \"Paper Title\": \"COIN: A Large-scale Dataset for Comprehensive Instructional Video Analysis (CVPR 2019)\", \"Paper URL\": \"https://arxiv.org/abs/1903.02874\", \"GitHub URL\": \"https://github.com/coin-dataset/annotations\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/coin#:~:text=The%20COIN%20dataset%20(a%20large,are%20all%20collected%20from%20YouTube.\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.02874\", \"Semantic Scholar Corpus ID\": 71147568, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/coin-dataset/annotations?tab=readme-ov-file#license\"}], \"Creators\": [\"Tsinghua University\", \"Meitu Inc.\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 476.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"20BN-jester\", \"Collection\": \"20BN-jester\", \"Collection URL\": \"https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf\", \"Dataset Name\": \"20BN-jester: The Jester Dataset: A Large-Scale Video Dataset of Human Gestures (ICCVW 2019)\", \"Paper Title\": \"20BN-jester: The Jester Dataset: A Large-Scale Video Dataset of Human Gestures (ICCVW 2019)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf\", \"Semantic Scholar Corpus ID\": 208010438, \"Year Released\": \"2019\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://developer.qualcomm.com/software/ai-datasets/jester\"}], \"Creators\": [\"Twenty Billion Neurons GmbH\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13.0, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"mmact\", \"Collection\": \"mmact\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Dataset Name\": \"MMAct\", \"Paper Title\": \"MMAct\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mmact\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Semantic Scholar Corpus ID\": 207980205, \"Year Released\": \"2019\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://mmact19.github.io/2019/\"}], \"Creators\": [\"The Hong Kong University of Science and Technology\", \"Alibaba Group\"], \"Countries\": [\"Hong Kong\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 100.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Temporal Localization\", \"Action Recognition\", \"Spatial-Temporal Action Localization\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hacs-dataset\", \"Collection\": \"hacs-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1712.09374\", \"Dataset Name\": \"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\", \"Paper Title\": \"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\", \"Paper URL\": \"https://arxiv.org/abs/1712.09374\", \"GitHub URL\": \"https://github.com/hangzhaomit/HACS-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hacs\", \"ArXiv URL\": \"https://arxiv.org/abs/1712.09374\", \"Semantic Scholar Corpus ID\": 68049510, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/hangzhaomit/HACS-dataset?tab=readme-ov-file#request-testing-videos-and-missing-videos-new\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"Dartmouth University\", \"UIUC\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask\", \"Paper Title\": \"CrossTask\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Middle East Technical University\", \"Inria\", \"PSL University - Universit\\u00e9 PSL\", \"University of Michigan\", \"CIIRC\"], \"Countries\": [\"Czech Republic\", \"France\", \"Turkey\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"eev-dataset\", \"Collection\": \"eev-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2001.05488\", \"Dataset Name\": \"EEV: A Large-Scale Dataset for Studying Evoked Expressions from Video\", \"Paper Title\": \"EEV: A Large-Scale Dataset for Studying Evoked Expressions from Video\", \"Paper URL\": \"https://arxiv.org/abs/2001.05488\", \"GitHub URL\": \"https://github.com/google-research-datasets/eev\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/abs/2001.05488\", \"Semantic Scholar Corpus ID\": 210701992, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://github.com/google-research-datasets/eev?tab=readme-ov-file#license\"}], \"Creators\": [\"Google Research\", \"California Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 370.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"omnisource-web-dataset\", \"Collection\": \"omnisource-web-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2003.13042\", \"Dataset Name\": \"OmniSource Web Dataset\", \"Paper Title\": \"OmniSource Web Dataset\", \"Paper URL\": \"https://arxiv.org/abs/2003.13042\", \"GitHub URL\": \"https://github.com/open-mmlab/mmaction\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/omni-sourced-webly-supervised-learning-for#code\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.13042\", \"Semantic Scholar Corpus ID\": 214714240, \"Year Released\": \"2020\", \"Text Sources\": [\"google videos\", \"instagram\", \"youtube\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/open-mmlab/mmaction?tab=readme-ov-file#license\"}], \"Creators\": [\"The Chinese University of Hong Kong\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13333.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"omnisource-web-dataset\", \"Collection\": \"omnisource-web-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2003.13042\", \"Dataset Name\": \"OmniSource Web Dataset\", \"Paper Title\": \"OmniSource Web Dataset\", \"Paper URL\": \"https://arxiv.org/abs/2003.13042\", \"GitHub URL\": \"https://github.com/open-mmlab/mmaction\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/omni-sourced-webly-supervised-learning-for#code\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.13042\", \"Semantic Scholar Corpus ID\": 214714240, \"Year Released\": \"2020\", \"Text Sources\": [\"google videos\", \"instagram\", \"youtube\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/open-mmlab/mmaction?tab=readme-ov-file#license\"}], \"Creators\": [\"The Chinese University of Hong Kong\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13333.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"condensed-movies\", \"Collection\": \"condensed-movies\", \"Collection URL\": \"https://arxiv.org/pdf/2005.04208\", \"Dataset Name\": \"Condensed Movies\", \"Paper Title\": \"Condensed Movies\", \"Paper URL\": \"https://arxiv.org/pdf/2005.04208\", \"GitHub URL\": \"https://github.com/m-bain/CondensedMovies\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/condensed-movies\", \"ArXiv URL\": \"https://arxiv.org/pdf/2005.04208\", \"Semantic Scholar Corpus ID\": 218571391, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://www.robots.ox.ac.uk/~vgg/data/condensed-movies/#download\"}], \"Creators\": [\"University of Oxford\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1270.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Summarization\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"lsmdc-ordering\", \"Collection\": \"lsmdc-ordering\", \"Collection URL\": \"https://arxiv.org/pdf/2004.02205\", \"Dataset Name\": \"LSMDC Ordering\", \"Paper Title\": \"LSMDC Ordering\", \"Paper URL\": \"https://arxiv.org/pdf/2004.02205\", \"GitHub URL\": \"https://github.com/vivoutlaw/TCBP\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/deep-multimodal-feature-encoding-for-video\", \"ArXiv URL\": \"https://arxiv.org/pdf/2004.02205\", \"Semantic Scholar Corpus ID\": 214802821, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/vivoutlaw/tcbp/blob/master/LICENSE\"}], \"Creators\": [\"University of Toronto\", \"Karlsruhe Institute of Technology\", \"Inria\", \"Massachusetts Institute of Technology\"], \"Countries\": [\"Germany\", \"Canada\", \"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"haa500-dataset\", \"Collection\": \"haa500-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2009.05224\", \"Dataset Name\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper Title\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper URL\": \"https://arxiv.org/abs/2009.05224\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/haa500-human-centric-atomic-action-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.05224\", \"Semantic Scholar Corpus ID\": 221640805, \"Year Released\": \"2020\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Carnegie Mellon University\", \"The Hong Kong University of Science and Technology\", \"Princeton University\", \"Kuaishou Technology\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 5.48, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"omnisource-web-dataset\", \"Collection\": \"omnisource-web-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2003.13042\", \"Dataset Name\": \"OmniSource Web Dataset\", \"Paper Title\": \"OmniSource Web Dataset\", \"Paper URL\": \"https://arxiv.org/abs/2003.13042\", \"GitHub URL\": \"https://github.com/open-mmlab/mmaction\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/omni-sourced-webly-supervised-learning-for#code\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.13042\", \"Semantic Scholar Corpus ID\": 214714240, \"Year Released\": \"2020\", \"Text Sources\": [\"google videos\", \"instagram\", \"youtube\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/open-mmlab/mmaction?tab=readme-ov-file#license\"}], \"Creators\": [\"The Chinese University of Hong Kong\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13333.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"100doh\", \"Collection\": \"100doh\", \"Collection URL\": \"https://arxiv.org/abs/2006.06669\", \"Dataset Name\": \"100DOH: Understanding Human Hands in Contact at Internet Scale (CVPR 2020)\", \"Paper Title\": \"100DOH: Understanding Human Hands in Contact at Internet Scale (CVPR 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2006.06669\", \"GitHub URL\": \"https://github.com/ddshan/hand_object_detector\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/understanding-human-hands-in-contact-at-1\", \"ArXiv URL\": \"https://arxiv.org/abs/2006.06669\", \"Semantic Scholar Corpus ID\": 215413188, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://fouheylab.eecs.umich.edu/~dandans/projects/100DOH/download.html\"}], \"Creators\": [\"University of Michigan\", \"Johns Hopkins University\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 4577.3, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Misc (Hand/Object Detection)\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"kinetics-700\", \"Collection\": \"kinetics-700\", \"Collection URL\": \"https://arxiv.org/pdf/2010.10864.pdf\", \"Dataset Name\": \"Kinetics-700\", \"Paper Title\": \"Kinetics-700\", \"Paper URL\": \"https://arxiv.org/pdf/2010.10864.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/kinetics-700\", \"ArXiv URL\": \"https://arxiv.org/pdf/2010.10864.pdf\", \"Semantic Scholar Corpus ID\": 196831809, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"DeepMind\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1805.56, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"finegym-dataset\", \"Collection\": \"finegym-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2004.06704\", \"Dataset Name\": \"FineGym: A Hierarchical Video Dataset for Fine-grained Action Understanding (CVPR 2020)\", \"Paper Title\": \"FineGym: A Hierarchical Video Dataset for Fine-grained Action Understanding (CVPR 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2004.06704\", \"GitHub URL\": \"https://github.com/SDOlivia/FineGym/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/finegym\", \"ArXiv URL\": \"https://arxiv.org/abs/2004.06704\", \"Semantic Scholar Corpus ID\": 215754360, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://sdolivia.github.io/FineGym/\"}], \"Creators\": [\"The Chinese University of Hong Kong\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 708.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"tiny-virat\", \"Collection\": \"tiny-virat\", \"Collection URL\": \"https://arxiv.org/abs/2007.07355\", \"Dataset Name\": \"TinyVIRAT: Low-resolution Video Action Recognition\", \"Paper Title\": \"TinyVIRAT: Low-resolution Video Action Recognition\", \"Paper URL\": \"https://arxiv.org/abs/2007.07355\", \"GitHub URL\": \"https://github.com/UgurDemir/Tiny-VIRAT\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tinyvirat\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.07355\", \"Semantic Scholar Corpus ID\": 220525685, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Central Florida\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 10.83, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hyu-vids\", \"Collection\": \"hyu-vids\", \"Collection URL\": \"https://arxiv.org/abs/1904.11451\", \"Dataset Name\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper Title\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/1904.11451\", \"GitHub URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/holistic-large-scale-video-understanding\", \"ArXiv URL\": \"https://arxiv.org/abs/1904.11451\", \"Semantic Scholar Corpus ID\": 131777079, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\"}], \"Creators\": [\"Karlsruhe Institute of Technology\", \"ETH Z\\u00fcrich\", \"KU Leuven\", \"University of Bonn\", \"Sensifai\"], \"Countries\": [\"Switzerland\", \"Belgium\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 96166.67, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moviescenes\", \"Collection\": \"moviescenes\", \"Collection URL\": \"https://arxiv.org/abs/2004.02678\", \"Dataset Name\": \"MovieScenes\", \"Paper Title\": \"MovieScenes\", \"Paper URL\": \"https://arxiv.org/abs/2004.02678\", \"GitHub URL\": \"https://github.com/AnyiRao/SceneSeg\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-local-to-global-approach-to-multi-modal\", \"ArXiv URL\": \"https://arxiv.org/abs/2004.02678\", \"Semantic Scholar Corpus ID\": 214802984, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"The Chinese University of Hong Kong\", \"UC Berkeley\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 250.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Misc (Scene Segmentation)\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"rare-act-dataset\", \"Collection\": \"rare-act-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Dataset Name\": \"RareAct: A video dataset of unusual interactions\", \"Paper Title\": \"RareAct: A video dataset of unusual interactions\", \"Paper URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"GitHub URL\": \"https://github.com/antoine77340/RareAct\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/rareact\", \"ArXiv URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Semantic Scholar Corpus ID\": 220936243, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Oxford\", \"Ecole Normale Sup\\u00e9rieure\", \"Inria\", \"CIIRC\", \"Czech Technical University\"], \"Countries\": [\"United Kingdom\", \"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 21.13, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"oops-dataset\", \"Collection\": \"oops-dataset\", \"Collection URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Epstein_Oops_Predicting_Unintentional_Action_in_Video_CVPR_2020_paper.pdf\", \"Dataset Name\": \"Oops!: Predicting Unintentional Action in Video (CVPR 2020)\", \"Paper Title\": \"Oops!: Predicting Unintentional Action in Video (CVPR 2020)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Epstein_Oops_Predicting_Unintentional_Action_in_Video_CVPR_2020_paper.pdf\", \"GitHub URL\": \"https://github.com/cvlab-columbia/oops\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/oops-predicting-unintentional-action-in-video\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Epstein_Oops_Predicting_Unintentional_Action_in_Video_CVPR_2020_paper.pdf\", \"Semantic Scholar Corpus ID\": 208291335, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://oops.cs.columbia.edu/data/\"}], \"Creators\": [\"Columbia University\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 50.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"violin\", \"Collection\": \"violin\", \"Collection URL\": \"https://arxiv.org/abs/2003.11618\", \"Dataset Name\": \"VIOLIN\", \"Paper Title\": \"VIOLIN\", \"Paper URL\": \"https://arxiv.org/abs/2003.11618\", \"GitHub URL\": \"https://github.com/jimmy646/violin\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/violin\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.11618\", \"Semantic Scholar Corpus ID\": 214668012, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Microsoft\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 582.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"titan\", \"Collection\": \"titan\", \"Collection URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf\", \"Dataset Name\": \"TITAN: Future Forecast using Action Priors (CVPR 2020)\", \"Paper Title\": \"TITAN: Future Forecast using Action Priors (CVPR 2020)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/titan-future-forecast-using-action-priors\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf\", \"Semantic Scholar Corpus ID\": 214727763, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Non Commercial\", \"License URL\": \"https://usa.honda-ri.com/titan\"}], \"Creators\": [\"Honda Research Institute\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 2.91, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"movie-net\", \"Collection\": \"movie-net\", \"Collection URL\": \"https://arxiv.org/abs/2007.10937\", \"Dataset Name\": \"MovieNet\", \"Paper Title\": \"MovieNet\", \"Paper URL\": \"https://arxiv.org/abs/2007.10937\", \"GitHub URL\": \"https://github.com/movienet/movienet-tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/movienet\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.10937\", \"Semantic Scholar Corpus ID\": 220665753, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"The Chinese University of Hong Kong\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3000.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Summarization\", \"Misc\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"lemma-dataset\", \"Collection\": \"lemma-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2007.15781\", \"Dataset Name\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper Title\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2007.15781\", \"GitHub URL\": \"https://github.com/Buzz-Beater/LEMMA\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/lemma\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.15781\", \"Semantic Scholar Corpus ID\": 220634784, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\", \"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"UCLA\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 10.8, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"lemma-dataset\", \"Collection\": \"lemma-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2007.15781\", \"Dataset Name\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper Title\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2007.15781\", \"GitHub URL\": \"https://github.com/Buzz-Beater/LEMMA\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/lemma\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.15781\", \"Semantic Scholar Corpus ID\": 220634784, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\", \"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"UCLA\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 10.8, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"homage\", \"Collection\": \"homage\", \"Collection URL\": \"https://arxiv.org/abs/2105.05226\", \"Dataset Name\": \"HOMAGE: Home Action Genome: Cooperative Compositional Action Understanding (CVPR 2021)\", \"Paper Title\": \"HOMAGE: Home Action Genome: Cooperative Compositional Action Understanding (CVPR 2021)\", \"Paper URL\": \"https://arxiv.org/abs/2105.05226\", \"GitHub URL\": \"https://github.com/nishantrai18/homage\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/home-action-genome-cooperative-compositional\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.05226\", \"Semantic Scholar Corpus ID\": 234357543, \"Year Released\": \"2021\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Stanford University\", \"Panasonic Corporation\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 30.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\", \"Temporal Action Segmentation\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"WebVid\", \"Collection\": \"WebVid\", \"Collection URL\": \"https://arxiv.org/abs/2104.00650\", \"Dataset Name\": \"WebVid\", \"Paper Title\": \"WebVid\", \"Paper URL\": \"https://arxiv.org/abs/2104.00650\", \"GitHub URL\": \"https://github.com/m-bain/webvid\", \"Hugging Face URL\": \"https://huggingface.co/datasets/TempoFunk/webvid-10M\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/webvid\", \"ArXiv URL\": \"https://arxiv.org/abs/2104.00650\", \"Semantic Scholar Corpus ID\": 232478955, \"Year Released\": \"2021\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/m-bain/webvid/blob/main/TERMS.md\"}], \"Creators\": [\"University of Oxford\", \"CNRS\"], \"Countries\": [\"United Kingdom\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13000.0, \"Taken Down\": \"True\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"uav-human\", \"Collection\": \"uav-human\", \"Collection URL\": \"https://arxiv.org/abs/2104.00946\", \"Dataset Name\": \"UAV-Human: A Large Benchmark for Human Behavior Understanding with Unmanned Aerial Vehicles\", \"Paper Title\": \"UAV-Human: A Large Benchmark for Human Behavior Understanding with Unmanned Aerial Vehicles\", \"Paper URL\": \"https://arxiv.org/abs/2104.00946\", \"GitHub URL\": \"https://github.com/sutdcv/UAV-Human\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/uav-human-a-large-benchmark-for-human\", \"ArXiv URL\": \"https://arxiv.org/abs/2104.00946\", \"Semantic Scholar Corpus ID\": 233004700, \"Year Released\": \"2021\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://sutdcv.github.io/uav-human-web/\"}], \"Creators\": [\"Shandong University\", \"Singapore University of Technology and Design\"], \"Countries\": [\"Singapore\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 18.34, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hd-vila-100m\", \"Collection\": \"hd-vila-100m\", \"Collection URL\": \"https://arxiv.org/abs/2111.10337\", \"Dataset Name\": \"Advancing High-Resolution Video-Language Representation with Large-Scale Video Transcriptions\", \"Paper Title\": \"Advancing High-Resolution Video-Language Representation with Large-Scale Video Transcriptions\", \"Paper URL\": \"https://arxiv.org/abs/2111.10337\", \"GitHub URL\": \"https://github.com/microsoft/XPretrain/blob/main/hd-vila-100m/README.md\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/advancing-high-resolution-video-language/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2111.10337\", \"Semantic Scholar Corpus ID\": 244462849, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/microsoft/XPretrain/blob/main/hd-vila-100m/README.md\"}], \"Creators\": [\"Microsoft\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 371.5, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"videolt-dataset\", \"Collection\": \"videolt-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2105.02668\", \"Dataset Name\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper Title\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper URL\": \"https://arxiv.org/abs/2105.02668\", \"GitHub URL\": \"https://github.com/17Skye17/VideoLT\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/videolt\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.02668\", \"Semantic Scholar Corpus ID\": 233864776, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Non Commercial\", \"License URL\": \"https://github.com/17Skye17/VideoLT?tab=readme-ov-file#data-preparation\"}], \"Creators\": [\"Fudan University\", \"Shanghai Collaborative Innovation Center of Intelligent Visual Computing\", \"Inception Institute of Artificial Intelligence\", \"University of Maryland\"], \"Countries\": [\"China\", \"UAE\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13664.96, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"YT-Temporal-180m\", \"Collection\": \"YT-Temporal-180m\", \"Collection URL\": \"https://arxiv.org/pdf/2106.02636\", \"Dataset Name\": \"MERLOT: Multimodal Neural Script Knowledge Models\", \"Paper Title\": \"MERLOT: Multimodal Neural Script Knowledge Models\", \"Paper URL\": \"https://arxiv.org/pdf/2106.02636\", \"GitHub URL\": \"https://github.com/rowanz/merlot\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/yttemporal180m\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/merlot-multimodal-neural-script-knowledge\", \"ArXiv URL\": \"https://arxiv.org/pdf/2106.02636\", \"Semantic Scholar Corpus ID\": 235352775, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/rowanz/merlot/blob/main/LICENSE\"}], \"Creators\": [\"University of Washington\", \"Allen Institute for AI\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1515.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"queryd\", \"Collection\": \"queryd\", \"Collection URL\": \"https://arxiv.org/abs/2011.11071\", \"Dataset Name\": \"QuerYD\", \"Paper Title\": \"QuerYD\", \"Paper URL\": \"https://arxiv.org/abs/2011.11071\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/queryd\", \"ArXiv URL\": \"https://arxiv.org/abs/2011.11071\", \"Semantic Scholar Corpus ID\": 261006321, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"youdescribe\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Oxford\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 207.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"queryd\", \"Collection\": \"queryd\", \"Collection URL\": \"https://arxiv.org/abs/2011.11071\", \"Dataset Name\": \"QuerYD\", \"Paper Title\": \"QuerYD\", \"Paper URL\": \"https://arxiv.org/abs/2011.11071\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/queryd\", \"ArXiv URL\": \"https://arxiv.org/abs/2011.11071\", \"Semantic Scholar Corpus ID\": 261006321, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"youdescribe\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"University of Oxford\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 207.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"multi-moments-in-time-dataset\", \"Collection\": \"multi-moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Dataset Name\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper Title\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Semantic Scholar Corpus ID\": 207780280, \"Year Released\": \"2021\", \"Text Sources\": [\"crowdsourced\", \"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"flickr\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"multi-moments-in-time-dataset\", \"Collection\": \"multi-moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Dataset Name\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper Title\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Semantic Scholar Corpus ID\": 207780280, \"Year Released\": \"2021\", \"Text Sources\": [\"crowdsourced\", \"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Massachusetts Institute of Technology\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"apes\", \"Collection\": \"apes\", \"Collection URL\": \"https://arxiv.org/pdf/2106.01667\", \"Dataset Name\": \"Apes\", \"Paper Title\": \"Apes\", \"Paper URL\": \"https://arxiv.org/pdf/2106.01667\", \"GitHub URL\": \"https://github.com/fuankarion/audiovisual-person-search\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/apes-audiovisual-person-search-in-untrimmed/review/\", \"ArXiv URL\": \"https://arxiv.org/pdf/2106.01667\", \"Semantic Scholar Corpus ID\": 235313698, \"Year Released\": \"2021\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Universidad de los Andes\", \"Adobe Research\", \"King Abdullah University of Science and Technology (KAUST)\"], \"Countries\": [\"Chile\", \"United States of America\", \"Saudi Arabia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 36.0, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Massachusetts Institute of Technology\", \"IBM\", \"The University of Texas at Austin\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"mimetics-dataset\", \"Collection\": \"mimetics-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1912.07249\", \"Dataset Name\": \"Mimetics: Towards Understanding Human Actions Out of Context\", \"Paper Title\": \"Mimetics: Towards Understanding Human Actions Out of Context\", \"Paper URL\": \"https://arxiv.org/abs/1912.07249\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/mimetics-towards-understanding-human-actions\", \"ArXiv URL\": \"https://arxiv.org/abs/1912.07249\", \"Semantic Scholar Corpus ID\": 209376248, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Naver\"], \"Countries\": [\"South Korea\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.99, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"ego-4d\", \"Collection\": \"ego-4d\", \"Collection URL\": \"https://arxiv.org/abs/2110.07058\", \"Dataset Name\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper Title\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper URL\": \"https://arxiv.org/abs/2110.07058\", \"GitHub URL\": \"https://github.com/EGO4D/forecasting\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego4d-around-the-world-in-3000-hours-of\", \"ArXiv URL\": \"https://arxiv.org/abs/2110.07058\", \"Semantic Scholar Corpus ID\": 238856888, \"Year Released\": \"2022\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://ego4d-data.org/pdfs/Ego4D-Licenses-Draft.pdf\"}], \"Creators\": [\"Facebook AI Research\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3670.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Classification\", \"Temporal Action Segmentation\", \"Video Captioning\", \"Misc\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"YT-Temporal-1B\", \"Collection\": \"YT-Temporal-1B\", \"Collection URL\": \"https://arxiv.org/pdf/2201.02639\", \"Dataset Name\": \"MERLOT Reserve: Multimodal Neural Script Knowledge through Vision and Language and Sound\", \"Paper Title\": \"MERLOT Reserve: Multimodal Neural Script Knowledge through Vision and Language and Sound\", \"Paper URL\": \"https://arxiv.org/pdf/2201.02639\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/merlot-reserve-neural-script-knowledge\", \"ArXiv URL\": \"https://arxiv.org/pdf/2201.02639\", \"Semantic Scholar Corpus ID\": 245837609, \"Year Released\": \"2022\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/rowanz/merlot_reserve/blob/main/LICENSE\"}], \"Creators\": [\"University of Washington\", \"Allen Institute for AI\", \"University of Edinburgh\"], \"Countries\": [\"United States of America\", \"Scotland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 55555.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"mad\", \"Collection\": \"mad\", \"Collection URL\": \"https://arxiv.org/abs/2112.00431\", \"Dataset Name\": \"MAD: A Scalable Dataset for Language Grounding in Videos from Movie Audio Descriptions\", \"Paper Title\": \"MAD: A Scalable Dataset for Language Grounding in Videos from Movie Audio Descriptions\", \"Paper URL\": \"https://arxiv.org/abs/2112.00431\", \"GitHub URL\": \"https://github.com/Soldelli/MAD\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mad\", \"ArXiv URL\": \"https://arxiv.org/abs/2112.00431\", \"Semantic Scholar Corpus ID\": 244773187, \"Year Released\": \"2022\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdtUV3uweS0u7AHAMIJAL_dRRdZ5MHpJS3fdZVbhnVt-Yb4NA/viewform\"}], \"Creators\": [\"King Abdullah University of Science and Technology (KAUST)\"], \"Countries\": [\"Saudi Arabia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1207.3, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Captioning\"], \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"cacd\", \"Collection\": \"cacd\", \"Collection URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"Dataset Name\": \"CDAD: A Common Daily Action Dataset with Collected Hard Negative Samples (CVPR 2022)\", \"Paper Title\": \"CDAD: A Common Daily Action Dataset with Collected Hard Negative Samples (CVPR 2022)\", \"Paper URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"GitHub URL\": \"https://github.com/MartinXM/CDAD\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"Semantic Scholar Corpus ID\": 251035434, \"Year Released\": \"2022\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"The Hong Kong Polytechnic University\", \"Alibaba Group\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 215.0, \"Taken Down\": \"False\", \"Video Sources\": \"crowdsourced\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"ferv39k-dataset\", \"Collection\": \"ferv39k-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2203.09463\", \"Dataset Name\": \"FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos (CVPR 2022)\", \"Paper Title\": \"FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos (CVPR 2022)\", \"Paper URL\": \"https://arxiv.org/abs/2203.09463\", \"GitHub URL\": \"https://github.com/wangyanckxx/FERV39k\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ferv39k-a-large-scale-multi-scene-dataset-for\", \"ArXiv URL\": \"https://arxiv.org/abs/2203.09463\", \"Semantic Scholar Corpus ID\": 247518747, \"Year Released\": \"2022\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://wangyanckxx.github.io/Proj_CVPR2022_FERV39k.html\"}], \"Creators\": [\"Fudan University\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 16.47, \"Taken Down\": \"False\", \"Video Sources\": \"undisclosed web\", \"Task Categories\": [\"Video Classification\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"ego-exo4D\", \"Collection\": \"ego-exo4D\", \"Collection URL\": \"https://arxiv.org/abs/2311.18259\", \"Dataset Name\": \"Ego-Exo4D\", \"Paper Title\": \"Ego-Exo4D\", \"Paper URL\": \"https://arxiv.org/abs/2311.18259\", \"GitHub URL\": \"https://github.com/facebookresearch/Ego4d\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego-exo4d-understanding-skilled-human/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2311.18259\", \"Semantic Scholar Corpus ID\": 265506384, \"Year Released\": \"2023\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/facebookresearch/Ego4d/blob/main/LICENSE\"}], \"Creators\": [\"Meta\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1422.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Pose Estimation\", \"Video Classification\", \"Video Captioning\", \"Misc\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"project-aria-digital-twin-dataset\", \"Collection\": \"project-aria-digital-twin-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2306.06362\", \"Dataset Name\": \"Aria Digital Twin\", \"Paper Title\": \"Aria Digital Twin\", \"Paper URL\": \"https://arxiv.org/abs/2306.06362\", \"GitHub URL\": \"https://github.com/facebookresearch/projectaria_tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/aria-digital-twin-a-new-benchmark-dataset-for\", \"ArXiv URL\": \"https://arxiv.org/abs/2306.06362\", \"Semantic Scholar Corpus ID\": 261243365, \"Year Released\": \"2023\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/facebookresearch/projectaria_tools/blob/main/LICENSE\"}], \"Creators\": [\"Meta\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 6.6, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Object Detection\", \"Video Segmentation\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"cinepile\", \"Collection\": \"cinepile\", \"Collection URL\": \"https://arxiv.org/pdf/2405.08813\", \"Dataset Name\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper Title\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper URL\": \"https://arxiv.org/pdf/2405.08813\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/tomg-group-umd/cinepile\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/cinepile\", \"ArXiv URL\": \"https://arxiv.org/pdf/2405.08813\", \"Semantic Scholar Corpus ID\": 269761335, \"Year Released\": \"2024\", \"Text Sources\": [\"youtube\", \"movies\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://creativecommons.org/licenses/by/4.0/\"}], \"Creators\": [\"University of Maryland\", \"Weizmann Institute of Science\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 417.6, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"egopet\", \"Collection\": \"egopet\", \"Collection URL\": \"https://arxiv.org/pdf/2404.09991\", \"Dataset Name\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper Title\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper URL\": \"https://arxiv.org/pdf/2404.09991\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egopet-egomotion-and-interaction-data-from-an\", \"ArXiv URL\": \"https://arxiv.org/pdf/2404.09991\", \"Semantic Scholar Corpus ID\": 269148727, \"Year Released\": \"2024\", \"Text Sources\": [\"tiktok\", \"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://github.com/DannyTran123/egopet/blob/main/LICENSE\"}], \"Creators\": [\"Tel Aviv University\", \"UC Berkeley\", \"New York University\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 84.0, \"Taken Down\": \"False\", \"Video Sources\": \"youtube\", \"Task Categories\": [\"Misc (Locomotion Prediction\", \"Visual Interaction Prediction\", \"Vision to Proprioception Prediction)\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"project-aria-dataset\", \"Collection\": \"project-aria-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/2402.13349\", \"Dataset Name\": \"Aria Everyday Activities Dataset\", \"Paper Title\": \"Aria Everyday Activities Dataset\", \"Paper URL\": \"https://arxiv.org/pdf/2402.13349\", \"GitHub URL\": \"https://github.com/facebookresearch/projectaria_tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/aria-everyday-activities-dataset\", \"ArXiv URL\": \"https://arxiv.org/pdf/2402.13349\", \"Semantic Scholar Corpus ID\": 267770215, \"Year Released\": \"2024\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/facebookresearch/Aria_data_tools/blob/main/LICENSE\"}], \"Creators\": [\"Meta\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1400.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Misc (Scene Reconstruction)\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"cinepile\", \"Collection\": \"cinepile\", \"Collection URL\": \"https://arxiv.org/pdf/2405.08813\", \"Dataset Name\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper Title\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper URL\": \"https://arxiv.org/pdf/2405.08813\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/tomg-group-umd/cinepile\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/cinepile\", \"ArXiv URL\": \"https://arxiv.org/pdf/2405.08813\", \"Semantic Scholar Corpus ID\": 269761335, \"Year Released\": \"2024\", \"Text Sources\": [\"youtube\", \"movies\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://creativecommons.org/licenses/by/4.0/\"}], \"Creators\": [\"University of Maryland\", \"Weizmann Institute of Science\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 417.6, \"Taken Down\": \"False\", \"Video Sources\": \"movies\", \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"egopet\", \"Collection\": \"egopet\", \"Collection URL\": \"https://arxiv.org/pdf/2404.09991\", \"Dataset Name\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper Title\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper URL\": \"https://arxiv.org/pdf/2404.09991\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egopet-egomotion-and-interaction-data-from-an\", \"ArXiv URL\": \"https://arxiv.org/pdf/2404.09991\", \"Semantic Scholar Corpus ID\": 269148727, \"Year Released\": \"2024\", \"Text Sources\": [\"tiktok\", \"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://github.com/DannyTran123/egopet/blob/main/LICENSE\"}], \"Creators\": [\"Tel Aviv University\", \"UC Berkeley\", \"New York University\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 84.0, \"Taken Down\": \"False\", \"Video Sources\": \"Other\", \"Task Categories\": [\"Misc (Locomotion Prediction\", \"Visual Interaction Prediction\", \"Vision to Proprioception Prediction)\"], \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"egoschema\", \"Collection\": \"egoschema\", \"Collection URL\": \"https://arxiv.org/pdf/2308.09126\", \"Dataset Name\": \"EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding\", \"Paper Title\": \"EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding\", \"Paper URL\": \"https://arxiv.org/pdf/2308.09126\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egoschema-a-diagnostic-benchmark-for-very-1\", \"ArXiv URL\": \"https://arxiv.org/pdf/2308.09126\", \"Semantic Scholar Corpus ID\": 261031047, \"Year Released\": \"2024\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"UC Berkeley\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 250.0, \"Taken Down\": \"False\", \"Video Sources\": \"human\", \"Task Categories\": [\"Video Q&A\"], \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}], \"data-dd5c5a2a31ed97d4549b517cbef49661\": [{\"Year Released\": \"<2004\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"<2004\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"<2004\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"<2004\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"<2004\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"<2004\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"<2004\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2004\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2004\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2004\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2004\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2004\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2004\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2004\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2005\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2005\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2005\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2005\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2005\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2005\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2005\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2006\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2006\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2006\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2006\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2006\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2006\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2006\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2007\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2007\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2007\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2007\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2007\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2007\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2007\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2008\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2008\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2008\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2008\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2008\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2008\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2008\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2009\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2009\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2009\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2009\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.1}, {\"Year Released\": \"2009\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 20.1}, {\"Year Released\": \"2009\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2009\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2010\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2010\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 20.1}, {\"Year Released\": \"2010\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.1}, {\"Year Released\": \"2010\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2010\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2010\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2010\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2011\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 7000.0}, {\"Year Released\": \"2011\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7020.1}, {\"Year Released\": \"2011\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.1}, {\"Year Released\": \"2011\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 7000.0}, {\"Year Released\": \"2011\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2011\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 14000.0}, {\"Year Released\": \"2011\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2012\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 14000.0}, {\"Year Released\": \"2012\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2012\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2012\", \"Video Sources\": \"human\", \"Cumulative Hours\": 0.1}, {\"Year Released\": \"2012\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7020.1}, {\"Year Released\": \"2012\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 7000.0}, {\"Year Released\": \"2012\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 7026.0}, {\"Year Released\": \"2013\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7020.1}, {\"Year Released\": \"2013\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 7000.0}, {\"Year Released\": \"2013\", \"Video Sources\": \"human\", \"Cumulative Hours\": 40.1}, {\"Year Released\": \"2013\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 8026.0}, {\"Year Released\": \"2013\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2013\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2013\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 14000.0}, {\"Year Released\": \"2014\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 114784.41}, {\"Year Released\": \"2014\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 14000.0}, {\"Year Released\": \"2014\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 1.11}, {\"Year Released\": \"2014\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2014\", \"Video Sources\": \"human\", \"Cumulative Hours\": 117.1}, {\"Year Released\": \"2014\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7036.150000000001}, {\"Year Released\": \"2014\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 7000.0}, {\"Year Released\": \"2015\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 114788.01000000001}, {\"Year Released\": \"2015\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 7849.0}, {\"Year Released\": \"2015\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7417.150000000001}, {\"Year Released\": \"2015\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 14000.0}, {\"Year Released\": \"2015\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2015\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 1.11}, {\"Year Released\": \"2015\", \"Video Sources\": \"human\", \"Cumulative Hours\": 144.1}, {\"Year Released\": \"2016\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7417.150000000001}, {\"Year Released\": \"2016\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 8103.4}, {\"Year Released\": \"2016\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 464795.01}, {\"Year Released\": \"2016\", \"Video Sources\": \"human\", \"Cumulative Hours\": 253.64}, {\"Year Released\": \"2016\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 75.21}, {\"Year Released\": \"2016\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 14086.1}, {\"Year Released\": \"2016\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2017\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 8112.7}, {\"Year Released\": \"2017\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7631.650000000001}, {\"Year Released\": \"2017\", \"Video Sources\": \"human\", \"Cumulative Hours\": 1104.32}, {\"Year Released\": \"2017\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 467108.11}, {\"Year Released\": \"2017\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 266.66999999999996}, {\"Year Released\": \"2017\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 14086.1}, {\"Year Released\": \"2017\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 0.0}, {\"Year Released\": \"2018\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 15647.2}, {\"Year Released\": \"2018\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 266.66999999999996}, {\"Year Released\": \"2018\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 275.0}, {\"Year Released\": \"2018\", \"Video Sources\": \"human\", \"Cumulative Hours\": 1273.6499999999999}, {\"Year Released\": \"2018\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 7725.55}, {\"Year Released\": \"2018\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 8112.7}, {\"Year Released\": \"2018\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 471120.63}, {\"Year Released\": \"2019\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 608601.21}, {\"Year Released\": \"2019\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 9112.7}, {\"Year Released\": \"2019\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 8241.550000000001}, {\"Year Released\": \"2019\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 279.66999999999996}, {\"Year Released\": \"2019\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 1108.0}, {\"Year Released\": \"2019\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 24182.7}, {\"Year Released\": \"2019\", \"Video Sources\": \"human\", \"Cumulative Hours\": 1642.23}, {\"Year Released\": \"2020\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 10211.83}, {\"Year Released\": \"2020\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 12919.55}, {\"Year Released\": \"2020\", \"Video Sources\": \"human\", \"Cumulative Hours\": 1658.51}, {\"Year Released\": \"2020\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 725115.74}, {\"Year Released\": \"2020\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 304.21}, {\"Year Released\": \"2020\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 50848.7}, {\"Year Released\": \"2020\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 1108.0}, {\"Year Released\": \"2021\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 54805.73}, {\"Year Released\": \"2021\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 1137.21}, {\"Year Released\": \"2021\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 1524.67}, {\"Year Released\": \"2021\", \"Video Sources\": \"human\", \"Cumulative Hours\": 1706.85}, {\"Year Released\": \"2021\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 12955.55}, {\"Year Released\": \"2021\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 24044.83}, {\"Year Released\": \"2021\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 741291.86}, {\"Year Released\": \"2022\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 796846.86}, {\"Year Released\": \"2022\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 25268.6}, {\"Year Released\": \"2022\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 12955.55}, {\"Year Released\": \"2022\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 1352.21}, {\"Year Released\": \"2022\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 1524.67}, {\"Year Released\": \"2022\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 54805.73}, {\"Year Released\": \"2022\", \"Video Sources\": \"human\", \"Cumulative Hours\": 5376.85}, {\"Year Released\": \"2023\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 796846.86}, {\"Year Released\": \"2023\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 12955.55}, {\"Year Released\": \"2023\", \"Video Sources\": \"human\", \"Cumulative Hours\": 6805.45}, {\"Year Released\": \"2023\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 25268.6}, {\"Year Released\": \"2023\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 1352.21}, {\"Year Released\": \"2023\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 54805.73}, {\"Year Released\": \"2023\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 1524.67}, {\"Year Released\": \"2024\", \"Video Sources\": \"undisclosed web\", \"Cumulative Hours\": 25268.6}, {\"Year Released\": \"2024\", \"Video Sources\": \"Other\", \"Cumulative Hours\": 54889.73}, {\"Year Released\": \"2024\", \"Video Sources\": \"crowdsourced\", \"Cumulative Hours\": 1352.21}, {\"Year Released\": \"2024\", \"Video Sources\": \"flickr\", \"Cumulative Hours\": 1524.67}, {\"Year Released\": \"2024\", \"Video Sources\": \"human\", \"Cumulative Hours\": 8455.45}, {\"Year Released\": \"2024\", \"Video Sources\": \"movies\", \"Cumulative Hours\": 13373.15}, {\"Year Released\": \"2024\", \"Video Sources\": \"youtube\", \"Cumulative Hours\": 797348.46}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart_sourceyearcombined = alt.hconcat(\n",
    "    base_sourceyear,\n",
    "    chart_sourceyearhours\n",
    ").configure_axis(\n",
    "    labelFontSize=FONT_SIZE,\n",
    "    titleFontSize=FONT_SIZE,\n",
    "    grid=False\n",
    ").configure_legend(\n",
    "    labelFontSize=FONT_SIZE,\n",
    "    titleFontSize=FONT_SIZE,\n",
    "    labelLimit=MAX_LABELLIMIT\n",
    ").configure_header(\n",
    "    titleFontSize=FONT_SIZE,\n",
    "    labelFontSize=FONT_SIZE\n",
    ").configure_title(\n",
    "    fontSize=FONT_SIZE\n",
    ").resolve_scale(\n",
    "    x=\"independent\",\n",
    "    y=\"independent\"\n",
    ")\n",
    "\n",
    "if PLOT_TOFILE:\n",
    "    chart_sourceyearcombined.save(\n",
    "        os.path.join(PLOT_DIR, \"video_sourcecategories-yearscombined.png\"),\n",
    "        ppi=PLOT_PPI\n",
    "    )\n",
    "\n",
    "chart_sourceyearcombined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Task Vs Year Release "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Categories\n",
      "Video Classification                    51\n",
      "Video Captioning                        25\n",
      "Misc                                    12\n",
      "Video Summarization                      7\n",
      "Video Q&A                                5\n",
      "Video Segmentation                       3\n",
      "Action Segmentation                      2\n",
      "Temporal Action Detection                2\n",
      "Temporal Action Segmentation             2\n",
      "Temporal Localization                    2\n",
      "Action Recognition                       2\n",
      "Group Activity Recognition               2\n",
      "Temporal Action Localization             2\n",
      "Visual Interaction Prediction            1\n",
      "Vision to Proprioception Prediction)     1\n",
      "Spatial-Temporal Action Localization     1\n",
      "Action Localization                      1\n",
      "Video Object Detection                   1\n",
      "Pose Estimation                          1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5     2009\n",
       "3     2009\n",
       "68    2011\n",
       "47    2012\n",
       "86    2013\n",
       "Name: Year Released, dtype: category\n",
       "Categories (22, object): ['<2004' < '2004' < '2005' < '2006' ... '2021' < '2022' < '2023' < '2024']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "task_categories: dict[str, list[str]] = {}\n",
    "# categories['Video Q&A'] = ['Video Question Answering', \"Video Summarization\", \"Video Q&A\", \"Video Captioning\"]\n",
    "task_categories['Video Q&A'] = [\"Video Question Answering\"]\n",
    "task_categories['Misc'] = [\"Misc (Hand/Object Detection)\", \"Misc\", \"Misc (Scene Reconstruction)\", \"Misc (video retrieval\", \n",
    "                        \"Misc (Locomotion Prediction\", \"Misc\", \"interaction understanding via ordering\", \n",
    "                        \"reason prediction)\", \"Misc (Scene Segmentation)\", ]\n",
    "\n",
    "# reverse the categories\n",
    "task_categories = invert_dict_of_lists(task_categories)\n",
    "\n",
    "# Task Categories are a list of categories, but applu the mapping to each item in the list\n",
    "df_video['Task Categories'] = df_video['Task Categories'].apply(\n",
    "    lambda x: [task_categories.get(item, item) for item in x]\n",
    ")\n",
    "print(df_video['Task Categories'].explode().value_counts())\n",
    "\n",
    "INCLUDE_TOP_N_CATEGORIES = 6\n",
    "df_videotaskyears = df_video.explode(\"Task Categories\")\n",
    "df_videotaskyears = reduce_categories_to_topk(df_videotaskyears, \"Task Categories\", INCLUDE_TOP_N_CATEGORIES)\n",
    "\n",
    "df_videotaskyears = df_videotaskyears.sort_values(by=\"Year Released\")\n",
    "df_videotaskyears.head()['Year Released']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-e5166c283f3446bfaee25aaf0f3afe53.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-e5166c283f3446bfaee25aaf0f3afe53.vega-embed details,\n",
       "  #altair-viz-e5166c283f3446bfaee25aaf0f3afe53.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-e5166c283f3446bfaee25aaf0f3afe53\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e5166c283f3446bfaee25aaf0f3afe53\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e5166c283f3446bfaee25aaf0f3afe53\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"Times New Roman\"}, \"axis\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\", \"labelFontSize\": 20, \"titleFontSize\": 20}, \"header\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\"}, \"legend\": {\"labelFont\": \"Times New Roman\", \"titleFont\": \"Times New Roman\", \"columns\": 4, \"labelFontSize\": 20, \"labelLimit\": 1000, \"orient\": \"bottom\", \"titleFontSize\": 20}, \"text\": {\"font\": \"Times New Roman\"}}, \"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"Task Categories\", \"title\": \"Video Task Categories\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30}, \"field\": \"Year Released\", \"sort\": [\"<2004\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"], \"title\": \"Year Released\", \"type\": \"nominal\"}, \"y\": {\"aggregate\": \"count\", \"axis\": {\"format\": \"%\"}, \"stack\": \"normalize\", \"title\": \"Pct. Datasets\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"top\", \"dy\": -90, \"fontSize\": 12}, \"encoding\": {\"text\": {\"aggregate\": \"count\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"Year Released\", \"sort\": [\"<2004\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"], \"title\": \"Year Released\", \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-26c3c8f180d9aadefe0888d89c963003\"}, \"height\": 160, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-26c3c8f180d9aadefe0888d89c963003\": [{\"Unique Dataset Identifier\": \"hollywood2-dataset\", \"Collection\": \"hollywood2-dataset\", \"Collection URL\": \"https://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf\", \"Dataset Name\": \"HOLLYWOOD2: Actions in Context (CVPR 2009)\", \"Paper Title\": \"HOLLYWOOD2: Actions in Context (CVPR 2009)\", \"Paper URL\": \"https://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf\", \"Semantic Scholar Corpus ID\": 3155054, \"Year Released\": \"2009\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Research Group\"], \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 20.1, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"collective\", \"Collection\": \"collective\", \"Collection URL\": \"https://cvgl.stanford.edu/papers/Wongun_CollectiveActivityRecognition09.pdf\", \"Dataset Name\": \"Collective: What are they doing? : Collective activity classification using spatio-temporal relationship among people\", \"Paper Title\": \"Collective: What are they doing? : Collective activity classification using spatio-temporal relationship among people\", \"Paper URL\": \"https://cvgl.stanford.edu/papers/Wongun_CollectiveActivityRecognition09.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://cvgl.stanford.edu/papers/Wongun_CollectiveActivityRecognition09.pdf\", \"Semantic Scholar Corpus ID\": 5925915, \"Year Released\": \"2009\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.1, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hmdb-dataset\", \"Collection\": \"hmdb-dataset\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Dataset Name\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper Title\": \"HMDB: A Large Video Database for Human Motion Recognition (ICCV 2011)\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hmdb51\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/6126543\", \"Semantic Scholar Corpus ID\": 206769852, \"Year Released\": \"2011\", \"Text Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/\"}], \"Creators\": [\"Academic\", \"Academic\", \"Academic\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\", \"prelinger archive\", \"undisclosed web\", \"youtube\", \"google videos\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ucf101-dataset\", \"Collection\": \"ucf101-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1212.0402\", \"Dataset Name\": \"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\", \"Paper Title\": \"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\", \"Paper URL\": \"https://arxiv.org/abs/1212.0402\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/ucf101\", \"ArXiv URL\": \"https://arxiv.org/abs/1212.0402\", \"Semantic Scholar Corpus ID\": 7197134, \"Year Released\": \"2012\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 26.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"youcook\", \"Collection\": \"youcook\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2013/papers/Das_A_Thousand_Frames_2013_CVPR_paper.pdf\", \"Dataset Name\": \"YouCook: A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching (CVPR 2013)\", \"Paper Title\": \"YouCook: A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching (CVPR 2013)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2013/papers/Das_A_Thousand_Frames_2013_CVPR_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youcook\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2013/papers/Das_A_Thousand_Frames_2013_CVPR_paper.pdf\", \"Semantic Scholar Corpus ID\": 12284555, \"Year Released\": \"2013\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"50salads\", \"Collection\": \"50salads\", \"Collection URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"Dataset Name\": \"50Salads\", \"Paper Title\": \"50Salads\", \"Paper URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/50-salads\", \"ArXiv URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"Semantic Scholar Corpus ID\": 2333743, \"Year Released\": \"2013\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://cvip.computing.dundee.ac.uk/datasets/foodpreparation/50salads/\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 40.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"50salads\", \"Collection\": \"50salads\", \"Collection URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"Dataset Name\": \"50Salads\", \"Paper Title\": \"50Salads\", \"Paper URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/50-salads\", \"ArXiv URL\": \"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b9410401cec076baef045e83953f3ff24f25d149\", \"Semantic Scholar Corpus ID\": 2333743, \"Year Released\": \"2013\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://cvip.computing.dundee.ac.uk/datasets/foodpreparation/50salads/\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 40.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"summe\", \"Collection\": \"summe\", \"Collection URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"Dataset Name\": \"SumMe: Creating Summaries from User Videos (ECCV 2014)\", \"Paper Title\": \"SumMe: Creating Summaries from User Videos (ECCV 2014)\", \"Paper URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/summe\", \"ArXiv URL\": \"https://link.springer.com/chapter/10.1007/978-3-319-10584-0_33\", \"Semantic Scholar Corpus ID\": 2111093, \"Year Released\": \"2014\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\", \"Academic\", \"Corporation\"], \"Countries\": [\"Belgium\", \"Switzerland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1.11, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": \"Video Summarization\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"stroygraphs\", \"Collection\": \"stroygraphs\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/papers/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.pdf\", \"Dataset Name\": \"StoryGraphs\", \"Paper Title\": \"StoryGraphs\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/papers/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.pdf\", \"GitHub URL\": \"https://github.com/makarandtapaswi/StoryGraphs_CVPR2014\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/storygraphs-visualizing-character\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/papers/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.pdf\", \"Semantic Scholar Corpus ID\": 1055956, \"Year Released\": \"2014\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7.3, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Misc\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"hollywood-extended\", \"Collection\": \"hollywood-extended\", \"Collection URL\": \"https://arxiv.org/pdf/1407.1208\", \"Dataset Name\": \"Hollywood Extended\", \"Paper Title\": \"Hollywood Extended\", \"Paper URL\": \"https://arxiv.org/pdf/1407.1208\", \"GitHub URL\": \"https://github.com/piotr-bojanowski/action-ordering\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/weakly-supervised-action-labeling-in-videos\", \"ArXiv URL\": \"https://arxiv.org/pdf/1407.1208\", \"Semantic Scholar Corpus ID\": 9342651, \"Year Released\": \"2014\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/piotr-bojanowski/action-ordering/blob/master/LICENSE\"}], \"Creators\": [\"Research Group\"], \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 8.75, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"hollywood-extended\", \"Collection\": \"hollywood-extended\", \"Collection URL\": \"https://arxiv.org/pdf/1407.1208\", \"Dataset Name\": \"Hollywood Extended\", \"Paper Title\": \"Hollywood Extended\", \"Paper URL\": \"https://arxiv.org/pdf/1407.1208\", \"GitHub URL\": \"https://github.com/piotr-bojanowski/action-ordering\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/weakly-supervised-action-labeling-in-videos\", \"ArXiv URL\": \"https://arxiv.org/pdf/1407.1208\", \"Semantic Scholar Corpus ID\": 9342651, \"Year Released\": \"2014\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/piotr-bojanowski/action-ordering/blob/master/LICENSE\"}], \"Creators\": [\"Research Group\"], \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 8.75, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"videostory\", \"Collection\": \"videostory\", \"Collection URL\": \"https://isis-data.science.uva.nl/cgmsnoek/pub/habibian-videostory-mm2014.pdf\", \"Dataset Name\": \"VideoStory: A New Multimedia Embedding for Few-Example Recognition and Translation of Events\", \"Paper Title\": \"VideoStory: A New Multimedia Embedding for Few-Example Recognition and Translation of Events\", \"Paper URL\": \"https://isis-data.science.uva.nl/cgmsnoek/pub/habibian-videostory-mm2014.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://isis-data.science.uva.nl/cgmsnoek/pub/habibian-videostory-mm2014.pdf\", \"Semantic Scholar Corpus ID\": 28203, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"Netherlands\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 743.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"sports1M-dataset\", \"Collection\": \"sports1M-dataset\", \"Collection URL\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\", \"Dataset Name\": \"Sports-1M: Large-scale Video Classification with Convolutional Neural Networks\", \"Paper Title\": \"Sports-1M: Large-scale Video Classification with Convolutional Neural Networks\", \"Paper URL\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\", \"GitHub URL\": \"https://github.com/gtoderici/sports-1m-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/large-scale-video-classification-with-1\", \"ArXiv URL\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\", \"Semantic Scholar Corpus ID\": 206592218, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 3.0\", \"License URL\": \"https://github.com/gtoderici/sports-1m-dataset\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 105761.41, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"breakfast\", \"Collection\": \"breakfast\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"Dataset Name\": \"Breakfast\", \"Paper Title\": \"Breakfast\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/breakfast\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"Semantic Scholar Corpus ID\": 9621856, \"Year Released\": \"2014\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/breakfast-actions-dataset/\"}], \"Creators\": [\"Research Group\", \"Academic\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 77.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"breakfast\", \"Collection\": \"breakfast\", \"Collection URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"Dataset Name\": \"Breakfast\", \"Paper Title\": \"Breakfast\", \"Paper URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/breakfast\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_cvpr_2014/html/Kuehne_The_Language_of_2014_CVPR_paper.html\", \"Semantic Scholar Corpus ID\": 9621856, \"Year Released\": \"2014\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://serre-lab.clps.brown.edu/resource/breakfast-actions-dataset/\"}], \"Creators\": [\"Research Group\", \"Academic\"], \"Countries\": [\"United States of America\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 77.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"thumos-challenge\", \"Collection\": \"thumos-challenge\", \"Collection URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Dataset Name\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper Title\": \"The THUMOS Challenge on Action Recognition for Videos in the Wild\", \"Paper URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/thumos14-1\", \"ArXiv URL\": \"https://arxiv.org/pdf/1604.06182.pdf\", \"Semantic Scholar Corpus ID\": 14049355, \"Year Released\": \"2014\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLScs9davISAtYQS7SEF5qQNu0jUpLzNH3aHmPfuqk2q1VYDkmw/viewform\"}], \"Creators\": [\"Academic\", \"Academic\", \"Academic\", \"Research Group\"], \"Countries\": [\"United States of America\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 254.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"activitynet\", \"Collection\": \"activitynet\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"Dataset Name\": \"ActivityNet\", \"Paper Title\": \"ActivityNet\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/Leyo/ActivityNet_Captions\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/activitynet\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7298698\", \"Semantic Scholar Corpus ID\": 1710722, \"Year Released\": \"2015\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/facebookresearch/ActivityNet-Entities/blob/main/LICENSE\"}], \"Creators\": [\"Academic\", \"Academic\"], \"Countries\": [\"Saudi Arabia\", \"Colombia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 849.0, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"movieqa\", \"Collection\": \"movieqa\", \"Collection URL\": \"https://arxiv.org/abs/1512.02902\", \"Dataset Name\": \"MovieQA\", \"Paper Title\": \"MovieQA\", \"Paper URL\": \"https://arxiv.org/abs/1512.02902\", \"GitHub URL\": \"https://github.com/makarandtapaswi/MovieQA_CVPR2016/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/movieqa\", \"ArXiv URL\": \"https://arxiv.org/abs/1512.02902\", \"Semantic Scholar Corpus ID\": 1017389, \"Year Released\": \"2015\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\", \"Academic\", \"Academic\"], \"Countries\": [\"Germany\", \"Canada\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 381.0, \"Taken Down\": \"True\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Video Q&A\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"tvsum\", \"Collection\": \"tvsum\", \"Collection URL\": \"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\", \"Dataset Name\": \"TVSum: Summarizing web videos using titles (CVPR 2015)\", \"Paper Title\": \"TVSum: Summarizing web videos using titles (CVPR 2015)\", \"Paper URL\": \"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\", \"GitHub URL\": \"https://github.com/yalesong/tvsum\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tvsum-1\", \"ArXiv URL\": \"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\", \"Semantic Scholar Corpus ID\": 7675635, \"Year Released\": \"2015\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 3.0\", \"License URL\": \"https://github.com/yalesong/tvsum\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3.5, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Summarization\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"volleyball-vids\", \"Collection\": \"volleyball-vids\", \"Collection URL\": \"https://arxiv.org/abs/1511.06040\", \"Dataset Name\": \"Volleyball: A Hierarchical Deep Temporal Model for Group Activity Recognition\", \"Paper Title\": \"Volleyball: A Hierarchical Deep Temporal Model for Group Activity Recognition\", \"Paper URL\": \"https://arxiv.org/abs/1511.06040\", \"GitHub URL\": \"https://github.com/mostafa-saad/deep-activity-rec#dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/volleyball\", \"ArXiv URL\": \"https://arxiv.org/abs/1511.06040\", \"Semantic Scholar Corpus ID\": 8483403, \"Year Released\": \"2015\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.1, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mpii-cooking\", \"Collection\": \"mpii-cooking\", \"Collection URL\": \"https://arxiv.org/abs/1502.06648\", \"Dataset Name\": \"MPII-Cooking: Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data (IJCV 2015)\", \"Paper Title\": \"MPII-Cooking: Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data (IJCV 2015)\", \"Paper URL\": \"https://arxiv.org/abs/1502.06648\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/recognizing-fine-grained-and-composite\", \"ArXiv URL\": \"https://arxiv.org/abs/1502.06648\", \"Semantic Scholar Corpus ID\": 14036544, \"Year Released\": \"2015\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/human-activity-recognition/mpii-cooking-activities-dataset\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 27.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"msr-vtt\", \"Collection\": \"msr-vtt\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7780940\", \"Dataset Name\": \"MSR-VTT\", \"Paper Title\": \"MSR-VTT\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7780940\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/msr-vtt\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7780940\", \"Semantic Scholar Corpus ID\": 206594535, \"Year Released\": \"2016\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 41.2, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"vtw\", \"Collection\": \"vtw\", \"Collection URL\": \"https://arxiv.org/abs/1608.07068\", \"Dataset Name\": \"VTW\", \"Paper Title\": \"VTW\", \"Paper URL\": \"https://arxiv.org/abs/1608.07068\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/title-generation-for-user-generated-videos\", \"ArXiv URL\": \"https://arxiv.org/abs/1608.07068\", \"Semantic Scholar Corpus ID\": 6155397, \"Year Released\": \"2016\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\", \"Academic\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 213.2, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mars\", \"Collection\": \"mars\", \"Collection URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Dataset Name\": \"Mars\", \"Paper Title\": \"Mars\", \"Paper URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mars\", \"ArXiv URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Semantic Scholar Corpus ID\": 2214158, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Industry Lab\", \"Academic\", \"Academic\", \"Academic\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.24, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Segmentation\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mars\", \"Collection\": \"mars\", \"Collection URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Dataset Name\": \"Mars\", \"Paper Title\": \"Mars\", \"Paper URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mars\", \"ArXiv URL\": \"https://link.springer.com/content/pdf/10.1007/978-3-319-46466-4_52.pdf\", \"Semantic Scholar Corpus ID\": 2214158, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Industry Lab\", \"Academic\", \"Academic\", \"Academic\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.24, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"tgif\", \"Collection\": \"tgif\", \"Collection URL\": \"https://arxiv.org/abs/1604.02748\", \"Dataset Name\": \"TGIF\", \"Paper Title\": \"TGIF\", \"Paper URL\": \"https://arxiv.org/abs/1604.02748\", \"GitHub URL\": \"https://github.com/raingo/TGIF-Release\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/TGIF\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tgif\", \"ArXiv URL\": \"https://arxiv.org/abs/1604.02748\", \"Semantic Scholar Corpus ID\": 6262415, \"Year Released\": \"2016\", \"Text Sources\": [\"tumblr\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/raingo/TGIF-Release\"}], \"Creators\": [\"Academic\", \"Corporation\", \"Corporation\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 86.1, \"Taken Down\": \"False\", \"Video Sources\": [\"tumblr\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"youtube-8m\", \"Collection\": \"youtube-8m\", \"Collection URL\": \"https://arxiv.org/abs/1609.08675\", \"Dataset Name\": \"Youtube-8M: A Large-Scale Video Classification Benchmark\", \"Paper Title\": \"Youtube-8M: A Large-Scale Video Classification Benchmark\", \"Paper URL\": \"https://arxiv.org/abs/1609.08675\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youtube-8m\", \"ArXiv URL\": \"https://arxiv.org/abs/1609.08675\", \"Semantic Scholar Corpus ID\": 11241677, \"Year Released\": \"2016\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 350000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"mpii-cooking2\", \"Collection\": \"mpii-cooking2\", \"Collection URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"Dataset Name\": \"MPII Cooking 2\", \"Paper Title\": \"MPII Cooking 2\", \"Paper URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mpii-cooking-2-dataset\", \"ArXiv URL\": \"https://arxiv.org/pdf/1502.06648.pdf\", \"Semantic Scholar Corpus ID\": 14036544, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/human-activity-recognition/mpii-cooking-2-dataset/\"}], \"Creators\": [\"Academic\", \"Academic\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 27.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"narrated-instruction-vids\", \"Collection\": \"narrated-instruction-vids\", \"Collection URL\": \"https://arxiv.org/abs/1506.09215\", \"Dataset Name\": \"Narrated Instruction Videos\", \"Paper Title\": \"Narrated Instruction Videos\", \"Paper URL\": \"https://arxiv.org/abs/1506.09215\", \"GitHub URL\": \"https://github.com/jalayrac/instructionVideos\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youtube-inria-instructional\", \"ArXiv URL\": \"https://arxiv.org/abs/1506.09215\", \"Semantic Scholar Corpus ID\": 2617244, \"Year Released\": \"2016\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/jalayrac/instructionVideos?tab=readme-ov-file#license\"}], \"Creators\": [\"Academic\", \"Academic\", \"Research Group\", \"Academic\"], \"Countries\": [\"United States of America\", \"India\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 7.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"charades\", \"Collection\": \"charades\", \"Collection URL\": \"https://arxiv.org/abs/1604.01753\", \"Dataset Name\": \"Charades\", \"Paper Title\": \"Charades\", \"Paper URL\": \"https://arxiv.org/abs/1604.01753\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/charades\", \"ArXiv URL\": \"https://arxiv.org/abs/1604.01753\", \"Semantic Scholar Corpus ID\": 18061547, \"Year Released\": \"2016\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://huggingface.co/datasets/HuggingFaceM4/charades#licensing-information\"}], \"Creators\": [\"Academic\", \"Research Group\", \"Academic\", \"Academic\"], \"Countries\": [\"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 82.3, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ntu-rgbd\", \"Collection\": \"ntu-rgbd\", \"Collection URL\": \"https://arxiv.org/pdf/1604.02808.pdf\", \"Dataset Name\": \"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis (CVPR 2016, TPAMI 2019)\", \"Paper Title\": \"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis (CVPR 2016, TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1604.02808.pdf\", \"GitHub URL\": \"https://github.com/shahroudy/NTURGB-D\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ntu-rgbd-a-large-scale-dataset-for-3d-human\", \"ArXiv URL\": \"https://arxiv.org/pdf/1604.02808.pdf\", \"Semantic Scholar Corpus ID\": 15928602, \"Year Released\": \"2016\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://rose1.ntu.edu.sg/dataset/actionRecognition/\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"Singapore\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 74.1, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"davis\", \"Collection\": \"davis\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"Dataset Name\": \"Davis\", \"Paper Title\": \"Davis\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"GitHub URL\": \"https://github.com/fperazzi/davis\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-benchmark-dataset-and-evaluation\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"Semantic Scholar Corpus ID\": 3619941, \"Year Released\": \"2017\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/fperazzi/davis/blob/main/LICENSE\"}], \"Creators\": [\"Academic\", \"Industry Lab\"], \"Countries\": [\"Switzerland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.04, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"kinetics-400\", \"Collection\": \"kinetics-400\", \"Collection URL\": \"https://arxiv.org/abs/1705.06950\", \"Dataset Name\": \"Kinetics 400\", \"Paper Title\": \"Kinetics 400\", \"Paper URL\": \"https://arxiv.org/abs/1705.06950\", \"GitHub URL\": \"https://github.com/cvdfoundation/kinetics-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/kinetics\", \"ArXiv URL\": \"https://arxiv.org/abs/1705.06950\", \"Semantic Scholar Corpus ID\": 27300853, \"Year Released\": \"2017\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 850.68, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"ava\", \"Collection\": \"ava\", \"Collection URL\": \"https://arxiv.org/pdf/1705.08421\", \"Dataset Name\": \"AVA\", \"Paper Title\": \"AVA\", \"Paper URL\": \"https://arxiv.org/pdf/1705.08421\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ava-a-video-dataset-of-spatio-temporally\", \"ArXiv URL\": \"https://arxiv.org/pdf/1705.08421\", \"Semantic Scholar Corpus ID\": 688013, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://research.google.com/ava/\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 107.5, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"mpii-md\", \"Collection\": \"mpii-md\", \"Collection URL\": \"https://arxiv.org/pdf/1501.02530.pdf\", \"Dataset Name\": \"MPII-MD: A Dataset for Movie Description\", \"Paper Title\": \"MPII-MD: A Dataset for Movie Description\", \"Paper URL\": \"https://arxiv.org/pdf/1501.02530.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1501.02530.pdf\", \"Semantic Scholar Corpus ID\": 15184723, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 56.5, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"youcook-2\", \"Collection\": \"youcook-2\", \"Collection URL\": \"https://arxiv.org/abs/1703.09788\", \"Dataset Name\": \"YouCook2\", \"Paper Title\": \"YouCook2\", \"Paper URL\": \"https://arxiv.org/abs/1703.09788\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/youcook2\", \"ArXiv URL\": \"https://arxiv.org/abs/1703.09788\", \"Semantic Scholar Corpus ID\": 19713015, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"http://youcook2.eecs.umich.edu/static/YouCookII/LICENSE_YOUCOOK2.txt\"}], \"Creators\": [\"Academic\", \"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 175.6, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"multi-thumos-challenge\", \"Collection\": \"multi-thumos-challenge\", \"Collection URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"Dataset Name\": \"MultiTHUMOS: Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos (IJCV 2017)\", \"Paper Title\": \"MultiTHUMOS: Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos (IJCV 2017)\", \"Paper URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/multithumos\", \"ArXiv URL\": \"https://arxiv.org/pdf/1507.05738v3.pdf\", \"Semantic Scholar Corpus ID\": 3337929, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://ai.stanford.edu/~syyeung/resources/multithumos.zip\"}], \"Creators\": [\"Academic\", \"Academic\", \"Academic\"], \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 30.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"pku-mmd-dataset\", \"Collection\": \"pku-mmd-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1703.07475\", \"Dataset Name\": \"PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding (ACM Multimedia Workshop)\", \"Paper Title\": \"PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding (ACM Multimedia Workshop)\", \"Paper URL\": \"https://arxiv.org/abs/1703.07475\", \"GitHub URL\": \"https://struct002.github.io/PKUMMD/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/pku-mmd-a-large-scale-benchmark-for\", \"ArXiv URL\": \"https://arxiv.org/abs/1703.07475\", \"Semantic Scholar Corpus ID\": 1904265, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Industry Lab\", \"Academic\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 50.0, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"ava\", \"Collection\": \"ava\", \"Collection URL\": \"https://arxiv.org/pdf/1705.08421\", \"Dataset Name\": \"AVA\", \"Paper Title\": \"AVA\", \"Paper URL\": \"https://arxiv.org/pdf/1705.08421\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ava-a-video-dataset-of-spatio-temporally\", \"ArXiv URL\": \"https://arxiv.org/pdf/1705.08421\", \"Semantic Scholar Corpus ID\": 688013, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://research.google.com/ava/\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 107.5, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"20bn-something\", \"Collection\": \"20bn-something\", \"Collection URL\": \"https://arxiv.org/abs/1706.04261\", \"Dataset Name\": \"20BN-SOMETHING-SOMETHING: The \\\"something something\\\" video database for learning and evaluating visual common sense\", \"Paper Title\": \"20BN-SOMETHING-SOMETHING: The \\\"something something\\\" video database for learning and evaluating visual common sense\", \"Paper URL\": \"https://arxiv.org/abs/1706.04261\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/something-something-v2\", \"ArXiv URL\": \"https://arxiv.org/abs/1706.04261\", \"Semantic Scholar Corpus ID\": 834612, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://developer.qualcomm.com/software/ai-datasets/something-something\"}], \"Creators\": [\"Corporation\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 121.46, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"imagenet-vid\", \"Collection\": \"imagenet-vid\", \"Collection URL\": \"https://link.springer.com/article/10.1007/s11263-015-0816-y?sa_campaign=email/event/articleAuthor/onlineFirst#\", \"Dataset Name\": \"ImageNet VID\", \"Paper Title\": \"ImageNet VID\", \"Paper URL\": \"https://link.springer.com/article/10.1007/s11263-015-0816-y?sa_campaign=email/event/articleAuthor/onlineFirst#\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/sota/video-object-detection-on-imagenet-vid\", \"ArXiv URL\": \"https://link.springer.com/article/10.1007/s11263-015-0816-y?sa_campaign=email/event/articleAuthor/onlineFirst#\", \"Semantic Scholar Corpus ID\": 2930547, \"Year Released\": \"2017\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://www.image-net.org/challenges/LSVRC/2017/index.php\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 9.26, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"lsmdc\", \"Collection\": \"lsmdc\", \"Collection URL\": \"https://arxiv.org/pdf/1605.03705\", \"Dataset Name\": \"LSMDC\", \"Paper Title\": \"LSMDC\", \"Paper URL\": \"https://arxiv.org/pdf/1605.03705\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/movie-description\", \"ArXiv URL\": \"https://arxiv.org/pdf/1605.03705\", \"Semantic Scholar Corpus ID\": 18217052, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://datasets.d2.mpi-inf.mpg.de/movieDescription/protected/lsmdc2016/README.txt\"}], \"Creators\": [\"Academic\", \"Industry Lab\", \"Academic\", \"Academic\", \"Academic\", \"Corporation\"], \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"lsmdc\", \"Collection\": \"lsmdc\", \"Collection URL\": \"https://arxiv.org/pdf/1605.03705\", \"Dataset Name\": \"LSMDC\", \"Paper Title\": \"LSMDC\", \"Paper URL\": \"https://arxiv.org/pdf/1605.03705\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/movie-description\", \"ArXiv URL\": \"https://arxiv.org/pdf/1605.03705\", \"Semantic Scholar Corpus ID\": 18217052, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://datasets.d2.mpi-inf.mpg.de/movieDescription/protected/lsmdc2016/README.txt\"}], \"Creators\": [\"Academic\", \"Industry Lab\", \"Academic\", \"Academic\", \"Academic\", \"Corporation\"], \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Misc\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"lsmdc\", \"Collection\": \"lsmdc\", \"Collection URL\": \"https://arxiv.org/pdf/1605.03705\", \"Dataset Name\": \"LSMDC\", \"Paper Title\": \"LSMDC\", \"Paper URL\": \"https://arxiv.org/pdf/1605.03705\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/movie-description\", \"ArXiv URL\": \"https://arxiv.org/pdf/1605.03705\", \"Semantic Scholar Corpus ID\": 18217052, \"Year Released\": \"2017\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://datasets.d2.mpi-inf.mpg.de/movieDescription/protected/lsmdc2016/README.txt\"}], \"Creators\": [\"Academic\", \"Industry Lab\", \"Academic\", \"Academic\", \"Academic\", \"Corporation\"], \"Countries\": [\"United States of America\", \"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Video Summarization\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"voxceleb\", \"Collection\": \"voxceleb\", \"Collection URL\": \"https://arxiv.org/abs/1706.08612\", \"Dataset Name\": \"VoxCeleb\", \"Paper Title\": \"VoxCeleb\", \"Paper URL\": \"https://arxiv.org/abs/1706.08612\", \"GitHub URL\": \"https://github.com/a-nagrani/VGGVox\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://cs.paperswithcode.com/paper/voxceleb-a-large-scale-speaker-identification\", \"ArXiv URL\": \"https://arxiv.org/abs/1706.08612\", \"Semantic Scholar Corpus ID\": 10475843, \"Year Released\": \"2017\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United Kingdom\", \"South Korea\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 2000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"davis\", \"Collection\": \"davis\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"Dataset Name\": \"Davis\", \"Paper Title\": \"Davis\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"GitHub URL\": \"https://github.com/fperazzi/davis\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-benchmark-dataset-and-evaluation\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/7780454\", \"Semantic Scholar Corpus ID\": 3619941, \"Year Released\": \"2017\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/fperazzi/davis/blob/main/LICENSE\"}], \"Creators\": [\"Academic\", \"Industry Lab\"], \"Countries\": [\"Switzerland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.04, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": \"Video Segmentation\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"qfvs\", \"Collection\": \"qfvs\", \"Collection URL\": \"https://arxiv.org/abs/1707.04960\", \"Dataset Name\": \"QFVS: Query-Focused Video Summarization: Dataset, Evaluation, and A Memory Network Based Approach (CVPR 2017)\", \"Paper Title\": \"QFVS: Query-Focused Video Summarization: Dataset, Evaluation, and A Memory Network Based Approach (CVPR 2017)\", \"Paper URL\": \"https://arxiv.org/abs/1707.04960\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/query-focused-video-summarization-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/1707.04960\", \"Semantic Scholar Corpus ID\": 2774608, \"Year Released\": \"2017\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\", \"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 20.0, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": \"Video Summarization\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"vlog-vids\", \"Collection\": \"vlog-vids\", \"Collection URL\": \"https://arxiv.org/abs/1712.02310\", \"Dataset Name\": \"VLOG: From Lifestyle Vlogs to Everyday Interactions (CVPR 2018)\", \"Paper Title\": \"VLOG: From Lifestyle Vlogs to Everyday Interactions (CVPR 2018)\", \"Paper URL\": \"https://arxiv.org/abs/1712.02310\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/vlog-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/1712.02310\", \"Semantic Scholar Corpus ID\": 22264672, \"Year Released\": \"2018\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://web.eecs.umich.edu/~fouhey/2017/VLOG/index.html\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 336.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"epic-kitchenes\", \"Collection\": \"epic-kitchenes\", \"Collection URL\": \"https://arxiv.org/abs/1804.02748\", \"Dataset Name\": \"EPIC-KITCHENS\", \"Paper Title\": \"EPIC-KITCHENS\", \"Paper URL\": \"https://arxiv.org/abs/1804.02748\", \"GitHub URL\": \"https://github.com/epic-kitchens\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/epic-kitchens-100\", \"ArXiv URL\": \"https://arxiv.org/abs/1804.02748\", \"Semantic Scholar Corpus ID\": 4710439, \"Year Released\": \"2018\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://epic-kitchens.github.io/2024\"}], \"Creators\": [\"Academic\", \"Academic\", \"Academic\"], \"Countries\": [\"United Kingdom\", \"Canada\", \"Spain\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 100.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"kinetics-600\", \"Collection\": \"kinetics-600\", \"Collection URL\": \"https://arxiv.org/abs/1808.01340\", \"Dataset Name\": \"Kinetics 600\", \"Paper Title\": \"Kinetics 600\", \"Paper URL\": \"https://arxiv.org/abs/1808.01340\", \"GitHub URL\": \"https://github.com/cvdfoundation/kinetics-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/kinetics-600\", \"ArXiv URL\": \"https://arxiv.org/abs/1808.01340\", \"Semantic Scholar Corpus ID\": 51927456, \"Year Released\": \"2018\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1376.52, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"soa-dataset\", \"Collection\": \"soa-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1904.11451\", \"Dataset Name\": \"Scenes-objects-actions: A multi-task, multi-label video dataset\", \"Paper Title\": \"Scenes-objects-actions: A multi-task, multi-label video dataset\", \"Paper URL\": \"https://arxiv.org/pdf/1904.11451\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/scenes-objects-actions-a-multi-task-multi\", \"ArXiv URL\": \"https://arxiv.org/pdf/1904.11451\", \"Semantic Scholar Corpus ID\": 52968009, \"Year Released\": \"2018\", \"Text Sources\": [\"facebook\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Corporation\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1561.1, \"Taken Down\": \"False\", \"Video Sources\": [\"facebook\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"moviegraphs\", \"Collection\": \"moviegraphs\", \"Collection URL\": \"https://arxiv.org/pdf/1712.06761\", \"Dataset Name\": \"MovieGraphs\", \"Paper Title\": \"MovieGraphs\", \"Paper URL\": \"https://arxiv.org/pdf/1712.06761\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/moviegraphs\", \"ArXiv URL\": \"https://arxiv.org/pdf/1712.06761\", \"Semantic Scholar Corpus ID\": 4856028, \"Year Released\": \"2018\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moviegraphs.cs.toronto.edu/download.html\"}], \"Creators\": [\"Other\", \"Academic\", \"Academic\"], \"Countries\": [\"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 93.9, \"Taken Down\": \"True\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Misc\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moviegraphs\", \"Collection\": \"moviegraphs\", \"Collection URL\": \"https://arxiv.org/pdf/1712.06761\", \"Dataset Name\": \"MovieGraphs\", \"Paper Title\": \"MovieGraphs\", \"Paper URL\": \"https://arxiv.org/pdf/1712.06761\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/moviegraphs\", \"ArXiv URL\": \"https://arxiv.org/pdf/1712.06761\", \"Semantic Scholar Corpus ID\": 4856028, \"Year Released\": \"2018\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moviegraphs.cs.toronto.edu/download.html\"}], \"Creators\": [\"Other\", \"Academic\", \"Academic\"], \"Countries\": [\"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 93.9, \"Taken Down\": \"True\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Misc\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moviegraphs\", \"Collection\": \"moviegraphs\", \"Collection URL\": \"https://arxiv.org/pdf/1712.06761\", \"Dataset Name\": \"MovieGraphs\", \"Paper Title\": \"MovieGraphs\", \"Paper URL\": \"https://arxiv.org/pdf/1712.06761\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/moviegraphs\", \"ArXiv URL\": \"https://arxiv.org/pdf/1712.06761\", \"Semantic Scholar Corpus ID\": 4856028, \"Year Released\": \"2018\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moviegraphs.cs.toronto.edu/download.html\"}], \"Creators\": [\"Other\", \"Academic\", \"Academic\"], \"Countries\": [\"Canada\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 93.9, \"Taken Down\": \"True\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Misc\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"charades-ego\", \"Collection\": \"charades-ego\", \"Collection URL\": \"https://arxiv.org/abs/1804.09627\", \"Dataset Name\": \"Charades-Ego: Actor and Observer: Joint Modeling of First and Third-Person Videos (CVPR 2018)\", \"Paper Title\": \"Charades-Ego: Actor and Observer: Joint Modeling of First and Third-Person Videos (CVPR 2018)\", \"Paper URL\": \"https://arxiv.org/abs/1804.09627\", \"GitHub URL\": \"https://github.com/gsig/actor-observer\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/search?q_meta=&q_type=&q=Actor+and+Observer%3A+Joint+Modeling+of+First+and+Third-Person+Videos\", \"ArXiv URL\": \"https://arxiv.org/abs/1804.09627\", \"Semantic Scholar Corpus ID\": 4562167, \"Year Released\": \"2018\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://prior.allenai.org/projects/data/charades-ego/license.txt\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 69.33, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"how2\", \"Collection\": \"how2\", \"Collection URL\": \"https://arxiv.org/abs/1811.00347\", \"Dataset Name\": \"How2: A Large-scale Dataset for Multimodal Language Understanding (NeurIPS 2018)\", \"Paper Title\": \"How2: A Large-scale Dataset for Multimodal Language Understanding (NeurIPS 2018)\", \"Paper URL\": \"https://arxiv.org/abs/1811.00347\", \"GitHub URL\": \"https://github.com/srvk/how2-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/abs/1811.00347\", \"Semantic Scholar Corpus ID\": 53186236, \"Year Released\": \"2018\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Various\", \"License URL\": \"https://github.com/srvk/how2-dataset?tab=readme-ov-file#how2-license\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 2300.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"didemo\", \"Collection\": \"didemo\", \"Collection URL\": \"https://paperswithcode.com/dataset/didemo\", \"Dataset Name\": \"DiDeMo: Localizing Moments in Video with Temporal Language (EMNLP 2018)\", \"Paper Title\": \"DiDeMo: Localizing Moments in Video with Temporal Language (EMNLP 2018)\", \"Paper URL\": \"https://paperswithcode.com/dataset/didemo\", \"GitHub URL\": \"https://github.com/LisaAnne/TemporalLanguageRelease\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://paperswithcode.com/dataset/didemo\", \"Semantic Scholar Corpus ID\": 52164739, \"Year Released\": \"2018\", \"Text Sources\": [\"flickr\"], \"Licenses\": [{\"License\": \"BSD 2-Clause License\", \"License URL\": \"https://github.com/LisaAnne/TemporalLanguageRelease\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 275.0, \"Taken Down\": \"False\", \"Video Sources\": [\"flickr\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"hacs-dataset\", \"Collection\": \"hacs-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1712.09374\", \"Dataset Name\": \"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\", \"Paper Title\": \"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\", \"Paper URL\": \"https://arxiv.org/abs/1712.09374\", \"GitHub URL\": \"https://github.com/hangzhaomit/HACS-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/hacs\", \"ArXiv URL\": \"https://arxiv.org/abs/1712.09374\", \"Semantic Scholar Corpus ID\": 68049510, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/hangzhaomit/HACS-dataset?tab=readme-ov-file#request-testing-videos-and-missing-videos-new\"}], \"Creators\": [\"Academic\", \"Academic\", \"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moments-in-time-dataset\", \"Collection\": \"moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Dataset Name\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper Title\": \"Moments in Time Dataset: one million videos for event understanding (TPAMI 2019)\", \"Paper URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1801.03150.pdf\", \"Semantic Scholar Corpus ID\": 11868155, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"http://moments.csail.mit.edu/\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper Title\": \"CrossTask: weakly supervised learning from instructional videos (CVPR 2019)\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\", \"Research Group\", \"Other\", \"Academic\", \"Academic\"], \"Countries\": [\"France\", \"Turkey\", \"United States of America\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"msa\", \"Collection\": \"msa\", \"Collection URL\": \"https://arxiv.org/abs/1910.11009\", \"Dataset Name\": \"MSA\", \"Paper Title\": \"MSA\", \"Paper URL\": \"https://arxiv.org/abs/1910.11009\", \"GitHub URL\": \"https://github.com/ycxioooong/MovieSynopsisAssociation\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-graph-based-framework-to-bridge-movies-and-1\", \"ArXiv URL\": \"https://arxiv.org/abs/1910.11009\", \"Semantic Scholar Corpus ID\": 204852218, \"Year Released\": \"2019\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\", \"Academic\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 516.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Video Summarization\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"howto100m\", \"Collection\": \"howto100m\", \"Collection URL\": \"https://arxiv.org/abs/1906.03327\", \"Dataset Name\": \"HowTo100M\", \"Paper Title\": \"HowTo100M\", \"Paper URL\": \"https://arxiv.org/abs/1906.03327\", \"GitHub URL\": \"https://github.com/antoine77340/howto100m\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/howto100m\", \"ArXiv URL\": \"https://arxiv.org/abs/1906.03327\", \"Semantic Scholar Corpus ID\": 182952863, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\", \"Research Group\", \"Other\", \"Academic\"], \"Countries\": [\"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 134472.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"coin-dataset\", \"Collection\": \"coin-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1903.02874\", \"Dataset Name\": \"COIN: A Large-scale Dataset for Comprehensive Instructional Video Analysis (CVPR 2019)\", \"Paper Title\": \"COIN: A Large-scale Dataset for Comprehensive Instructional Video Analysis (CVPR 2019)\", \"Paper URL\": \"https://arxiv.org/abs/1903.02874\", \"GitHub URL\": \"https://github.com/coin-dataset/annotations\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/coin#:~:text=The%20COIN%20dataset%20(a%20large,are%20all%20collected%20from%20YouTube.\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.02874\", \"Semantic Scholar Corpus ID\": 71147568, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/coin-dataset/annotations?tab=readme-ov-file#license\"}], \"Creators\": [\"Academic\", \"Corporation\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 476.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"20BN-jester\", \"Collection\": \"20BN-jester\", \"Collection URL\": \"https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf\", \"Dataset Name\": \"20BN-jester: The Jester Dataset: A Large-Scale Video Dataset of Human Gestures (ICCVW 2019)\", \"Paper Title\": \"20BN-jester: The Jester Dataset: A Large-Scale Video Dataset of Human Gestures (ICCVW 2019)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf\", \"Semantic Scholar Corpus ID\": 208010438, \"Year Released\": \"2019\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://developer.qualcomm.com/software/ai-datasets/jester\"}], \"Creators\": [\"Corporation\"], \"Countries\": [\"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13.0, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"mmact\", \"Collection\": \"mmact\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Dataset Name\": \"MMAct\", \"Paper Title\": \"MMAct\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mmact\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Semantic Scholar Corpus ID\": 207980205, \"Year Released\": \"2019\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://mmact19.github.io/2019/\"}], \"Creators\": [\"Academic\", \"Corporation\"], \"Countries\": [\"Hong Kong\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 100.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"mmact\", \"Collection\": \"mmact\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Dataset Name\": \"MMAct\", \"Paper Title\": \"MMAct\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mmact\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Semantic Scholar Corpus ID\": 207980205, \"Year Released\": \"2019\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://mmact19.github.io/2019/\"}], \"Creators\": [\"Academic\", \"Corporation\"], \"Countries\": [\"Hong Kong\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 100.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"trecvid\", \"Collection\": \"trecvid\", \"Collection URL\": \"https://arxiv.org/abs/2009.09984\", \"Dataset Name\": \"TRECVID\", \"Paper Title\": \"TRECVID\", \"Paper URL\": \"https://arxiv.org/abs/2009.09984\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/trecvid-2019-an-evaluation-campaign-to/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.09984\", \"Semantic Scholar Corpus ID\": 212694843, \"Year Released\": \"2019\", \"Text Sources\": [\"undisclosed web\", \"bbc\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://trecvid.nist.gov/\"}], \"Creators\": [\"Government\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\", \"bbc\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"toyota-smarthome\", \"Collection\": \"toyota-smarthome\", \"Collection URL\": \"https://openaccess.thecvf.com/content_ICCV_2019/papers/Das_Toyota_Smarthome_Real-World_Activities_of_Daily_Living_ICCV_2019_paper.pdf\", \"Dataset Name\": \"Toyota Smarthome: Real-World Activities of Daily Living (ICCV 2019)\", \"Paper Title\": \"Toyota Smarthome: Real-World Activities of Daily Living (ICCV 2019)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_ICCV_2019/papers/Das_Toyota_Smarthome_Real-World_Activities_of_Daily_Living_ICCV_2019_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_ICCV_2019/papers/Das_Toyota_Smarthome_Real-World_Activities_of_Daily_Living_ICCV_2019_paper.pdf\", \"Semantic Scholar Corpus ID\": 207971208, \"Year Released\": \"2019\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://project.inria.fr/toyotasmarthome/files/2020/12/License_v2.pdf\"}], \"Creators\": [\"Corporation\"], \"Countries\": [\"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 268.58, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"crosstask\", \"Collection\": \"crosstask\", \"Collection URL\": \"https://arxiv.org/abs/1903.08225\", \"Dataset Name\": \"CrossTask\", \"Paper Title\": \"CrossTask\", \"Paper URL\": \"https://arxiv.org/abs/1903.08225\", \"GitHub URL\": \"https://github.com/DmZhukov/CrossTask\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/crosstask\", \"ArXiv URL\": \"https://arxiv.org/abs/1903.08225\", \"Semantic Scholar Corpus ID\": 84187266, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\", \"Research Group\", \"Academic\", \"Academic\", \"Other\"], \"Countries\": [\"Czech Republic\", \"France\", \"Turkey\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 376.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"trecvid\", \"Collection\": \"trecvid\", \"Collection URL\": \"https://arxiv.org/abs/2009.09984\", \"Dataset Name\": \"TRECVID\", \"Paper Title\": \"TRECVID\", \"Paper URL\": \"https://arxiv.org/abs/2009.09984\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/trecvid-2019-an-evaluation-campaign-to/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.09984\", \"Semantic Scholar Corpus ID\": 212694843, \"Year Released\": \"2019\", \"Text Sources\": [\"undisclosed web\", \"bbc\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://trecvid.nist.gov/\"}], \"Creators\": [\"Government\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\", \"bbc\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"mmact\", \"Collection\": \"mmact\", \"Collection URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Dataset Name\": \"MMAct\", \"Paper Title\": \"MMAct\", \"Paper URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mmact\", \"ArXiv URL\": \"https://ieeexplore.ieee.org/document/9009579\", \"Semantic Scholar Corpus ID\": 207980205, \"Year Released\": \"2019\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://mmact19.github.io/2019/\"}], \"Creators\": [\"Academic\", \"Corporation\"], \"Countries\": [\"Hong Kong\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 100.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"ava-dataset\", \"Collection\": \"ava-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1901.01342\", \"Dataset Name\": \"AVA Active Speaker\", \"Paper Title\": \"AVA Active Speaker\", \"Paper URL\": \"https://arxiv.org/abs/1901.01342\", \"GitHub URL\": \"https://github.com/cvdfoundation/ava-dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/ava-activespeaker\", \"ArXiv URL\": \"https://arxiv.org/abs/1901.01342\", \"Semantic Scholar Corpus ID\": 216211909, \"Year Released\": \"2019\", \"Text Sources\": [\"Not Prohibited\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://research.google.com/ava/download.html#ava_active_speaker_download\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 38.5, \"Taken Down\": \"False\", \"Video Sources\": [\"Not Prohibited\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"vatex\", \"Collection\": \"vatex\", \"Collection URL\": \"https://arxiv.org/abs/1904.03493\", \"Dataset Name\": \"VaTeX\", \"Paper Title\": \"VaTeX\", \"Paper URL\": \"https://arxiv.org/abs/1904.03493\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/vatex\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/vatex\", \"ArXiv URL\": \"https://arxiv.org/abs/1904.03493\", \"Semantic Scholar Corpus ID\": 102352148, \"Year Released\": \"2019\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://eric-xw.github.io/vatex-website/index.html\"}], \"Creators\": [\"Corporation\", \"Academic\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 114.58, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"haa500-dataset\", \"Collection\": \"haa500-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2009.05224\", \"Dataset Name\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper Title\": \"HAA500: Human-Centric Atomic Action Dataset with Curated Videos (ICCV 2021)\", \"Paper URL\": \"https://arxiv.org/abs/2009.05224\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/haa500-human-centric-atomic-action-dataset\", \"ArXiv URL\": \"https://arxiv.org/abs/2009.05224\", \"Semantic Scholar Corpus ID\": 221640805, \"Year Released\": \"2020\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\", \"Academic\", \"Academic\", \"Corporation\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 5.48, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"eev-dataset\", \"Collection\": \"eev-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2001.05488\", \"Dataset Name\": \"EEV: A Large-Scale Dataset for Studying Evoked Expressions from Video\", \"Paper Title\": \"EEV: A Large-Scale Dataset for Studying Evoked Expressions from Video\", \"Paper URL\": \"https://arxiv.org/abs/2001.05488\", \"GitHub URL\": \"https://github.com/google-research-datasets/eev\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/abs/2001.05488\", \"Semantic Scholar Corpus ID\": 210701992, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://github.com/google-research-datasets/eev?tab=readme-ov-file#license\"}], \"Creators\": [\"Industry Lab\", \"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 370.0, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"omnisource-web-dataset\", \"Collection\": \"omnisource-web-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2003.13042\", \"Dataset Name\": \"OmniSource Web Dataset\", \"Paper Title\": \"OmniSource Web Dataset\", \"Paper URL\": \"https://arxiv.org/abs/2003.13042\", \"GitHub URL\": \"https://github.com/open-mmlab/mmaction\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/omni-sourced-webly-supervised-learning-for#code\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.13042\", \"Semantic Scholar Corpus ID\": 214714240, \"Year Released\": \"2020\", \"Text Sources\": [\"google videos\", \"instagram\", \"youtube\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/open-mmlab/mmaction?tab=readme-ov-file#license\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13333.0, \"Taken Down\": \"False\", \"Video Sources\": [\"google videos\", \"instagram\", \"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"finegym-dataset\", \"Collection\": \"finegym-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2004.06704\", \"Dataset Name\": \"FineGym: A Hierarchical Video Dataset for Fine-grained Action Understanding (CVPR 2020)\", \"Paper Title\": \"FineGym: A Hierarchical Video Dataset for Fine-grained Action Understanding (CVPR 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2004.06704\", \"GitHub URL\": \"https://github.com/SDOlivia/FineGym/\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/finegym\", \"ArXiv URL\": \"https://arxiv.org/abs/2004.06704\", \"Semantic Scholar Corpus ID\": 215754360, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://sdolivia.github.io/FineGym/\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 708.0, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"lsmdc-ordering\", \"Collection\": \"lsmdc-ordering\", \"Collection URL\": \"https://arxiv.org/pdf/2004.02205\", \"Dataset Name\": \"LSMDC Ordering\", \"Paper Title\": \"LSMDC Ordering\", \"Paper URL\": \"https://arxiv.org/pdf/2004.02205\", \"GitHub URL\": \"https://github.com/vivoutlaw/TCBP\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/deep-multimodal-feature-encoding-for-video\", \"ArXiv URL\": \"https://arxiv.org/pdf/2004.02205\", \"Semantic Scholar Corpus ID\": 214802821, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/vivoutlaw/tcbp/blob/master/LICENSE\"}], \"Creators\": [\"Academic\", \"Academic\", \"Research Group\", \"Academic\"], \"Countries\": [\"Germany\", \"Canada\", \"United States of America\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 158.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"hyu-vids\", \"Collection\": \"hyu-vids\", \"Collection URL\": \"https://arxiv.org/abs/1904.11451\", \"Dataset Name\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper Title\": \"HVU: Large Scale Holistic Video Understanding (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/1904.11451\", \"GitHub URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/holistic-large-scale-video-understanding\", \"ArXiv URL\": \"https://arxiv.org/abs/1904.11451\", \"Semantic Scholar Corpus ID\": 131777079, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/holistic-video-understanding/HVU-Dataset\"}], \"Creators\": [\"Academic\", \"Academic\", \"Academic\", \"Academic\", \"Startup\"], \"Countries\": [\"Switzerland\", \"Belgium\", \"Germany\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 96166.67, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"condensed-movies\", \"Collection\": \"condensed-movies\", \"Collection URL\": \"https://arxiv.org/pdf/2005.04208\", \"Dataset Name\": \"Condensed Movies\", \"Paper Title\": \"Condensed Movies\", \"Paper URL\": \"https://arxiv.org/pdf/2005.04208\", \"GitHub URL\": \"https://github.com/m-bain/CondensedMovies\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/condensed-movies\", \"ArXiv URL\": \"https://arxiv.org/pdf/2005.04208\", \"Semantic Scholar Corpus ID\": 218571391, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://www.robots.ox.ac.uk/~vgg/data/condensed-movies/#download\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1270.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Video Summarization\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"100doh\", \"Collection\": \"100doh\", \"Collection URL\": \"https://arxiv.org/abs/2006.06669\", \"Dataset Name\": \"100DOH: Understanding Human Hands in Contact at Internet Scale (CVPR 2020)\", \"Paper Title\": \"100DOH: Understanding Human Hands in Contact at Internet Scale (CVPR 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2006.06669\", \"GitHub URL\": \"https://github.com/ddshan/hand_object_detector\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/understanding-human-hands-in-contact-at-1\", \"ArXiv URL\": \"https://arxiv.org/abs/2006.06669\", \"Semantic Scholar Corpus ID\": 215413188, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://fouheylab.eecs.umich.edu/~dandans/projects/100DOH/download.html\"}], \"Creators\": [\"Academic\", \"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 4577.3, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Misc\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"lemma-dataset\", \"Collection\": \"lemma-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2007.15781\", \"Dataset Name\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper Title\": \"LEMMA: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020)\", \"Paper URL\": \"https://arxiv.org/abs/2007.15781\", \"GitHub URL\": \"https://github.com/Buzz-Beater/LEMMA\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/lemma\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.15781\", \"Semantic Scholar Corpus ID\": 220634784, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\", \"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 10.8, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\", \"human\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"violin\", \"Collection\": \"violin\", \"Collection URL\": \"https://arxiv.org/abs/2003.11618\", \"Dataset Name\": \"VIOLIN\", \"Paper Title\": \"VIOLIN\", \"Paper URL\": \"https://arxiv.org/abs/2003.11618\", \"GitHub URL\": \"https://github.com/jimmy646/violin\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/violin\", \"ArXiv URL\": \"https://arxiv.org/abs/2003.11618\", \"Semantic Scholar Corpus ID\": 214668012, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 582.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"tiny-virat\", \"Collection\": \"tiny-virat\", \"Collection URL\": \"https://arxiv.org/abs/2007.07355\", \"Dataset Name\": \"TinyVIRAT: Low-resolution Video Action Recognition\", \"Paper Title\": \"TinyVIRAT: Low-resolution Video Action Recognition\", \"Paper URL\": \"https://arxiv.org/abs/2007.07355\", \"GitHub URL\": \"https://github.com/UgurDemir/Tiny-VIRAT\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/tinyvirat\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.07355\", \"Semantic Scholar Corpus ID\": 220525685, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 10.83, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"movie-net\", \"Collection\": \"movie-net\", \"Collection URL\": \"https://arxiv.org/abs/2007.10937\", \"Dataset Name\": \"MovieNet\", \"Paper Title\": \"MovieNet\", \"Paper URL\": \"https://arxiv.org/abs/2007.10937\", \"GitHub URL\": \"https://github.com/movienet/movienet-tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/movienet\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.10937\", \"Semantic Scholar Corpus ID\": 220665753, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Video Summarization\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"movie-net\", \"Collection\": \"movie-net\", \"Collection URL\": \"https://arxiv.org/abs/2007.10937\", \"Dataset Name\": \"MovieNet\", \"Paper Title\": \"MovieNet\", \"Paper URL\": \"https://arxiv.org/abs/2007.10937\", \"GitHub URL\": \"https://github.com/movienet/movienet-tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/movienet\", \"ArXiv URL\": \"https://arxiv.org/abs/2007.10937\", \"Semantic Scholar Corpus ID\": 220665753, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3000.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Misc\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"kinetics-700\", \"Collection\": \"kinetics-700\", \"Collection URL\": \"https://arxiv.org/pdf/2010.10864.pdf\", \"Dataset Name\": \"Kinetics-700\", \"Paper Title\": \"Kinetics-700\", \"Paper URL\": \"https://arxiv.org/pdf/2010.10864.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/kinetics-700\", \"ArXiv URL\": \"https://arxiv.org/pdf/2010.10864.pdf\", \"Semantic Scholar Corpus ID\": 196831809, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1805.56, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"titan\", \"Collection\": \"titan\", \"Collection URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf\", \"Dataset Name\": \"TITAN: Future Forecast using Action Priors (CVPR 2020)\", \"Paper Title\": \"TITAN: Future Forecast using Action Priors (CVPR 2020)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/titan-future-forecast-using-action-priors\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf\", \"Semantic Scholar Corpus ID\": 214727763, \"Year Released\": \"2020\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Non Commercial\", \"License URL\": \"https://usa.honda-ri.com/titan\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 2.91, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"moviescenes\", \"Collection\": \"moviescenes\", \"Collection URL\": \"https://arxiv.org/abs/2004.02678\", \"Dataset Name\": \"MovieScenes\", \"Paper Title\": \"MovieScenes\", \"Paper URL\": \"https://arxiv.org/abs/2004.02678\", \"GitHub URL\": \"https://github.com/AnyiRao/SceneSeg\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/a-local-to-global-approach-to-multi-modal\", \"ArXiv URL\": \"https://arxiv.org/abs/2004.02678\", \"Semantic Scholar Corpus ID\": 214802984, \"Year Released\": \"2020\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\", \"Academic\"], \"Countries\": [\"China\", \"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 250.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Misc\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"oops-dataset\", \"Collection\": \"oops-dataset\", \"Collection URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Epstein_Oops_Predicting_Unintentional_Action_in_Video_CVPR_2020_paper.pdf\", \"Dataset Name\": \"Oops!: Predicting Unintentional Action in Video (CVPR 2020)\", \"Paper Title\": \"Oops!: Predicting Unintentional Action in Video (CVPR 2020)\", \"Paper URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Epstein_Oops_Predicting_Unintentional_Action_in_Video_CVPR_2020_paper.pdf\", \"GitHub URL\": \"https://github.com/cvlab-columbia/oops\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/oops-predicting-unintentional-action-in-video\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Epstein_Oops_Predicting_Unintentional_Action_in_Video_CVPR_2020_paper.pdf\", \"Semantic Scholar Corpus ID\": 208291335, \"Year Released\": \"2020\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC-SA 4.0\", \"License URL\": \"https://oops.cs.columbia.edu/data/\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 50.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 1, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 1, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"rare-act-dataset\", \"Collection\": \"rare-act-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Dataset Name\": \"RareAct: A video dataset of unusual interactions\", \"Paper Title\": \"RareAct: A video dataset of unusual interactions\", \"Paper URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"GitHub URL\": \"https://github.com/antoine77340/RareAct\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/rareact\", \"ArXiv URL\": \"https://arxiv.org/pdf/2008.01018.pdf\", \"Semantic Scholar Corpus ID\": 220936243, \"Year Released\": \"2020\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\", \"Academic\", \"Research Group\", \"Other\", \"Academic\"], \"Countries\": [\"United Kingdom\", \"France\", \"Czech Republic\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 21.13, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"videolt-dataset\", \"Collection\": \"videolt-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2105.02668\", \"Dataset Name\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper Title\": \"VideoLT: Large-scale Long-tailed Video Recognition\", \"Paper URL\": \"https://arxiv.org/abs/2105.02668\", \"GitHub URL\": \"https://github.com/17Skye17/VideoLT\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/videolt\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.02668\", \"Semantic Scholar Corpus ID\": 233864776, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Non Commercial\", \"License URL\": \"https://github.com/17Skye17/VideoLT?tab=readme-ov-file#data-preparation\"}], \"Creators\": [\"Academic\", \"Research Group\", \"Other\", \"Academic\"], \"Countries\": [\"China\", \"UAE\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13664.96, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"uav-human\", \"Collection\": \"uav-human\", \"Collection URL\": \"https://arxiv.org/abs/2104.00946\", \"Dataset Name\": \"UAV-Human: A Large Benchmark for Human Behavior Understanding with Unmanned Aerial Vehicles\", \"Paper Title\": \"UAV-Human: A Large Benchmark for Human Behavior Understanding with Unmanned Aerial Vehicles\", \"Paper URL\": \"https://arxiv.org/abs/2104.00946\", \"GitHub URL\": \"https://github.com/sutdcv/UAV-Human\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/uav-human-a-large-benchmark-for-human\", \"ArXiv URL\": \"https://arxiv.org/abs/2104.00946\", \"Semantic Scholar Corpus ID\": 233004700, \"Year Released\": \"2021\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://sutdcv.github.io/uav-human-web/\"}], \"Creators\": [\"Academic\", \"Academic\"], \"Countries\": [\"Singapore\", \"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 18.34, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"homage\", \"Collection\": \"homage\", \"Collection URL\": \"https://arxiv.org/abs/2105.05226\", \"Dataset Name\": \"HOMAGE: Home Action Genome: Cooperative Compositional Action Understanding (CVPR 2021)\", \"Paper Title\": \"HOMAGE: Home Action Genome: Cooperative Compositional Action Understanding (CVPR 2021)\", \"Paper URL\": \"https://arxiv.org/abs/2105.05226\", \"GitHub URL\": \"https://github.com/nishantrai18/homage\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/home-action-genome-cooperative-compositional\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.05226\", \"Semantic Scholar Corpus ID\": 234357543, \"Year Released\": \"2021\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\", \"Corporation\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 30.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"homage\", \"Collection\": \"homage\", \"Collection URL\": \"https://arxiv.org/abs/2105.05226\", \"Dataset Name\": \"HOMAGE: Home Action Genome: Cooperative Compositional Action Understanding (CVPR 2021)\", \"Paper Title\": \"HOMAGE: Home Action Genome: Cooperative Compositional Action Understanding (CVPR 2021)\", \"Paper URL\": \"https://arxiv.org/abs/2105.05226\", \"GitHub URL\": \"https://github.com/nishantrai18/homage\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/home-action-genome-cooperative-compositional\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.05226\", \"Semantic Scholar Corpus ID\": 234357543, \"Year Released\": \"2021\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\", \"Corporation\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 30.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"YT-Temporal-180m\", \"Collection\": \"YT-Temporal-180m\", \"Collection URL\": \"https://arxiv.org/pdf/2106.02636\", \"Dataset Name\": \"MERLOT: Multimodal Neural Script Knowledge Models\", \"Paper Title\": \"MERLOT: Multimodal Neural Script Knowledge Models\", \"Paper URL\": \"https://arxiv.org/pdf/2106.02636\", \"GitHub URL\": \"https://github.com/rowanz/merlot\", \"Hugging Face URL\": \"https://huggingface.co/datasets/HuggingFaceM4/yttemporal180m\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/merlot-multimodal-neural-script-knowledge\", \"ArXiv URL\": \"https://arxiv.org/pdf/2106.02636\", \"Semantic Scholar Corpus ID\": 235352775, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/rowanz/merlot/blob/main/LICENSE\"}], \"Creators\": [\"Academic\", \"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1515.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Q&A\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"multi-moments-in-time-dataset\", \"Collection\": \"multi-moments-in-time-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Dataset Name\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper Title\": \"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\", \"Paper URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://arxiv.org/pdf/1911.00232.pdf\", \"Semantic Scholar Corpus ID\": 207780280, \"Year Released\": \"2021\", \"Text Sources\": [\"crowdsourced\", \"undisclosed web\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 833.0, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\", \"undisclosed web\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"queryd\", \"Collection\": \"queryd\", \"Collection URL\": \"https://arxiv.org/abs/2011.11071\", \"Dataset Name\": \"QuerYD\", \"Paper Title\": \"QuerYD\", \"Paper URL\": \"https://arxiv.org/abs/2011.11071\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/queryd\", \"ArXiv URL\": \"https://arxiv.org/abs/2011.11071\", \"Semantic Scholar Corpus ID\": 261006321, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"youdescribe\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United Kingdom\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 207.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\", \"youdescribe\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"WebVid\", \"Collection\": \"WebVid\", \"Collection URL\": \"https://arxiv.org/abs/2104.00650\", \"Dataset Name\": \"WebVid\", \"Paper Title\": \"WebVid\", \"Paper URL\": \"https://arxiv.org/abs/2104.00650\", \"GitHub URL\": \"https://github.com/m-bain/webvid\", \"Hugging Face URL\": \"https://huggingface.co/datasets/TempoFunk/webvid-10M\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/webvid\", \"ArXiv URL\": \"https://arxiv.org/abs/2104.00650\", \"Semantic Scholar Corpus ID\": 232478955, \"Year Released\": \"2021\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/m-bain/webvid/blob/main/TERMS.md\"}], \"Creators\": [\"Academic\", \"Academic\"], \"Countries\": [\"United Kingdom\", \"France\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 13000.0, \"Taken Down\": \"True\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"hd-vila-100m\", \"Collection\": \"hd-vila-100m\", \"Collection URL\": \"https://arxiv.org/abs/2111.10337\", \"Dataset Name\": \"Advancing High-Resolution Video-Language Representation with Large-Scale Video Transcriptions\", \"Paper Title\": \"Advancing High-Resolution Video-Language Representation with Large-Scale Video Transcriptions\", \"Paper URL\": \"https://arxiv.org/abs/2111.10337\", \"GitHub URL\": \"https://github.com/microsoft/XPretrain/blob/main/hd-vila-100m/README.md\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/advancing-high-resolution-video-language/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2111.10337\", \"Semantic Scholar Corpus ID\": 244462849, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://github.com/microsoft/XPretrain/blob/main/hd-vila-100m/README.md\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 371.5, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"apes\", \"Collection\": \"apes\", \"Collection URL\": \"https://arxiv.org/pdf/2106.01667\", \"Dataset Name\": \"Apes\", \"Paper Title\": \"Apes\", \"Paper URL\": \"https://arxiv.org/pdf/2106.01667\", \"GitHub URL\": \"https://github.com/fuankarion/audiovisual-person-search\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/apes-audiovisual-person-search-in-untrimmed/review/\", \"ArXiv URL\": \"https://arxiv.org/pdf/2106.01667\", \"Semantic Scholar Corpus ID\": 235313698, \"Year Released\": \"2021\", \"Text Sources\": [\"movies\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\", \"Corporation\", \"Academic\"], \"Countries\": [\"Chile\", \"United States of America\", \"Saudi Arabia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 36.0, \"Taken Down\": \"False\", \"Video Sources\": [\"movies\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"spoken-moments\", \"Collection\": \"spoken-moments\", \"Collection URL\": \"https://arxiv.org/abs/2105.04489\", \"Dataset Name\": \"Spoken Moments\", \"Paper Title\": \"Spoken Moments\", \"Paper URL\": \"https://arxiv.org/abs/2105.04489\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/spoken-moments-learning-joint-audio-visual\", \"ArXiv URL\": \"https://arxiv.org/abs/2105.04489\", \"Semantic Scholar Corpus ID\": 233992735, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdUOScon6uWkslgcA2-BCkAhMp86SihgKtMqX53zRf-E2fIHw/formResponse\"}], \"Creators\": [\"Academic\", \"Corporation\", \"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 416.67, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\", \"flickr\", \"vine\", \"metacafe\", \"peeks\", \"vimeo\", \"videoblocks\", \"bing videos\", \"giphy\", \"weather channel\", \"getty-images\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"mimetics-dataset\", \"Collection\": \"mimetics-dataset\", \"Collection URL\": \"https://arxiv.org/abs/1912.07249\", \"Dataset Name\": \"Mimetics: Towards Understanding Human Actions Out of Context\", \"Paper Title\": \"Mimetics: Towards Understanding Human Actions Out of Context\", \"Paper URL\": \"https://arxiv.org/abs/1912.07249\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/mimetics-towards-understanding-human-actions\", \"ArXiv URL\": \"https://arxiv.org/abs/1912.07249\", \"Semantic Scholar Corpus ID\": 209376248, \"Year Released\": \"2021\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Corporation\"], \"Countries\": [\"South Korea\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 0.99, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"ego-4d\", \"Collection\": \"ego-4d\", \"Collection URL\": \"https://arxiv.org/abs/2110.07058\", \"Dataset Name\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper Title\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper URL\": \"https://arxiv.org/abs/2110.07058\", \"GitHub URL\": \"https://github.com/EGO4D/forecasting\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego4d-around-the-world-in-3000-hours-of\", \"ArXiv URL\": \"https://arxiv.org/abs/2110.07058\", \"Semantic Scholar Corpus ID\": 238856888, \"Year Released\": \"2022\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://ego4d-data.org/pdfs/Ego4D-Licenses-Draft.pdf\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3670.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ego-4d\", \"Collection\": \"ego-4d\", \"Collection URL\": \"https://arxiv.org/abs/2110.07058\", \"Dataset Name\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper Title\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper URL\": \"https://arxiv.org/abs/2110.07058\", \"GitHub URL\": \"https://github.com/EGO4D/forecasting\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego4d-around-the-world-in-3000-hours-of\", \"ArXiv URL\": \"https://arxiv.org/abs/2110.07058\", \"Semantic Scholar Corpus ID\": 238856888, \"Year Released\": \"2022\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://ego4d-data.org/pdfs/Ego4D-Licenses-Draft.pdf\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3670.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ego-4d\", \"Collection\": \"ego-4d\", \"Collection URL\": \"https://arxiv.org/abs/2110.07058\", \"Dataset Name\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper Title\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper URL\": \"https://arxiv.org/abs/2110.07058\", \"GitHub URL\": \"https://github.com/EGO4D/forecasting\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego4d-around-the-world-in-3000-hours-of\", \"ArXiv URL\": \"https://arxiv.org/abs/2110.07058\", \"Semantic Scholar Corpus ID\": 238856888, \"Year Released\": \"2022\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://ego4d-data.org/pdfs/Ego4D-Licenses-Draft.pdf\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3670.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"mad\", \"Collection\": \"mad\", \"Collection URL\": \"https://arxiv.org/abs/2112.00431\", \"Dataset Name\": \"MAD: A Scalable Dataset for Language Grounding in Videos from Movie Audio Descriptions\", \"Paper Title\": \"MAD: A Scalable Dataset for Language Grounding in Videos from Movie Audio Descriptions\", \"Paper URL\": \"https://arxiv.org/abs/2112.00431\", \"GitHub URL\": \"https://github.com/Soldelli/MAD\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/mad\", \"ArXiv URL\": \"https://arxiv.org/abs/2112.00431\", \"Semantic Scholar Corpus ID\": 244773187, \"Year Released\": \"2022\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://docs.google.com/forms/d/e/1FAIpQLSdtUV3uweS0u7AHAMIJAL_dRRdZ5MHpJS3fdZVbhnVt-Yb4NA/viewform\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"Saudi Arabia\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1207.3, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"academic-only\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"academic-only\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"ego-4d\", \"Collection\": \"ego-4d\", \"Collection URL\": \"https://arxiv.org/abs/2110.07058\", \"Dataset Name\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper Title\": \"Ego4D: Around the World in 3,000 Hours of Egocentric Video\", \"Paper URL\": \"https://arxiv.org/abs/2110.07058\", \"GitHub URL\": \"https://github.com/EGO4D/forecasting\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego4d-around-the-world-in-3000-hours-of\", \"ArXiv URL\": \"https://arxiv.org/abs/2110.07058\", \"Semantic Scholar Corpus ID\": 238856888, \"Year Released\": \"2022\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Custom\", \"License URL\": \"https://ego4d-data.org/pdfs/Ego4D-Licenses-Draft.pdf\"}], \"Creators\": [\"Industry Lab\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 3670.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Misc\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ferv39k-dataset\", \"Collection\": \"ferv39k-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2203.09463\", \"Dataset Name\": \"FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos (CVPR 2022)\", \"Paper Title\": \"FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos (CVPR 2022)\", \"Paper URL\": \"https://arxiv.org/abs/2203.09463\", \"GitHub URL\": \"https://github.com/wangyanckxx/FERV39k\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ferv39k-a-large-scale-multi-scene-dataset-for\", \"ArXiv URL\": \"https://arxiv.org/abs/2203.09463\", \"Semantic Scholar Corpus ID\": 247518747, \"Year Released\": \"2022\", \"Text Sources\": [\"undisclosed web\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://wangyanckxx.github.io/Proj_CVPR2022_FERV39k.html\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 16.47, \"Taken Down\": \"False\", \"Video Sources\": [\"undisclosed web\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"YT-Temporal-1B\", \"Collection\": \"YT-Temporal-1B\", \"Collection URL\": \"https://arxiv.org/pdf/2201.02639\", \"Dataset Name\": \"MERLOT Reserve: Multimodal Neural Script Knowledge through Vision and Language and Sound\", \"Paper Title\": \"MERLOT Reserve: Multimodal Neural Script Knowledge through Vision and Language and Sound\", \"Paper URL\": \"https://arxiv.org/pdf/2201.02639\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/merlot-reserve-neural-script-knowledge\", \"ArXiv URL\": \"https://arxiv.org/pdf/2201.02639\", \"Semantic Scholar Corpus ID\": 245837609, \"Year Released\": \"2022\", \"Text Sources\": [\"youtube\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/rowanz/merlot_reserve/blob/main/LICENSE\"}], \"Creators\": [\"Academic\", \"Academic\", \"Academic\"], \"Countries\": [\"United States of America\", \"Scotland\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 55555.0, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\"], \"Task Categories\": \"Video Q&A\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"cacd\", \"Collection\": \"cacd\", \"Collection URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"Dataset Name\": \"CDAD: A Common Daily Action Dataset with Collected Hard Negative Samples (CVPR 2022)\", \"Paper Title\": \"CDAD: A Common Daily Action Dataset with Collected Hard Negative Samples (CVPR 2022)\", \"Paper URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"GitHub URL\": \"https://github.com/MartinXM/CDAD\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"\", \"ArXiv URL\": \"https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Xiang_CDAD_A_Common_Daily_Action_Dataset_With_Collected_Hard_Negative_CVPRW_2022_paper.pdf\", \"Semantic Scholar Corpus ID\": 251035434, \"Year Released\": \"2022\", \"Text Sources\": [\"crowdsourced\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\", \"Corporation\"], \"Countries\": [\"China\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 215.0, \"Taken Down\": \"False\", \"Video Sources\": [\"crowdsourced\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"ego-exo4D\", \"Collection\": \"ego-exo4D\", \"Collection URL\": \"https://arxiv.org/abs/2311.18259\", \"Dataset Name\": \"Ego-Exo4D\", \"Paper Title\": \"Ego-Exo4D\", \"Paper URL\": \"https://arxiv.org/abs/2311.18259\", \"GitHub URL\": \"https://github.com/facebookresearch/Ego4d\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego-exo4d-understanding-skilled-human/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2311.18259\", \"Semantic Scholar Corpus ID\": 265506384, \"Year Released\": \"2023\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/facebookresearch/Ego4d/blob/main/LICENSE\"}], \"Creators\": [\"Corporation\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1422.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"project-aria-digital-twin-dataset\", \"Collection\": \"project-aria-digital-twin-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2306.06362\", \"Dataset Name\": \"Aria Digital Twin\", \"Paper Title\": \"Aria Digital Twin\", \"Paper URL\": \"https://arxiv.org/abs/2306.06362\", \"GitHub URL\": \"https://github.com/facebookresearch/projectaria_tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/aria-digital-twin-a-new-benchmark-dataset-for\", \"ArXiv URL\": \"https://arxiv.org/abs/2306.06362\", \"Semantic Scholar Corpus ID\": 261243365, \"Year Released\": \"2023\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/facebookresearch/projectaria_tools/blob/main/LICENSE\"}], \"Creators\": [\"Corporation\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 6.6, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Segmentation\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ego-exo4D\", \"Collection\": \"ego-exo4D\", \"Collection URL\": \"https://arxiv.org/abs/2311.18259\", \"Dataset Name\": \"Ego-Exo4D\", \"Paper Title\": \"Ego-Exo4D\", \"Paper URL\": \"https://arxiv.org/abs/2311.18259\", \"GitHub URL\": \"https://github.com/facebookresearch/Ego4d\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego-exo4d-understanding-skilled-human/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2311.18259\", \"Semantic Scholar Corpus ID\": 265506384, \"Year Released\": \"2023\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/facebookresearch/Ego4d/blob/main/LICENSE\"}], \"Creators\": [\"Corporation\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1422.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Captioning\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ego-exo4D\", \"Collection\": \"ego-exo4D\", \"Collection URL\": \"https://arxiv.org/abs/2311.18259\", \"Dataset Name\": \"Ego-Exo4D\", \"Paper Title\": \"Ego-Exo4D\", \"Paper URL\": \"https://arxiv.org/abs/2311.18259\", \"GitHub URL\": \"https://github.com/facebookresearch/Ego4d\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego-exo4d-understanding-skilled-human/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2311.18259\", \"Semantic Scholar Corpus ID\": 265506384, \"Year Released\": \"2023\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/facebookresearch/Ego4d/blob/main/LICENSE\"}], \"Creators\": [\"Corporation\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1422.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Misc\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"project-aria-digital-twin-dataset\", \"Collection\": \"project-aria-digital-twin-dataset\", \"Collection URL\": \"https://arxiv.org/abs/2306.06362\", \"Dataset Name\": \"Aria Digital Twin\", \"Paper Title\": \"Aria Digital Twin\", \"Paper URL\": \"https://arxiv.org/abs/2306.06362\", \"GitHub URL\": \"https://github.com/facebookresearch/projectaria_tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/aria-digital-twin-a-new-benchmark-dataset-for\", \"ArXiv URL\": \"https://arxiv.org/abs/2306.06362\", \"Semantic Scholar Corpus ID\": 261243365, \"Year Released\": \"2023\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/facebookresearch/projectaria_tools/blob/main/LICENSE\"}], \"Creators\": [\"Corporation\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 6.6, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"ego-exo4D\", \"Collection\": \"ego-exo4D\", \"Collection URL\": \"https://arxiv.org/abs/2311.18259\", \"Dataset Name\": \"Ego-Exo4D\", \"Paper Title\": \"Ego-Exo4D\", \"Paper URL\": \"https://arxiv.org/abs/2311.18259\", \"GitHub URL\": \"https://github.com/facebookresearch/Ego4d\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/ego-exo4d-understanding-skilled-human/review/\", \"ArXiv URL\": \"https://arxiv.org/abs/2311.18259\", \"Semantic Scholar Corpus ID\": 265506384, \"Year Released\": \"2023\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"MIT License\", \"License URL\": \"https://github.com/facebookresearch/Ego4d/blob/main/LICENSE\"}], \"Creators\": [\"Corporation\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1422.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Classification\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"egopet\", \"Collection\": \"egopet\", \"Collection URL\": \"https://arxiv.org/pdf/2404.09991\", \"Dataset Name\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper Title\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper URL\": \"https://arxiv.org/pdf/2404.09991\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egopet-egomotion-and-interaction-data-from-an\", \"ArXiv URL\": \"https://arxiv.org/pdf/2404.09991\", \"Semantic Scholar Corpus ID\": 269148727, \"Year Released\": \"2024\", \"Text Sources\": [\"tiktok\", \"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://github.com/DannyTran123/egopet/blob/main/LICENSE\"}], \"Creators\": [\"Academic\", \"Academic\", \"Academic\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 84.0, \"Taken Down\": \"False\", \"Video Sources\": [\"tiktok\", \"youtube\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"egoschema\", \"Collection\": \"egoschema\", \"Collection URL\": \"https://arxiv.org/pdf/2308.09126\", \"Dataset Name\": \"EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding\", \"Paper Title\": \"EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding\", \"Paper URL\": \"https://arxiv.org/pdf/2308.09126\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egoschema-a-diagnostic-benchmark-for-very-1\", \"ArXiv URL\": \"https://arxiv.org/pdf/2308.09126\", \"Semantic Scholar Corpus ID\": 261031047, \"Year Released\": \"2024\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Unspecified\", \"License URL\": \"\"}], \"Creators\": [\"Academic\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 250.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Video Q&A\", \"License Use (DataProvenance)\": \"unspecified\", \"License Attribution (DataProvenance)\": 0, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"unspecified\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 0, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Unspecified\"}, {\"Unique Dataset Identifier\": \"project-aria-dataset\", \"Collection\": \"project-aria-dataset\", \"Collection URL\": \"https://arxiv.org/pdf/2402.13349\", \"Dataset Name\": \"Aria Everyday Activities Dataset\", \"Paper Title\": \"Aria Everyday Activities Dataset\", \"Paper URL\": \"https://arxiv.org/pdf/2402.13349\", \"GitHub URL\": \"https://github.com/facebookresearch/projectaria_tools\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/aria-everyday-activities-dataset\", \"ArXiv URL\": \"https://arxiv.org/pdf/2402.13349\", \"Semantic Scholar Corpus ID\": 267770215, \"Year Released\": \"2024\", \"Text Sources\": [\"human\"], \"Licenses\": [{\"License\": \"Apache License 2.0\", \"License URL\": \"https://github.com/facebookresearch/Aria_data_tools/blob/main/LICENSE\"}], \"Creators\": [\"Corporation\"], \"Countries\": [\"United States of America\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 1400.0, \"Taken Down\": \"False\", \"Video Sources\": [\"human\"], \"Task Categories\": \"Misc\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"cinepile\", \"Collection\": \"cinepile\", \"Collection URL\": \"https://arxiv.org/pdf/2405.08813\", \"Dataset Name\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper Title\": \"CinePile: A Long Video Question Answering Dataset and Benchmark\", \"Paper URL\": \"https://arxiv.org/pdf/2405.08813\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"https://huggingface.co/datasets/tomg-group-umd/cinepile\", \"Papers with Code URL\": \"https://paperswithcode.com/dataset/cinepile\", \"ArXiv URL\": \"https://arxiv.org/pdf/2405.08813\", \"Semantic Scholar Corpus ID\": 269761335, \"Year Released\": \"2024\", \"Text Sources\": [\"youtube\", \"movies\"], \"Licenses\": [{\"License\": \"CC BY 4.0\", \"License URL\": \"https://creativecommons.org/licenses/by/4.0/\"}], \"Creators\": [\"Academic\", \"Academic\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 417.6, \"Taken Down\": \"False\", \"Video Sources\": [\"youtube\", \"movies\"], \"Task Categories\": \"Video Q&A\", \"License Use (DataProvenance)\": \"commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Commercial\"}, {\"Unique Dataset Identifier\": \"egopet\", \"Collection\": \"egopet\", \"Collection URL\": \"https://arxiv.org/pdf/2404.09991\", \"Dataset Name\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper Title\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper URL\": \"https://arxiv.org/pdf/2404.09991\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egopet-egomotion-and-interaction-data-from-an\", \"ArXiv URL\": \"https://arxiv.org/pdf/2404.09991\", \"Semantic Scholar Corpus ID\": 269148727, \"Year Released\": \"2024\", \"Text Sources\": [\"tiktok\", \"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://github.com/DannyTran123/egopet/blob/main/LICENSE\"}], \"Creators\": [\"Academic\", \"Academic\", \"Academic\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 84.0, \"Taken Down\": \"False\", \"Video Sources\": [\"tiktok\", \"youtube\"], \"Task Categories\": \"Misc\", \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}, {\"Unique Dataset Identifier\": \"egopet\", \"Collection\": \"egopet\", \"Collection URL\": \"https://arxiv.org/pdf/2404.09991\", \"Dataset Name\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper Title\": \"EgoPet: Egomotion and Interaction Data from an Animal's Perspective\", \"Paper URL\": \"https://arxiv.org/pdf/2404.09991\", \"GitHub URL\": \"\", \"Hugging Face URL\": \"\", \"Papers with Code URL\": \"https://paperswithcode.com/paper/egopet-egomotion-and-interaction-data-from-an\", \"ArXiv URL\": \"https://arxiv.org/pdf/2404.09991\", \"Semantic Scholar Corpus ID\": 269148727, \"Year Released\": \"2024\", \"Text Sources\": [\"tiktok\", \"youtube\"], \"Licenses\": [{\"License\": \"CC BY-NC 4.0\", \"License URL\": \"https://github.com/DannyTran123/egopet/blob/main/LICENSE\"}], \"Creators\": [\"Academic\", \"Academic\", \"Academic\"], \"Countries\": [\"United States of America\", \"Israel\"], \"License Verified By\": \"Vivek Sharma\", \"Video Hours\": 84.0, \"Taken Down\": \"False\", \"Video Sources\": [\"tiktok\", \"youtube\"], \"Task Categories\": \"Other\", \"License Use (DataProvenance)\": \"non-commercial\", \"License Attribution (DataProvenance)\": 1, \"License Share Alike (DataProvenance)\": 0, \"License Use (DataProvenance IgnoreOpenAI)\": \"non-commercial\", \"License Attribution (DataProvenance IgnoreOpenAI)\": 1, \"License Share Alike (DataProvenance IgnoreOpenAI)\": 0, \"License Type\": \"Non-Commercial/Academic\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_taskyear = alt.Chart(\n",
    "    df_videotaskyears\n",
    ").mark_bar().encode(\n",
    "    x=alt.X(\n",
    "        \"Year Released:N\",\n",
    "        title=\"Year Released\",\n",
    "        sort=YEARS_ORDER,\n",
    "        axis=alt.Axis(labelAngle=-30)\n",
    "    ),\n",
    "    y=alt.Y(\n",
    "        \"count():Q\",\n",
    "        stack=\"normalize\",\n",
    "        axis=alt.Axis(format=\"%\"),\n",
    "        title=\"Pct. Datasets\"\n",
    "    ),\n",
    "    color=alt.Color(\n",
    "        \"Task Categories:N\",\n",
    "        title=\"Video Task Categories\"\n",
    "    )\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=160\n",
    ")\n",
    "\n",
    "text_sourceyear = alt.Chart(df_videotaskyears).mark_text(\n",
    "    dy=-90,\n",
    "    align=\"center\",\n",
    "    baseline=\"top\",\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    x=alt.X(\n",
    "        \"Year Released:N\",\n",
    "        title=\"Year Released\",\n",
    "        sort=YEARS_ORDER\n",
    "    ),\n",
    "    text=\"count():Q\"\n",
    ")\n",
    "\n",
    "chart_taskyear = (base_taskyear + text_sourceyear).configure_axis(\n",
    "    labelFontSize=FONT_SIZE,\n",
    "    titleFontSize=FONT_SIZE\n",
    ").configure_legend(\n",
    "    labelFontSize=FONT_SIZE,\n",
    "    titleFontSize=FONT_SIZE,\n",
    "    orient=LEGEND_POSITION,\n",
    "    columns=4,\n",
    "    labelLimit=MAX_LABELLIMIT\n",
    ")\n",
    "\n",
    "\n",
    "if PLOT_TOFILE:\n",
    "    chart_taskyear.save(\n",
    "        os.path.join(PLOT_DIR, \"video_taskcategories-years.png\"),\n",
    "        ppi=PLOT_PPI\n",
    "    )\n",
    "\n",
    "chart_taskyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Category (YouTube or Other) by License Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2104418/2641403864.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_counts_by_license_source = df_video.explode(\"Video Sources\").groupby([\"License Type\", \"Video Sources\"]).size().reset_index(name=\"Count\")\n"
     ]
    }
   ],
   "source": [
    "# By count\n",
    "df_counts_by_license_source = df_video.explode(\"Video Sources\").groupby([\"License Type\", \"Video Sources\"]).size().reset_index(name=\"Count\")\n",
    "df_counts_by_license_source = df_counts_by_license_source.sort_values(by=\"Count\")\n",
    "df_counts_by_license_source[\"YouTube\"] = df_counts_by_license_source[\"Video Sources\"].map(\n",
    "    lambda x: \"YouTube\" if \"youtube\" in x.lower() else \"Other\"\n",
    ")\n",
    "\n",
    "# # By hours\n",
    "# df_hours_by_license_source = df_speech.explode(\"Source\").groupby([\"License Type\", \"Source\"])[\"Hours\"].sum().reset_index(name=\"Total Hours\")\n",
    "# df_hours_by_license_source = df_hours_by_license_source.sort_values(by=\"Total Hours\")\n",
    "# df_hours_by_license_source[\"YouTube\"] = df_hours_by_license_source[\"Source\"].map(\n",
    "#     lambda x: \"YouTube\" if \"youtube\" in x.lower() else \"Other\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creator Categories by Year\n",
    "\n",
    "Note: we use the original annotations here instead of the DPI constants, for a different view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of License Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Custom\n",
       "48       CC BY-NC 4.0\n",
       "52            Various\n",
       "54    CC BY-NC-SA 4.0\n",
       "56     Non Commercial\n",
       "           ...       \n",
       "11          CC BY 4.0\n",
       "45        MIT License\n",
       "74          CC BY 4.0\n",
       "13             Custom\n",
       "31             Custom\n",
       "Name: Licenses, Length: 99, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video['Licenses'].apply(lambda x: [item['License'] for item in x][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Pct.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Licenses</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unspecified</th>\n",
       "      <td>38</td>\n",
       "      <td>38.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>27</td>\n",
       "      <td>27.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC BY 4.0</th>\n",
       "      <td>9</td>\n",
       "      <td>9.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIT License</th>\n",
       "      <td>8</td>\n",
       "      <td>8.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC BY-NC 4.0</th>\n",
       "      <td>5</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apache License 2.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC BY-NC-SA 4.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC BY 3.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non Commercial</th>\n",
       "      <td>2</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Various</th>\n",
       "      <td>1</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSD 2-Clause License</th>\n",
       "      <td>1</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Count   Pct.\n",
       "Licenses                          \n",
       "Unspecified              38  38.38\n",
       "Custom                   27  27.27\n",
       "CC BY 4.0                 9   9.09\n",
       "MIT License               8   8.08\n",
       "CC BY-NC 4.0              5   5.05\n",
       "Apache License 2.0        3   3.03\n",
       "CC BY-NC-SA 4.0           3   3.03\n",
       "CC BY 3.0                 2   2.02\n",
       "Non Commercial            2   2.02\n",
       "Various                   1   1.01\n",
       "BSD 2-Clause License      1   1.01"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "licensetype_counts = df_video[\"Licenses\"].value_counts()\n",
    "licensetype_counts = df_video['Licenses'].apply(lambda x: [item['License'] for item in x][0]).value_counts()\n",
    "df_licensetypes = pd.concat([\n",
    "    licensetype_counts,\n",
    "    (licensetype_counts / licensetype_counts.sum()).round(4) * 100\n",
    "], axis=1)\n",
    "\n",
    "df_licensetypes.columns = [\"Count\", \"Pct.\"]\n",
    "\n",
    "df_licensetypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Task Categories by Licence Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Youtuve to Licence Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2104418/859477006.py:6: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_youtube = df_video.groupby([\"License Type\", \"YouTube\"]).size().reset_index(name=\"Count\")\n",
      "/tmp/ipykernel_2104418/859477006.py:8: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_youtube[\"Pct.\"] = df_youtube.groupby(\"License Type\")[\"Count\"].transform(lambda x: (x / x.sum()).round(4) * 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>License Type</th>\n",
       "      <th>YouTube</th>\n",
       "      <th>Count</th>\n",
       "      <th>Pct.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-Commercial/Academic</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>13</td>\n",
       "      <td>41.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unspecified</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>13</td>\n",
       "      <td>34.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Commercial</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>13</td>\n",
       "      <td>43.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Commercial</td>\n",
       "      <td>Other</td>\n",
       "      <td>17</td>\n",
       "      <td>56.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Non-Commercial/Academic</td>\n",
       "      <td>Other</td>\n",
       "      <td>18</td>\n",
       "      <td>58.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Other</td>\n",
       "      <td>25</td>\n",
       "      <td>65.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              License Type  YouTube  Count   Pct.\n",
       "1  Non-Commercial/Academic  YouTube     13  41.94\n",
       "3              Unspecified  YouTube     13  34.21\n",
       "5               Commercial  YouTube     13  43.33\n",
       "4               Commercial    Other     17  56.67\n",
       "0  Non-Commercial/Academic    Other     18  58.06\n",
       "2              Unspecified    Other     25  65.79"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By count\n",
    "df_video[\"YouTube\"] = df_video[\"Video Sources\"].map(\n",
    "    lambda x: \"YouTube\" if any(\"youtube\" in xi.lower() for xi in x) else \"Other\"\n",
    ")\n",
    "\n",
    "df_youtube = df_video.groupby([\"License Type\", \"YouTube\"]).size().reset_index(name=\"Count\")\n",
    "df_youtube = df_youtube.sort_values(by=\"Count\")\n",
    "df_youtube[\"Pct.\"] = df_youtube.groupby(\"License Type\")[\"Count\"].transform(lambda x: (x / x.sum()).round(4) * 100)\n",
    "\n",
    "df_youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Hours by Licence Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2104418/192219567.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_youtubehours = df_video.groupby([\"License Type\", \"YouTube\"])[\"Video Hours\"].sum().reset_index(name=\"Total Hours\")\n",
      "/tmp/ipykernel_2104418/192219567.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_youtubehours[\"Pct.\"] = df_youtubehours.groupby(\"License Type\")[\"Total Hours\"].transform(lambda x: (x / x.sum()).round(4) * 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>License Type</th>\n",
       "      <th>YouTube</th>\n",
       "      <th>Total Hours</th>\n",
       "      <th>Pct.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Other</td>\n",
       "      <td>8380.77</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Commercial</td>\n",
       "      <td>Other</td>\n",
       "      <td>9847.75</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Non-Commercial/Academic</td>\n",
       "      <td>Other</td>\n",
       "      <td>16920.19</td>\n",
       "      <td>12.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-Commercial/Academic</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>121946.43</td>\n",
       "      <td>87.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Commercial</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>184436.86</td>\n",
       "      <td>94.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unspecified</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>490965.17</td>\n",
       "      <td>98.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              License Type  YouTube  Total Hours   Pct.\n",
       "2              Unspecified    Other      8380.77   1.68\n",
       "4               Commercial    Other      9847.75   5.07\n",
       "0  Non-Commercial/Academic    Other     16920.19  12.18\n",
       "1  Non-Commercial/Academic  YouTube    121946.43  87.82\n",
       "5               Commercial  YouTube    184436.86  94.93\n",
       "3              Unspecified  YouTube    490965.17  98.32"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By hours\n",
    "df_youtubehours = df_video.groupby([\"License Type\", \"YouTube\"])[\"Video Hours\"].sum().reset_index(name=\"Total Hours\")\n",
    "df_youtubehours = df_youtubehours.sort_values(by=\"Total Hours\")\n",
    "df_youtubehours[\"Pct.\"] = df_youtubehours.groupby(\"License Type\")[\"Total Hours\"].transform(lambda x: (x / x.sum()).round(4) * 100)\n",
    "\n",
    "df_youtubehours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tables of Creator Categories (By Count and Hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Creators</th>\n",
       "      <th>Count</th>\n",
       "      <th>Pct.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Academic</td>\n",
       "      <td>132</td>\n",
       "      <td>69.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Corporation</td>\n",
       "      <td>20</td>\n",
       "      <td>10.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Government</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Industry Lab</td>\n",
       "      <td>17</td>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Other</td>\n",
       "      <td>6</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Research Group</td>\n",
       "      <td>12</td>\n",
       "      <td>6.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Startup</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Creators  Count   Pct.\n",
       "0        Academic    132  69.84\n",
       "1     Corporation     20  10.58\n",
       "2      Government      1   0.53\n",
       "3    Industry Lab     17   8.99\n",
       "4           Other      6   3.17\n",
       "5  Research Group     12   6.35\n",
       "6         Startup      1   0.53"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_creatorcategories = df_video.explode(\"Creators\").groupby(\"Creators\").size().reset_index(name=\"Count\")\n",
    "df_creatorcategories[\"Pct.\"] = df_creatorcategories[\"Count\"].transform(lambda x: (x / x.sum()).round(4) * 100)\n",
    "\n",
    "df_creatorcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Creators</th>\n",
       "      <th>Video Hours</th>\n",
       "      <th>Pct.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Academic</td>\n",
       "      <td>1057588.71</td>\n",
       "      <td>58.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Corporation</td>\n",
       "      <td>6518.77</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Government</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Industry Lab</td>\n",
       "      <td>359428.15</td>\n",
       "      <td>19.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Other</td>\n",
       "      <td>149003.99</td>\n",
       "      <td>8.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Research Group</td>\n",
       "      <td>149517.24</td>\n",
       "      <td>8.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Startup</td>\n",
       "      <td>96166.67</td>\n",
       "      <td>5.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Creators  Video Hours   Pct.\n",
       "0        Academic   1057588.71  58.13\n",
       "1     Corporation      6518.77   0.36\n",
       "2      Government      1000.00   0.05\n",
       "3    Industry Lab    359428.15  19.76\n",
       "4           Other    149003.99   8.19\n",
       "5  Research Group    149517.24   8.22\n",
       "6         Startup     96166.67   5.29"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_creatorcategories = df_video.explode(\"Creators\").groupby(\"Creators\")[\"Video Hours\"].sum().reset_index(name=\"Video Hours\")\n",
    "df_creatorcategories[\"Pct.\"] = df_creatorcategories[\"Video Hours\"].transform(lambda x: (x / x.sum()).round(4) * 100)\n",
    "df_creatorcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Sources</th>\n",
       "      <th>Total Hours</th>\n",
       "      <th>Pct.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Prohibited</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tiktok</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tumblr</td>\n",
       "      <td>86.1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>youdescribe</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bbc</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Video Sources  Total Hours  Pct.\n",
       "0   Not Prohibited         38.5  0.00\n",
       "15          tiktok         84.0  0.01\n",
       "16          tumblr         86.1  0.01\n",
       "22     youdescribe        207.0  0.02\n",
       "1              bbc       1000.0  0.11"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do video hours vs. video source categories\n",
    "df_videohours = df_video.explode(\"Video Sources\")\n",
    "df_videohours = df_videohours.groupby(\"Video Sources\")[\"Video Hours\"].sum().reset_index(name=\"Total Hours\")\n",
    "df_videohours = df_videohours.sort_values(by=\"Total Hours\")\n",
    "df_videohours[\"Pct.\"] = df_videohours[\"Total Hours\"].transform(lambda x: (x / x.sum()).round(4) * 100)\n",
    "df_videohours.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
